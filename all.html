
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  邪逍遥
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="历经千重罪，练就不死心">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="邪逍遥" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">邪逍遥</a></h1>
  
    <h2>历经千重罪，练就不死心</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15454660806753.html">深度学习中的正则化-Dropout方法</a></h1>
			<p class="meta"><time datetime="2018-12-22T16:08:00+08:00" 
			pubdate data-updated="true">2018/12/22</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p><strong>Dropout</strong>提供了正则化一大类模型的方法，计算方便但功能强大。但训练一个深层神经网络时，我们可以随机丢弃一部分神经元（同时丢弃其对应的连接边）来避免过拟合，这种方法称为<strong>丢弃法（Dropout Method）</strong>。每次选择丢弃的神经元是随机的。最简单的方法是设置一个固定的概率 \(p\)。对每一个神经元都一个概率 \(p\) 来判定要不要保留。对于一个神经层 \(\mathbf f = f(W\mathbf x + b)\)，我们可以引入一个丢弃函数 \(d(\cdot)\) 使得 \(\mathbf y = f(Wd(\mathbf x) + b)\)。丢弃函数 \(d(\cdot)\) 的定义为<br/>
\[<br/>
\begin{align*}<br/>
d(\mathbf x) = \left \{ \begin{array} \\ \mathbf m \odot \mathbf x &amp;\qquad \text{当训练阶段时}\\ p\mathbf x &amp;\qquad \text{当测试阶段时} \\ \end{array} \right .<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\mathbf m\in \{0,1\}^d\) 是丢弃掩码，通过以概率为 \(p\) 的贝努力分布随机生成。\(p\) 可以通过验证集来选取一个最优的值。或者 \(p\) 也可以设为 0.5，这对大部分的网络和任务比较有效。在训练时，这会造成训练和测试时的网络输出不一致。为了缓解这个问题，在测试时需要将每一个神经元的输出乘以 \(p\)，也相当于把不同的神经网络做了平均。</p>

<p>下图给出了一个网络应用 dropout 方法后的示例。</p>

<div align="center">
    <img width="460" src="media/15454660806753/15472819545032.jpg" />
</div>

<p>一般来讲，对于隐藏层的神经元，其丢弃率 \(p=0.5\) 时效果最好。当 \(p=0.5\) 时，在训练时有一半的神经元被丢弃，只剩余一半的神经元是可以激活的，随机生成的网络结果最具多样性。对于输入层的神经元，其丢弃率通常设为更接近1的数，使得输入变化不会变化太大。对输入层神经元进行丢弃时，相当于给数据增加噪声，以此来提高网络的鲁棒性。</p>

<p>丢弃法一般是针对神经元进行随机丢弃，但是也可以扩展到对神经元之间的连接进行随机丢弃，或每一层进行随机丢弃。</p>

<p><strong>集成学习的解释</strong>：每做一次丢弃，相当于从原始的网络采样得到一个子网络。如果一个神经网络有 \(n\) 个神经元，那么总共可以采样出 \(2^n\) 个子网络。每次迭代都相当于训练一个不同的子网络，这些子网络都可以共享原始网络的参数。那么最终的网络可以近似看作为集成了指数级个不同网络的组合模型。</p>

<p><strong>贝叶斯学习的解释</strong>：丢弃法也可以解释为一种贝叶斯学习的近似。用 \(y=f(\mathbf x,\theta)\) 来表示要学习的神经网络，贝叶斯学习是假设参数 \(\theta\) 为随机向量，并且先验分布为 \(q(\theta)\)，贝叶斯方法的预测为<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E_{q(\theta)}[y] &amp;= \int_q f(\mathbf x,\theta) q(\theta) d\theta \\<br/>
&amp;\approx \frac 1 M \sum_{m=1}^M f(\mathbf x,\theta_m)<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(f(\mathbf x,\theta_m)\) 为第 \(m\) 次应用丢弃方法后的网络，其参数 \(\theta_m\) 为对全部参数 \(\theta\) 的一次采样。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15446218642343.html">图像相似度方法</a></h1>
			<p class="meta"><time datetime="2018-12-12T21:37:44+08:00" 
			pubdate data-updated="true">2018/12/12</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>实现图片相似度的方法有很多，其中平均哈希（aHash），感知哈希（pHash），差异值哈希（dHash）最是常见。</p>

<h3 id="toc_0">平均哈希</h3>

<p>一张图片就是一个二维信号，它包含了不同频率的成分。亮度变化小的区域是低频成分，它描述大范围的信息。而亮度变化剧烈的区域（比如物体的边缘）就是高频的成分，它描述具体的细节。或者说高频可以提供图片详细的信息，而低频可以提供一个框架。 而一张大的，详细的图片有很高的频率，而小图片缺乏图像细节，所以都是低频的。所以我们平时的下采样，也就是缩小图片的过程，实际上是损失高频信息的过程。均值哈希算法就是利用图片的低频信息。</p>

<p>平均哈希的步骤如下：</p>

<ol>
<li>缩小尺寸：去除高频和细节的最快方法是缩小图片，将图片缩小到8x8的尺寸，总共64个像素。不要保持纵横比，只需将其变成8*8的正方形。这样就可以比较任意大小的图片，摒弃不同尺寸、比例带来的图片差异。</li>
<li>简化色彩：将8*8的小图片转换成灰度图像。</li>
<li>计算平均值：计算所有64个像素的灰度平均值。</li>
<li>比较像素的灰度：将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。</li>
<li>计算hash值：将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。(我设置的是从左到右，从上到下用二进制保存)。</li>
</ol>

<p>计算一个图片的hash指纹的过程就是这么简单。如果图片放大或缩小，或改变纵横比，结果值也不会改变。增加或减少亮度或对比度，或改变颜色，对hash值都不会太大的影响。最大的优点：计算速度快！这时候，比较两个图片的相似性，就是先计算这两张图片的hash指纹，也就是64位0或1值，然后计算不同位的个数(汉明距离)。如果这个值为0，则表示这两张图片非常相似，如果汉明距离小于5，则表示有些不同，但比较相近，如果汉明距离大于10则表明完全不同的图片。</p>

<p>缺点：对均值敏感，例如对图像进行伽马校正或直方图均衡就会影响均值，从而影响最终的hash值。</p>

<h3 id="toc_1">感知哈希</h3>

<p>均值哈希虽然简单，但受均值的影响非常大。例如对图像进行伽马校正或直方图均衡就会影响均值，从而影响最终的hash值。存在一个更健壮的算法叫pHash。它将均值的方法发挥到极致。使用离散余弦变换(DCT)来获取图片的低频成分。</p>

<h4 id="toc_2">离散余弦变换 DCT</h4>

<p>图像的离散余弦变换广泛用于图像的压缩。对原始图像进行离散余弦变换，变换后DCT系数能量主要集中在左上角，其余大部分系数接近于零，DCT具有适用于图像压缩的特性。将变换后的DCT系数进行门限操作，将小于一定值得系数归零，这就是图像压缩中的量化过程，然后进行逆DCT运算，可以得到压缩后的图像。</p>

<h5 id="toc_3">离散余弦变换的原理</h5>

<p>一维DCT变换时二维DCT变换的基础，所以我们先来讨论下一维DCT变换。一维DCT变换共有8种形式，其中最常用的是第二种形式，由于其运算简单、适用范围广。我们在这里只讨论这种形式，其表达式如下：</p>

<p>\[<br/>
\begin{align*}<br/>
F(u) = C(u)\sum_{x=0}^{N-1} f(u) \cos\Big( \frac{u\pi(2x+1)}{2N} \Big)<br/>
\end{align*}<br/>
\]</p>

<p>其中<br/>
\[<br/>
C(u) = \left \{ \begin{array}\\\sqrt{\frac{1}{N}},\qquad &amp;u=0\\\sqrt{\frac{2}{N}},&amp;u\neq 0\\\end{array}\right .<br/>
\]</p>

<p>其中，\(f(u)\) 表示原始信号，\(F(u)\) 表示DCT变换后的系数，\(N\) 为原始信号的点数，\(C(u)\) 可以认为是补偿系数，可以使DCT变换矩阵为正交矩阵。</p>

<p>二维离散余弦变换其实就是在一维变换的基础上再做了一次变换，公式为： <br/>
\[<br/>
\begin{align*}<br/>
F(u,v) = \frac 1 N C(u) C(v) \sum_{x=0}^{N-1} \sum_{y=0}^{N-1} f(x,y) \cos\Big( \frac{u\pi(2x+1)}{2N}\Big) \cos\Big(\frac{v\pi(2y+1)}{2N}\Big)<br/>
\end{align*}<br/>
\]</p>

<p>在图像的压缩码中，\(N\) 一般为8，另外由于DCT变换高度的对称性，因此我们可以使用更简单的矩阵处理方式：<br/>
\[<br/>
\begin{align*}<br/>
F &amp;= AfA^T\\<br/>
A(i,j) &amp;= C(i) \cos\Big(\frac{i\pi(2j + 1)}{2N}\Big)<br/>
\end{align*}<br/>
\]</p>

<p>二维DCT逆变换公式为：<br/>
\[<br/>
\begin{align*}<br/>
f(x,y) = \frac 1 N \sum_{x=0}^{N-1} \sum_{y=0}^{N-1} C(u) C(v) F(u,v) \cos\Big(\frac{u\pi(2x+1)}{2N}\Big) \cos\Big(\frac{v\pi(2y+1)}{2N}\Big)<br/>
\end{align*}<br/>
\]</p>

<p>上式的各项系数分别为：<br/>
\[<br/>
C(u),C(v) = \left \{ \begin{array}\\ \frac{1}{\sqrt{N}} &amp;\qquad \text{if u,v = 0}\\ \sqrt{\frac{2}{N}} &amp; \qquad \text{otherwise} \\ \end{array} \right .<br/>
\]</p>

<p>同样的道理，我们利用之前的矩阵运算公式可以推导出DCT反变换相应的矩阵形式：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\quad F = AfA^T\\<br/>
&amp;\because A^{-1} = A^T\\<br/>
&amp;\therefore f = A^{-1} F(A^T)^{-1} = A^T F A\\<br/>
\end{align*}<br/>
\]</p>

<p>现在再来看 pHash，它先将图像从像素域变换到频率域。然后一般图像都存在很多冗余和相关性的，所以转换到频率域之后，只有很少的一部分频率分量的系数才不为0，大部分系数都为0（或者说接近于0）。经过DCT变换后的系数矩阵从左上角到右下角频率越来越高，因此图片的能量主要保留在左上角的低频系数上了。</p>

<h4 id="toc_4">pHash 具体步骤</h4>

<ol>
<li>缩小尺寸：pHash以小图片开始，但图片大于8*8，32*32是最好的。这样做的目的是简化了DCT的计算，而不是减小频率。</li>
<li>简化色彩：将图片转化成灰度图像，进一步简化计算量。</li>
<li>计算DCT：计算图片的DCT变换，得到32*32的DCT系数矩阵。</li>
<li>缩小DCT：虽然DCT的结果是32*32大小的矩阵，但我们只要保留左上角的8*8的矩阵，这部分呈现了图片中的最低频率。</li>
<li>计算平均值：如同均值哈希一样，计算DCT的均值。</li>
<li>计算hash值：这是最主要的一步，根据8*8的DCT矩阵，设置0或1的64位的hash值，大于等于DCT均值的设为1，小于DCT均值的设为0。组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。</li>
</ol>

<p>分析： 结果并不能告诉我们真实性的低频率，只能粗略地告诉我们相对于平均值频率的相对比例。只要图片的整体结构保持不变，hash结果值就不变。能够避免伽马校正或颜色直方图被调整带来的影响。对于变形程度在25%以内的图片也能精准识别。</p>

<h3 id="toc_5">差值哈希算法</h3>

<p>比pHash，dHash的速度要快的多，相比aHash，dHash在效率几乎相同的情况下的效果要更好，它是基于渐变实现的。主要步骤：</p>

<ol>
<li>缩小尺寸：收缩到8*9（高宽）的大小，一遍它有72的像素点</li>
<li>转化为灰度图：把缩放后的图片转化为256阶的灰度图。</li>
<li>计算差异值：dHash算法工作在相邻像素之间，这样每行9个像素之间产生了8个不同的差异，一共8行，则产生了64个差异值</li>
<li>获得指纹：如果左边的像素比右边的更亮，则记录为1，否则为0.</li>
</ol>

<hr/>

<p><a href="https://blog.csdn.net/chenghaoy/article/details/83271885">哈希算法-图片相似度计算</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15436296136092.html">蒙特卡罗树搜搜 MCTS</a></h1>
			<p class="meta"><time datetime="2018-12-01T10:00:13+08:00" 
			pubdate data-updated="true">2018/12/1</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>蒙特卡罗树搜索全称 Monte Carlo Tree Search，是一种人工智能问题中做出最优决策的方法，一般是在组合博弈中的行动（move）规划形式。它结合了随机模拟的一般性和树搜索的准确性。</p>

<p>MCTS 受到快速关注主要是由计算机围棋程序的成功以及其潜在的在众多难题上的应用所致。超越博弈游戏本身，MCTS 理论上可以被用在以 {状态 state，行动 action} 对定义和用模拟进行预测输出结果的任何领域。</p>

<h3 id="toc_0">蒙特卡罗树</h3>

<p>关于蒙特卡罗树搜索，有个常见的错误认知，在此先纠正。在棋类博弈中，很多年前出现的是蒙特卡罗方法，就是随机游走，然后看哪里的胜率最高。但是这里有个问题：</p>

<ol>
<li>如果走在A，人有100种应对，其中99种，电脑会立刻赢，其中只有1种电脑会立刻输。</li>
<li>如果走在B，人有100中应对，但局势很复杂，随机走下去，双方赢的概率都是50%。</li>
</ol>

<p>如果使用蒙特卡罗方法计算胜率，电脑会发现走在A的胜率是99%，走在B的胜率是50%。可是，电脑的正解应该是B，因为如果走了A，人如果足够聪明，就一定会走电脑立刻输的棋着。</p>

<p>蒙特卡罗树搜索是博弈树和蒙特卡罗方法的结合，它不会犯A和B的错误，它很快就会发现B比A好。容易证明，如果给定足够的计算时间和足够的存储空间，蒙特卡罗树搜索可以收敛到完美的博弈树。</p>

<p>树的搜索算法很多，如果树的层数比较浅，我们可以穷举计算每一个节点输赢的概率，那么可以使用一种最简单的策略，叫做minmax算法。基本思路是，从树的叶子节点开始看，如果是本节点就选择max的，如果是对方回合就选min，实际上这也是假设对方是聪明的也会使用minmax算法，这样在博弈论里面就达到一个纳什均衡点。</p>

<p>这是搜索空间比较小的策略，MCTS要解决的是搜索空间足够大，不能计算得到所有子树的价值，这是需要一种较为高效的搜索策略，同事也得兼顾探索和利用，避免陷入局部最优解。MCTS实现这些特性的方式有很较多中，例如经典的UCB（Upper Confidence Bounds）算法，就是选择子节点的时候优先考虑没有探索过的，如果都探索过的就根据得分来选择，得分不仅是由这个子节点最终赢的概率来，而是根据这个节点玩的次数成负相关，也就是说这个子节点如果平均得分高就会被选中的概率高，同时如果子节点选中次数较多则下次不太会被选中（因为其他选择次数少的更值得探索），因此MCTS根据配置探索和利用不同的权重，可以实现比随机或者其他策略更有启发式的方法。</p>

<p>前面提到的MCTS的使用场景需要是搜索空间巨大，因为搜索空间如果在计算能力以内，其实是没有必要使用MCTS的，而真正地应用上还需要其他的假设。涉及到博弈论的概率，我们要求场景必须是能分出输赢（zero-sum）、游戏信息完全公开的（fully information）、确定的（每一个操作结果没有随机因素）（determinism）、顺序的（操作都是按顺序执行）（sequential）、离散的（discrete），除了博弈论我们还要求场景是类似多臂老虎机的黑盒环境，不能通过求导或者凸优化方法来找到最优解，否则MCTS也是没有意义的。在蒙特卡罗搜索之前，没有先要有下面的理论基础。</p>

<h3 id="toc_1">Game theory 基础</h3>

<p>Game theory 中文名称是博弈论，是研究多个玩家在相互交互中取胜的方法。先看几个博弈论中的概念。</p>

<h4 id="toc_2">零和（zero-sum）</h4>

<p>零和就是所有玩家的权益之和为零，如果我赢你就是输，没有双赢或双输的出现，也不考虑合作等因素的出现。</p>

<h4 id="toc_3">纳什均衡</h4>

<p>所有玩家都选择对自己而言的最优解并且自己单方面做其他选择也无法再提高的点。也就是说，如果玩家都是高手，能达到或逼近纳什均衡的策略就是最优策略，如果对手不是高手不会选择最优策略，那么纳什均衡点不一定保证每局都赢，但长远看来极大概率会赢这样的新手。</p>

<h4 id="toc_4">信息对称（fully information）</h4>

<p>游戏中所有的信息和状态对所有玩家都是可见的，不存在只有自己可以观察到的状态，一次双方的游戏策略只需要关注共同的状态即可。</p>

<h3 id="toc_5">Black box optimazation 基础</h3>

<p>黑盒优化（Black box optimization）就是根据给定的数据集找到更好的选择，但是我们使用的学习算法如SVM、DNN都不是黑盒，它们是根据数学公式推导通过函数求导等方式进行的优化。如果我们能把问题描述成一个函数或凸优化问题，那么我们通过数学上的求导就可以得到最优解，这类问题并不需要用到MCTS等搜索算法，但实际上很多问题例如围棋等就无法找到一个描述输赢的函数曲线，这样就无法通过纯数学的方法解决。</p>

<p>这类问题统称为黑盒优化问题，我们不能假设知道这个场景内部的函数或者模型结构，只能通过给定模型输入得到模型输出结果来优化。例如多臂老虎机（Multi-arm Bandit）问题，我们有多台老虎机可以投币，但不知道每一台输赢的概率，只能通过多次投币来测试，根据观察的结果预估每台机器的收益分布，最终选择认为收益最大的，这种方法一般会比随机方法效果好。</p>

<p>黑盒优化的算法也有很多，例如进化算法、贝叶斯优化、MCTS也算是，而这些算法都需要解决如何权衡探索和利用（Exploration and Exploitation）的问题。如果我们只有一个投币，那么当前会选择期望收益最高的老虎机来投（Exploitation），但如果我们有一万个投币，我们不应该只投一个老虎机，而应该用少量币来探索一下其他老虎机（Exploration），说不定能跳过局部最优解找到更优解，当然我们也不能全部投币都用来探索了。</p>

<h3 id="toc_6">UCB算法基础</h3>

<p>算法本身很简单，公式如下：<br/>
\[<br/>
\arg\max_{v&#39;\in children\text{ }of\text{ }v} \frac{Q(v&#39;)}{N(v&#39;)} + c\sqrt{\frac{2\ln N(v)}{N(v&#39;)}}<br/>
\]</p>

<p>其中 \(v&#39;\) 表示当前树节点，\(v\) 表示父节点，Q表示这个树节点累积的quality值，\(N\) 表示这个树节点visit次数，\(C\) 是一个常量（控制exploitation和exploration权重）。</p>

<p>这个公式的意思时，由两部分组成，左边是这个节点的平均收益值（越高表示这个节点期望收益好，越值得选择，用于exploitation），右边的变量是这个父节点的总访问次数除以子节点的访问次数（如果子节点访问次数越少则值越大，越值得选择，用户exploration），因此使用这个公式是可以兼顾探索和利用的。</p>

<h3 id="toc_7">MCTS算法原理</h3>

<p>MCTS的算法分为四步，第一步是Selection，就是在树中找到一个最好的值得探索的节点，一般策略是先选择未被探索的子节点，如果都探索过就选择UCB值最大的子节点。第二步是Expansion，在前面选中的子节点中走一步创建一个新的子节点，一般策略是随机执行一个操作并且这个操作不能与前面的子节点重复。第三步是Simulation，在前面Expansion选出来的节点开始模拟游戏，知道到达游戏结算状态，这样可以收到这个expansion出来的节点的得分。第四步是Backpropagation，就是把前面expansion出来的节点得分反馈到前面所有父节点中，更新这些节点的quality value和visit times，方便后面计算UCB。</p>

<p>基本思路就是这样的，通过不断的模拟得到大部分节点的UCB值，然后下次模拟的时候根据UCB值有策略得选择值得利用和值得探索的节点继续模拟，在搜索空间巨大并且计算能力有限的情况下，这种启发式搜索能更集中地、更大概率找到一些更好的节点。下面是论文的伪代码实现。</p>

<div align="center">
    <img width="360" src="media/15436296136092/15461567273020.jpg" />
</div>

<hr/>

<p><a href="https://zhuanlan.zhihu.com/p/24801451">28天自制你的 Alpha Go（1）</a><br/>
<a href="https://zhuanlan.zhihu.com/p/30458774">如何学习蒙特卡罗树搜索（MCTS）</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15424711438602.html">人工神经网络-GAN</a></h1>
			<p class="meta"><time datetime="2018-11-18T00:12:23+08:00" 
			pubdate data-updated="true">2018/11/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>生成式对抗网络 GAN（Generative adversarial networks）是 Goodfellow 等在2014年提出的一种生成式模型。GAN 在结构上受博弈论中的二人零和博弈（即二人的利益之和为零，一方的所得正是另一方的所失）的启发，系统由一个生成器 \(G\) 和一个判别器 \(D\) 构成。</p>

<p>GAN 的核心思想来源于博弈论的纳什均衡。它设定参与游戏双方分别为一个生成器（Generator）和一个判别器（Discriminator），生成器的目的是尽量去学习真实的数据分布，而判别器的目的是尽量正确输入数据是来自真实数据还是来自生成器；为了取得游戏胜利，这两个游戏参与者需要不断优化，各自提高自己的生成能力和判别能力，这个学习优化过程就是寻找二者之间的一个纳什均衡。</p>

<p>这里以生成图片为例进行说明，假设我们有两个网络，\(G\)和\(D\)。正如它们的名字所暗示的那样，它们的功能分别是：</p>

<ol>
<li>\(G\) 是一个生成图片的网络，它接受一个随机的噪声 \(z\)，通过这个噪声生成图片，记做 \(G(z)\)。</li>
<li>\(D\) 是一个判别图片的网络，判别一张图片是不是“真实的”。它的输入参数是 \(x\),\(x\) 代表一张图片，输出为 \(D(x)\) 代表 \(x\) 为真实图片的概率，如果为1，就代表 100%是真实的图片，而输出为0，就代表不可能是真实的图片。</li>
</ol>

<p>在训练过程中，生成网络 \(G\) 的目标就是尽量生成真实的图片去欺骗判别网络 \(D\)。而 \(D\) 的目标就是尽量把 \(G\) 生成的图片和真实的图片分别开来。这样，\(G\) 和 \(D\) 构成了一个动态的“博弈过程”。</p>

<p>最后博弈的结果是在最理想的状态下，\(G\)可以生成足以“以假乱真”的图片 \(G(z)\)。对于 \(D\) 来说，它难以判定 \(G\) 生成的图片究竟是不是真实的，因此 \(D(G(z)) = 0.5\)。</p>

<p>这样，我们的目的就达到了，我们得到了衣蛾生成式的模型 \(G\)，可以用来生成图片。</p>

<div align="center">
    <img src="media/15424711438602/15457475619356.jpg" width="680" />
</div>

<p>训练两个模型的方法：<strong>单独交替迭代训练</strong></p>

<p><strong>判别模型</strong>：希望真样本集尽可能输出1，假样本集输出。因此对于判别网络，问题可以转换为一个<strong>有监督的二分类问题</strong>，直接送到神经网络模型中训练就好。</p>

<p><strong>生成网络</strong>：我们的目的是生成尽可能逼真的样本。那么需要将原始的生成网络生成的样本送到判别网络中，所以在训练生成网络的时候，我们需要联合判别网络一起才能达到训练的目的。我们可以将判别网络串接在生成网络的后面，这样便可以知道生成网络生成的样本的误差，有了误差我们便可以对判别-生成网络进行训练。</p>

<p>现在我们再来看一下训练方式，首先我们有原始的噪音数组 \(Z\)，也就是我们生成了假样本，现在很关键的一点，我们要把这些假样本的标签都设置为1，也就是认为这些假样本在生成网络训练的时候是真样本。这样能起到迷惑判别器的目的，也才能使得生成的假样本逐渐逼近正样本。现在对于生成网络的训练，我们有了样本集（只有假样本集，没有真样本集），有了对应的label（全为1），在训练过程中，<strong>判别网络的网络参数不发生变化</strong>，只需要将误差一直传到生成网络那一块更新生成网络的参数。这样就完成了生成网络的训练。</p>

<p>在完成生成网络的训练后，我们可以根据目前新的生成网络再对先前的噪声 \(z\) 生成新的假样本，这时候生成的假样本应该更真了。有了新的真假样本的集，就又可以重复上述过程，我们把这个过程称为单独交替训练。我们可以定义一个迭代次数，交替迭代到一定次数后即可停止。这时候，噪声 \(z\) 生成的假样本已经很真了。</p>

<h3 id="toc_0">GAN 的学习方法</h3>

<p>首先我们直接给出原始论文中的目标公式：<br/>
\[<br/>
\min_G \max_D V(D,G) = E_{x \sim \text{data}(x)} [ \log(D(x)) ] + E_{z\sim p_z(z)}[\log(1 - D(G(z))) ]<br/>
\]</p>

<p>这是一个极大极小优化问题，其实对应的就是上述的两个优化过程，对比我们的分析流程，先优化 \(D\)，再优化 \(G\)，本质上是两个优化问题，上式可以拆解为下面两个公式：</p>

<p>优化 D ：<br/>
\[<br/>
\max_D V(D,G) = E_{x\sim p_{data}(x)}[\log(D(x))] + E_{z\sim p_z(z)}[\log( 1 - D(G(z))]<br/>
\]</p>

<p>优化 G ：<br/>
\[<br/>
\min_G V(D,G) = E_{z\sim p_z(z)} [\log(1 - D(G(z))]<br/>
\]</p>

<p>可以看到，优化 \(D\) 的时候，也就是判别网络，其实没有生成网络什么事，后面的 \(G(z)\) 这里就是相当于已经得到的假样本。优化 \(D\) 的公式的第一项，使得真样本 \(x\) 输入的时候得到的结果越大越好，可以理解，因为需要真样本的预测结果越接近于1判别效果越好。对于假样本，需要优化的结果是 \(D(G(z))\) 越小越好，因为假样本的标签理论是应该是0。所以优化 \(D\) 的第二项，\(1 - D(G(z))\) 也就是越大越好，所以优化 \(D\) 取得是式子的极大值。</p>

<p>同理在优化 \(G\) 的时候，这个时候不需要真样本的参与，这个时候把第一项直接去掉，只流向假样本项，因为我们希望能迷惑判别器 \(D\)，也就是希望假样本的标签为1，所以是 \(D(G(z))\) 越大越好，为了统一也就是希望 \(1- D(G(z))\) 越小越好。</p>

<p>这样便得到了之前的极小极大问题，里面包含了生成模型以假乱真的优化和判别模型的优化，完美阐释了这样一个优美的理论。</p>

<p>GAN可以和CNN、RNN结合在一起。任何一个可微分的函数，都可以用来参数化GAN的生成模型和判别模型。那么，在实际中，我们就可以使用深度卷积网络，来参数化生成模型。另外，GAN和RNN结合在一起，用来处理和描述一些连续的序列数据，可以学习到序列数据的分布，同时也可以产生序列数据应用，包括对音乐数据或者是一些自然语言数据的建模和生成。</p>

<hr/>

<p><a href="https://blog.csdn.net/on2way/article/details/72773771">简单理解与实验生成对抗网络GAN</a><br/>
<a href="https://blog.csdn.net/u010834458/article/details/71286376">GAN生成式对抗网络总结</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15418610530072.html">人工神经网络-SOM自组织系统</a></h1>
			<p class="meta"><time datetime="2018-11-10T22:44:13+08:00" 
			pubdate data-updated="true">2018/11/10</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>自组织映射是一个很有趣的竞争性学习系统，其中输出神经元之间竞争激活，结果是在任意时间只有一个神经元被激活。这个激活的神经元被称为胜者神经元（winner-takes-all neuron）。这种竞争可以通过在神经元之间具有横向抑制连接（负反馈路径）来实现。其结果是神经元被迫对自身进行重新组合，这样的网络我们称之为自组织映射（Self Organizing Map，SOM）。</p>

<p>生物学研究表明，在人脑的感觉通道上，神经元的组织原理是有序排列的。当外界的特定信息输入时，大脑皮层的特定区域兴奋，而且类似的外界信息在对应区域是连续映像的。生物视网膜中有许多特定细胞对特定的图形比较敏感，当视网膜中有若干个接受单元同时受特定模式刺激时，就使大脑皮层中的特定神经元开始兴奋，输入模式越近，与之对应的兴奋神经元也接近；在听觉通道上，神经元在结构排列上与频率的关系十分密切，对于某个频率，特定的神经元具有最大的响应，位置相邻的神经元具有相近的频率特征，而远离的神经元具有的频率特征差别也较大。大脑皮层中神经元的这种响应特点不是先天安排好的，而是后天的学习自组织形成的。</p>

<h3 id="toc_0">自组织神经网络</h3>

<p>自组织神经网络是无导师学习网络。它通过自动寻找样本的内在规律和本质属性，自组织、自适应地改变网络参数与结构。层次性结构，具有竞争层。如下图所示：</p>

<div align="center">
    <img src="media/15418610530072/15458312665496.jpg" width="400" />
</div>

<p>a. 输入层：接受外界信息，将输入模式向竞争层传递，起“观察”作用。 <br/>
b. 竞争层：负责对输入模式进行“分析比较”，寻找规律，并归类。</p>

<p>在SOM中，一层是输入层，一层是竞争层，又称为输出层和核心层。在一次输入中，权值是随机给定的，在捐赠层，每一个神经元获胜的概率是相同的，但是最后会有一个兴奋最强的神经元。兴奋最强的神经元战胜了其他神经元，在权值调整过程中，兴奋得到进一步加强，而其他神经元保持不变，竞争神经网络通过这种方式获取训练样本的分布信息，每一个训练样本对应一个兴奋的竞争层神经元，也就是对应一个类别。当有新样本输入时，就可以根据兴奋的神经元进行模式分类。</p>

<p>当有一个新样本输入时，要进行相似性测量，神经网络的输入模式向量的相似性测量可用向量之间的距离来衡量。常用的方法有欧氏距离法和余弦法两种。</p>

<h4 id="toc_1">欧式距离法</h4>

<p>设 \(X\)、\(X_1\) 为两行向量，其间的欧式距离：<br/>
\[<br/>
d = || X - X_i || = \sqrt{(X-X_i)(X-X_i)^T}<br/>
\]</p>

<p>\(d\) 越小，\(X\) 与 \(X_i\) 越接近，两者越相似，当 \(d=0\) 时，\(X=X_i\)  以 \(d=T\)（常数）为判据，可对输入向量模式进行聚类分析：由于 \(d_{12}\)、\(d_{23}\)、\(d_{31}\) 均小于 \(T\)，\(d_{45}\)、\(d_{56}\)、\(d_{46}\) 均小于 \(T\) ,而 \(d_{1i} \gt T(i=4,5,6)\)；\(d_{2i}\gt T(i=4,5,6)\) ,\(d_{3i}\gt T(i=4,5,6)\),故将输入模式 \(X_i\) 按如下分类：</p>

<div align="center">
    <img width="360" src="media/15418610530072/15458363067627.jpg" />
</div>

<h4 id="toc_2">余弦法</h4>

<p>计算两个向量夹角的余弦：<br/>
\[<br/>
\cos \psi = \frac{X^T X_i}{||X||\text{ }||X_i||}<br/>
\]</p>

<p>两个模式向量越接近，其夹角越小，余弦越大。如果对同一类内各个模式向量间的夹角做出规定，不允许超过某一最大角，最这个最大夹角就成为一种聚类判据。同模式向量的夹角小于此最大角，不同模式类的夹角大于此最大角。余弦法适合模式向量长度相同或者模式特征只与向量相关的相似性测量。</p>

<div align="center">
    <img width="360" src="media/15418610530072/15458372832995.jpg" />
</div>

<p>很容易证明，当图中 \(\mathbf X\) 与 \(\mathbf X_i\) 的模为1的单位向量时（其实不一定要1,，只要是常数就行），余弦相似度也就退化成了内积计算：<br/>
\[<br/>
\cos \psi(\mathbf X,\mathbf X_i) = \frac{\mathbf X^T \mathbf X_i}{||\mathbf X||\text{ }||\mathbf X_i||} = \mathbf X^T \mathbf X_i<br/>
\]</p>

<p>此时欧式距离等价于余弦相似度<br/>
\[<br/>
\begin{align*}<br/>
(\mathbf X - \mathbf X_i)^T(\mathbf X - \mathbf X_i) &amp;= \mathbf X^T\mathbf X - 2\mathbf X^T \mathbf X)i + \mathbf X_i^T \mathbf X_i\\<br/>
&amp;= 2 - 2\mathbf X^T \mathbf X_i \\<br/>
&amp;= 2 - 2\cos \psi(\mathbf X,\mathbf X_i)\\<br/>
\end{align*}<br/>
\]</p>

<p>从式子中可以看出，夹角越大，欧式距离的平方就越小。</p>

<h3 id="toc_3">竞争学习规则</h3>

<p>自组织映射中首先对网络权值进行初始化，选择较小的初始值，对向量进行归一化，然后经过三个过程：竞争过程、合作过程和权值调节。<br/>
<strong>竞争过程</strong>：对每个输入信号，网络中的神经元计算他们各自的判别函数的值，判别值最大的特定神经元成为本次的获胜神经元。<br/>
<strong>合作过程</strong>：获胜的神经元决定兴奋神经元的拓扑领域，即获胜神经元周围空间位置内的神经元，提供相邻神经元的合作基础。<br/>
<strong>权值调节</strong>：通过对获胜神经元及其周围的兴奋神经元的权值进行调节，以增加它们对输入信号判别函数值，随着权值的不断调整，获胜神经元对相似的输入信号会有更强的响应，即判别函数的值越大。</p>

<h4 id="toc_4">竞争过程</h4>

<p>假设网络中输入信号（数据）空间的维度为 \(m\)，从中随机选择一个输入信号（向量）记为 \(\mathbf x\)，<br/>
\[<br/>
\mathbf x = \left [ \begin{array}\\ x_1 &amp; x_2 &amp; x_3 &amp; \cdots x_m \\\end{array}\right ]^T<br/>
\]</p>

<p>输出层的每一个神经元与输入层是全连接的结构，所以每个神经元的权值向量和输入空间的维度相同，神经元 \(j\) 的权值向量记为：\(w_j\)，<br/>
\[<br/>
w_j = \left [ \begin{array}\\ w_{j1} &amp; w_{j2} &amp; w_{j3} &amp; \cdots &amp; w_{jm} \\\end{array} \right ]\qquad j = 1,2,3\dots l<br/>
\]</p>

<p>其中 \(l\) 是输出层网络中神经元的总数，竞争过程就是找到与向量 \(\mathbf x\) 最佳匹配的权值向量 \(w_j\)。最佳匹配的意思是：对于 \(j=1,2,3,\dots\)，比较每一个神经元对应的权值与输入向量 \(\mathbf x\) 的内积 \(w_j^T \mathbf x\)，选择最大值，对应的神经元作为获胜神经元。前面已经说过<strong>内积 \(w_j^T\mathbf x\) 最大化，这可以等价于向量 \(\mathbf x\) 与 \(w_j\) 的欧几里得距离最小。</strong></p>

<p>我们定义 \(i(x)\) 标识与向量 \(\mathbf x\) 最佳匹配的神经元，\(i(x)\) 定义为：<br/>
\[<br/>
i(x) = \arg\min || \mathbf x - w_j|| \qquad j = 1,2,3\dots l<br/>
\]</p>

<h4 id="toc_5">合作过程</h4>

<p>在竞争过程中产生的获胜神经元处于兴奋拓扑领域的中心位置。在神经生物学中有证据显示，一个获胜神经元倾向于激活它紧接着的领域内神经元，而不是隔得很远的神经元。所以对于获胜神经元的拓扑领域按照侧向距离光滑地缩减。具体的，用 \(h_{j,i}\) 表示以获胜神经元为中心的拓扑领域且包含这一组兴奋（合作）神经元，\(j\) 表示一个输出神经元，设 \(d(i,j)\) 表示获胜神经元 \(i\) 与兴奋神经元 \(j\) 之间的距离。假设拓扑领域 \(h_{j,i}\) 是一个单峰函数，与 \(d_{i,j}\) 大小有关，获胜神经元与兴奋神经元之间的距离越小，兴奋神经元收到的刺激越大。拓扑领域 \(h_{j,i}\) 也可以表示兴奋神经元受到影响的程度。</p>

<p><strong>单峰函数 \(h_{j,i}\) 满足两个要求</strong>：</p>

<ol>
<li>对于单峰函数 \(h_{j,i}\)，在 \(d_{i,j} = 0\) 处，获胜神经元 \(i\) 达到最大值。</li>
<li>\(h_{j,i}\) 的幅值随距离 \(d_{i,j}\) 的增加而减小，距离趋于无穷大时幅值趋向于0；</li>
</ol>

<p>高斯函数满足这些要求：<br/>
\[<br/>
h_{j,i(x)} = \exp\Big( -\frac{d_{j,i}^2}{2\sigma^2} \Big)<br/>
\]</p>

<p>\(i(x)\) 为获胜神经元的位置（在输出神经元网络中的坐标），\(j\) 是神经元在网络中的位置，\(d_{j,i}^2\) 是其他神经元距离获胜神经元的距离，\(\sigma\) 是拓扑领域的有效宽度，它度量了靠近获胜神经元的兴奋神经元在学习过程中的参与程度，由此可见领域函数依赖于获胜神经元和兴奋神经元在输出空间的位置距离，不依赖于原始输入空间的度量。</p>

<p>在二维网格的情况下<br/>
\[<br/>
d_{i,j}^2 = || r_j - r_i ||<br/>
\]</p>

<p>\(r_j\) 是兴奋神经元在输出网格中的位置向量，\(r_i\) 是获胜神经元在输出网格中的位置向量。</p>

<p>在 SOM网络中海油一个特征就是拓扑领域的大小随着时间收缩，总要求拓扑领域函数 \(h_{i,j}\) 的有效宽度 \(\sigma\) 随时间减小来实现，对于 \(\sigma\) 依赖于时间 \(n\) 流行的选择是：<br/>
\[<br/>
\sigma(n) = \sigma_0 \exp(-\frac{n}{\tau_1}) \qquad n = 1,2,3\dots<br/>
\]</p>

<p>\(\sigma_0\) 是 \(\sigma\) 的初始值，\(\tau_1\) 是一个时间常数；</p>

<p><strong>加入时间依赖的拓扑领域定义为：</strong><br/>
\[<br/>
h_{j,i}(n) = \exp\Big(-\frac{2d_{j,i}^2}{2\sigma(n)^2}\Big) \qquad n = 1,2,3\dots<br/>
\]</p>

<p>在网络进行学习的初始阶段，拓扑领域 \(h_{i,j}\) 应该包含以获胜神经元为中心的所有神经元，然后随着时间 \(n\)（即：迭代次数增加）慢慢收缩，宽度 \(\sigma(n)\) 以指数下滑，拓扑领域也一相应的方式收缩。\(h_{j,i}\) 会减少到仅有围绕获胜神经元的少量邻居神经元或者减少到只剩下获胜神经元。</p>

<p>在网络初始阶段 \(\sigma_0\) 的初始值为输出网格的半径，时间常数为：\(\tau_1 = \frac{1000}{\log(\sigma_0)}\)（1000不是固定的，也可以更大）</p>

<h4 id="toc_6">自适应过程</h4>

<p>自组织网络的神经元的权值 \(w_j\) 随着输入向量 \(\mathbf x\) 的变化而改变。\(n\) 轮的迭代：</p>

<ol>
<li>从训练数据中：随机选择一个向量作为输入向量 \(\mathbf x\)；</li>
<li>竞争过程：确定一个获胜神经元以及神经元在输出网格中的位置向量（拓扑领域的中心位置）；</li>
<li>合作过程：在 \(n\) 时刻确定拓扑领域的有效半径内所有的兴奋神经元，每一轮训练中，拓扑领域 \(h_{j,i}(n)\) 和有效半径（随时间 \(n\) 衰减）。</li>
<li>权值更新：
\[
w_j(n+1) = w_j(n) + \eta(n)(x(n) - w_j(n))\qquad j\in \mathcal A[h_{ji}(n)]
\]</li>
</ol>

<p>其中 \(j\in\mathcal A[h_{ji}(n)]\) 代表在 \(n\) 时刻拓扑领域的有效半径内所有的兴奋神经元（含获胜神经元）\(\eta\)表示学校效率参数，学习效率也是随时间逐渐衰减的：<br/>
\[<br/>
\eta(n) = \eta(0)\exp(-\frac{n}{\tau_2})\qquad n = 1,2,3\dots<br/>
\]</p>

<p>\(\tau_2\) 是另一个时间常数，\(\eta_0\) 是学习效率的初始值，一般设为0.1然后随着时间 \(n\) 递减，但是永远不等于零。</p>

<p>权值更新的公式，实际上是在将获胜神经元和拓扑邻域内的兴奋神经元的权值向量，向输入向量 \(\mathbf x\) 移动，随着训练数据的重复出现，拓扑邻域内的网络权值向量的分布会趋于服从输入向量 \(\mathbf x\) 的分布。网络中的相邻神经元的权值向量会很相似。</p>

<h3 id="toc_7">SOM算法小结</h3>

<p>1．初始化，对初始权值向量 \(w_j\) 选择随机的值初始化，选择较小的权值; <br/>
2．取样，随机从输入空间选取样本 \(\mathbf x\) ; <br/>
3．相似性匹配，在时间 \(n\) 时刻根据最小距离准则找到最佳匹配(获胜神经元) \(i(x)\);<br/>
\[<br/>
i(x)=\arg\min||\mathbf x−w_j||\qquad j\in[1,2,3,\dots,l]<br/>
\]　</p>

<p>4．更新权值，通过更新公式调整所有神经元的权值; <br/>
\[<br/>
w_j(n+1)=w_j(n)+\eta(n)(x(n)−w_j(n))<br/>
\]</p>

<p>5．重复2，3，4步骤，知道特征映射不再发生明显变化为止;</p>

<hr/>

<p><a href="https://blog.csdn.net/u014281392/article/details/76461270">自组织映射网 SOMnet</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15406533448507.html">人工神经网络-长短时记忆网络 GRU</a></h1>
			<p class="meta"><time datetime="2018-10-27T23:15:44+08:00" 
			pubdate data-updated="true">2018/10/27</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	

		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15396209035459.html">矩阵求导</a></h1>
			<p class="meta"><time datetime="2018-10-16T00:28:23+08:00" 
			pubdate data-updated="true">2018/10/16</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>矩阵求导在机器学习中占据了相当的作用，而矩阵求导本身也难以理解。这里我们了解一下矩阵求导与迹的相关知识。</p>

<h4 id="toc_0">基础矩阵知识-迹</h4>

<p>在线性代数中，\(n\times n\) 方阵 \(A\) 的迹，是指 \(A\) 的主对角线各元素的总和（从左上方至右下方的对角线），例如：<br/>
\[<br/>
Tr(A) = A_{11} + A_{22} + \cdots + A_{nn} = \sum_{i=1}^n A_{ii}<br/>
\]</p>

<p>其中 \(A_{ij}\) 代表在 \(i\) 行 \(j\) 栏中的数值。同样的，元素的迹是其特征值的总和，使其不变量根据选择的基本准则而定。</p>

<p>矩阵迹的性质：</p>

<ol>
<li>常数的迹：\(Tr(a) = a\)</li>
<li>加减法：\(Tr(A\pm B) = Tr(A) \pm Tr(B)\)</li>
<li>转置：\(Tr(A^T) = Tr(A)\)</li>
<li>标量乘法：\(Tr(\alpha A) = \alpha Tr(A)\)</li>
<li>向量乘法：\(Tr(AB) = Tr(BA)\)</li>
<li><p>矩阵迹的求导：<br/>
\[<br/>
\nabla_A Tr(AB) = B^T<br/>
\]</p>

<p>证明：假设矩阵 \(A\) 的大小为 \(m\times n\)，矩阵 \(B\) 的大小为 \(n\times m\)，则<br/>
\[<br/>
\begin{align*}<br/>
\because Tr(AB) &amp;= \sum_{i=1}^m\sum_{j=1}^n A_{ij} B_{ji}\\<br/>
\therefore \frac{\partial Tr(AB)}{\partial A} &amp;= \left [ \begin{array}{cccc} \frac{\partial Tr(AB)}{\partial A_{11}} &amp; \frac{\partial Tr(AB)}{\partial A_{12}} &amp; \cdots &amp; \frac{\partial Tr(AB)}{\partial A_{1n}} \\ \frac{\partial Tr(AB)}{\partial A_{21}} &amp; \frac{\partial Tr(AB)}{\partial A_{22}} &amp; \cdots &amp; \frac{\partial Tr(AB)}{\partial A_{2n}} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\  \frac{\partial Tr(AB)}{\partial A_{m1}} &amp; \frac{\partial Tr(AB)}{\partial A_{m2}} &amp; \cdots &amp; \frac{\partial Tr(AB)}{\partial A_{mn}}\end{array} \right ]\\<br/>
&amp;= \left [ \begin{array}{cccc} B_{11} &amp; B_{21} &amp; \cdots &amp; B_{n1}\\ B_{12} &amp; B_{22} &amp;\cdots &amp; B_{n2} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ B_{1m} &amp; B_{2m} &amp; \cdots &amp; B_{nm} \end{array} \right ]\\<br/>
&amp;= B^T<br/>
\end{align*}<br/>
\]</p>

<p>得证。</p></li>
<li><p>\(\nabla_{A^T} f(A) = \big(\nabla_A f(X) \big)^T\)</p></li>
<li><p>\(\nabla_A Tr(ABA^T C) = CAB + C^TAB^T\)<br/>
证明：令 \(u(A) = AB\)，\(v(A^T) = A^T C\)，则<br/>
\[<br/>
\begin{align*}<br/>
\nabla_A Tr(ABA^T C) &amp;= \nabla_A Tr\big(u(A) v(A^T)\big) \\<br/>
&amp;= \nabla_{A:u(A)} Tr\big(u(A) v(A^T)\big) + \nabla_{A:v(A^T)} Tr\big(u(A) v(A^T) \big)\\<br/>
&amp;= \nabla_{A:u(A)} Tr\big(u(A) v(A^T)\big) + \Big(\nabla_{A^T:v(A^T)} Tr\big(u(A) v(A^T) \big)\Big)^T\\<br/>
&amp;= \big(v(A^T)\big)^T \nabla_{A}u(A) + \Big(\big(u(A)\big)^T \nabla_{A^T} v(A^T)\Big)^T\\<br/>
&amp;= C^TAB^T + \big(B^TA^T C^T\big)^T\\<br/>
&amp;= C^TAB^T + CAB<br/>
\end{align*}<br/>
\]</p></li>
<li><p>矩阵逐元素乘法：\(Tr\Big(A^T(B\odot C)\Big) = Tr\Big((A\odot B)^T C\Big)\)</p></li>
</ol>

<h4 id="toc_1">基础矩阵知识-内积</h4>

<p>向量 \(\mathbf x,\mathbf y \in \mathbb R^n\) 的内积定义为<br/>
\[<br/>
&lt;\mathbf x,\mathbf y&gt; = \mathbf x^T \mathbf y = \sum_{i=1}^n x_i y_i = Tr(\mathbf x^T \mathbf y) = Tr(\mathbf y\mathbf x^T)<br/>
\]</p>

<p>矩阵的 \(\mathbf X,\mathbf Y \in \mathbb R^{m\times n}\) 内积定义为<br/>
\[<br/>
&lt;\mathbf X,\mathbf Y&gt; = Tr(\mathbf X^T\mathbf Y) = \sum_{i=1}^m \sum_{j=1}^n X_{ij} Y_{ij}<br/>
\]</p>

<p>利用 Tr 的性质 \(Tr(\mathbf A\mathbf B) = Tr(\mathbf B\mathbf A)\) 和内积的定义，可以知道<br/>
\[<br/>
&lt;\mathbf A\mathbf X\mathbf B,\mathbf C&gt; = &lt;\mathbf X,\mathbf A^T\mathbf C\mathbf B^T&gt;<br/>
\]</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
&lt;\mathbf A\mathbf X\mathbf B,\mathbf C&gt; &amp;= Tr\Big((\mathbf A\mathbf X\mathbf B)^T\mathbf C\Big) \\<br/>
&amp;= Tr(\mathbf B^T\mathbf X^T \mathbf A^T \mathbf C)\\<br/>
&amp;= Tr(\mathbf X^T \mathbf A^T \mathbf C \mathbf B^T)\\<br/>
&amp;= &lt;\mathbf X,\mathbf A^T\mathbf C\mathbf B^T&gt;\\<br/>
\end{align*}<br/>
\]</p>

<h4 id="toc_2">导数与微分的关系</h4>

<p>我们首先来看一下一元函数的导数与微分的联系:\(df = f&#39;(x) dx\)；多元微积分中的梯度（标量对向量的导数）也与微分有联系:<br/>
\[<br/>
df = \sum_{i=1}^n \frac{\partial f}{\partial x_i} dx_i = \frac{\partial f^T}{\partial \mathbf x} d\mathbf x<br/>
\]</p>

<p>这里第一个等号是全微分公式，第二个等号表达了梯度与微分的联系；全微分 \(df\) 是梯度向量 \(\frac{\partial f}{\partial \mathbf x}\quad (n\times 1)\) 与微分向量 \(d\mathbf x\quad (n\times 1)\) 的内积；受此启发，我们将矩阵导数与微分建立联系：<br/>
\[<br/>
df = \sum_{i=1}^m \sum_{j=1}^n \frac{\partial f}{\partial X_{ij}} dX_{ij} = Tr\Big( \frac{\partial f^T}{\partial X} dX\Big)<br/>
\]</p>

<p>其中 \(Tr\) 表示迹（trace）是方阵对角线元素之和，满足性质：对尺寸相同的矩阵A，B，\(Tr(A^TB) = \sum_{i,j} A_{ij} B_{ij}\)，，即 \(\text{tr}(A^TB)\) 是矩阵 \(A,B\) 的内积。与梯度相似，这里第一个等号是全微分公式，第二个等号表达了矩阵导数与微分的联系：全微分 \(df\) 是导数 \(\frac{\partial f}{\partial X}(m\times n)\) 与微分矩阵 \(dX(m\times n)\) 的内积。</p>

<p>我们来创立常用的矩阵微分的运算法则：</p>

<ol>
<li>加减法：\(d(X\pm Y) = dX \pm dY\)；矩阵乘法：\(d(XY) = (dX)Y + X dY\) ；转置：\(d(X^T) = (dX)^T\)；迹：\(d\text{Tr}(X) = \text{Tr}(dX)\)。</li>
<li><p>逆：\(dX^{-1} = -X^{-1}dX X^{-1}\)。此式可在 \(XX^{-1}=I\) 两侧求微分来证明。<br/>
证明：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because \quad XX^{-1} = I \\<br/>
&amp;\therefore \quad d(XX^{-1}) = dXX^{-1} + XdX^{-1} = 0\\<br/>
&amp;\Rightarrow \quad XdX^{-1} = -dXX^{-1} \\<br/>
&amp;\Rightarrow \quad dX^{-1} = -X^{-1}dXX^{-1}\\<br/>
\end{align*}<br/>
\]</p></li>
<li><p>行列式：\(d|X| = \text{tr}(X^{\#}dX)\) ，其中 \(X^{\#}\) 表示 \(X\) 的伴随矩阵，在 \(X\) 可逆时又可以写作 \(d|X|= |X|\text{tr}(X^{-1}dX)\)。</p></li>
<li><p>逐元素乘法：\(d(X\odot Y) = dX\odot Y + X\odot dY\)，\(\odot\) 表示尺寸相同的矩阵 \(X,Y\) 逐元素相乘。</p></li>
<li><p>逐元素函数：\(d\sigma(X) = \sigma&#39;(X)\odot dX\) ，\(\sigma(X) = \left[\sigma(X_{ij})\right]\) 是逐元素标量函数运算， \(\sigma&#39;(X)=[\sigma&#39;(X_{ij})]\) 是逐元素求导数。举个例子，<br/>
\[<br/>
X=\left[\begin{matrix}x_{11} &amp; x_{12} \\ x_{21} &amp; x_{22}\end{matrix}\right], d \sin(X) = \left[\begin{matrix}\cos x_{11} dx_{11} &amp; \cos x_{12} d x_{12}\\ \cos x_{21} d x_{21}&amp; \cos x_{22} dx_{22}\end{matrix}\right] = \cos(X)\odot dX<br/>
\]</p></li>
</ol>

<p>在建立法则的最后，来谈一谈复合：假设已求得 \(\frac{\partial f}{\partial Y}\) ，而 \(Y\) 是 \(X\) 的函数，如何求 \(\frac{\partial f}{\partial X}\) 呢？在微积分中有标量求导的链式法则 \(\frac{\partial f}{\partial x} = \frac{\partial f}{\partial y} \frac{\partial y}{\partial x}\)，但这里我们不能沿用链式法则，因为矩阵对矩阵的导数 \(\frac{\partial Y}{\partial X}\) 截至目前仍是未定义的。于是我们继续追本溯源，链式法则是从何而来？源头仍然是微分。我们直接从微分入手建立复合法则：先写出 \(df = \text{tr}\left(\frac{\partial f}{\partial Y}^T dY\right)\)，再将 \(dY\) 用 \(dX\) 表示出来代入，并使用迹技巧将其他项交换至 \(dX\) 左侧，即可得到 \(\frac{\partial f}{\partial X}\)。</p>

<p>接下来演示一些算例。特别提醒要依据已经建立的运算法则来计算，不能随意套用微积分中标量导数的结论，比如认为 \(AX\) 对 \(X\) 的导数为 \(A\)，这是没有根据、意义不明的。</p>

<p>例1：\(f = \boldsymbol{a}^T X\boldsymbol{b}\)，求 \(\frac{\partial f}{\partial X}\)。其中 \(\boldsymbol{a}\) 是 \(m\times 1\) 列向量，\(X\) 是 \(m\times n\) 矩阵，\(\boldsymbol{b}\) 是 \(n\times 1\) 列向量，\(f\) 是标量。</p>

<p>解：先使用矩阵乘法法则求微分，这里的 \(\boldsymbol{a}\), \(\boldsymbol{b}\) 是常量，\(d\boldsymbol{a} = \boldsymbol{0}\), \(d\boldsymbol{b} = \boldsymbol{0}\)，得到：\(df = \boldsymbol{a}^T dX\boldsymbol{b}\)，再套上迹并做矩阵乘法交换：<br/>
\[<br/>
df = \text{tr}(\boldsymbol{a}^TdX\boldsymbol{b}) = \text{tr}(\boldsymbol{b}\boldsymbol{a}^TdX)<br/>
\]</p>

<p>对照导数与微分的联系 \(df = \text{tr}\left(\frac{\partial f}{\partial X}^T dX\right)\)，得到 \(\frac{\partial f}{\partial X} = (\boldsymbol{b}\boldsymbol{a}^T)^T= \boldsymbol{a}\boldsymbol{b}^T\)。</p>

<p>例2：\(f = \boldsymbol{a}^T \exp(X\boldsymbol{b})\)，求 \(\frac{\partial f}{\partial X}\)。其中\(\boldsymbol{a}\) 是 \(m\times 1\) 列向量，\(X\) 是 \(m\times n\) 矩阵，\(\boldsymbol{b}\) 是 \(n\times 1\) 列向量，\(f\) 是标量。</p>

<p>解：先使用矩阵乘法、逐元素函数法则求微分：\(df = \boldsymbol{a}^T(\exp(X\boldsymbol{b})\odot (dX\boldsymbol{b}))\)，再套上迹并做交换：<br/>
\[<br/>
\begin{align*}<br/>
df &amp;= \text{tr}( \boldsymbol{a}^T(\exp(X\boldsymbol{b})\odot (dX\boldsymbol{b}))) \\<br/>
&amp;=\text{tr}((\boldsymbol{a}\odot \exp(X\boldsymbol{b}))^TdX \boldsymbol{b}) \\<br/>
&amp;= \text{tr}(\boldsymbol{b}(\boldsymbol{a}\odot \exp(X\boldsymbol{b}))^TdX)<br/>
\end{align*}<br/>
\]</p>

<p>对照导数与微分的联系 \(df = \text{tr}\left(\frac{\partial f}{\partial X}^T dX\right)\)，得到 <br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial f}{\partial X} &amp;= (\boldsymbol{b}(\boldsymbol{a}\odot \exp(X\boldsymbol{b}))^T)^T \\<br/>
&amp;= (\boldsymbol{a}\odot \exp(X\boldsymbol{b}))\boldsymbol{b}^T\\<br/>
\end{align*}<br/>
\]</p>

<p>例3：\(f = \text{Tr}(Y^T M Y)\), \(Y = \sigma(WX)\)，求 \(\frac{\partial f}{\partial X}\)。其中 \(W\) 是 \(l\times m\) 矩阵，\(X\) 是 \(m\times n\) 矩阵，\(Y\) 是 \(l\times n\) 矩阵，\(M\) 是 \(l\times l\) 对称矩阵，\(\sigma\) 是逐元素函数，\(f\) 是标量。<br/>
解：先求 \(\frac{\partial y}{\partial Y}\)，用矩阵乘法和转置法则：<br/>
\[<br/>
\begin{align*}<br/>
\because f &amp;= \text{Tr}(Y^T M Y)\\<br/>
\Rightarrow df &amp;= d\text{Tr}(Y^T M Y) = \text{Tr}(d(Y^TMY))\\<br/>
&amp;= \text{Tr}((dY)^TMY) + \text{Tr}(Y^TMdY)\\<br/>
&amp;= \text{Tr}(Y^TM^TdY) + \text{Tr}(Y^TMdY)\qquad \because \text{M是对称矩阵}\\<br/>
&amp;= 2\text{Tr}(Y^TMdY)<br/>
\end{align*}<br/>
\]</p>

<p>对照微分和导数的关系 \(df = \text{Tr}\Big (\frac{\partial f^T}{\partial Y} dY\Big)\)，所以有：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial f}{\partial Y} = (2 Y^T M)^T = 2MY<br/>
\end{align*}<br/>
\]</p>

<p>现在再来看 \(Y = \sigma(WX)\)，可知：\(dY = \sigma&#39;(WX)\odot (WdX)\)，代入 \(df\)，得：<br/>
\[<br/>
\begin{align*}<br/>
df &amp;= \text{Tr}\Big(\frac{\partial f^T}{\partial Y}\big(\sigma&#39;(WX)\odot (WdX)\big)\Big)\\<br/>
&amp;= \text{Tr}\Big(\big(\frac{\partial f}{\partial Y} \odot \sigma&#39;(WX)\big )^T WdX \Big) \\<br/>
\end{align*}<br/>
\]</p>

<p>对照导数与微分的联系，得到<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial f}{\partial X} &amp;= \Big(\big(\frac{\partial f}{\partial Y} \odot \sigma&#39;(WX)\big )^T W \Big)^T\\<br/>
&amp;= W^T \big(\frac{\partial f}{\partial Y} \odot \sigma&#39;(WX)\big )\\<br/>
&amp;= W^T \big(2MY\odot \sigma&#39;(WX)\big)\\<br/>
&amp;= W^T \big(2M\sigma(WX)\odot \sigma&#39;(WX)\big) \\<br/>
\end{align*}<br/>
\]</p>

<p>例4【线性回归】：\(l = \|X\boldsymbol{w}- \boldsymbol{y}\|^2\)， 求\(\boldsymbol{w}\) 的最小二乘估计，即求 \(\frac{\partial l}{\partial \boldsymbol{w}}\) 的零点。其中 \(\boldsymbol{y}\) 是 \(m\times 1\) 列向量，\(X\) 是 \(m\times n\) 矩阵，\(\boldsymbol{w}\) 是 \(n×1\) 列向量，\(l\) 是标量。<br/>
解：关于 \(l\) 的模的平方可以写为向量与自身的内积，即<br/>
\[<br/>
l = (X\boldsymbol{w} - \boldsymbol{y})^T(X\boldsymbol{w} - \boldsymbol{y})<br/>
\]</p>

<p>所以，它的微分为<br/>
\[<br/>
\begin{align*}<br/>
dl &amp;= \big(d(X\boldsymbol{w} - \boldsymbol{y})^T\big)(X\boldsymbol{w} - \boldsymbol{y})+ (X\boldsymbol w - \boldsymbol y)^T d(X\boldsymbol w - \boldsymbol x)\\<br/>
&amp;= (Xd\boldsymbol w)^T(X\boldsymbol{w} - \boldsymbol{y}) + (X\boldsymbol w - \boldsymbol y)^T(Xd\boldsymbol w)\\<br/>
&amp;= \big((X\boldsymbol w - \boldsymbol y)^T(Xd\boldsymbol w)\big)^T + (X\boldsymbol w - \boldsymbol y)^T(Xd\boldsymbol w)\\<br/>
\because \quad &amp; (X\boldsymbol w - \boldsymbol x) \in \mathcal A_{m\times 1}\qquad (Xd\boldsymbol w)\in \mathcal A_{m\times 1}\\<br/>
\therefore \quad &amp; (X\boldsymbol w - \boldsymbol y)^T(Xd\boldsymbol w) \in \mathcal A_{1\times 1}\\<br/>
dl &amp;= 2(X\boldsymbol w - \boldsymbol y)^T(Xd\boldsymbol w)<br/>
\end{align*}<br/>
\]</p>

<p>按照微分和导数的关系：<br/>
\[<br/>
\begin{align*}<br/>
dl &amp;= Tr\big(\frac{\partial f^T}{\partial \boldsymbol w} d\boldsymbol w\big)\\<br/>
\end{align*}<br/>
\]</p>

<p>可知：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial f}{\partial \boldsymbol w} &amp; = \big( 2(X\boldsymbol w - \boldsymbol y)^T X\big)^T\\<br/>
&amp;= 2X^T(X\boldsymbol w - \boldsymbol y)<br/>
\end{align*}<br/>
\]</p>

<p>\(\frac{\partial l}{\partial \boldsymbol{w}}\) 的零点即\(\boldsymbol{w}\) 的最小二乘估计为 \(\boldsymbol{w} = (X^TX)^{-1}X^T\boldsymbol{y}\)</p>

<p>例5【方差的最大似然估计】：样本 \(\boldsymbol{x}_1,\dots, \boldsymbol{x}_N \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma)\)，求方差 \(\Sigma\) 的最大似然估计。写成数学式是：\(l = \log|\Sigma|+\frac{1}{N}\sum_{i=1}^N(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})\)，求 \(\frac{\partial l }{\partial \Sigma}\) 的零点。其中 \(\boldsymbol{x}_i\) 是 \(m\times 1\) 列向量，\(\bar{\boldsymbol{x}}=\frac{1}{N}\sum_{i=1}^N \boldsymbol{x}_i\) 是样本均值，\(\Sigma\) 是 \(m\times m\) 对称正定矩阵，\(l\) 是标量，\(<br/>
\log\)表示自然对数。<br/>
解：首先求微分，使用矩阵乘法、行列式、逆等运算法则，第一项是：<br/>
\[<br/>
\begin{align*}<br/>
d\log|\Sigma| &amp;= |\Sigma|^{-1} \odot d|\Sigma|\\<br/>
&amp;= |\Sigma|^{-1} \odot \Big(|\Sigma|\text{Tr}(\Sigma^{-1} d\Sigma)\Big)\\<br/>
&amp;= \text{Tr}(\Sigma^{-1} d\Sigma) \qquad \because \text{Tr(*) is Scalar}<br/>
\end{align*}<br/>
\]</p>

<p>再来看第二项，<br/>
\[<br/>
\begin{align*}<br/>
d \Big(\frac{1}{N}\sum_{i=1}^N(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})\Big) &amp;= \frac 1 N \sum_{i=1}^N(\boldsymbol x_i - \boldsymbol{\bar{x}})^T d(\Sigma^{-1}) (\boldsymbol x_i - \boldsymbol{\bar{x}})\\<br/>
&amp;= -\frac 1 N \sum_{i=1}^N(\boldsymbol x_i - \boldsymbol{\bar{x}})^T \Sigma^{-1} d\Sigma \Sigma^{-1}) (\boldsymbol x_i - \boldsymbol{\bar{x}})\\<br/>
\end{align*}<br/>
\]</p>

<p>给第二项套上迹然后做交换：<br/>
\[<br/>
\begin{align*}<br/>
\text{Tr}\Big(-\frac 1 N \sum_{i=1}^N(\boldsymbol x_i - \boldsymbol{\bar{x}})^T \Sigma^{-1} d\Sigma \Sigma^{-1}) (\boldsymbol x_i - \boldsymbol{\bar{x}})\Big) &amp;= -\frac 1 N \sum_{i=1}^N \text{Tr}\Big((\boldsymbol x_i - \boldsymbol{\bar{x}})^T \Sigma^{-1}d\Sigma\Sigma^{-1} (\boldsymbol x_i - \boldsymbol{\bar{x}})\Big)\\<br/>
&amp;= -\frac 1 N \sum_{i=1}^N \text{Tr}\Big(\Sigma^{-1} (\boldsymbol x_i - \boldsymbol{\bar{x}})(\boldsymbol x_i - \boldsymbol{\bar{x}})^T \Sigma^{-1}d\Sigma\Big)\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(S = \frac1 N \sum{i=1}^N (\boldsymbol x_i - \boldsymbol{\bar{x}})(\boldsymbol x_i - \boldsymbol{\bar{x}})^T\)，所以第二项可以写为：\(-\text{Tr}\Big(\Sigma^{-1} S \Sigma^{-1}d\Sigma\Big)\)，结合第一项得到：<br/>
\[<br/>
\begin{align*}<br/>
dl &amp;= \text{Tr}(\Sigma^{-1} d\Sigma) - \text{Tr}\big(\Sigma^{-1} S \Sigma^{-1}d\Sigma\big) \\<br/>
&amp;= \text{Tr}\Big(\big(\Sigma^{-1} - \Sigma^{-1} S \Sigma^{-1} \big)d\Sigma\Big)\\<br/>
\end{align*}<br/>
\]</p>

<p>对照微分与导数的关系：<br/>
\[<br/>
dl = \text{Tr}\Big(\frac{\partial l^T}{\partial \Sigma} d\Sigma \Big)<br/>
\]</p>

<p>可知<br/>
\[<br/>
\frac{\partial l}{\partial \Sigma} = \big(\Sigma^{-1} - \Sigma^{-1} S \Sigma^{-1} \big)^T<br/>
\]</p>

<p>其零点也就是 \(S = \Sigma\) 的时候。</p>

<p>例6【多元logistic回归】：\(l = -\boldsymbol{y}^T\log\text{softmax}(W\boldsymbol{x})\)，求 \(\frac{\partial l}{\partial W}\)。其中\(\boldsymbol{y}\) 是除一个元素为1外其它元素为0的 \(m\times 1\) 列向量，\(W\) 是 \(m\times n\) 矩阵，\(\boldsymbol{x}\) 是 \(n\times 1\) 列向量，\(l\) 是标量；\(\log\) 表示自然对数，\(\text{softmax}(\boldsymbol{a}) = \frac{\exp(\boldsymbol{a})}{\boldsymbol{1}^T\exp(\boldsymbol{a})}\)，其中 \(\exp(\boldsymbol{a})\) 表示逐元素求指数，\(\boldsymbol{1}\) 代表全1向量。<br/>
解1：首先将 softmax 代入 \(l\) 中，得：<br/>
\[<br/>
\begin{align*}<br/>
l &amp;= -\boldsymbol{y}^T\log \frac{\exp(W\boldsymbol{x})}{\boldsymbol{1}^T\exp(W\boldsymbol{x})}\\<br/>
&amp;= -\boldsymbol{y}^T \Big(\log\exp(W\boldsymbol{x}) -\boldsymbol{1} \log\big(\boldsymbol{1}^T \exp(W\boldsymbol{x})\big)\Big) \\<br/>
&amp;= -\boldsymbol{y}^TW\boldsymbol{x} + \log\big(\boldsymbol{1}^T \exp(W\boldsymbol{x})\big)<br/>
\end{align*}<br/>
\]</p>

<p>这里需要注意两点，一个是\(\log{\boldsymbol{x}/y} = \log \boldsymbol{x} - \boldsymbol{1} \log y\)，另一个是 \(\boldsymbol{y}^T \boldsymbol{1} = 1\)。现在求微分，利用矩阵乘法和逐乘法得<br/>
\[<br/>
dl = -\boldsymbol{y}^T dW\boldsymbol x + \big(\boldsymbol{1}^T \exp(W\boldsymbol x)\big)^{-1} \odot \Big(\boldsymbol{1}^T \big(\exp(W\boldsymbol x)\odot (dW\boldsymbol x)\big)\Big)\\<br/>
\]</p>

<p>再套上迹作交换<br/>
\[<br/>
\begin{align*}<br/>
dl &amp;= \text{Tr}\bigg( -\boldsymbol{y}^T dW\boldsymbol x + \big(\boldsymbol{1}^T \exp(W\boldsymbol x)\big)^{-1} \odot \Big(\boldsymbol{1}^T \big(\exp(W\boldsymbol x)\odot (dW\boldsymbol x)\big)\Big) \bigg)\\<br/>
&amp;= \text{Tr}\bigg( -\boldsymbol{y}^T dW\boldsymbol x + \big(\boldsymbol{1}^T \exp(W\boldsymbol x)\big)^{-1} \odot \Big(\big(\boldsymbol{1}\odot\exp(W\boldsymbol x)\big)^T (dW\boldsymbol x)\Big) \bigg)\\<br/>
&amp;= \text{Tr}\bigg( -\boldsymbol{y}^T dW\boldsymbol x + \big(\boldsymbol{1}^T \exp(W\boldsymbol x)\big)^{-1} \odot \Big(\exp(W\boldsymbol x)^T (dW\boldsymbol x)\Big) \bigg)\\<br/>
&amp;= \text{Tr}\bigg( -\boldsymbol x \big( \boldsymbol y^T + \big(\boldsymbol{1}^T \exp(W\boldsymbol x)\big)^{-1} \odot \exp(W\boldsymbol x)^T  \big) dW\bigg)<br/>
\end{align*}<br/>
\]</p>

<p>最后一步是利用迹的可交换性得到，此时按照微分和导数的关系：<br/>
\[<br/>
dl = \text{Tr}(\frac{\partial l^T}{\partial W} dW)^T<br/>
\]</p>

<p>所以有<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial l}{\partial W} &amp;= \bigg( -\boldsymbol x \big( \boldsymbol y^T - \big(\boldsymbol{1}^T \exp(W\boldsymbol x)\big)^{-1} \odot \exp(W\boldsymbol x)^T  \big)\bigg)^T\\<br/>
&amp;= \bigg( -\boldsymbol x \big( \boldsymbol y^T - \text{softmax}(W\boldsymbol x)^T  \big)\bigg)^T\\<br/>
&amp;= \big(\text{softmax}(W\boldsymbol x) - \boldsymbol y\big) \boldsymbol x^T<br/>
\end{align*}<br/>
\]</p>

<p>解2：定义 \(\boldsymbol{a} = W\boldsymbol{x}\)，则 \(l = -\boldsymbol{y}^T\log\text{softmax}(\boldsymbol{a})\) ，先同上求出 \(\frac{\partial l}{\partial \boldsymbol{a}} = \text{softmax}(\boldsymbol{a})-\boldsymbol{y}\)，再利用复合法则：\(dl = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}}^Td\boldsymbol{a}\right) = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}}^TdW \boldsymbol{x}\right) = \text{tr}\left(\boldsymbol{x}\frac{\partial l}{\partial \boldsymbol{a}}^TdW\right)\)，得到\(\frac{\partial l}{\partial W}= \frac{\partial l}{\partial\boldsymbol{a}}\boldsymbol{x}^T\)。</p>

<p>例7【二层神经网络】：\(l = -\boldsymbol{y}^T\log\text{softmax}(W_2\sigma(W_1\boldsymbol{x}))\) ，求 \(\frac{\partial l}{\partial W_1}和\frac{\partial l}{\partial W_2}\)。其中 \(\boldsymbol{y}\) 是除一个元素为1外其它元素为0的的 \(m\times 1\) 列向量，\(W_2\) 是 \(m\times p\) 矩阵，\(W_1\) 是 \(p \times n\) 矩阵，\(\boldsymbol{x}\) 是 \(n\times 1\) 列向量，l是标量；\(\log\) 表示自然对数，\(\text{softmax}(\boldsymbol{a}) = \frac{\exp(\boldsymbol{a})}{\boldsymbol{1}^T\exp(\boldsymbol{a})}\) 。同上，\(\sigma\) 是逐元素 \(\text{sigmoid}\) 函数 \(\sigma(a) = \frac{1}{1+\exp(-a)}\)。</p>

<p>解：定义 \(\boldsymbol{a}_1=W_1\boldsymbol{x}\)，\(\boldsymbol{h}_1 = \sigma(\boldsymbol{a}_1)\)，\(\boldsymbol{a}_2 = W_2 \boldsymbol{h}_1\)，则 \(l =-\boldsymbol{y}^T\log\text{softmax}(\boldsymbol{a}_2)\)。上例中已经求出 \(\frac{\partial l}{\partial \boldsymbol{a}_2} = \text{softmax}(\boldsymbol{a}_2)-\boldsymbol{y}\)。使用复合法则 <br/>
\[<br/>
dl = \text{Tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^Td\boldsymbol{a}_2\right) = \text{Tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^TdW_2 \boldsymbol{h}_1\right) + \underbrace{ \text{Tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^TW_2 d\boldsymbol{h}_1\right)}_{dl_2}<br/>
\]</p>

<p>使用矩阵乘法交换的迹技巧从第一项得到 <br/>
\[<br/>
\frac{\partial l}{\partial W_2}= \frac{\partial l}{\partial\boldsymbol{a}_2}\boldsymbol{h}_1^T<br/>
\]</p>

<blockquote>
<p>因为 \(\boldsymbol a_2 = W_2 \boldsymbol h_1\)，所以 \(d\boldsymbol a_2 = (dW_2) \boldsymbol h_1\)，所以 \(dl = \text{Tr}(\frac{l}{\partial \boldsymbol a_2}^T d\boldsymbol a_2)\) ，将 \(d\boldsymbol a_2\) 代入可得 <br/>
\[<br/>
\begin{align*}<br/>
dl &amp;= \text{Tr}\Big(\frac{l}{\partial \boldsymbol a_2}^T (dW_2)\boldsymbol h_1\Big)^T\\<br/>
&amp;= \text{Tr}\Big(\boldsymbol h_1 \frac{l}{\partial \boldsymbol a_2}^T dW_2\Big) \\<br/>
\end{align*}<br/>
\]</p>

<p>对比微分和导数的关系 \(dl = \text{Tr}(\frac{l}{\boldsymbol W_2}^T dW_2)\)，可得<br/>
\[<br/>
\frac{l}{\boldsymbol W_2} = \Big(\boldsymbol h_1 \frac{l}{\partial \boldsymbol a_2}^T \Big)^T = \frac{l}{\partial \boldsymbol a_2} \boldsymbol h_1^T<br/>
\]</p>
</blockquote>

<p>从第二项得到 \(\frac{\partial l}{\partial \boldsymbol{h}_1}= W_2^T\frac{\partial l}{\partial\boldsymbol{a}_2}\)。接下来对第二项继续使用复合法则来求 \(\frac{\partial l}{\partial \boldsymbol{a}_1}\)，并利用矩阵乘法和逐元素乘法交换的迹技巧：<br/>
\[<br/>
\begin{align*}<br/>
dl_2 = \text{Tr}\left(\frac{\partial l}{\partial\boldsymbol{h}_1}^Td\boldsymbol{h}_1\right) \\<br/>
&amp;= \text{Tr}\left(\frac{\partial l}{\partial\boldsymbol{h}_1}^T(\sigma&#39;(\boldsymbol{a}_1)\odot d\boldsymbol{a}_1)\right) \\<br/>
&amp;= \text{Tr}\left(\left(\frac{\partial l}{\partial\boldsymbol{h}_1}\odot \sigma&#39;(\boldsymbol{a}_1)\right)^Td\boldsymbol{a}_1\right)\\<br/>
\end{align*}<br/>
\]</p>

<p>得到 \(\frac{\partial l}{\partial \boldsymbol{a}_1}= \frac{\partial l}{\partial\boldsymbol{h}_1}\odot\sigma&#39;(\boldsymbol{a}_1)\)。为求 \(\frac{\partial l}{\partial W_1}\)，再用一次复合法则：<br/>
\[<br/>
\begin{align*}<br/>
dl_2 &amp;= \text{Tr}\left(\frac{\partial l}{\partial\boldsymbol{a}_1}^Td\boldsymbol{a}_1\right) \\<br/>
&amp;= \text{tr}\left(\frac{\partial l}{\partial\boldsymbol{a}_1}^TdW_1\boldsymbol{x}\right) \\<br/>
&amp;= \text{tr}\left(\boldsymbol{x}\frac{\partial l}{\partial\boldsymbol{a}_1}^TdW_1\right)<br/>
\end{align*}<br/>
\]</p>

<p>得到 \(\frac{\partial l}{\partial W_1}= \frac{\partial l}{\partial\boldsymbol{a}_1}\boldsymbol{x}^T\)。</p>

<p>推广：样本 \((\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_N,y_N)\)，\(l = -\sum_{i=1}^N \boldsymbol{y}_i^T\log\text{softmax}(W_2\sigma(W_1\boldsymbol{x}_i + \boldsymbol{b}_1) + \boldsymbol{b}_2)\)，其中 \(\boldsymbol{b}_1\) 是 \(p \times 1\) 列向量，\(\boldsymbol{b}_2\) 是 \(m\times 1\) 列向量，其余定义同上。</p>

<p>解1：定义 \(\boldsymbol{a}_{1,i} = W_1 \boldsymbol{x}_i + \boldsymbol{b}_1\)，\(\boldsymbol{h}_{1,i} = \sigma(\boldsymbol{a}_{1,i})\)，\(\boldsymbol{a}_{2,i} = W_2\boldsymbol{h}_{1,i} + \boldsymbol{b}_2\)，则 \(l = -\sum_{i=1}^N \boldsymbol{y}_i^T \log \text{softmax}(\boldsymbol{a}_{2,i})\)。先同上可求出 \(\frac{\partial l}{\partial \boldsymbol{a}_{2,i}} = \text{softmax}(\boldsymbol{a}_{2,i})-\boldsymbol{y}_i\) 。使用复合法则，<br/>
\[<br/>
\begin{align*}<br/>
dl &amp;= \text{tr}\left(\sum_{i=1}^N\frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T d \boldsymbol{a}_{2,i}\right) \\<br/>
&amp;= \text{tr}\left( \sum_{i=1}^N \frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T dW_2 \boldsymbol{h}_{1,i}\right) + \underbrace{\text{tr}\left( \sum_{i=1}^N \frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T W_2 d\boldsymbol{h}_{1,i}\right)}_{dl_2} + \text{tr}\left( \sum_{i=1}^N \frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T d \boldsymbol{b}_2\right)，<br/>
\end{align*}<br/>
\]</p>

<p>从第一项得到得到 \(\frac{\partial l}{\partial W_2}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{2,i}}\boldsymbol{h}_{1,i}^T\)，从第二项得到 \(\frac{\partial l}{\partial \boldsymbol{h}_{1,i}}= W_2^T\frac{\partial l}{\partial\boldsymbol{a}_{2,i}}\)，从第三项得到到 \(\frac{\partial l}{\partial \boldsymbol{b}_2}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{2,i}}\)。接下来对第二项继续使用复合法则，得到 \(\frac{\partial l}{\partial \boldsymbol{a}_{1,i}}= \frac{\partial l}{\partial\boldsymbol{h}_{1,i}}\odot\sigma&#39;(\boldsymbol{a}_{1,i})\)。为求 \(\frac{\partial l}{\partial W_1}, \frac{\partial l}{\partial \boldsymbol{b}_1}\)，再用一次复合法则：\(dl_2 = \text{tr}\left(\sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}^Td\boldsymbol{a}_{1,i}\right) = \text{tr}\left(\sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}^TdW_1\boldsymbol{x}_i\right) + \text{tr}\left(\sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}^Td\boldsymbol{b}_1\right)\)，得到 \(\frac{\partial l}{\partial W_1}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}\boldsymbol{x}_i^T，\frac{\partial l}{\partial \boldsymbol{b}_1}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}\)。</p>

<p>解2：可以用矩阵来表示 \(N\) 个样本，以简化形式。定义 \(X = [\boldsymbol{x}_1, \cdots, \boldsymbol{x}_N]，A_1 = [\boldsymbol{a}_{1,1},\cdots,\boldsymbol{a}_{1,N}] =W_1 X + \boldsymbol{b}_1 \boldsymbol{1}^T，H_1 = [\boldsymbol{h}_{1,1}, \cdots, \boldsymbol{h}_{1,N}] = \sigma(A_1)，A_2 = [\boldsymbol{a}_{2,1},\cdots,\boldsymbol{a}_{2,N}] = W_2 H_1 + \boldsymbol{b}_2 \boldsymbol{1}^T\)，注意这里使用全1向量来扩展维度。先同上求出 \(\frac{\partial l}{\partial A_2} = [\text{softmax}(\boldsymbol{a}_{2,1})-\boldsymbol{y}_1, \cdots, \text{softmax}(\boldsymbol{a}_{2,N})-\boldsymbol{y}_N]\) 。使用复合法则，\(dl = \text{tr}\left(\frac{\partial l}{\partial A_2}^T d A_2\right) = \text{tr}\left( \frac{\partial l}{\partial A_2}^T dW_2 H_1 \right) + \underbrace{\text{tr}\left(\frac{\partial l}{\partial A_2}^T W_2 d H_1\right)}_{dl_2} + \text{tr}\left(\frac{\partial l}{\partial A_2}^T d \boldsymbol{b}_2 \boldsymbol{1}^T\right)\) ，从第一项得到 \(\frac{\partial l}{\partial W_2}= \frac{\partial l}{\partial A_2}H_1^T\)，从第二项得到 \(\frac{\partial l}{\partial H_1}= W_2^T\frac{\partial l}{\partial A_{2}}\)，从第三项得到到 \(\frac{\partial l}{\partial \boldsymbol{b}_2}= \frac{\partial l}{\partial A_2}\boldsymbol{1}\)。接下来对第二项继续使用复合法则，得到 \(\frac{\partial l}{\partial A_1}= \frac{\partial l}{\partial H_1}\odot\sigma&#39;(A_1)。为求\frac{\partial l}{\partial W_1}, \frac{\partial l}{\partial \boldsymbol{b}_1}\)，再用一次复合法则：\(dl_2 = \text{tr}\left(\frac{\partial l}{\partial A_1}^TdA_1\right) = \text{tr}\left(\frac{\partial l}{\partial A_1}^TdW_1X\right) + \text{tr}\left( \frac{\partial l}{\partial A_1}^Td\boldsymbol{b}_1 \boldsymbol{1}^T\right)\)，得到 \(\frac{\partial l}{\partial W_1}=  \frac{\partial l}{\partial A_1}X^T，\frac{\partial l}{\partial \boldsymbol{b}_1}= \frac{\partial l}{\partial A_1}\boldsymbol{1}\)。</p>

<h4 id="toc_3">矩阵对矩阵求导</h4>

<p>我们先定义向量 \(\mathbf f(p\times 1)\) 对向量 \(\mathbf x(m\times 1)\) 的导数 \(\frac{\partial \mathbf f}{\partial \mathbf x} = \left [\begin{array}{cccc} \frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_1} &amp; \cdots &amp; \frac{\partial f_p}{\partial x_1} \\ \frac{\partial f_1}{\partial x_2} &amp; \frac{\partial f_2}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_p}{\partial x_2} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_1}{\partial x_m} &amp; \frac{\partial f_2}{\partial x_m} &amp; \cdots &amp; \frac{\partial f_p}{\partial x_m} \\ \end{array} \right ]\)\((m\times p)\)，有 \(d\mathbf f = \frac{\partial \mathbf f}{\partial \mathbf x}^T d\mathbf x\)；再定义矩阵的向量化（按列优先）：\(\text{vec}(X) = [X_{11},\cdots,X_{m1},X_{12},\cdots,X_{m2},\cdots,X_{1n},\cdots,X_{mn}]^T\)\((mn\times 1)\)，并定义矩阵 \(F(p\times q)\) 对矩阵 \(X(m\times n)\) 的导数 \(\frac{\partial F}{\partial X} = \frac{\text{vec}(F)}{\text{vec}(X)}\)\((mn\times pq)\)。导数与微分有联系 \(\text{vec}(dF) = \frac{\partial F}{\partial X}^T \text{vec}(dX)\)。几点说明如下：</p>

<ol>
<li>按此定义，标量 \(f\) 对矩阵 \(X(m\times n)\) 的导数 \(\frac{\partial f}{\partial X}\) 是 \(mn\times 1\) 向量，与上面的定义不兼容，不过二者容易相互转换。为避免混淆，用记号 \(\nabla_X f\) 表示上篇定义的 \(m\times n\) 矩阵，则有 \(\frac{\partial f}{\partial X}=\mathrm{vec}(\nabla_X f)\)。虽然本篇的技术可以用于标量对矩阵求导这种特殊情况，但使用上篇中的技术更方便。</li>
<li>标量对矩阵的二阶导数，又称 Hessian 矩阵，定义为 \(\nabla^2_X f = \frac{\partial^2 f}{\partial X^2} = \frac{\partial \nabla_X f}{\partial X}\)\((mn\times mn)\)，是对称矩阵。对向量 \(\frac{\partial f}{\partial X}\) 或矩阵 \(\nabla_X f\) 求导都可以得到 Hessian 矩阵，但从矩阵 \(\nabla_X f\) 出发更方便。</li>
<li>\(\frac{\partial F}{\partial X} = \frac{\partial\mathrm{vec} (F)}{\partial X} = \frac{\partial F}{\partial \mathrm{vec}(X)} = \frac{\partial\mathrm{vec}(F)}{\partial \mathrm{vec}(X)}\)，求导时矩阵被向量化，弊端是这在一定程度破坏了矩阵的结构，会导致结果变得形式复杂；好处是多元微积分中关于梯度、Hessian矩阵的结论可以沿用过来，只需将矩阵向量化。例如优化问题中，牛顿法的更新 \(\Delta X\)，满足 \(\mathrm{vec}(\Delta X) = -(\nabla^2_X f)^{-1}\mathrm{vec}(\nabla_X f)\)。</li>
<li>在资料中，矩阵对矩阵的导数还有其它定义，比如 \(\frac{\partial F}{\partial X} = \left[\frac{\partial F_{kl}}{\partial X}\right](mp×nq)\)，它能兼容上篇中的标量对矩阵导数的定义，但微分与导数的联系（\(dF\) 等于 \(\frac{\partial F}{\partial X}\) 中每个 \(m\times n\) 子块分别与 \(dX\) 做内积）不够简明，不便于计算和应用。</li>
</ol>

<p>然后来建立运算法则。仍然要利用导数与微分的联系 \(\mathrm{vec}(dF) = \frac{\partial F}{\partial X}^T \mathrm{vec}(dX)\)，求微分的方法与上篇相同，而从微分得到导数需要一些向量化的技巧：</p>

<ol>
<li>线性：\(\mathrm{vec}(A+B) = \mathrm{vec}(A) + \mathrm{vec}(B)\)。</li>
<li>矩阵乘法：\(\mathrm{vec}(AXB) = (B^T \otimes A) \mathrm{vec}(X)\)，其中 \(\otimes\) 表示Kronecker积，\(A\)\((m\times n)\) 与 \(B\)\((p\times q)\) 的Kronecker积是 \(A\otimes B = [A_{ij}B]\)\((mp\times nq)\)。</li>
<li>转置：\(\mathrm{vec}(A^T) = K_{mn}\mathrm{vec}(A)\)，\(A\) 是 \(m\times n\) 矩阵，其中 \(K_{mn}\)\((mn\times mn)\) 是交换矩阵(commutation matrix)。</li>
<li>逐元素乘法：\(\mathrm{vec}(A\odot X) = \mathrm{diag}(A)\mathrm{vec}(X)\)，其中 \(\mathrm{diag}(A)\)\((mn\times mn)\) 是用 \(A\) 的元素（按列优先）排成的对角阵。</li>
</ol>

<p>观察一下可以断言，若矩阵函数 \(F\) 是矩阵 \(X\) 经加减乘法、逆、行列式、逐元素函数等运算构成，则使用相应的运算法则对 \(F\) 求微分，再做向量化并使用技巧将其它项交换至 \(\text{vec}(dX)\) 左侧，即能得到导数。</p>

<p>再谈一谈复合：假设已求得 \(\frac{\partial F}{\partial Y}\)，而 \(Y\) 是 \(X\) 的函数，如何求 \(\frac{\partial F}{\partial X}\) 呢？从导数与微分的联系入手，\(\mathrm{vec}(dF) = \frac{\partial F}{\partial Y}^T\mathrm{vec}(dY) = \frac{\partial F}{\partial Y}^T\frac{\partial Y}{\partial X}^T\mathrm{vec}(dX)\) ，可以推出链式法则 \(\frac{\partial F}{\partial X} = \frac{\partial Y}{\partial X}\frac{\partial F}{\partial Y}\)。</p>

<p>和标量对矩阵的导数相比，矩阵对矩阵的导数形式更加复杂，从不同角度出发常会得到形式不同的结果。有一些Kronecker积和交换矩阵相关的恒等式，可用来做等价变形：\((A\otimes B)^T = A^T \otimes B^T\)。\(\mathrm{vec}(\boldsymbol{ab}^T) = \boldsymbol{b}\otimes\boldsymbol{a}\)。\((A\otimes B)(C\otimes D) = (AC)\otimes (BD)\)。可以对 \(F = D^TB^TXAC\) 求导来证明，一方面，直接求导得到 \(\frac{\partial F}{\partial X} = (AC) \otimes (BD)\)；另一方面，引入 \(Y = B^T X A\)，有 \(\frac{\partial F}{\partial Y} = C \otimes D\), \(\frac{\partial Y}{\partial X} = A \otimes B\)，用链式法则得到 \(\frac{\partial F}{\partial X} = (A\otimes B)(C \otimes D)\)。\(K_{mn} = K_{nm}^T\), \(K_{mn}K_{nm} = I\)。\(K_{pm}(A\otimes B) K_{nq} = B\otimes A\)，\(A\) 是 \(m\times n\) 矩阵，\(B\) 是 \(p\times q\) 矩阵。可以对 \(AXB^T\) 做向量化来证明，一方面，\(\mathrm{vec}(AXB^T) = (B\otimes A)\mathrm{vec}(X)\)；另一方面，\(\mathrm{vec}(AXB^T) = K_{pm}\mathrm{vec}(BX^TA^T) = K_{pm}(A\otimes B)\mathrm{vec}(X^T) = K_{pm}(A\otimes B) K_{nq}\mathrm{vec}(X)\)。</p>

<p>接下来演示一些算例。</p>

<p>例1：\(F = AX\)，\(X\) 是 \(m\times n\) 矩阵，求 \(\frac{\partial F}{\partial X}\)。</p>

<p>解：先求微分：\(dF=AdX\)，再做向量化，使用矩阵乘法的技巧，注意在 \(dX\) 右侧添加单位阵：\(\mathrm{vec}(dF) = \mathrm{vec}(AdX) = (I_n\otimes A)\mathrm{vec}(dX)\)，对照导数与微分的联系得到 \(\frac{\partial F}{\partial X} = I_n\otimes A^T\)。</p>

<p>特例：如果 \(X\) 退化为向量，即 \(\boldsymbol{f} = A \boldsymbol{x}\)，则根据向量的导数与微分的关系 \(d\boldsymbol{f} = \frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}}^T d\boldsymbol{x}\)，得到 \(\frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}} = A^T\)。</p>

<p>例2：\(f = \log |X|\) ，\(X\) 是 \(n\times n\) 矩阵，求 \(\nabla_X f\) 和 \(\nabla^2_X f\)。</p>

<p>解：使用上篇中的技术可求得 \(\nabla_X f = X^{-1T}\) 。为求 \(\nabla^2_X f\)，先求微分：\(d\nabla_X f = -(X^{-1}dXX^{-1})^T\)，再做向量化，使用转置和矩阵乘法的技巧 \(\mathrm{vec}(d\nabla_X f)= -K_{nn}\mathrm{vec}(X^{-1}dX X^{-1}) = -K_{nn}(X^{-1T}\otimes X^{-1})\mathrm{vec}(dX)\)，对照导数与微分的联系，得到 \(\nabla^2_X f = -K_{nn}(X^{-1T}\otimes X^{-1})\)，注意它是对称矩阵。在 \(X\) 是对称矩阵时，可简化为 \(\nabla^2_X f = -X^{-1}\otimes X^{-1}\)。</p>

<p>例3：\(F = A\exp(XB)\)，\(A\) 是 \(l\times m\) 矩阵，\(X\) 是 \(m\times n\) 矩阵，\(B\) 是 \(n\times p\) 矩阵，\(\exp\) 为逐元素函数，求\(\frac{\partial F}{\partial X}\)。</p>

<p>解：先求微分：\(dF = A(\exp(XB)\odot (dXB))\)，再做向量化，使用矩阵乘法的技巧：\(\mathrm{vec}(dF) = (I_p\otimes A)\mathrm{vec}(\exp(XB)\odot (dXB))\)，再用逐元素乘法的技巧：\(\mathrm{vec}(dF) = (I_p \otimes A) \mathrm{diag}(\exp(XB))\mathrm{vec}(dXB)\)，再用矩阵乘法的技巧：\(\mathrm{vec}(dF) = (I_p\otimes A)\mathrm{diag}(\exp(XB))(B^T\otimes I_m)\mathrm{vec}(dX)\)，对照导数与微分的联系得到 \(\frac{\partial F}{\partial X} = (B\otimes I_m)\mathrm{diag}(\exp(XB))(I_p\otimes A^T)\)。</p>

<p>例4【一元logistic回归】：\(l = -y \boldsymbol{x}^T \boldsymbol{w} + \log(1 + \exp(\boldsymbol{x}^T\boldsymbol{w}))\)，求 \(\nabla_\boldsymbol{w} l\) 和 \(\nabla^2_\boldsymbol{w} l\)。其中 \(y\) 是取值0或1的标量，\(\boldsymbol{x}\),\(\boldsymbol{w}\) 是 \(n\times 1\) 列向量。</p>

<p>解：使用上篇中的技术可求得 \(\nabla_\boldsymbol{w} l = \boldsymbol{x}(\sigma(\boldsymbol{x}^T\boldsymbol{w}) - y)\)，其中 \(\sigma(a) = \frac{\exp(a)}{1+\exp(a)}\) 为sigmoid函数。为求 \(\nabla^2_\boldsymbol{w} l\)，先求微分：\(d\nabla_\boldsymbol{w} l = \boldsymbol{x} \sigma&#39;(\boldsymbol{x}^T\boldsymbol{w})\boldsymbol{x}^T d\boldsymbol{w}\) ，其中 \(\sigma&#39;(a) = \frac{\exp(a)}{(1+\exp(a))^2}\) 为sigmoid函数的导数，对照导数与微分的联系，得到 \(\nabla_w^2 l = \boldsymbol{x}\sigma&#39;(\boldsymbol{x}^T\boldsymbol{w})\boldsymbol{x}^T\)。</p>

<p>推广：样本 \((\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_N,y_N)\)，\(l = \sum_{i=1}^N \left(-y_i \boldsymbol{x}_i^T\boldsymbol{w} + \log(1+\exp(\boldsymbol{x_i}^T\boldsymbol{w}))\right)\)，求 \(\nabla_w l\) 和 \(\nabla^2_w l\)。有两种方法，方法一：先对每个样本求导，然后相加；方法二：定义矩阵 \(X = \begin{bmatrix}\boldsymbol{x}_1^T \\ \vdots \\ \boldsymbol{x}_n^T \end{bmatrix}\)，向量 \(\boldsymbol{y} = \begin{bmatrix}y_1 \\ \vdots \\ y_n\end{bmatrix}\)，将 \(l\) 写成矩阵形式 \(l = -\boldsymbol{y}^T X\boldsymbol{w} + \boldsymbol{1}^T\log(\boldsymbol{1} + \exp(X\boldsymbol{w}))\)，进而可以求得 \(\nabla_\boldsymbol{w} l = X^T(\sigma(X\boldsymbol{w}) - \boldsymbol{y})，\nabla_w^2 l = X^T\text{diag}(\sigma&#39;(X\boldsymbol{w}))X\)。</p>

<p>例5【多元logistic回归】：\(l = -\boldsymbol{y}^T\log \text{softmax}(W\boldsymbol{x}) = -\boldsymbol{y}^TW\boldsymbol{x} + \log(\boldsymbol{1}^T\exp(W\boldsymbol{x}))\)，求 \(\nabla_W l\) 和 \(\nabla^2_W l\) 。其中其中 \(\boldsymbol{y}\) 是除一个元素为1外其它元素为0的 \(m\times 1\) 列向量，\(W\) 是 \(m\times n\) 矩阵，\(\boldsymbol{x}\) 是 \(n\times 1\) 列向量，l是标量。</p>

<p>解：上篇中已求得 \(\nabla_W l = (\text{softmax}(W\boldsymbol{x})-\boldsymbol{y})\boldsymbol{x}^T\)。为求 \(\nabla^2_W l\)，先求微分：定义 <br/>
\[<br/>
\begin{align*}<br/>
\boldsymbol{a} &amp;= W\boldsymbol{x}，d\text{softmax}(\boldsymbol{a}) \\<br/>
&amp;= \frac{\exp(\boldsymbol{a})\odot d\boldsymbol{a}}{\boldsymbol{1}^T\exp(\boldsymbol{a})} - \frac{\exp(\boldsymbol{a}) (\boldsymbol{1}^T(\exp(\boldsymbol{a})\odot d\boldsymbol{a}))}{(\boldsymbol{1}^T\exp(\boldsymbol{a}))^2}<br/>
\end{align*}<br/>
\]</p>

<p>这里需要化简去掉逐元素乘法，第一项中 \(\exp(\boldsymbol{a})\odot d\boldsymbol{a} = \text{diag}(\exp(\boldsymbol{a})) d\boldsymbol{a}\) ，第二项中 \(\boldsymbol{1}^T(\exp(\boldsymbol{a})\odot d\boldsymbol{a}) = \exp(\boldsymbol{a})^Td\boldsymbol{a}\)，故有 \(d\text{softmax}(\boldsymbol{a}) = D\text{softmax}(\boldsymbol{a})d\boldsymbol{a}\)，其中 \(D\text{softmax}(\boldsymbol{a}) = \frac{\text{diag}(\exp(\boldsymbol{a}))}{\boldsymbol{1}^T\exp(\boldsymbol{a})} - \frac{\exp(\boldsymbol{a})\exp(\boldsymbol{a})^T}{(\boldsymbol{1}^T\exp(\boldsymbol{a}))^2}\) ，代入有 \(d\nabla_W l =D \text{softmax}(\boldsymbol{a})d\boldsymbol{a}\boldsymbol{x}^T = D\text{softmax}(W\boldsymbol{x})dW \boldsymbol{x}\boldsymbol{x}^T\)，做向量化并使用矩阵乘法的技巧，得到 \(\nabla^2_W l = (\boldsymbol{x}\boldsymbol{x}^T) \otimes D\text{softmax}(W\boldsymbol{x})\)。</p>

<p>最后做个总结。我们发展了从整体出发的矩阵求导的技术，导数与微分的联系是计算的枢纽，标量对矩阵的导数与微分的联系是 \(df = \mathrm{tr}(\nabla_X^T f dX)\)，先对 \(f\) 求微分，再使用迹技巧可求得导数，特别地，标量对向量的导数与微分的联系是 \(df = \nabla^T_{\boldsymbol{x}}f d\boldsymbol{x}\)；矩阵对矩阵的导数与微分的联系是 \(\mathrm{vec}(dF) = \frac{\partial F}{\partial X}^T \mathrm{vec}(dX)\)，先对 \(F\) 求微分，再使用向量化的技巧可求得导数，特别地，向量对向量的导数与微分的联系是 \(d\boldsymbol{f} = \frac{\partial \boldsymbol{f}}{\partial \boldsymbol{x}}^Td\boldsymbol{x}\)。</p>

<hr/>

<p><a href="https://zhuanlan.zhihu.com/p/27523007">矩阵求导浅析（一）</a><br/>
<a href="https://zhuanlan.zhihu.com/p/24709748">矩阵求导术（上）</a><br/>
<a href="https://zhuanlan.zhihu.com/p/24863977">矩阵求导术（下）</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15385007008840.html">次梯度 subgradient</a></h1>
			<p class="meta"><time datetime="2018-10-03T01:18:20+08:00" 
			pubdate data-updated="true">2018/10/3</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>次梯度方法是传统梯度下降算法的拓展，传统梯度下降算法是为了解决可导凸函数的问题，而次梯度方法主要是为了解决不可导梯度的问题。但是其算法收敛速度会相对较慢。</p>

<h3 id="toc_0">次梯度的定义</h3>

<p>次梯度是指对于函数 \(f\) 上的点 \(x\) 满足一下条件的 \(g\in\mathbb R^n\)： <br/>
\[<br/>
f(y) \geq f(x) + g^T(y-x)  <br/>
\]</p>

<p>即 </p>

<ol>
<li><p>若 \(f\) 是一个凸函数，若 \(f\) 在 \(x\) 处可导，则由一阶泰勒展开式：<br/>
\[ <br/>
f(y) \geq f(x) + \nabla  f(x)^T(y-x)  <br/>
\]</p></li>
<li><p>若 \(f\) 在 \(x\) 处不可导，则仍可得到一个下届： <br/>
\[<br/>
f(y) \geq f(x) + g^T(y-x) <br/>
\]</p>

<p>这个 \(g\) 就是 \(f\) 的子梯度。</p></li>
</ol>

<p>注意：虽然次梯度是针对不可导函数而设计的，但是可导函数也仍然可以使用，因此 \(f\) 是非凸函数也是可以的。</p>

<p>对于一个给定的点，可能不止一个这样的次梯度存在，而是一个次梯度的集合，这样的集合就叫做次微分（次导数），表示为 \(\partial f(x)\)。注意，如果微分存在的情况下，这样的次微分集合只包含一个元素，就是该点的梯度值，也就是蜕化为正常的梯度方式，所以说这是梯度的一种扩展。</p>

<h3 id="toc_1">次梯度的计算公式</h3>

<p>在点 \(x_0\) 的次导数的集合是一个非空闭区间 \([a,b]\) ，其中 \(a\) 和 \(b\) 是单侧极限<br/>
\[<br/>
a = lim_{x\rightarrow x_0^-} \frac{f(x) - f(x_0)}{x-x_0} \\<br/>
b = lim_{x\rightarrow x_0^+} \frac{f(x) - f(x_0)}{x-x_0} \\<br/>
\]</p>

<p>\(a\) 和 \(b\) 一定存在，且 \(a\le b\)。所有次导数的集合 \([a,b]\) 称为函数 \(f\) 在\(x_0\) 的次微分。</p>

<p>假设 \(f(x)=|x|\) 在 \(x=0\) 的次梯度为 \([-1, 1]\)。这是因为<br/>
\[<br/>
\begin{align*}<br/>
a &amp;= \lim_{x-&gt;0^-}\frac{|x|-0}{x}=\frac{-x}{x}=-1\\<br/>
b &amp;= \lim_{x-&gt;0^+}\frac{|x|-0}{x}=\frac{x}{x}=1\\<br/>
\end{align*}<br/>
\]</p>

<p>因此 \(f(x)\) 在 \(x=0\) 的次微分为 \([-1,1]\)。</p>

<h3 id="toc_2">次梯度的性质</h3>

<ol>
<li><strong>数乘不变性</strong>：\(\forall \alpha \ge 0, \partial(\alpha f)(x)=\alpha \partial f(x)\)</li>
<li><strong>加法不变性</strong>：\(\partial(f_1(x)+f_2(x)+...+f_m(x))=\partial f_1(x)+...+\partial f_m(x)\)</li>
<li><strong>放射特性</strong>：如果 \(f\) 是凸函数，那么 \(\partial f(Ax+b)=A^T\partial f(Ax+b)\)</li>
</ol>

<h3 id="toc_3">次梯度算法</h3>

<p>次梯度算法与梯度下降类似，仅仅是使用次梯度代替梯度，即： <br/>
\[<br/>
x^{(k)}=x^{(k-1)}-t_k  \cdot g^{(k-1)}, k=1,2,3... <br/>
\]</p>

<p>其中，\(g^{(k-1)} \in \partial f(x^{(k-1)})\) 为 \(f(x)\) 在 \(x\) 处的次梯度。 <br/>
与梯度下降算法不同的地方在于，次梯度算法并不是下降算法，每次对于参数的更新并不能保证代价函数是呈单调递减的趋势。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15378797300710.html">强化学习 Reinforcement Learning</a></h1>
			<p class="meta"><time datetime="2018-09-25T20:48:50+08:00" 
			pubdate data-updated="true">2018/9/25</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>强化学习（Reinforcement Learning，RL），也叫增强学习，是指一类从（环境）交互中不断学习的问题以及解决这类问题的方法。强化学习问题可以描述为一个智能体从与环境的交互中不断学习以完成特定目标（比如取得最大奖励值）。和深度学习类似，强化学习中的关键问题也是<strong>贡献度分配问题</strong>，每个动作并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并有一定的<strong>延时性</strong>。</p>

<p>强化学习也是机器学习中的一个重要分支。强化学习和监督学习的不同在于，强化学习问题不需要给出“正确”策略作为监督信息，只需要给出策略的（延迟）回报，并通过调整策略来取得最大化的期望回报。</p>

<h3 id="toc_0">强化学习问题</h3>

<p>在强化学习中，有两个可以进行交互的对象：智能体和环境。</p>

<ul>
<li><p><strong>智能体（agent）</strong>：可以感知外界环境的环境（state）和反馈的奖励（reward），并举行学习和决策。</p>

<p>智能体的<strong>决策</strong>功能是指根据外界环境的状态来做出不同的动作（action），而学习的功能是指根据外界环境的奖励来调整策略。</p></li>
<li><p><strong>环境（environment）</strong>：智能体外部的所有事物，并受智能体动作的影响而改变其状态，并反馈给智能体相应的<strong>奖励</strong>。</p></li>
</ul>

<p>在强化学习中的基本要素包括：</p>

<ul>
<li><strong>状态 \(s\)</strong> 是对环境的描述，可以是离散的连续的，其状态空间为 \(\mathcal S\)；</li>
<li><strong>动作 \(a\)</strong> 是对智能体行为的描述，可以是离散的或连续的，其动作空间为 \(\mathcal A\)；</li>
<li><strong>策略 \(\pi(a|s)\)</strong> 是智能体根据环境状态 \(s\) 来决定下一步的动作 \(a\) 的函数；</li>
<li><strong>状态转移概率 \(p(s&#39;|s,a)\)</strong> 是在智能体根据当前状态 \(s\) 做出一个动作 \(a\) 之后，环境在下一个时刻转变为状态 \(s&#39;\) 的概率；</li>
<li><strong>即时奖励 \(r(s,a,s&#39;)\)</strong> 是一个标量函数，即智能体根据当前状态 \(s\) 做出动作 \(a\) 之后，环境会反馈给智能体一个奖励，这个奖励也经常和下一个时刻的状态 \(s&#39;\) 有关。</li>
</ul>

<h4 id="toc_1">策略</h4>

<p>智能体的策略（policy）就是智能体如何根据环境 \(s\) 来决定下一步的动作 \(a\)，通常可以分为确定性策略（Deterministic Policy）和随机性策略（Stochastic Policy）两组。</p>

<p><strong>确定性策略</strong>是从状态空间到动作空间的映射函数 \(\pi : \mathcal S\rightarrow \mathcal A\)。<strong>随机性策略</strong>表示在给定环境状态时，智能体选择某个动作的概率分布：<br/>
\[<br/>
\begin{align*}<br/>
\pi(a|s) &amp;\overset{\vartriangle}= p(a|s)\\<br/>
\sum_{a \in \mathcal A} \pi(a|s) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p>

<p>通常情况下，强化学习一般使用随机性的策略。随机性的策略可以有很多优点。比如在学习时可以通过引入一定随机性更好地探索环境。二是使得策略（利用-探索策略）更加地多样性。比如在围棋中，确定性策略总是会在同一个位置上下棋，会导致你的策略很容易被对手预测。</p>

<h3 id="toc_2">马尔可夫决策过程</h3>

<p>为了简单起见，我们将智能体与环境的交互看做是离散的时间序列。下图给出了智能体与环境的交互。</p>

<div align="center">
    <img width="360" src="media/15378797300710/15378866965799.jpg" />
</div>

<p>智能体从感知到的初始环境 \(s_0\) 开始，然后决定做一个相应的动作 \(a_0\)，环境相应地发生改变到新的状态 \(s_1\)，并反馈给智能体一个即时奖励 \(r_1\)，然后智能体又根据状态 \(s_1\) 做一个动作 \(a_1\)，环境相应改变为 \(s_2\)，并反馈奖励 \(r_2\)。这样的交互可以一直进行下去。<br/>
\[<br/>
s_0,a_0,s_1,r_1,a_1,...,s_{t-1},r_{t-1},a_{t-1},s_t,r_t,...,<br/>
\]</p>

<p>其中 \(r_t = r(s_{t-1},a_{t-1},s_t)\) 是第 \(t\) 时刻的即时奖励。</p>

<p>智能体与环境的交互的过程可以看作是一个<strong>马尔可夫决策过程。</strong></p>

<p><strong>马尔可夫过程（Markov Process）</strong>：具有马尔可夫性的随机变量序列 \(s_0,s_1,...,s_t \in \mathcal S\)，其下一个时刻的状态 \(s_{t+1}\) 只取决于当前状态\(s_t\)，<br/>
\[<br/>
p(s_{t+1}|s_t,\cdots,s_0) = p(s_{t+1}|s_t),<br/>
\]</p>

<p>其中 \(p(s_{t+1}|s_t)\) 称为状态转移概率，\(\sum_{s_{t+1}\in \mathcal S} p(s_{t+1}|s_t) = 1\)。</p>

<p><strong>马尔可夫决策过程（Markov Decision Process，MDP）</strong>：在马尔可夫过程中加入一个额外的变量：动作 \(a\)，即下一个时刻的状态 \(s_{t+1}\) 和当前时刻的状态 \(s_t\) 以及动作 \(a_t\) 相关，<br/>
\[<br/>
p(s_{t+1}|s_t,a_t,\cdots,s_0,a_0) = p(s_{t+1}|s_t,a_t),<br/>
\]</p>

<p>其中 \(p(s_{t+1}|s_t, a_t)\) 为状态转移概率。</p>

<p>给定策略 \(\pi(a|s)\)，马尔可夫决策过程的一个轨迹（trajectory）<br/>
\[<br/>
\tau = s_0, a_0, s_1, r_1, a_1,\cdots, s_{T−1}, a_{T−1}, s_T , r_T<br/>
\]</p>

<p>的概率为<br/>
\[<br/>
\begin{align*}<br/>
p(\tau) &amp;= p(s_0,a_0,s_1,a_1,\cdots),\\<br/>
&amp;= p(s_0) \sum_{t=0}^{T-1} \pi(a_t|s_t) p(s_{t+1}|s_t,a_t)<br/>
\end{align*}<br/>
\]</p>

<p>给出了马尔可夫决策过程的图模型表示。</p>

<div align="center">
    <img width="540" src="media/15378797300710/15378887529961.jpg" />
</div>

<h3 id="toc_3">强化学习的目标函数</h3>

<h4 id="toc_4">总回报</h4>

<p>给定策略 \(\pi(a|s)\) 智能体和环境一次交互过程的轨迹 \(\tau\) 所收到的累积奖励为总回报（return）。<br/>
\[<br/>
\begin{align*}<br/>
G(\tau) &amp;= \sum_{t=0}^{T-1} r_{t+1} \\<br/>
&amp;= \sum_{t=0}^{T-1} r(s_t,a_t,s_{t+1})<br/>
\end{align*}<br/>
\]</p>

<p>假设环境中有一个或多个特殊的终止状态（terminal state），当到达终止状态时，一个智能体和环境的交互过程就结束了。这一轮交互的过程称为一个回合（episode）或试验（trial）。一般的强化学习任务（比如下棋、游戏)都属于这种回合式的任务。</p>

<p>如果环境中没有终止状态（比如终身学习的机器人），即 \(T = \infty\)，称为持续性强化学习任务，其总回报也可能是无穷大。为了解决这个问题，我们可以引入一个折扣率来降低远期回报的权重。折扣回报（discounted return）定义为<br/>
\[<br/>
G(\tau) = r_1 + \gamma r_2 + \gamma^2 r_3 + ... + \gamma^{T-1} r_{T} = \sum_{t=0}^{T-1} \gamma^t r_{t+1}<br/>
\]</p>

<p>其中 \(\gamma \in [0,1]\) 是折扣率。当 \(\gamma\) 接近于0时，智能体更在意短期回报；而当 \(\gamma\) 接近于1时，长期回报变得更重要。</p>

<h4 id="toc_5">目标函数</h4>

<p>因为策略和状态转移都有一定的随机性，每次试验得到的轨迹是一个随机序列，其收获的总回报也不一样。强化学习的目标是学习到一个策略 \(\pi_\theta(a|s)\) 来最大化期望回报（expected return），即希望智能体执行一系列的动作来获得尽可能多的平均回报。<br/>
\[<br/>
\mathcal J(\theta) = \mathbb E_{\tau\sim p_\theta(\tau)}[G(\tau)] = \mathbb E_{r\sim p_\theta(\tau)}[\sum_{t=0}^{T-1}\gamma^t r_{t+1}]<br/>
\]</p>

<p>其中 \(\theta\) 为策略函数的参数。</p>

<h3 id="toc_6">值函数</h3>

<p>为了评估一个策略π 的期望回报，我们定义两个值函数：状态值函数和状态-动作值函数。</p>

<h4 id="toc_7">状态值函数</h4>

<p>状态值函数 \(V^{\pi}(s)\) 表示从状态 \(s\) 出发，按照策略 \(\pi\) 采取行为得到的期望回报总回报<br/>
\[<br/>
V^{\pi}(s) = \mathbb E_{\tau\sim p(\tau)}\Big[\sum_{t=0}^{T-1} \gamma^t r_{t+1} | \tau_{s_0} = s\Big]<br/>
\]</p>

<p>其中 \(\tau_{s_0}\) 表示轨迹 \(\tau\) 的起始桩头。</p>

<p>为了方便，我们用  \(\tau_{0:T}\) 表示轨迹 \(s_0,a_0,s_1,...,s_T\)，用 \(\tau_{1:T}\) 表示轨迹 \(s_1,a_1,...,s_T\)，因此有 \(\tau_{0:T} = s_0,a_0,\tau_{1:T}\)。</p>

<p>根据马尔可夫性，\(V^\pi(s)\) 可展开得到<br/>
 \[<br/>
 \begin{align}<br/>
 V^{\pi}(s) &amp;= \mathbb E_{\tau_{0:T}\sim p(\tau)}\Big[\sum_{t=0}^{T-1} \gamma^t r_{t+1} | \tau_{s_0} = s\Big]\nonumber\\<br/>
 &amp;= \mathbb E_{\tau_{0:T}\sim p(\tau)}\Big[r_1 +\sum_{t=1}^{T-1} \gamma^t r_{t+1} | \tau_{s_0} = s\Big]\nonumber\\<br/>
 &amp;= \mathbb E_{a\sim \pi(a|s)} \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \mathbb E_{\tau_{0:T}\sim p(\tau)}\Big[r(s,a,s&#39;) +\sum_{t=1}^{T-1} \gamma^t r_{t+1} | \tau_{s_0} = s&#39;\Big]\nonumber\\<br/>
 &amp;= \mathbb E_{a\sim \pi(a|s)} \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \mathbb E_{\tau_{0:T}\sim p(\tau)}\Big[r(s,a,s&#39;) +\gamma\sum_{t=1}^{T-1} \gamma^{t-1} r_{t+1} | \tau_{s_0} = s&#39;\Big]\nonumber\\<br/>
 &amp;= \mathbb E_{a\sim \pi(a|s)} \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \bigg [r(s,a,s&#39;) + \gamma\mathbb E_{\tau_{0:T}\sim p(\tau)}\Big[\sum_{t=1}^{T-1} \gamma^{t-1} r_{t+1} | \tau_{s_0} = s&#39;\Big]\bigg ]\nonumber\\<br/>
 &amp;= \mathbb E_{a\sim \pi(a|s)} \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \Big [r(s,a,s&#39;) + \gamma V^{\pi}(s&#39;)\Big]\label{meap}\\<br/>
 \end{align}<br/>
 \]</p>

<p>这称为贝尔曼方程（Bellman equation），表示当前状态的值函数可以通过下个状态的值函数来计算。</p>

<p>如果给定策略 \(\pi(a|s)\)，状态转移概率 \(p(s&#39;|s, a)\) 和奖励 \(r(s,a,s&#39;)\) ，我们就可以通过迭代的方式来计算 \(V^\pi(<br/>
s)\)。由于存在折扣率，迭代一定步数后，每个状态的值函数就会固定不变。</p>

<h4 id="toc_8">状态-动作值函数</h4>

<p>公式 ( \ref{meap} ) 中的第二个期望是指初始状态为 \(s\) 并进行动作 \(a\)，然后执行策略 \(\pi\) 得到的期望总回报，称为状态-动作值函函数（state-action value function）<br/>
\[<br/>
\begin{equation}<br/>
Q^\pi(s,a) = \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \Big [r(s,a,s&#39;) + \gamma V^{\pi}(s&#39;)\Big]\label{qpsa}<br/>
\end{equation}<br/>
\]</p>

<p>状态-动作值函数也经常称为Q函数（Q-function）。</p>

<p>状态值函数 \(V^\pi(s)\) 是Q函数 \(Q^\pi(s, a)\) 关于动作 \(a\) 的期望，<br/>
\[<br/>
\begin{equation}<br/>
V^\pi(s) = \mathbb E_{a\sim\pi(a|s)}[Q^\pi(s, a)].\label{vpma}<br/>
\end{equation}<br/>
\]</p>

<p>结合公式 ( \ref{qpsa} ) 和 ( \ref{vpma} )，Q函数可以写成<br/>
\[<br/>
\begin{align}<br/>
Q^\pi(s,a) &amp;= \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \Big [r(s,a,s&#39;) + \gamma V^{\pi}(s&#39;)\Big]\nonumber\\<br/>
&amp;= \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \Big [r(s,a,s&#39;) + \gamma \mathbb E_{a&#39;\sim\pi(a&#39;|s&#39;)}[Q^\pi(s&#39;, a&#39;)]\Big]\label{mess}\\<br/>
\end{align}<br/>
\]</p>

<p>这是关于Q函数的贝尔曼方程。</p>

<h4 id="toc_9">值函数的作用</h4>

<p>值函数可以看作是对策略 \(\pi\) 的评估。如果在状态 \(s\)，有一个动作 \(a^*\) 使得 \(Q^\pi(s, a^*) \gt V^\pi(s)\) ，说明执行动作 \(a^*\) 比当前的策略 \(\pi(a|s)\) 要好，我们就可以调整参数使得策略 \(\pi(a^*|s)\)的概率增加。</p>

<h3 id="toc_10">基于值函数的学习方法</h3>

<p>值函数是对策略 \(\pi\) 的评估，如果策略 \(\pi\) 有限（即状态数和动作数都有限）时，可以对所有的策略进行评估并选出<strong>最优策略 \(\pi^*\)</strong>。<br/>
\[<br/>
\forall s,\quad \pi^* = {\arg\max}_\pi V^\pi(s)<br/>
\]</p>

<p>但这种方式在实践找那个很难实现。假设状态空间 \(\mathcal S\) 和动作空间 \(\mathcal A\) 都是离散且有效的，策略空间为 \(|\mathcal A|^{|\mathcal S|}\)，往往也非常大。</p>

<p>一种可行的方式是通过迭代的方式不断优化策略，直到选出最优策略。对于一个策略 \(\pi(a|s)\)，其Q函数为 \(Q^\pi(s,a)\)，我们可以设置一个新的策略 \(\pi&#39;(a|s)\)，<br/>
\[<br/>
\pi&#39;(a|s) = \left \{\begin{array}\\1\quad&amp;\text{if }a=\arg\max_{\hat a}Q^\pi(s,\hat a)\\0\quad&amp;\text{otherwise} \end{array} \right .<br/>
\]</p>

<p>即 \(\pi&#39;(a|s)\) 为一个确定性策略，也可以直接写为<br/>
\[<br/>
\pi&#39;(s) = {\arg\max}_a Q^\pi(s,a)<br/>
\]</p>

<p>如果执行 \(\pi&#39;\)，会有<br/>
\[<br/>
\forall s,\quad V^{\pi&#39;}(s) \ge V^\pi(s)<br/>
\]</p>

<p>我们可以通过下面方式来学习最优策略：先随机初始化一个策略，计算该策略的值函数，并根据值函数来设置新的策略，然后一直反复迭代直到收敛。</p>

<p>基于值函数的策略学习方法中最关键的是如何计算策略 \(\pi\) 的值函数，一般有<strong>动态规划</strong>或<strong>蒙特卡罗</strong>两种计算方式。</p>

<h4 id="toc_11">动态规划算法</h4>

<p>从贝尔曼方程可知，如果知道马尔可夫决策过程的状态转移概率 \(p(s&#39;|s,a)\) 和奖励 \(r(s,a,s&#39;)\)，我们直接可以通过贝尔曼方程来迭代计算其值函数。这种模型已知的强化学习算法也称为基于模型的强化学习（ Model-Based Reinforcement Learning）算法，这里的模型就是指马尔可夫决策过程。</p>

<p>在已知模型时，可以通过动态规划的方法来计算。常用的方法主要有策略迭代算法和值迭代算法。</p>

<h5 id="toc_12">策略迭代</h5>

<p>策略迭代（Policy Iteration）算法中，每次迭代可以分成两步：</p>

<ol>
<li><strong>策略评估（policy evaluation）</strong>：计算当前策略下，每个状态的函数值函数，策略评估可以通过贝尔曼方程 ( \ref{meap} ) 进行计算 \(V^\pi(s)\)。</li>
<li><strong>策略改进（policy imporvement）</strong>：根据值函数来更新策略。</li>
</ol>

<p>策略迭代算法如下：<br/>
<strong>输入</strong>：MDP五元组：\(\mathcal S,\mathcal A,P,r,\gamma\)；<br/>
<strong>输出</strong>：策略 \(\pi\)；<br/>
<strong>算法过程</strong></p>

<ul>
<li>初始化：\(\forall s,\forall a,\pi(a|s) = \frac{1}{|\mathcal A|}\)；</li>
<li>repeat：

<ul>
<li>repeat：//策略评估

<ul>
<li>根据贝尔曼方程 ( \ref{meap} ) 计算 \(V^\pi(s),\forall s\)；</li>
</ul></li>
<li>until \(\forall s,V^\pi(s)\) 收敛</li>
<li>根据公式  ( \ref{qpsa} ) 计算 \(Q(s,a)\)；</li>
<li>\(forall s,\pi(s) = \arg\max_a Q(s,a)\)；</li>
</ul></li>
<li>until \(\forall s\)，\(\pi(s)\) 收敛；</li>
</ul>

<p>现在我们将<strong>策略评估</strong>和<strong>策略改进</strong>算法分开重点阐述一下，并举例说明。</p>

<ol>
<li><p>策略评估</p>

<p>循环每一个状态 \(s\)，在该状态下循环所有所有的动作，利用贝尔曼公式 ( \ref{meap} ) ，利用当前的 \(V^\pi(s)\) 计算 \(V^\pi(s)\) 直到收敛。</p>

<p><strong>输入</strong>：策略 \(\pi\)，要估计的策略；<br/>
<strong>输出</strong>：收敛后的状态值 \(V^\pi\)；<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>初始化 \(\forall s \in \mathcal S, V^\pi(s) = 0\)；</li>
<li>repeat：

<ul>
<li>\(\triangle \leftarrow 0\)</li>
<li>for each \(s \in \mathcal S\):do

<ul>
<li>\(v \leftarrow V^\pi(s)\)</li>
<li>\(V(s) \leftarrow \mathbb E_{a\sim \pi(a|s)}\mathbb E_{s&#39;\sim p(s&#39;|s,a)}[r(s,a,s&#39;) + \gamma V^\pi(s&#39;)]\)</li>
<li>\(\triangle \leftarrow max(\triangle,|v - V^\pi(s)|)\)</li>
</ul></li>
<li>end for</li>
</ul></li>
<li>until \(\triangle \lt \theta\)（一个很小的正数）</li>
<li>return \(V^\pi\)</li>
</ul></li>
<li><p>策略改进</p>

<p>我们计算策略的价值函数的原因是了帮助找到更好的策略。因为我们之前进行了策略评估得到了上一个策略下的每个状态下的状态值，所以接下来就要根据这些状态值对策略进行改进，计算出新的策略。计算方式如下 <br/>
在每个状态 \(s\) 时，对每个可能的动作 \(a\) ,都计算一下采取这个动作后到达的下一个状态的期望价值。看看哪个动作可以到达的状态的期望价值函数最大，就选取这个动作。以此更新了 \(\pi(s)\)。</p>

<p>首先我们可以根据公式 ( \ref{meap} ) 计算 \(Q(s,a)\)，再利用<br/>
\[<br/>
\pi(s) = \arg\max_a Q(s,a)<br/>
\]</p>

<p>改进策略。</p>

<p><strong>输入</strong>：上一步收敛的 \(V^\pi\)；<br/>
<strong>输出</strong>：策略 \(\pi\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>repeat：

<ul>
<li>policy-stable \(\leftarrow\) true</li>
<li>for each \(s\in \mathcal S\): do

<ul>
<li>\(\text{old-action}\leftarrow \pi(s)\)</li>
<li>\(\pi(s) \leftarrow \arg\max_a \mathbb E_{s&#39;\sim p(s&#39;|s,a)}[r(s,a,s&#39;) + \gamma V^\pi(s&#39;)]\)</li>
<li>if \(\text{old-action}\neq \pi(s)\)，then policy-stable\(\leftarrow\) false</li>
</ul></li>
<li>if policy-stable：

<ul>
<li>停止并返回 \(V^\pi\) 和 \(\pi\)</li>
</ul></li>
<li>else

<ul>
<li>继续策略评估步骤</li>
</ul></li>
</ul></li>
</ul></li>
</ol>

<p>策略评估和策略改进两部分就组成了策略迭代，策略迭代的算法如下：<br/>
<strong>输入</strong>：MDP 五元组：\(\mathcal S\)，\(\mathcal A\)，\(P\)，\(r\)，\(\gamma\);<br/>
<strong>输出</strong>：输出 \(\pi\);<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>初始化：\(\forall s,\forall a,\pi(a|s) = \frac{1}{|\mathcal A|}\);</li>
<li>repeat:

<ul>
<li>策略评估</li>
<li>repeat:

<ul>
<li>根据贝尔曼方程 ( 公式\ref{meap} )，计算 \(V^{\pi}(s),\forall s\);</li>
</ul></li>
<li>until \(\forall s,V^{\pi}(s)\) 收敛;</li>
<li>策略改进</li>
<li>根据公式 ( \ref{qpsa} ) 计算 \(Q(s,a)\);</li>
<li>\(\forall s,\pi(s) = \arg\max_a Q(s,a)\);</li>
<li>until \(\forall s,\pi(s)\) 收敛;</li>
<li>输出：策略 \(\pi\)</li>
</ul></li>
</ul>

<p>用 python 简单的实现这两个过程，可以参考<a href="https://zhuanlan.zhihu.com/p/28084990">这篇文章</a>，我们这里使用这个简单的例子来了解一下这两个过程。</p>

<h5 id="toc_13">值迭代</h5>

<p>策略迭代中的<strong>策略评估</strong>和<strong>策略改进</strong>是交替轮流进行，其中策略评估也是通过一个内部迭代来进行计算，其计算量比较大。事实上，我们不需要每次计算出每次策略对应的精确的值函数，也就是说内部迭代不需要执行到完全收敛。</p>

<p>值迭代（Value Iteration）方法将策略评估和策略改进两个过程合并，来直接计算出最优策略。</p>

<p>假设最优策略 \(\pi^*\) 对应的值函数称为最优值函数，那么最优状态值函数 \(V^*(s)\) 和最优状态-动作值函数 \(Q^*(s,a)\) 的关系为<br/>
\[<br/>
V^*(s) = \max_a Q^*(s,a)<br/>
\]</p>

<p>根据贝尔曼方程可知，最优状态值函数 \(V^*(s)\) 和最优状态-动作函数 \(Q^*(s,a)\) 也可以进行迭代计算<br/>
\[<br/>
\begin{align}<br/>
V^*(s) &amp;= \max_a \mathbb E_{s&#39;\sim p(s&#39;|s,a)}\Big [r(s,a,s&#39;) + \gamma V^*(s&#39;) \Big]\label{vsmm}\\<br/>
Q^*(s,a) &amp;= \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \Big[r(s,a,s&#39;) + \gamma \max_{a&#39;} Q^*(s&#39;,a&#39;)]\label{qsme}\\<br/>
\end{align}<br/>
\]</p>

<p>这个公式称为<strong>贝尔曼最优方程（Bellman Optimality Equation）</strong>。</p>

<p>值迭代算法如下：<br/>
<strong>输入</strong>：MDP五元组：\(\mathcal S,\mathcal A,P,r,\gamma\)；<br/>
<strong>输出</strong>：策略 \(\pi\)；<br/>
<strong>算法过程</strong></p>

<ol>
<li>初始化：\(\forall s,V(s) = 0\)；</li>
<li>repeat：

<ul>
<li>\(\forall s,V(s)\leftarrow \max_a \mathbb E_{s&#39;\sim p(s&#39;|s,a)} \Big [r(s,a,s&#39;) + \gamma V(s&#39;) \Big ]\)；</li>
</ul></li>
<li>until \(forall s\)，\(V(s)\) 收敛；</li>
<li>根据公式 ( \ref{qsme} ) 计算 \(Q(s,a)\)；</li>
<li>\(forall s,\pi(s) = \arg\max_a Q(s,a)\)；</li>
</ol>

<h5 id="toc_14">策略迭代与值迭代比较</h5>

<p>在策略迭代中，每次迭代的时间复杂度最大为 \(O(|S|^3|A|^3)\)，<br/>
最大迭代次数为 \(|A|^{|S|}\) 。而在值迭代中，每次迭代的时间复杂度最大为 \(O(|S|^2|A|)\)，<br/>
但迭代次数要比策略迭代算法更多。</p>

<p>策略迭代是根据贝尔曼方程来更新值函数，并根据当前的值函数来改进策<br/>
略。而值迭代算法是直接使用贝尔曼最优方程来更新值函数，收敛时的值函数就是最优的值函数，其对应的策略也就是最优的策略。</p>

<p>值迭代和策略迭代都需要经过非常多的迭代次数才能完全收敛。在实际应<br/>
用中，可以不必等到完全收敛。这样，当状态和动作数量有限时，经过有限次迭代就可以能收敛到近似最优策略。</p>

<p>基于模型的强化学习算法实际上是一种动态规划方法。在实际应用中有以下两点限制。</p>

<ol>
<li><p>要求模型已知，即要给出马尔可夫决策过程的状态转移概率 \(p(s&#39;|s,a)\) 和奖励函数 \(r(s,a,s&#39;)\)，这个要求很难满足。如果是事先不知道模型，但仍然希望通过基于模型的学习算法，也可以通过与环境交互来学习出状态转移概率和奖励函数。一个简单的计算模型的方法为 R-max [Brafman and Tennenholtz, 2002]，通过随机游走的方法来探索环境。每次随机一个策略并执行，然后收集状态转移和奖励的样本。在收集一定的样本后，就可以通过统计或监督学习来重构出马尔可夫决策过程。但是，这种基于采样的重构过程的复杂度也非常高，只能应用于状态数非常少的场合。</p></li>
<li><p>效率问题，当状态数量较大的时候，算法的效率比较低。但在实际应用中，很多问题的状态数量和动作数量非常多。比如，围棋有 19 × 19 = 361个位置，每个位置有黑子、白子或无子三种状态，整个棋局有 \(3^361 \sim 10^170\) 种状态。动作（即落子位置）数量为 361。不管是值迭代还是策略迭代，以当前计算<br/>
机的计算能力，根本无法计算。一个有效的方法是通过一个函数（比如神经网络）来近似计算值函数，以减少复杂度，并提高泛化能力。</p></li>
</ol>

<h4 id="toc_15">模特卡罗方法</h4>

<p>在很多应用场景中，马尔可夫决策过程的状态转移概率 \(p(s&#39;|s,a)\) 和奖励函数 \(r(s,a,s&#39;)\) 都是未知的。在这种情况下，我们一般需要智能体和环境进行交互，并收集一些样本。然后再根据这些样本来求解马尔可夫决策过程最优策略。这种模型未知，基于采样的学习算法也称为模型无关的强化学习（Model-Free Reinforcement Learning）算法（也称为无模型的强化学习）。</p>

<p>Q函数 \(Q^\pi(s,a)\) 为初始状态为 \(s\)，并执行动作 \(a\) 后的所能得到的期望总回报，可以写为<br/>
\[<br/>
Q^\pi(s, a) = \mathbb E_{\tau \sim p(\tau)} [G(\tau_{s_0=s,a_0=a})]<br/>
\]</p>

<p>其中 \(\tau_{s_0=s,a_0=a}\) 表示轨迹 \(\tau\) 的起始状态和动作为 \(s\), \(a\)。</p>

<p>如果模型未知，Q函数可以通过采样来进行计算，这就是蒙特卡罗方法。对于一个策略 \(\pi\)，智能体从状态 \(s\)，执行动作 \(a\) 开始，然后通过随机游走的方法来探索环境，并计算其得到的总回报。假设我们进行 \(N\) 次试验，得到 \(N\) 个轨迹 \(\tau(1), \tau(2), \cdots, \tau(N)\)，其总回报分别为 \(G(\tau(1))\) , \(G(\tau(2))\) ,..., \(G(\tau(N))\)。 Q函数可以近似为<br/>
\[<br/>
Q^\pi(s,a) \approx \hat Q^\pi(s,a) = \frac 1 N \sum_{i=1}^N G(\tau^{(i)}_{s_0=s,a_0=a})<br/>
\]</p>

<p>当 \(N \rightarrow \infty\) 时， \(Q^\pi(s,a) \rightarrow Q^\pi(s,a)\)。</p>

<p>在近似估计出 Q函数 \(Q^\pi(s,a)\) 之后，就可以进行策略改进。然后在新的策略下重新通过采样来估计 Q函数，并不断重复，直至收敛。</p>

<p><strong>利用和探索</strong>：但在蒙特卡罗方法中，如果采用确定性策略 \(\pi\)，每次试验得到的轨迹是一样的，只能计算出 \(Q^\pi(s,\pi(s))\)，而无法计算其它动作 \(a&#39;\) 的 Q函数，因此也无法进一步改进策略。这样情况仅仅是对当前策略的利用（exploitation），而缺失了对环境的探索（exploration），即试验的轨迹尽可能覆盖所有的状态和动作，以找到更好的策略。</p>

<p>为了平衡利用和探索，我们可以采用 \(\epsilon\)-贪心法（\(\epsilon\)-greedy method）。对于多臂赌博机问题。一个目标策略 \(\pi\)，其对应的 \(\epsilon\)-贪心法策略为<br/>
\[<br/>
\pi^\epsilon(s) = \left \{ \begin{array}\\\pi(s)\quad&amp;\text{按照概率 }1-\epsilon\\\text{随机选择 }\mathcal A\text{ 中的动作}\quad&amp;\text{按概率 }\epsilon\\\end{array}\right .<br/>
\]</p>

<p>这样， \(\epsilon\)-贪心法将一个仅利用的策略转为带探索的策略。每次选择动作 \(\pi(s)\) 的概率为 \(1 − \epsilon + \frac{1}{|\mathcal A|}\)，其它动作的概率为 \(\frac{1}{|\mathcal A|}\)。</p>

<p><strong>同策略</strong>：在蒙特卡罗方法中，如果采样策略是 \(\pi^\epsilon(s)\)，不断改进策略也是 \(\pi^\epsilon(s)\) 而不是目标策略 \(\pi(s)\)。这种采样与改进策略相同（即都是 \(\pi^\epsilon(s)\)）的强化学习方法叫做同策略（on policy）方法。</p>

<p><strong>异策略</strong>：如果采样策略是 \(\pi^\epsilon(s)\)，而优化目标是策略 \(\pi\)，可以通过重要性采样，引入重要性权重来实现对目标策略 \(\pi\) 的优化。这种采样与改进分别使用不同策略的强化学习方法叫做异策略（off policy）方法。</p>

<h4 id="toc_16">时序差分学习方法</h4>

<p>蒙特卡罗采样方法一般需要拿到完整的轨迹，才能对策略进行评估并更新模型，因此效率也比较低。</p>

<p>时序差分学习（temporal-difference learning）结合了动态规划和蒙特卡罗方法，比仅仅使用蒙特卡罗采样方法的效率要高很多 [Sutton and Barto, 2011]。时序差分学习是模拟一段轨迹，每行动一步(或者几步)，就利用贝尔曼方程来评估行动前状态的价值。当时序差分学习中每次更新的动作数为最大步数时，就等价于蒙特卡罗方法。</p>

<p>首先，将蒙特卡罗方法中 Q函数 \(Q^\pi(s,a)\) 的估计改为增量计算的方式，假设第 \(N\) 试验后值函数 \(\hat Q^\pi_N(s,a)\) 的平均为<br/>
\[<br/>
\begin{align*}<br/>
\hat Q^\pi_N(s,a) &amp;= \frac 1 N \sum_{i=1}^N G(\tau^{(i)}_{s_0 = s,a_0 = a})\\<br/>
&amp;= \frac 1 N \Big( G(\tau^{(N)}_{s_0 = s,a_0 = a}) + \sum_{i=1}^{N-1}G(\tau^{(i)_{s_0=s,a_0=a}}) \Big) \\<br/>
&amp;= \frac 1 N \Big( G(\tau^{(N)}_{s_0 = s,a_0 = a}) + (N-1)Q^\pi_{N-1}(s,a)\Big)\\<br/>
&amp;= \hat Q^\pi_{N-1}(s,a) + \frac 1 N \Big( G(\tau^{N}_{s_0=s,a_0=a}) - \hat Q^\pi_{N-1}(s,a) \Big)\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\tau_{s_0=s,a_0=a}\) 表示轨迹 \(\tau\) 的起始状态和动作为 \(s,a\)。</p>

<p>值函数 \(\hat Q^\pi(s,a)\) 在第 \(N\) 试验后的平均加加上一个增量，更一般性地，我们将权重系数 \(\frac 1 N\) 改成一个比较小的正数 \(\alpha\)。这样每次采用一个新的轨迹 \(\tau_{s_0=s,a_0=a}\)，就可以更新 \(\hat Q^\pi(s,a)\)。<br/>
\[<br/>
\begin{equation}<br/>
\hat Q^\pi(s,a) \leftarrow \hat Q^\pi(s,a) + \alpha \Big( G(\tau_{s_0=s,a_0=a}) - \hat Q^\pi(s,a) \Big)\label{hqpl}<br/>
\end{equation}<br/>
\]</p>

<p>其中增量 \(\delta  \buildrel \Delta \over = G(\tau_{s_0=s,a_0=a}) - \hat Q^\pi(s,a)\) 称为蒙特卡罗误差，表示当前轨迹的真实回报 \(G(\tau_{s_0=s,a_0=a})\) 与期望回报 \(\hat Q^\pi(s,a)\) 之间的差距。</p>

<p>在式 ( \ref{hqpl} ) 中，\(G(\tau_{s_0=s,a_0=a})\) 为一次实验的完整轨迹所得到的总回报。为了提高效率，可以借助动态规划的方法来计算 \(G(\tau_{s_0=s,a_0=a})\) ，而不需要得到完整的轨迹。从 \(s\)，\(a\) 开始，采样下一步的状态和动作 \((s&#39;,a&#39;)\)，并得到奖励 \(r(s,a,s&#39;)\)，然后利用贝尔曼方程来近似估计 \(G(\tau_{s_0=s,a_0=a})\) ,<br/>
\[<br/>
\begin{align}<br/>
G(\tau_{s_0=s,a_0=a,s_1=s&#39;,a_1=a&#39;}) &amp;= r(s,a,s&#39;) + \gamma G(\tau_{s_0=s&#39;,a_0=a&#39;}) \nonumber\\<br/>
&amp;\simeq r(s,a,s&#39;) + \gamma \hat Q^\pi(s&#39;,a&#39;)\label{gssr}\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(\hat Q^\pi(s&#39;,a&#39;)\) 是当前 Q函数的近似估计。</p>

<p>结合公式 ( \ref{hqpl} ) 和 ( \ref{gssr})，有<br/>
\[<br/>
\hat Q^\pi(s,a) \leftarrow \hat Q^\pi(s,a) + \alpha\Big( r(s,a,s&#39;) + \gamma\hat Q^\pi(s&#39;a&#39;) - \hat Q^\pi(s,a) \Big)<br/>
\]</p>

<p>因此，更新 \(\hat Q^\pi(s,a)\) 只需要知道当前状态 \(s\) 和动作 \(a\)、奖励 \(r(s,a,s&#39;)\)、下一步的状态 \(s&#39;\) 和动作 \(a&#39;\)。这种策略学习称为 SARSA 算法。</p>

<p>SARSA算法其采样和优化的策略都是 \(\pi^\epsilon\)，因此是一种同策略算法。为了提高计算效率，我们不需要对环境中所有的 \(s,a\) 组合进行穷举，并计算值函数。只需要将当前的探索 \((s,a,r,s&#39;,a&#39;)\) 中\(s&#39;\),\(a&#39;\) 作为下一次估计的起始状态和动作。</p>

<p><strong>输入</strong>：状态空间 \(\mathcal S\)，动作空间 \(\mathcal A\)，折扣率 \(\gamma\)，学习率 \(\alpha\)<br/>
<strong>输出</strong>：策略 \(\pi(s)\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>随机初始化 \(Q(s,a)\)；</li>
<li>\(\forall s,\forall a,\pi(a|s) = \frac{1}{|\mathcal A|}\)；</li>
<li>repeat

<ul>
<li>初始化起始动作 \(s\)；</li>
<li>选择动作 \(a=\pi^\epsilon(s)\)；\qquad<font>采样策略使用 \(\pi^\epsilon\) </font></li>
<li>repeat

<ul>
<li>执行动作 \(a\)，得到即时奖励 \(r\) 和新状态 \(s&#39;\)；</li>
<li>在状态 \(s&#39;\)，选择动作 \(a&#39; = \pi^\epsilon(s&#39;)\)；\qquad<font>优化策略(\(a&#39;\)的选择)使用 \(\pi^\epsilon\)</font></li>
<li>\(Q(s,a) \leftarrow Q(s,a) + \alpha\Big( r + \gamma Q(s&#39;,a&#39;) - Q(s,a) \Big)\)</li>
<li>更新策略：\(\pi(s) = \arg\max_{\alpha\in|\mathcal A|} Q(s,a)\)；</li>
<li>\(s\leftarrow s&#39;,a\leftarrow a&#39;\)；</li>
</ul></li>
<li>until \(s\) 为终止状态；</li>
</ul></li>
<li>until \(\forall s,a\)，\(Q(s,a)\) 收敛；</li>
<li>输出 \(\pi(s)\)</li>
</ul>

<p>时序差分学习是强化学习的主要学习方法，其关键步骤就是在每次迭代中优化 Q 函数来减少现实 \(r + \gamma Q(s&#39;, a&#39;)\) 和预期 \(Q(s,a)\) 的差距。这和动物学习的机制十分相像。在大脑神经元中，多巴胺的释放机制和时序差分学习十分吻合。Schultz [1998]的一个实验中，通过监测猴子大脑释放的多巴胺浓度，发现如果猴子获得比预期更多的果汁，或者在没有预想到的时间喝到果汁,多巴胺释放大增。如果本来预期的果汁没有喝到，多巴胺的释放就会大减。多巴胺的释放, 来自对于实际奖励和预期奖励的差异，而不是奖励本身。</p>

<p>时序差分学习和蒙特卡罗方法的主要不同为：蒙特卡罗需要完整一个路径完成才能知道其总回报，也不依赖马尔可夫性质；而时序差分学习只需要一步，其总回报需要依赖马尔可夫性质来进行近似估计。</p>

<h5 id="toc_17">Q学习</h5>

<p>Q学习（Q-Learning）算法 [Watkins and Dayan, 1992]是一种异策略的时<br/>
序差分学习算法。在 Q学习中，\(a&#39;\) 的选择方法为<br/>
\[<br/>
a&#39; \leftarrow max_{a&#39;}Q(s&#39;,a&#39;)<br/>
\]</p>

<p>与 SARSA 算法的不同， Q 学习算法不通过 \(\pi^\epsilon\) 来选下一步的动作 \(a&#39;\)，而是<br/>
直接选最优的 Q函数，因此更新后的 Q函数是关于策略 \(\pi\) 的，而不是策略 \(\pi^\epsilon\) 的。</p>

<p><strong>输入</strong>：状态空间 \(\mathcal S\)，动作空间 \(\mathcal A\)，折扣率 \(\gamma\)，学习率 \(\alpha\)<br/>
<strong>输出</strong>：策略 \(\pi(s)\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>随机初始化 \(Q(s,a)\)；</li>
<li>\(\forall s,\forall a,\pi(a|s) = \frac{1}{|\mathcal A|}\)；</li>
<li>repeat

<ul>
<li>初始化起始动作 \(s\)；</li>
<li>选择动作 \(a=\pi^\epsilon(s)\)；\qquad<font>采样策略使用 \(\pi^\epsilon\) </font></li>
<li>repeat

<ul>
<li>执行动作 \(a\)，得到即时奖励 \(r\) 和新状态 \(s&#39;\)；</li>
<li>优化策略(\(a&#39;\)的选择)使用 \(\pi^\epsilon\)</font></li>
<li>\(Q(s,a) \leftarrow Q(s,a) + \alpha\Big( r + \gamma \max_{a&#39;} Q(s&#39;,a&#39;) - Q(s,a) \Big)\)</li>
<li>更新策略：\(\pi(s) = \arg\max_{\alpha\in|\mathcal A|} Q(s,a)\)；</li>
<li>\(s\leftarrow s&#39;,a\leftarrow a&#39;\)；</li>
</ul></li>
<li>until \(s\) 为终止状态；</li>
</ul></li>
<li>until \(\forall s,a\)，\(Q(s,a)\) 收敛；</li>
<li>输出 \(\pi(s)\)</li>
</ul>

<h4 id="toc_18">深度Q网络</h4>

<p>假设现在我们使用Q学习来模拟计算机玩游戏，我们会将输入原始图像数据，假设为300*240像素的图片，然后输出几个按键（上下左右）。这种情况下，每一秒钟的状态都不一样，从理论上看，如果每一个像素都有 256种选择，那么就有<br/>
\[<br/>
256^{320\times 240}<br/>
\]</p>

<p>这时候我们便不可能再通过矩阵来存储状态了，我们有必要对状态的维度进行压缩，解决办法就是值函数近似（value function approximation）。</p>

<p>为了在连续的状态和动作空间中计算值函数 \(Q_\pi(s,a)\)，我们可以用一个函数 \(Q\phi(s,a)\) 来表示近似计算，称为值函数近似。<br/>
\[<br/>
Q_\phi(\mathbf s,\mathbf a) \approx Q_\pi(s,a)<br/>
\]</p>

<p>其中 \(\mathbf s\), \(\mathbf a\) 分别是状态 \(s\) 和动作 \(a\) 的向量表示；函数 \(Q_\phi(\mathbf s,\mathbf a)\) 通常是一个参数为 \(\phi\) 的函数，比如神经网络，输出为一个实数，称为 Q网络（Q-network）。</p>

<blockquote>
<p>如果我们假设 \(Q_phi(\mathbf s,\mathbf a)\) 是一个线性函数，如下面这样的函数<br/>
\[<br/>
Q_\phi(\mathbf s,\mathbf a) = \mathbf w_1^T \mathbf s + \mathbf w_2^T \mathbf a + b<br/>
\]</p>

<p>其中参数 \(\phi=(\mathbf w_1,\mathbf w_2,b)\)。通过函数表示，我们就可以无所谓 \(s\) 到底是多大的维度，反正最后都通过矩阵运算降维输出为单值的 Q。</p>
</blockquote>

<p>如果动作为有限离散的 m 个动作 \(a_1,...,a_m\)，我们可以让 Q网络输出一个 m 维向量，其中每一维用 \(Q\phi(s,a_i)\) 来表示，对应值函数 \(Q(s,a_i)\) 的近似值。<br/>
\[<br/>
\begin{align*}<br/>
Q_\phi(\mathbf s) = \left [\begin{array}{c}Q_phi(\mathbf s,a_1)\\Q_phi(\mathbf s,a_2)\\...\\Q_phi(\mathbf s,a_n)\\\end{array} \right ] = \left [\begin{array}{c}Q^\pi(s,a_1)\\Q^\pi(s,a_2)\\...\\Q^\pi(s,a_n)\\\end{array}\right ]<br/>
\end{align*}<br/>
\]</p>

<p>我们需要学习一个参数 \(\phi\) 来使得函数 \(Q_\phi(\mathbf s,\mathbf a)\) 可以逼近值函数 \(Q^\pi(s,a)\)。如果采用蒙特卡罗方法，就直接让 \(Q_\phi(\mathbf s,\mathbf a)\) 去逼近平均的总回报 \(\hat Q^\pi(s,a)\)；如果采样时序差分方法，就让 \(Q_\phi(\mathbf s,\mathbf a)\) 去逼近 \(\mathbb E_{s&#39;,a&#39;}[r+\gamma Q_\phi(\mathbf s&#39;,\mathbf a&#39;)]\)。</p>

<p>以 Q学习为例，采用随机梯度下降，目标函数为 <br/>
\[<br/>
L(s,a,s&#39;|\phi) = \bigg(r + \gamma max_{a} Q_\phi(\mathbf s&#39;, \mathbf a&#39;)-Q_\phi(\mathbf s,\mathbf a)\bigg)^2<br/>
\]</p>

<p>其中 \(\mathbf s&#39;,\mathbf a&#39;\) 是下一时刻的状态 \(s&#39;\) 和动作 \(a&#39;\) 的向量表示。</p>

<p>然而，这个目标函数存在两个问题：一是目标不稳定，参数学习的目标依赖于参数本身；二是样本之间有很强的相关性。为了解决这两个问题，Mnih et al.[2015]提出了一种深度Q网络（deep Q-networks， DQN）。深度 Q网络采取两个措施：一是目标网络冻结（freezing target networks），即在一个时间段内固定目标中的参数，来稳定学习目标；二是经验回放（experience replay），构建一个经验池来去除数据相关性。经验池是由智能体最近的经历组成的数据集。经验回放可以形象地理解为在回忆中学习。</p>

<p>训练时，随机从经验池中抽取样本来来代替当前的样本用来进行训练。这样，也可以就打破了和相邻训练样本的相似性，避免模型陷入局部最优。经验回放在一定程度上类似于监督学习。先收集样本，然后在这些样本上进行训练。</p>

<p>经验回放的好处是：1）深度神经网络作为有监督学习模型，要求数据满足独立同分布；2）但 Q Learning 算法得到的样本前后是有关系的。由一个连续动作序列产生的经验相互之间具有很大的相关性，一个相关性很高的样本会增大更新的方差，甚至会导致算法不稳定。为了打破数据之间的关联性，Experience Replay 方法通过存储-采样的方法将这个关联性打破了。</p>

<p>深度 Q网络的学习过程如算法如下：</p>

<p><strong>输入</strong>: 状态空间 \(\mathcal S\)，动作空间 \(\mathcal A\)，折扣率 \(\gamma\)，学习率 \(\alpha\)；<br/>
<strong>输出</strong>：Q网络 \(Q_\phi(s,a)\)；<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>初始化经验池 \(\mathcal D\)，容量为 \(N\);</li>
<li>随机初始化 Q网络的参数 \(\phi\);</li>
<li>随机初始化目标 Q网络的参数 \(\hat\phi = \phi\);</li>
<li>repeat

<ul>
<li>初始化起始状态 \(s\);</li>
<li>repeat

<ul>
<li>在状态 \(s\)，选择动作 \(a = \pi^\epsilon\);</li>
<li>执行动作 \(a\)，观测环境，得到即时奖励 \(r\) 和新的状态 \(s&#39;\);</li>
<li>将 \(s,a,r,s&#39;\) 放入 \(\mathcal D\) 中;</li>
<li>从 \(\mathcal D\) 中采样 \(ss,aa,rr,ss&#39;\);
\[
\begin{align*}
y = \left \{\begin{array}{ll} rr,\qquad&amp; ss&#39;\text{ is terminative node}\\rr+\gamma \max_{a&#39;} Q_{\hat \phi}(ss&#39;,a&#39;),\qquad&amp; \text{otherwise}\\\end{array}
\right .
\end{align*}
\]</li>
<li>用梯度下降法以 \((y − Q_\phi(s,a))^2\) 为损失函数来训练 Q网络;</li>
<li>\(s \leftarrow s&#39;\);</li>
<li>每隔 C 步， \(\hat \phi \leftarrow \phi\);</li>
</ul></li>
<li>until \(s\) 为终止状态;</li>
</ul></li>
<li>until \(\forall s,a\)， \(Q_\phi(s,a)\) 收敛;</li>
</ul>

<p>在上述过程中</p>

<p>整体上，在基于值函数的学习方法中，策略一般为确定性的策略。策略优化通常都依赖于值函数，比如贪心策略 \(\pi(s) = \arg\max_a Q(s,a)\)。最优策略一般需要遍历当前状态 \(s\) 下的所有动作，并找出最优的 \(Q(s,a)\)。如果动作空间离散但是很大时，那么遍历求最大需要很高的时间复杂度；如果动作空间是连续的并且 \(Q(s,a)\) 非凸时，也很难求解出最佳的策略。</p>

<blockquote>
<p>在DQN中常见的策略优化时采用的是贪心策略，也就是说DQN常见的是off-policy的方法。由于使用了经验池，在更新当前权重的时候，其样本并不是基于当前权重的greedy策略（目标策略），因此，就必然地需要使用off-policy的方法，比如这里使用的Q-learning；</p>
</blockquote>

<h3 id="toc_19">基于策略函数的学习方法</h3>

<p>强化学习的目标是学习到一个策略 \(\pi_\theta(a|s)\) 来最大化期望回报。一种直接的方法是在策略空间直接搜索来得到最佳策略，称为策略搜索（ policy search）。策略搜索本质是一个优化问题，可以分为基于梯度的优化和无梯度优化。策略<br/>
搜索和基于值函数的方法相比，策略搜索可以不需要值函数，直接优化策略。参数化的策略能够处理连续状态和动作，可以直接学出随机性策略。</p>

<p>策略梯度（ policy gradient）是一种基于梯度的强化学习方法。假设 \(\pi_\theta(a|s)\) 是一个关于 \(\theta\) 的连续可微函数<br/>
\[<br/>
\mathcal J(\theta) = \mathbb E_{\tau\sim p_{\theta}(\tau)}[G(\tau)] = \mathbb E_{\tau\sim p_\theta(\tau)}[\sum_{t=0}^{T-1} \gamma^t r_{t+1}]<br/>
\]</p>

<p>我们可以用梯度上升的方法来优化参数 \(\theta\) 使得目标函数 \(\mathcal J(\theta)\) 最大。<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathcal J(\theta)}{\partial \theta} &amp;= \frac{\partial}{\partial \theta}\int p_\theta(\tau)G(\tau)d\tau\\<br/>
&amp;= \int \bigg(\frac{\partial}{\partial \theta} p_\theta(\tau) \bigg) G(\tau)d\tau\\<br/>
&amp;= \int p_\theta(\tau) \bigg(\frac{1}{p_\theta(\tau)} \frac{\partial}{\partial \theta}p_\theta(\tau)\bigg) G(\tau)d\tau\\<br/>
&amp;= \int p_\theta(\tau) \bigg( \frac{\partial}{\partial \theta} \log p_\theta(\tau) \bigg) G(\tau)d\tau\\<br/>
&amp;= \mathbb E_{\tau\sim p_\theta(\tau)}\bigg[\frac{\partial}{\partial \theta} \log p_\theta(\tau) G(\tau)\bigg]\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\frac{\partial}{\partial \theta} \log p_\theta(\tau)\) 为函数 \(\log p_\theta(\tau)\) 关于 \(\theta\) 的偏导数。从上式可以看出，参数 \(\theta\) 优化的方向是使得总回报 \(G(\tau)\) 越大的轨迹 \(\tau\) 的概率 \(p_\theta(\tau)\) 也越大。</p>

<p>\(\log p_\theta(\tau)\) 可以进一步分解为<br/>
\[<br/>
\begin{align*}<br/>
\log p_\theta(\tau) &amp;= \frac{\partial}{\partial \theta}\log\bigg(p(s_0) \prod_{t=0}^{T-1} \pi_\theta(a_t|s_t) p(s_{t+1}|s_t,a_t) \bigg)\\<br/>
&amp;= \frac{\partial}{\partial \theta} \bigg(\log p(s_0) + \sum_{t=0}^{T-1} \log \pi_\theta(a_t|s_t) + \log p(s_{t+1}|s_t,a_t)\bigg)\\<br/>
&amp;= \frac{\partial}{\partial \theta} \bigg( \log p(s_0) + \sum_{t=0}^{T-1}  \pi_\theta(a_t|s_t) + \log p(s_{t+1}|s_t,a_t) \bigg)\\<br/>
&amp;= \sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t)<br/>
\end{align*}<br/>
\]</p>

<p>可以看出，\(\frac{\partial}{\partial \theta} \log p_\theta(\tau)\) 是和状态转移概率无关，只和策略函数相关。</p>

<p>因此，策略梯度 \(\frac{\partial \mathcal J(\theta)}{\partial \theta}\) 可写为<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial \mathcal J(\theta)}{\partial \theta} &amp;= \mathbb E_{\tau \sim p_\theta(\tau)} \bigg [\bigg( \sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) \bigg) G(\tau)\bigg ]\nonumber\\<br/>
&amp;= \mathbb E_{\tau \sim p_\theta(\tau)} \bigg [\bigg( \sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) \bigg)\Big(G(\tau_{1,t-1}) + \gamma^t G(\tau_{t:T}) \Big) \bigg ]\nonumber\\<br/>
&amp;= \mathbb E_{\tau \sim p_\theta(\tau)} \bigg [\bigg( \sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) G(\tau_{1,t-1})\bigg) + \bigg(\sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) \gamma^t G(\tau_{t:T}) \bigg) \bigg ]\label{meps}\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(G(\tau_{t:T})\) 为从时刻 \(t\) 作为起始时刻收到总回报<br/>
\[<br/>
G(\tau_{t:T}) = \sum^{T−1}_{t&#39;=t} \gamma^{t&#39;-t} r_{t&#39;+1}<br/>
\]</p>

<p>然而，当前的动作与过去的回报实际上是没有关系的，即对于 \(t&#39;\lt t\)，有<br/>
\[<br/>
\mathbb E r(s_{t&#39;},a_{t&#39;},s_{t&#39;+1}) \frac{\partial}{\partial \theta} \log\pi_{\theta}(a_{t}|s_{t}) = 0<br/>
\]</p>

<p>所以<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E_{\tau \sim p_\theta(\tau)}  \sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) G(\tau_{1,t-1}) &amp;= \mathbb E_{\tau \sim p_\theta(\tau)}  \sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) \sum_{t&#39;=0}^{t-1} \gamma^{t&#39;} r(s_{t&#39;},a_{t&#39;},s_{t&#39;+1})\\<br/>
&amp;= \mathbb E_{\tau \sim p_\theta(\tau)}  \sum_{t=0}^{T-1} \sum_{t&#39;=0}^{t-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) \gamma^{t&#39;} r(s_{t&#39;},a_{t&#39;},s_{t&#39;+1})\\<br/>
&amp;= 0\\<br/>
\end{align*}<br/>
\]</p>

<p>因此，我们可以修改 \ref{meps} 中的回报函数：<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial \mathcal J(\theta)}{\partial \theta} = \mathbb E_{\tau \sim p_\theta(\tau)} \sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a_t|s_t) \gamma^t G(\tau_{t:T}) \label{fpmt}\\<br/>
\end{equation}<br/>
\]</p>

<h4 id="toc_20">REINFORCE算法</h4>

<p>公式 ( \ref{fpmt} ) 中，期望可以通过采样的方法来近似。对当前策略 \(\pi_\theta\) ，可以随机游走采集多个轨迹 \(\tau^{(1)}, \tau^{(2)},..., \tau^{(N)}\)，每一条轨迹 \(\tau^{(n)} = s_0^{(n)},a_0^{(n)},s_1^{(n)},a_1^{(n)},...\)，其梯度定义为<br/>
\[<br/>
\frac{\partial \mathcal J(\theta)}{\partial \theta} = \frac 1 N \sum_{n=1}^N \bigg(\sum_{t=0}^{T-1} \frac{\partial}{\partial \theta} \log \pi_\theta (a^{(n)}_t|s^{(n)}_t) \gamma^t G(\tau^{(n)}_{t:T}) \bigg)<br/>
\]</p>

<p>结合随机梯度上升算法，我们可以每次采集一条轨迹，计算每个时刻的梯度并更新参数，称为 REINFORCE算法[Williams, 1992]，如算法14.6所示。</p>

<p><strong>输入</strong>: 状态空间 \(\mathcal S\)，动作空间 \(\mathcal A\)，可微分的策略函数 \(\pi_\theta(a|s)\)，折扣率 \(\gamma\)，学习率 \(\alpha\)；<br/>
<strong>输出</strong>：策略 \(\pi_\theta\)；<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>随机初始化参数 \(\theta\);</li>
<li>repeat:

<ul>
<li>根据策略 \(\pi_\theta(a|s)\) 生成一条轨迹;</li>
<li>\(τ = s_0, a_0, s_1, a_1,..., s_{T−1}, a{T−1}, s_T\)</li>
<li>for t = 0 to T do:

<ul>
<li>计算 \(G(\tau_{t:T})\);</li>
<li>更新策略函数参数
\[
\theta \leftarrow \theta + \alpha \gamma^t G(\tau_{t:T}) \frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t)
\]</li>
</ul></li>
<li>end</li>
</ul></li>
<li>until \(\theta\) 收敛;
输出: 策略 \(\pi_\theta\);</li>
</ul>

<h4 id="toc_21">带基准线的REINFORCE算法</h4>

<p>REINFORCE算法的一个主要缺点是不同路径之间的方差很大，导致训练不稳定，这是在高维空间中使用蒙特卡罗方法的的通病。一种减少方差的通用方法是引入一个控制变量。假设要估计函数 \(f\) 的期望，为了减少 \(f\) 的方差，我们引入一个已知期望的函数 \(g\)，令<br/>
\[<br/>
\hat f = f - \alpha(g - \mathbb E[g])<br/>
\]</p>

<p>因为 \(\mathbb E[\hat f] = \mathbb E[f]\)，我们可以用 \(\hat f\) 的期望来估计函数 \(f\) 的期望，同时利用函数 \(g\) 来减小 \(\hat f\) 的方差。</p>

<p>函数 \(\hat f\) 的方差为<br/>
\[<br/>
\begin{align*}<br/>
\text{var}(\hat f) &amp;= \text{var}[f - \alpha(g - \mathbb E[g])]\\<br/>
&amp;= \text{var}[f - \alpha g + \alpha\mathbb E[g]]\\<br/>
&amp;= \text{var}[f - \alpha g]\\<br/>
&amp;= \text{var}(f) + \text{var}[\alpha g] - 2\text{cov}(f,\alpha g)\\<br/>
&amp;= \text{var}(f) + \alpha^2 \text{var}(g) - 2\alpha\text{cov}(f,g)\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\text{var}(\cdot)\), \(\text{cov}(\cdot,\cdot)\) 分别表示方差和协方差。</p>

<blockquote>
<p>D(X+Y) = D(X) + D(Y) + 2cov(X,Y)<br/>
D(X+c) = D(X)<br/>
D(aX) = a<sup>2D(X)</sup><br/>
cov(X,Y) = cov(Y,X)<br/>
cov(aX,bY) = a<em>b</em>cov(X,Y)<br/>
cov(X+Y,Z) = cov(X,Z) + cov(Y,Z)</p>
</blockquote>

<p>如果要使得 \(\text{var}(\hat f)\) 最小，令 \(\frac{\partial \text{var} \hat f}{\partial \alpha} = 0\)，得到<br/>
\[<br/>
\begin{align*}<br/>
&amp;\quad \frac{\partial \text{var} \hat f}{\partial \alpha} = 2\alpha \text{var}(g) - 2\text{cov}(f,g) = 0\\<br/>
&amp;\quad \Rightarrow\quad \alpha = \frac{\text{cov}(f,g)}{\text{var}(g)}<br/>
\end{align*}<br/>
\]</p>

<p>因此<br/>
\[<br/>
\begin{align*}<br/>
\text{var}(\hat f) &amp;= \text{var}(f) + \alpha^2 \text{var}(g) - 2\alpha\text{cov}(f,g)\\<br/>
&amp;= \text{var}(f) + \Big[\frac{\text{cov}(f,g)}{\text{var}(g)}\Big]^2 \text{var}(g) - 2\Big[\frac{\text{cov}(f,g)}{\text{var}(g)} \Big]\text{cov}(f,g)\\<br/>
&amp;= \text{var}(f) + \frac{\text{cov}(f,g)^2 - 2\text{cov}(f,g)^2}{\text{var}(g)}\\<br/>
&amp;= \text{var}(f) - \frac{\text{cov}(f,g)^2}{\text{var}(g)}\\<br/>
&amp;= \Big(1 - \frac{\text{cov}(f,g)^2}{\text{var}(g)\text{var}(f)}\Big)\text{var}(f)\\<br/>
&amp;= \Big(1 - \text{corr}(f,g)^2\Big) \text{var}(f)<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\text{corr}(f, g)\) 为函数 \(f\) 和 \(g\) 的相关性。如果相关性越高，则 \(\hat f\) 的方差越小。</p>

<blockquote>
<p>相关性的定义：<br/>
\[<br/>
\rho_{X,Y} = \frac{cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}<br/>
\]</p>
</blockquote>

<p><strong>带基准线的 REINFORCE 算法</strong>：在每个时刻 \(t\)，其策略梯度为<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathcal J_t(\theta)}{\partial\theta} = \mathbb E_{s_t}\Big[\mathbb E_{a_t} \Big[ \gamma^t G(\tau_{t:T} \frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t)) \Big] \Big]\\<br/>
\end{align*}<br/>
\]</p>

<p>为了减小策略梯度的方差，我们引入一个和 \(a_t\) 无关的基准函数 \(b(s_t)\)，<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \hat {\mathcal J_t}(\theta)}{\partial\theta} = \mathbb E_{s_t}\Big[\mathbb E_{a_t} \Big[ \gamma^t \big( G(\tau_{t:T}  - b(s_t)\big) \frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t)) \Big] \Big]\\<br/>
\end{align*}<br/>
\]</p>

<p>因为 \(b(s_t)\) 和 \(a_t\) 无关，有<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E_{a_t} \gamma^t b(s_t) \frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t) &amp;= \int_{a_t} \gamma^t b(s_t) \Big(\frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t) \Big)\pi(a_t|s_t) da_t\\<br/>
&amp;= \int_{a_t} \gamma^t b(s_t) \Big(\frac{\partial}{\partial \theta} \pi_\theta(a_t|s_t)\Big) \frac{1}{\pi(a_t|s_t) } \pi(a_t|s_t) da_t\\<br/>
&amp;= \int_{a_t} \gamma^t b(s_t) \frac{\partial}{\partial \theta} \pi_\theta(a_t|s_t) da_t\\<br/>
&amp;= \frac{\partial}{\partial \theta} \gamma^t b(s_t) \int_{a_t} \pi_\theta(a_t|s_t) da_t\\<br/>
&amp;= \frac{\partial}{\partial \theta} \Big(\gamma^t b(s_t) \cdot 1\Big)\\<br/>
&amp;= 0\\<br/>
\end{align*}<br/>
\]</p>

<p>上式中运用了积分、微分互换不变性和<br/>
\[<br/>
\int_{a_t} \pi(a_t|s_t) = 1<br/>
\]</p>

<p>因此<br/>
\[<br/>
\frac{\partial \hat {\mathcal J_t}(\theta)}{\partial\theta} = \frac{\partial \mathcal J_t(\theta)}{\partial\theta}<br/>
\]</p>

<p>为了可以有效地减小方差， \(b(s_t)\) 和 \(G(\tau_{t:T})\) 越相关越好，一个很自然的选择是令 \(b(s_t)\) 为值函数 \(V^{\pi_\theta}(s_t)\)。但是由于值函数未知，我们可以用一个可学习的函数 \(V_\phi(s_t)\) 来近似值函数，目标函数为<br/>
\[<br/>
\mathcal L(\phi|s_t,\pi_\theta) = [V^{\pi_\theta}(s_t) − V_\phi(s_t)]^2<br/>
\]</p>

<p>其中 \(V^{\pi_\theta}(s_t) = \mathbb E[G(\tau_{t:T})]\) 也用蒙特卡罗方法进行估计。采用随机梯度下降法，参数 \(\phi\) 的梯度为<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \phi} \mathcal L(\phi|s_t,\pi_\theta) &amp;= \frac{\partial}{\partial \phi} [V^{\pi_\theta}(s_t) − V_\phi(s_t)]^2\\<br/>
&amp;= -2[V^{\pi_\theta}(s_t) − V_\phi(s_t)]\frac{\partial}{\partial \theta} V_\phi(s_t)\\<br/>
&amp;= -2[\mathbb E[G(\tau_{t:T})] − V_\phi(s_t)]\frac{\partial V_\phi(s_t)}{\partial \theta} \\<br/>
\end{align*}<br/>
\]</p>

<p>策略函数参数 \(\theta\) 的梯度为<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \hat {\mathcal J_t}(\theta)}{\partial\theta} = \mathbb E_{s_t}\Big[\mathbb E_{a_t} \Big[ \gamma^t \big( G(\tau_{t:T}  - V_\phi(s_t) \big) \frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t)) \Big] \Big]\\<br/>
\end{align*}<br/>
\]</p>

<h5 id="toc_22">带基准线的 REINFORCE算法</h5>

<p><strong>输入</strong>: 状态空间 \(\mathcal S\)，动作空间 \(\mathcal A\)，可微分的策略函数 \(\pi_\theta(a|s)\)，可微分的状态值函数 \(V_\phi(s)\)，折扣率 \(\gamma\)，学习率 \(\alpha\)，\(\beta\);<br/>
<strong>输出</strong>: 策略 \(\pi_\theta\);<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>随机初始化参数 \(\theta,\phi\);</li>
<li>repeat:

<ul>
<li>根据策略 \(\pi_\theta(a|s)\) 生成一条轨迹</li>
<li>\(τ = s_0, a_0, s_1, a_1,..., s_{T−1}, a{T−1}, s_T\)</li>
<li>for t = 0 to T do:

<ul>
<li>计算 \(G(\tau_{t:T})\);
\[
\delta \leftarrow G(\tau_{t:T}) − V_\phi(s_t);
\]</li>
<li>更新值函数参数
\[
\phi \leftarrow \phi + \beta \delta \frac{\partial V_\phi(s_t)}{\partial \phi};
\]</li>
<li>更新策略函数参数
\[
\theta \leftarrow \theta + \alpha \gamma^t \delta \frac{\partial}{\partial \theta} \log \pi_\theta(a_t|s_t)
\]</li>
</ul></li>
<li>end</li>
</ul></li>
<li>until \(\theta\) 收敛;</li>
<li>输出: 策略 \(\pi_\theta\);</li>
</ul>

<h3 id="toc_23">Actor-Critic算法</h3>

<p>在 REINFORCE算法中，每次需要根据一个策略采集一条完整的轨迹，并计算这条轨迹上的回报。这种采样方式的方差比较大，学习效率也比较低。可以借鉴时序差分学习的思想，使用动态规划方法来提高采样的效率，即从状态开始 \(s\) 的总回报可以通过当前动作的即时奖励 \(r(s,a,s&#39;)\) 和下一个状态 \(s&#39;\) 的<br/>
值函数来近似估计。</p>

<p><strong>演员-评论员算法（Actor-Critic Algorithm）</strong> 是一种结合策略梯度和时序差分学习的强化学习方法。其中演员（actor）是指策略函数 \(\pi_\theta(s, a)\)，即学习一个策略来得到尽量高的回报， 评论员（critic）是指值函数 \(V_\phi(s)\)，对当前策略的值函数进行估计，即评估 actor 的好坏。借助于值函数，Actor-Critic 算法可以进行单步更新参数，不需要等到回合结束才进行更新。<br/>
在 Actor-Critic 算法中的策略函数 \(\pi_\theta(s,a)\) 和值函数 \(V_\phi(s)\) 都是待学习的函数，需要在训练过程中同时学习。</p>

<p>假设从时刻 \(t\) 开始的回报 \(G(\tau_{t:T})\)，我们用下面公式近似计算。<br/>
\[<br/>
\hat G(\tau_{t:T}) = r_{t+1} + \gamma V_\phi(s_{t+1}),<br/>
\]</p>

<p>其中 \(s_{t+1}\) 是 \(t+1\) 时刻的状态， \(r_{t+1}\) 是即时奖励。</p>

<p>在每步更新中，分别进行策略函数 \(\pi_\theta(s,a)\) 和值函数 \(V_\phi(s)\) 的学习。一方面，更新参数 \(\phi\) 使得值函数 \(V_\phi(s_t)\) 接近于估计的真实回报 \(\hat G(\tau_{t:T})\)，<br/>
\[<br/>
\min_\phi [\hat G(\tau_{t:T}) − V_\phi(s_t)]^2<br/>
\]</p>

<p>另一方面，将值函数 \(V_\phi(s_t)\) 作为基函数来更新参数 \(\theta\)，减少策略梯度的方差。<br/>
\[<br/>
\theta \leftarrow \theta + \alpha \gamma^t [\hat G(\tau_{t:T}) − V_\phi(s_t)] \frac{\partial}{\partial \theta}\log \pi_\theta(a_t|s_t)<br/>
\]</p>

<p>在每步更新中，演员根据当前的环境状态 \(s\) 和策略 \(\pi_\theta(a|s)\) 去执行动作 \(a\)，环境状态变为 \(s&#39;\)，并得到即时奖励 \(r\)。评论员（值函数 \(V_\phi(s)\)）根据环境给出的真实奖励和之前标准下的打分（\(r + \gamma V_\phi(s&#39;)\)），来调整自己的打分标准，使得自己的评分更接近环境的真实回报。演员则跟据评论员的打分，调整自己的策略 \(\pi_\theta\)，争取下次做得更好。开始训练时，演员随机表演，评论员随机打分。通过不断的学习，评论员的评分越来越准，演员的动作越来越好。</p>

<p><strong>输入</strong>: 状态空间 \(\mathcal S\)，动作空间 \(\mathcal A\), 可微分的策略函数 \(\pi_\theta(a|s)\), 可微分的状态值函数 \(V_\phi(s)\), 折扣率 \(\gamma\)，学习率 \(\alpha &gt; 0,\beta &gt; 0\);<br/>
<strong>输出</strong>：策略 \(\pi_\theta\);<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>随机初始化参数 \(\theta,\phi\);</li>
<li>repeat:

<ul>
<li>初始化起始状态 \(s\);</li>
<li>\(\lambda = 1\);</li>
<li>repeat:

<ul>
<li>在状态 \(s\)，选择动作 \(a = \pi_\theta(a|s)\);</li>
<li>执行动作 \(a\)，得到即时奖励 \(r\) 和新状态 \(s&#39;\) ;</li>
<li>\(\delta \leftarrow r + \gamma V_\phi(s&#39;) − V_\phi(s)\)</li>
<li>\(\phi \leftarrow \beta \delta \frac{\partial}{\partial \phi} V_\phi(s)\)</li>
<li>\(\theta \leftarrow \theta + \alpha \lambda \delta \frac{\partial}{\partial \theta} \log \pi_\theta(a|s)\)</li>
<li>\(\lambda \leftarrow \gamma \lambda\);</li>
<li>\(s \leftarrow s&#39;\);</li>
</ul></li>
<li>until \(s\) 为终止状态;</li>
</ul></li>
<li>until \(\theta\) 收敛;</li>
<li>输出: 策略 \(\pi_\theta\);</li>
</ul>

<p>虽然在带基准线的 REINFORCE算法也同时学习策略函数和值函数，但是它并不是一种 Actor-Critic 算法。因为其中值函数只是用作基线函数以减少方差，并不用来估计回报（即评论员的角色）。</p>

<hr/>

<p><a href="https://nndl.github.io/">神经网络与深度学习</a><br/>
<a href="https://zhuanlan.zhihu.com/p/28084990">强化学习实践一 迭代法评估4*4方格世界下的随机策略</a><br/>
<a href="https://zhuanlan.zhihu.com/p/28498261">增强学习3-策略迭代法</a><br/>
<a href="https://qqiang00.github.io/reinforce/javascript/demo_iteration.html">增强学习例子</a><br/>
<a href="https://blog.csdn.net/trillion_power/article/details/78934608">强化学习(reinforcement learning)学习笔记(二)——值迭代与策略迭代</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15370227198772.html">人工神经网络-长短时记忆网络 LSTM</a></h1>
			<p class="meta"><time datetime="2018-09-15T22:45:19+08:00" 
			pubdate data-updated="true">2018/9/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>长短期记忆（ long short-term memory， LSTM）网络是循环神经网络的一个变体，可以有效地解决简单循环神经网络的梯度爆炸或消失问题。</p>

<p><strong>新的内部状态</strong>：LSTM网络引入一个新的内部状态（internal state）\(\mathbf c_t\) 专门进行线性的循环信息传递，同时（非线性）输出信息给隐藏层的外部状态 \(\mathbf h_t\)。<br/>
\[<br/>
\begin{align}<br/>
\mathbf c_t &amp;= \mathbf f_t \odot \mathbf c_{t-1} + \mathbf i_t \odot \widetilde{\mathbf c}_t\label{mctm1}\\<br/>
\mathbf h_t &amp;= \mathbf o_t \odot \tanh(\mathbf c_t)\label{mctm2}\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(\mathbf f_t\)，\(\mathbf i_t\) 和 \(\mathbf o_t\) 为三个门（gate）来控制信息传递的路径；\(\odot\) 为向量元素乘积；\(\mathbf c_{t−1}\) 为上一时刻的记忆单元；\(\widetilde{\mathbf c}_t\) 是通过非线性函数得到候选状态，<br/>
\[<br/>
\widetilde{\mathbf c}_t = \tanh(W_c \mathbf x_t + U_c \mathbf h_{t−1} + \mathbf b_c)<br/>
\]</p>

<p>在每个时刻 \(t\)， LSTM网络的内部状态 \(\mathbf c_t\) 记录了到当前时刻为止的历史信息。</p>

<div align="center">
    <img src="media/15370227198772/15428977728733.jpg" width="260" />
</div>

<p><strong>门机制</strong>：LSTM 网络引入门机制（gating mechanism）来控制信息传递的路径。公式 ( \ref{mctm1} )和 ( \ref{mctm2} ) 中三个“门”分别为输入门 \(\mathbf i_t\), 遗忘门 \(\mathbf f_t\) 和输出门 \(\mathbf o_t\)，在数字电路中，门（gate）为一个二值变量 \(\{0,1\}\)， 0代表关闭状态，不许任何信息通过； 1代表开放状态，允许所有信息通过。 LSTM网络中的“门”是一种“软”门，取值在 \((0,1)\)之间，表示以一定的比例运行信息通过。 LSTM网络中三个门的作用为</p>

<ul>
<li>遗忘门 \(\mathbf f_t\) 控制上一个时刻的内部状态 \(\mathbf c_{t−1}\) 需要遗忘多少信息。</li>
<li>输入门 \(\mathbf i_t\) 控制当前时刻的候选状态 \(\widetilde{\mathbf c}_t\) 有多少信息需要保存。</li>
<li>输出门 \(\mathbf o_t\) 控制当前时刻的内部状态 \(\mathbf c_t\) 有多少信息需要输出给外部状态 \(\mathbf h_t\)。</li>
</ul>

<p>当 \(\mathbf f_t = 0\), \(\mathbf i_t = 1\)时，记忆单元将历史信息清空，并将候选状态向量 \(\widetilde c_t\) 写入。但此时记忆单元 \(\mathbf c_t\) 依然和上一时刻的历史信息相关。当 \(\mathbf f_t = 1\),\(\mathbf i_t = 0\) 时，记忆单元将复制上一时刻的内容，不写入新的信息。</p>

<p>第一个开关，负责控制继续保存长期状态 \(c\)；第二个开关，负责控制把即时状态输入到长期状态 \(c\) ；第三个开关，负责控制是否把长期状态 \(c\) 作为当前的LSTM的输出。三个开关的作用如下图所示：</p>

<div align=center>
    <img width="340" src="media/15370227198772/15428989376472.jpg" />
</div>

<p>三个门的计算范式为:<br/>
\[<br/>
\begin{align*}<br/>
\mathbf i_t &amp;= \sigma(W_i \mathbf x_t + U_i \mathbf h_{t−1} + \mathbf b_i),\\<br/>
\mathbf f_t &amp;= \sigma(W_f \mathbf x_t + U_f \mathbf h_{t-1} + \mathbf b_f),\\<br/>
\mathbf o_t &amp;= \sigma(W_o \mathbf x_t + U_o \mathbf h_{t−1} + \mathbf b_o),\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\sigma(\cdot)\) 为 logistic 函数，其输出区间为 (0, 1)， \(\mathbf x_t\) 为当前时刻的输入， \(\mathbf h_{t−1}\) 为上一时刻的外部状态。</p>

<p>下图给出了 LSTM 网络的循环单元结构，其计算过程为：（1）首先利用上一时刻的外部状态 \(\mathbf h_{t−1}\) 和当前时刻的输入 \(\mathbf x_t\)，计算出三个门，以及候选状态 \(\widetilde{\mathbf c}_t\);（2）结合遗忘门 \(\mathbf f_t\) 和输入门 \(\mathbf i_t\) 来更新记忆单元 \(\mathbf c_t\);（3）结合输出门 \(\mathbf o_t\)，将内部状态的信息传递给外部状态 \(\mathbf h_t\)。</p>

<p><font size=33 color=red>图</font></p>

<p>下面来分开介绍LSTM的各个步骤：下图展示了遗忘门的计算</p>

<div align="center">
    <img src="media/15370227198772/15429034872510.jpg" width="520" />
</div>

<p>\(W_f\) 和 \(U_f\) 分别是遗忘门当前输入 \(\mathbf x_i\) 和上一时刻外部状态 \(\mathbf h_i\) 的权重，\(\mathbf b_f\) 是遗忘门的偏置项，\(\sigma\) 是sigmoid函数。<br/>
\[<br/>
\mathbf f_t = \sigma(\left [ \begin{array}{cc} W_f &amp; U_f\\ \end{array}\right ] \cdot \left [\begin{array}{c} \mathbf x_t\\\mathbf h_{t-1}\\\end{array}\right ] + \mathbf b_f)<br/>
\]</p>

<p>接下来看看输入门：</p>

<div align="center">
    <img src="media/15370227198772/15429037793431.jpg" width="520" />
</div>

<p>\(W_i\) 和 \(U_i\) 分别是输入门当前输入 \(\mathbf x_i\) 和 上一时刻外部状态 \(\mathbf h_i\) 的权重，\(\mathbf b_i\) 是输入门的偏置项<br/>
\[<br/>
\mathbf i_t = \sigma(\left [ \begin{array}{cc} W_i &amp; U_i\\ \end{array}\right ] \cdot \left [\begin{array}{c} \mathbf x_t\\\mathbf h_{t-1}\\\end{array}\right ] + \mathbf b_i)<br/>
\]</p>

<p>接下来，我们计算用于描述当前输入的单元状态（候选状态）\(\widetilde{\mathbf c}_t\)，它是根据上一次的输出和本次输入来计算的，其中 \(W_c\) 和 \(U_c\) 表示候选状态的权重，\(\mathbf b_c\) 表示偏置项：<br/>
\[<br/>
\mathbf i_t = \tanh(\left [ \begin{array}{cc} W_c &amp; U_c\\ \end{array}\right ] \cdot \left [\begin{array}{c} \mathbf x_t\\\mathbf h_{t-1}\\\end{array}\right ] + \mathbf b_c)<br/>
\]</p>

<p>下图表示 \(\widetilde c_t\) 的计算</p>

<div align="center">
    <img src="media/15370227198772/15429038909847.jpg" width="520" />
</div>

<p>现在，我们计算当前时刻的单元状态 \(\mathbf c_t\) 。它是由上一次的单元状态 \(\mathbf c_{t-1}\) 按元素乘以遗忘门 \(\mathbf f_t\)，再用当前输入的候选状态 \(\widetilde{\mathbf c}_t\) 按元素乘以输入门 \(\mathbf i_t\)，再将两个积加和产生的：<br/>
\[<br/>
\mathbf c_t = \mathbf c_{t-1} \odot \mathbf f_t + \widetilde{\mathbf c}_t \odot \mathbf i_t<br/>
\]</p>

<p>下图是 \(\mathbf c_t\) 的计算</p>

<div align="center">
    <img src="media/15370227198772/15429042137568.jpg" width="520" />
</div>

<p>这样，我们就把LSTM关于当前的记忆 \(\widetilde{\mathbf c}_t\) 和长期的记忆 \(\mathbf c_{t-1}\) 组合在一起，形成了新的单元状态 \(\mathbf c_t\)。由于遗忘门的控制，它可以保存很久很久之前的信息，由于输入门的控制，它又可以避免当前无关紧要的内容进入记忆。</p>

<p>下面，我们要看看输出门，它控制了长期记忆对当前输出的影响，其中 \(W_o\) 和 \(U_o\) 表示输出门对当前输入 \(\mathbf x_t\) 和上一时刻外部状态 \(\mathbf h_{t-1}\) 的权重，\(\mathbf h_{t-1}\) 是偏置项：<br/>
\[<br/>
\mathbf o_t = \sigma(\left [ \begin{array}{cc} W_o &amp; U_o\\ \end{array}\right ] \cdot \left [\begin{array}{c} \mathbf x_t\\\mathbf h_{t-1}\\\end{array}\right ] + \mathbf b_o)<br/>
\]</p>

<p>下图表示输出门的计算</p>

<div align="center">
    <img src="media/15370227198772/15429043281567.jpg" width="520" />
</div>

<p>LSTM最终的输出，是由输出门和单元状态共同确定的：<br/>
\[<br/>
h_t = \mathbf o_t \odot \tanh(\mathbf c_t)<br/>
\]</p>

<p>如下图：</p>

<div align="center">
    <img src="media/15370227198772/15429043987838.jpg" width="520" />
</div>

<p>通过 LSTM循环单元，整个网络可以建立较长距离的时序依赖关系。上面公式可以简洁地描述为<br/>
\[<br/>
\begin{align*}<br/>
\left [ \begin{array}{c} \widetilde{\mathbf c}_t \\ \mathbf o_t \\ \mathbf i_t \\ \mathbf f_t \\\end{array} \right ] &amp;= \left [ \begin{array}{c} \tanh \\ \sigma \\ \sigma \\ \sigma \\\end{array}\right ] \Big( \left [ \begin{array}{cc} W &amp; U \\\end{array} \right ] \left [ \begin{array}{c} \mathbf x_t\\\mathbf h_{t-1}\\\end{array} \right ] + b\Big)\\<br/>
\mathbf c_t &amp;= \mathbf f_t \odot \mathbf c_{t-1} + \mathbf i_t \odot \widetilde{\mathbf c}_t\\<br/>
\mathbf h_t &amp;= \mathbf o_t \odot \tanh(\mathbf c_t)\\<br/>
\end{align*}<br/>
\]</p>

<p><strong>记忆</strong>：循环神经网络中的隐状态 \(\mathbf h\) 存储了历史信息，可以看作是一种记忆（memory）。在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作是一种短期记忆（short-term memory）。在神经网络中， 长期记忆（long-term memory）可以看作是网络参数，隐含了从训练数据中学到的经验，并更新周期要远远慢于短期记忆。而在 LSTM网络中，记忆单元 \(\mathbf c\) 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔。记忆单元 \(\mathbf c\) 中保存信息的生命周期要长于短期记忆 \(\mathbf h\)，但又远远短于长期记忆，因此称为长的短期记忆（long short-term memory）。</p>

<h3 id="toc_0">参数学习</h3>

<p>LSTM的训练算法仍然是反向传播算法，首先我们来看一下前向计算中出现的激活函数，激活函数有两个，分别是sigmoid函数函数和tanh函数<br/>
\[<br/>
\begin{align*}<br/>
\sigma(z) &amp;= y = \frac{1}{1 + e^{-z}} \\<br/>
\sigma&#39;(z) &amp;= y(1-y) \\<br/>
\tanh(z) &amp;= y = \frac{e^z - e^{-z}}{e^z + e^{-z}}\\<br/>
\tanh&#39;(z) &amp;= 1 - y^2\\<br/>
\end{align*}<br/>
\]</p>

<p>从上面可以看出，sigmoid和tanh函数的导数都是原函数的函数。这样，我们一旦计算原函数的值，就可以用它来计算出导数的值。</p>

<p>LSTM需要学习的参数共有8组，分别是：遗忘门的权重矩阵 \(W_f\)、\(U_f\) 和偏置项 \(b_f\) 、输入门的权重矩阵 \(W_i\)、\(U_i\) 和偏置项 \(b_i\)、输出门的权重矩阵 \(W_o\)、\(U_o\) 和偏置项 \(b_o\)，以及计算候选状态的权重矩阵 \(W_c\)、\(U_c\) 和偏置项 \(b_c\)。</p>

<p>我们解释一下按元素乘 \(\odot\) 符号。当 \(\odot\) 作用于两个向量时，运算如下：<br/>
\[<br/>
\mathbf a \odot \mathbf b = \left [ \begin{array}{c} a_1 \\ a_2 \\ a_3 \\ \dots \\ a_n \\ \end{array} \right ] \odot \left [ \begin{array}{c} b_1 \\ b_2 \\ b_3 \\ \dots \\ b_n \\ \end{array} \right ] = \left [ \begin{array}{c} a_1 b_1 \\ a_2 b_2 \\ a_3 b_3 \\ \dots \\ a_n b_n \\ \end{array} \right ]<br/>
\]</p>

<p>当 \(\odot\) 作用于一个<strong>向量</strong>和一个<strong>矩阵</strong>时，运算如下：<br/>
\[<br/>
\begin{align*}<br/>
\mathbf a \odot X &amp;= \left [ \begin{array}{c} a_1 \\ a_2 \\ a_3 \\ \dots \\ a_n \\ \end{array} \right ] \odot \left [ \begin{array}{ccccc} x_{11} &amp; x_{12} &amp; x_{13} &amp; \dots &amp; x_{1n} \\ x_{21} &amp; x_{22} &amp; x_{23} &amp; \dots &amp; x_{2n} \\ x_{31} &amp; x_{32} &amp; x_{33} &amp;\dots &amp;x_{3n} \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_{n1} &amp; x_{n2} &amp; x_{n3} &amp; \dots &amp; x_{nn}\\\end{array} \right ]\\<br/>
&amp;= \left [ \begin{array}{ccccc} a_1 x_{11} &amp; a_1 x_{12} &amp; a_1 x_{13} &amp; \dots &amp; a_1 x_{1n} \\ a_2 x_{21} &amp; a_2 x_{22} &amp; a_2 x_{23} &amp; \dots &amp; a_2 x_{2n} \\ a_3 x_{31} &amp; a_3 x_{32} &amp; a_3 x_{33} &amp; \dots &amp; a_3 x_{3n} \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_n x_{n1} &amp; a_n x_{n2} &amp; a_n x_{n3} &amp; \dots &amp; a_n x_{nn} \\\end{array} \right ]\\<br/>
\end{align*}<br/>
\]</p>

<p>当 \(\odot\) 作用于两个矩阵时，两个矩阵对应位置的元素相乘。按元素乘可以在某些情况下简化矩阵和向量运算。例如，当一个对角矩阵右乘一个矩阵时，相当于用对角矩阵的对角线组成的向量安元素乘那个矩阵：<br/>
\[<br/>
\text{diag}[a] X = a\odot X<br/>
\]</p>

<p>当一个行向量右乘一个对角矩阵时，相当于这个行向量按元素乘那个矩阵对角线组成的向量：<br/>
\[<br/>
a^T \text{diag}[b] = a^T \odot b<br/>
\]</p>

<p>上面这两点，在我们后续推导中会多次用到。</p>

<p>在t时刻，LSTM的输出值为 \(\mathbf h_t\)。我们定义t时刻的误差项 \(\delta_t\) 为：<br/>
\[<br/>
\delta_t = \frac{\partial E}{\partial \mathbf h_t}<br/>
\]</p>

<p>我们假设误差项是损失函数对输出值的导数，而不是对加权输入 \(\mathbf{net}_t^l\) 的导数。因为LSTM有四个加权输入，分别对于 \(\mathbf f_t\)、\(\mathbf i_t\)、\(\mathbf c_t\) 和 \(\mathbf o_t\)，我们希望往上一层传递一个误差项而不是四个。但我们仍然需要定义出这个四个加权输入，以及对应的误差项。<br/>
\[<br/>
\begin{align*}<br/>
\mathbf{net}_{f,t} &amp;= W_f \mathbf h_{t-1} + U_f \mathbf x_t + \mathbf b_f\\<br/>
\mathbf{net}_{i,t} &amp;= W_i \mathbf h_{t-1} + U_i \mathbf x_t + \mathbf b_i\\<br/>
\mathbf{net}_{\widetilde c,t} &amp;= W_c \mathbf h_{t-1} + U_c \mathbf x_t + \mathbf b_c\\<br/>
\mathbf{net}_{o,t} &amp;= W_o \mathbf h_{t-1} + U_o \mathbf x_o + \mathbf b_o\\<br/>
\delta_{f,t} &amp;= \frac{\partial E}{\partial \mathbf{net}_{f,t}}\\<br/>
\delta_{i,t} &amp;= \frac{\partial E}{\partial \mathbf{net}_{i,t}}\\<br/>
\delta_{\widetilde c,t} &amp;= \frac{\partial E}{\partial \text{net}_{\widetilde c,t}}\\<br/>
\delta_{o,t} &amp;= \frac{\partial E}{\partial \mathbf{net}_{o,t}}\\<br/>
\end{align*}<br/>
\]</p>

<h3 id="toc_1">误差沿时间反向传递</h3>

<p>沿时间反向传递误差项，就是要计算出 \(t-1\) 时刻的误差项 \(\delta_{t-1}\)。<br/>
\[<br/>
\begin{align*}<br/>
\delta_{t-1}^T &amp;= \frac{\partial E}{\partial \mathbf h_{t-1}}\\<br/>
&amp;= \frac{\partial E}{\partial \mathbf h_t} \frac{\partial \mathbf h_t}{\partial \mathbf h_{t-1}}\\<br/>
&amp;= \delta_t^T \frac{\partial \mathbf h_t}{\partial \mathbf h_{t-1}}<br/>
\end{align*}<br/>
\]</p>

<p>我们知道，\(\frac{\partial \mathbf h_t}{\partial \mathbf h_{t-1}}\) 是一个 Jacbian矩阵。如果隐藏 \(h\) 的维度是 \(N\) 的话，那么它就是一个 \(N\times N\) 矩阵。为了求出它，我们列出 \(\mathbf h_t\) 的计算公式<br/>
\[<br/>
\begin{align}<br/>
\mathbf h_t &amp;= \mathbf o_t \odot \tanh(\mathbf c_t)\label{mhmoo}\\<br/>
\mathbf c_t &amp;= \mathbf f_t \odot \mathbf c_{t-1} + \mathbf i_t \odot \widetilde{\mathbf c}_t\label{mhmoo2}\\<br/>
\end{align}<br/>
\]</p>

<p>显然，\(\mathbf o_t\)、\(\mathbf f_t\)、\(\mathbf i_t\)、\(\widetilde{\mathbf c}_t\) 都是 \(\mathbf h_{t-1}\) 的函数，那么利用全导数公式可得：<br/>
\[<br/>
\begin{align}<br/>
\delta_t^T \frac{\partial \mathbf h_t}{\partial \mathbf h_{t-1}} &amp;= \delta_t^T \frac{\partial \mathbf h_t}{\partial \mathbf o_t} \frac{\partial \mathbf o_t}{\partial \mathbf{net}_{o,t}} \frac{\partial \mathbf{net}_{o,t}}{\partial \mathbf h_{t-1}} + \delta_t^T \frac{\partial \mathbf h_t}{\partial \mathbf c_t} \frac{\partial \mathbf c_t}{\partial \mathbf f_t} \frac{\partial \mathbf f_t}{\partial \mathbf{net}_{f,t}} \frac{\partial \mathbf{net}_{f,t}}{\partial \mathbf h_{t-1}} + \delta_t^T \frac{\partial \mathbf h_t}{\partial \mathbf c_t} \frac{\partial \mathbf c_t}{\partial \mathbf i_t} \frac{\partial \mathbf i_t}{\partial \mathbf{net}_{i,t}} \frac{\partial \mathbf{net}_{i,t}}{\partial \mathbf h_{t-1}} + \delta_t^T \frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{c}_t}}\frac{\partial{\mathbf{c}_t}}{\partial{\mathbf{\tilde{c}}_{t}}}\frac{\partial{\mathbf{\tilde{c}}_t}}{\partial{\mathbf{net}_{\tilde{c},t}}}\frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{\mathbf{h_{t-1}}}}\nonumber\\<br/>
&amp;= \delta_{o,t}^T \frac{\partial \mathbf{net}_{o,t}}{\partial \mathbf h_{t-1}} + \delta_{f,t}^T \frac{\partial \mathbf{net}_{f,t}}{\partial \mathbf h_{t-1}}  + \delta_{i,t}^T \frac{\partial \mathbf{net}_{i,t}}{\partial \mathbf h_{t-1}} + \delta_{\widetilde c,t}^T \frac{\partial \mathbf{net}_{\widetilde c,t}}{\partial h_{t-1}}\label{dftpm}\\<br/>
\end{align}<br/>
\]</p>

<p>下面我们求出上式中的每一个偏导数，根据 ( \ref{mhmoo} ) ，我们可以求出：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathbf h_t}{\partial \mathbf o_t} &amp;= \text{diag}[\tanh(\mathbf c_t)]\\<br/>
\frac{\partial \mathbf h_t}{\partial \mathbf c_t} &amp;= \text{diag}[\mathbf o_t \odot (1 - \tanh(\mathbf c_t)^2 )]\\<br/>
\end{align*}<br/>
\]</p>

<p>根据 ( \ref{mhmoo2} )，我们可以求出：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathbf c_t}{\partial \mathbf f_t} &amp;= diag[\mathbf c_{t-1}]\\<br/>
\frac{\partial \mathbf c_t}{\partial \mathbf i_t} &amp;= diag[\widetilde{\mathbf c}_t] \\<br/>
\frac{\partial \mathbf c_t}{\partial \widetilde{\mathbf c}_t} &amp;= diag[\mathbf i_t]\\<br/>
\end{align*}<br/>
\]</p>

<p>因为：<br/>
\[<br/>
\begin{align*}<br/>
\mathbf o_t &amp;= \sigma(\mathbf{net}_{o,t}) \\<br/>
\mathbf{net}_{o,t} &amp;= W_{oh} \mathbf h_{t-1} + W_{ox} \mathbf x_t + \mathbf b_o\\<br/>
\\<br/>
\mathbf f_t &amp;= \sigma(\mathbf{net}_{f,t}) \\<br/>
\mathbf{net}_{f,t} &amp;= W_{fh} \mathbf h_{t-1} + W_{fx} \mathbf x_t + \mathbf b_f\\<br/>
\\<br/>
\mathbf i_t &amp;= \sigma(\mathbf{net}_{i,t}) \\<br/>
\mathbf{net}_{i,t} &amp;= W_{ih} \mathbf h_{t-1} + W_{ix} \mathbf x_t + \mathbf b_i\\<br/>
\\<br/>
\widetilde{\mathbf c}_t &amp;= \tanh(\mathbf{net}_{\widetilde c,t})\\<br/>
\mathbf{net}_{\widetilde c,t} &amp;= W_{ch} \mathbf h_{t-1} + W_{cx} \mathbf x_t + \mathbf b_c\\<br/>
\end{align*}<br/>
\]</p>

<p>我们容易得出<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathbf o_t}{\partial \mathbf{net}_{o,t}} &amp;= diag[\mathbf o_t \odot (1- \mathbf o_t)]\\<br/>
\frac{\partial \mathbf{net}_{o,t}}{\partial \mathbf h_{t-1}} &amp;= W_{oh}\\<br/>
\frac{\partial \mathbf f_t}{\partial \mathbf{net}_{f,t}} &amp;= diag[\mathbf f_t \odot (1 - \mathbf f_t)]\\<br/>
\frac{\partial \mathbf{net}_{f,t}}{\partial \mathbf h_{t-1}} &amp;= W_{fh}\\<br/>
\frac{\partial \mathbf i_t}{\partial \mathbf{net}_{i,t}} &amp;= diag[\mathbf i_t \odot (1 - \mathbf i_t)]\\<br/>
\frac{\partial \mathbf{net}_{i,t}}{\partial \mathbf h_{t-1}} &amp;= W_{ih}\\<br/>
\frac{\partial \widetilde{\mathbf c}_t}{\partial \mathbf{net}_{\widetilde c,t}} &amp;= diag[1 - \widetilde{\mathbf c}_t^2]\\<br/>
\frac{\partial \mathbf{net}_{\widetilde c,t}}{\partial \mathbf h_{t-1}} &amp;= W_{ch}\\<br/>
\end{align*}<br/>
\]</p>

<p>将上述偏导数代入 ( \ref{dftpm} ) 中，可以得到：<br/>
\[<br/>
\begin{align}<br/>
\delta_{t-1}^T &amp;= \delta_{o,t}^T \frac{\partial \mathbf{net}_{o,t}}{\partial \mathbf h_{t-1}} + \delta_{f,t}^T \frac{\partial \mathbf{net}_{f,t}}{\partial \mathbf h_{t-1}} + \delta_{i,t}^T \frac{\partial \mathbf{net}_{i,t}}{\partial \mathbf h_{t-1}} + \delta_{\widetilde c,t}^T \frac{\partial \mathbf{net}_{\widetilde c,t}}{\partial \mathbf h_{t-1}}\nonumber\\<br/>
&amp;= \delta_{o,t}^T W_{oh} + \delta_{f,t}^T W_{fh} + \delta_{i,t}^T W_{ih} + \delta_{\widetilde c,t}^T W_{ch}\label{dotwd}\\<br/>
\end{align}<br/>
\]</p>

<p>根据 \(\delta_{o,t}\)、\(\delta_{f,t}\)、\(\delta_{i,t}\) 和 \(\delta_{\widetilde c,t}\) 的定义，可知：<br/>
\[<br/>
\begin{align}<br/>
\delta_{o,t}^T &amp;= \frac{\partial E}{\partial \mathbf{net}_{o,t}} \\<br/>
&amp;= \frac{\partial E}{\partial \mathbf h_t} \frac{\partial \mathbf h_t}{\partial \mathbf{net}_{o,t}}\nonumber\\<br/>
&amp;= \delta_t^T \frac{\partial \mathbf h_t}{\partial \mathbf{net}_{o,t}}\nonumber\\<br/>
&amp;= \delta_t^T \frac{\partial \mathbf h_t}{\partial \mathbf o_t} \frac{\partial \mathbf o_t}{\partial \mathbf{net}_{o,t}}\nonumber\\<br/>
&amp;= \delta_t^T diag[\tanh(\mathbf c_t)] diag[\mathbf o_t \odot (1- \mathbf o_t)]\nonumber\\<br/>
&amp;= \delta_t^T diag[\tanh(\mathbf c_t) \odot \mathbf o_t \odot (1 - \mathbf o_t)]\nonumber\\<br/>
&amp;= \delta_t^T \odot \mathbf \tanh(\mathbf c_t) \odot \mathbf o_t \odot (1 - \mathbf o_t)\label{dotwd1}<br/>
\end{align}<br/>
\]</p>

<p>同理<br/>
\[<br/>
\begin{align}<br/>
\delta_{f,t}^T &amp;= \delta_t^T \odot \mathbf o_t \odot (1 - \tanh(\mathbf c_t)^2) \odot \mathbf c_{t-1} \odot \mathbf f_t \odot (1 - \mathbf f_t) \label{dotwd2}\\<br/>
\delta_{i,t}^T &amp;= \delta_t^T \odot \mathbf o_t \odot (1 - \tanh(\mathbf c_t)^2) \odot \widetilde{\mathbf c}_t \odot \mathbf i_t ( 1- \mathbf i_t)\label{dotwd3}\\<br/>
\delta_{\widetilde c,t}^T &amp;= \delta_t^T \odot \mathbf o_t \odot ( 1 - \tanh(\mathbf c_t)^2) \odot \mathbf i_t \odot (1 - \widetilde{\mathbf c}^2 ) \label{dotwd4}\\<br/>
\end{align}<br/>
\]</p>

<p>式 ( \ref{dotwd} ) 到式 ( \ref{dotwd4} ) 就是将误差沿时间反向传播一个时刻的公式。有了它，我们可以写出将误差项向前传递到任意时刻 \(k\) 的公式。</p>

<h3 id="toc_2">将误差项传递到上一层</h3>

<p>我们假设当前层为第 \(l\) 层，定义 \(l-1\) 层的误差项是误差函数对 \(l-1\) 层的加权输入的导数，即：<br/>
\[<br/>
\delta_t^{l-1} = \frac{E}{\partial \mathbf{net}_t^{l-1}}<br/>
\]</p>

<p>本次LSTM的输入 \(x_t\) 由下面的公式计算：<br/>
\[<br/>
\mathbf x_t^l = f^{l-1}(\mathbf{net}_t^{l-1})<br/>
\]</p>

<p>上式中，\(f^{l-1}\) 表示第 \(l-1\) 层的激活函数。</p>

<p>因为 \(\mathbf{net}_{f,t}^l\)、\(\mathbf{net}_{i,t}^l\)、\(\mathbf{net}_{\widetilde{c},t}^l\)、\(\mathbf{net}_{o,t}^l\) 都是 \(\mathbf x_t\) 的函数，\(\mathbf{x}_t \) 又是 \(\mathbf{net}_t^{l-1}\) 的函数，因此，要求 \(E\) 对  \(\mathbf{net}_t^{l-1}\) 的导数，就需要用全导数公式：<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial E}{\partial \mathbf{net}_t^{l-1}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{f,t}^l} \frac{\partial \mathbf{net}_{f,t}^l}{\partial \mathbf x_t^l} \frac{\partial \mathbf x_t^l}{\partial \mathbf{net}_t^{l-1}} + \frac{\partial E}{\partial \mathbf{net}_{i,t}^l}\frac{\partial \mathbf{net}_{i,t}^l}{\partial \mathbf x_t^l}\frac{\partial \mathbf x_t^l}{\partial \mathbf{net}_t^{l-1}} + \frac{\partial E}{\partial \mathbf{net}_{\widetilde c,t}^l}\frac{\partial \mathbf{net}_{\widetilde c,t}^l}{\partial \mathbf{net}_{\widetilde c,t}^t}{\partial \mathbf x_t^l} \frac{\partial \mathbf x_t^l}{\partial \mathbf{net}_t^{l-1}} + \frac{\partial E}{\partial \mathbf{net}_{o,t}^l} \frac{\partial \mathbf{net}_{o,t}^l}{\partial \mathbf x_t^l}\frac{\partial \mathbf x_t^l}{\partial \mathbf{net}_t^{l-1}}\nonumber\\<br/>
&amp;= \delta^T_{f,t} W_{fx} \odot f&#39;(\mathbf{net}_t^{l-1}) + \delta^T_{i,t} W_{ix} \odot f&#39;(\mathbf{net}_t^{l-1}) + \delta^T_{\widetilde c,t} W_{cx}\odot f&#39;(\mathbf{net}_t^{l-1}) + \delta^T_{o,t} W_{ox} \odot f&#39;(\mathbf{net}_t^{l-1})\nonumber\\<br/>
&amp;= (\delta^T_{f,t} W_{fx} + \delta^T_{i,t} W_{ix} + \delta_{\widetilde{c},t}^T W_{cx} + \delta_{o,t}^T W_{ox}) \odot f&#39;(\mathbf{net}_t^{l-1})\label{dtftw}\\<br/>
\end{align}<br/>
\]</p>

<p>式 ( \ref{dtftw} ) 就是将误差传递到上一层的公式。</p>

<h3 id="toc_3">权重梯度的计算</h3>

<p>对于 \(W_{fh}\)、\(W_{ih}\)、\(W_{ch}\)、\(W_{oh}\) 的权重梯度，我们知道它的梯度式各个时刻的梯度之和，我们首先求出它们在 \(t\) 时刻的梯度，然后再求出他们最终的梯度。</p>

<p>我们已经求得了误差项 \(\delta_{o,t}\)、\(\delta_{f,t}\)、\(\delta_{i,t}\)、\(\delta_{\widetilde{c},t}\)，很容易求出 \(t\) 时刻的 \(W_{fh}\)、\(W_{ih}\)、\(W_{ch}\)、\(W_{oh}\)：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial W_{oh,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{o,t}} \frac{\partial \mathbf{net}_{o,t}}{\partial W_{oh,t}}\\<br/>
&amp;= \delta_{o,t} \mathbf h_{t-1}^T\\<br/>
\frac{\partial E}{\partial W_{fh,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{f,t}} \frac{\partial \mathbf{net}_{f,t}}{\partial W_{fh,t}}\\<br/>
&amp;= \delta_{f,t} \mathbf h_{t-1}^T\\<br/>
\frac{\partial E}{\partial W_{ih,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{i,t}} \frac{\partial \mathbf{net}_{i,t}}{\partial W_{ih,t}} \\<br/>
&amp;= \delta_{i,t} \mathbf h_{t-1}^T\\<br/>
\frac{\partial E}{\partial W_{ch,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{\widetilde{c},t}} \frac{\partial \mathbf{net}_{\widetilde{c},t}}{\partial W_{ch,t}}\\<br/>
&amp;= \delta_{\widetilde{c},t} \mathbf h_{t-1}^T \\<br/>
\end{align*}<br/>
\]</p>

<p>将各个时刻的梯度加在一起，就能得到最终的梯度：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial W_{oh}} = \sum_{j=1}^t \delta_{o,j} \mathbf h_{j-1}^T\\<br/>
\frac{\partial E}{\partial W_{fh}} = \sum_{j=1}^t \delta_{f,j} \mathbf h_{j-1}^T\\<br/>
\frac{\partial E}{\partial W_{ih}} = \sum_{j=1}^t \delta_{i,j} \mathbf h_{j-1}^T\\<br/>
\frac{\partial E}{\partial W_{ch}} = \sum_{j=1}^t \delta_{\widetilde{c},j} \mathbf h_{j-1}^T \\<br/>
\end{align*}<br/>
\]</p>

<p>对于偏置项 \(\mathbf b_{f}\)、\(\mathbf b_{i}\)、\(\mathbf b_{c}\)、\(\mathbf b_{o}\) 的梯度，也是将各个时刻的梯度加在一起。下面是各个时刻的偏置项梯度：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial \mathbf b_{o,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{o,t}} \frac{\partial \mathbf{net}_{o,t}}{\partial \mathbf b_{o,t}}\\<br/>
&amp;= \delta_{o,t}\\<br/>
\frac{\partial E}{\partial \mathbf b_{f,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{f,t}} \frac{\partial \mathbf{net}_{f,t}}{\partial \mathbf b_{f,t}}\\<br/>
&amp;= \delta_{f,t}\\<br/>
\frac{\partial E}{\partial \mathbf b_{i,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{i,t}} \frac{\partial \mathbf{net}_{i,t}}{\partial \mathbf b_{i,t}}\\<br/>
&amp;= \delta_{i,t}\\<br/>
\frac{\partial E}{\partial \mathbf b_{c,t}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{\widetilde{c},t}} \frac{\partial \mathbf{net}_{\widetilde{c},t}}{\partial \mathbf b_{c,t}}\\<br/>
&amp;= \delta_{\widetilde{c},t}\\<br/>
\end{align*}<br/>
\]</p>

<p>下面是最终的偏置项梯度，即将各个时刻的偏置项梯度加在一起：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial \mathbf{b}_o} = \sum_{j=1}^t \delta_{o,j}\\<br/>
\frac{\partial E}{\partial \mathbf{b}_i} = \sum_{j=1}^t \delta_{i,j}\\<br/>
\frac{\partial E}{\partial \mathbf{b}_f} = \sum_{j=1}^t \delta_{f,j}\\<br/>
\frac{\partial E}{\partial \mathbf{b}_c} = \sum_{j=1}^t \delta_{\widetilde{c},j}\\<br/>
\end{align*}<br/>
\]</p>

<p>对于 \(W_{fx}\)、\(W_{ix}\)、\(W_{cx}\)、\(W_{ox}\) 的权重梯度，只需要根据相应的误差项直接计算即可：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial W_{ox}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{o,t}}\frac{\partial \mathbf{net}_{o,t}}{\partial W_{ox}}\\<br/>
&amp;= \delta_{o,t} \mathbf x_t^T \\<br/>
\frac{\partial E}{\partial W_{fx}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{f,t}} \frac{\partial \mathbf{net}_{f,t}}{\partial W_{fx}} \\<br/>
&amp;= \delta_{f,t} \mathbf x_t^T \\<br/>
\frac{\partial E}{\partial W_{ix}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{i,t}} \frac{\partial \mathbf{net}_{i,t}}{\partial W_{ix}} \\<br/>
&amp;= \delta_{i,t} \mathbf x_t^T \\<br/>
\frac{\partial E}{\partial W_{cx}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{\widetilde{c},t}} \frac{\partial \mathbf{net}_{\widetilde{c},t}}{\partial W_{cx}} \\<br/>
&amp;= \delta_{\widetilde{c},t} \mathbf x_t^T\\<br/>
\end{align*}<br/>
\]</p>

<p>以上就是LSTM的训练算法的全部公式。</p>

<hr/>

<p><a href="https://zybuluo.com/hanbingtao/note/581764">零基础入门深度学习(6) - 长短时记忆网络(LSTM)</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15357311876395.html">人工神经网络-递归神经网络</a></h1>
			<p class="meta"><time datetime="2018-08-31T23:59:47+08:00" 
			pubdate data-updated="true">2018/8/31</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>对于常见的树结构、图结构等更复杂的结构，循环神经网络往往力不从心。我们需要一种更为强大、复杂的神经网络：递归神经网络，以及它的训练算法 BPTS（Back Propagation Through Structure）。顾名思义，递归神经网络可以处理诸如树、图这样的递归结构。</p>

<h3 id="toc_0">递归神经网络介绍</h3>

<p>因为神经网络的输入层单元个数是固定的，因此使用必须使用循环或递归的方式来处理长度可变的输入。循环神经网络实现了前者，通过将长度不定的输入分割成等长度的小块，然后再依次的输入到网络中，从而实现了神经网络对变长输入的处理。一个典型的例子是，当我们处理一句话的时候，我们可以把一句话看做词组成的序列，然后，每次向循环神经网络输入一个词，如此循环直到整句话输入完毕，循环神经网络将产生对应的输出。如此循环直到整句话输入完毕，循环神经网络将产生对应的输出。这样，我们便可以处理任意长度的句子了。如下图所以：</p>

<div align="center">
    <img width="450" src="media/15357311876395/15447178201186.jpg" />
</div>

<p>递归神经网络是循环神经网络在有向无环图上的扩展，一般为树状的层次结构，如下图所示：</p>

<div align="center">
    <img width="400" src="media/15357311876395/15447182614717.jpg" />
</div>

<p>除上述的一般结构外，递归神经网络还有一种退化结构，如下图所示：</p>

<div align="center">
    <img width="280" src="media/15357311876395/15452285668908.jpg" />
</div>

<h3 id="toc_1">递归神经网络的前向计算</h3>

<p>递归神经网络的输入是两个子节点（也可以是多个），输出就是将这两个子节点编码后产生的父节点，父节点的维度和每个子节点是相同的。如下图所示：</p>

<div align="center">
    <img width="260" src="media/15357311876395/15452309662076.jpg" />
</div>

<p>\(\mathbf c_1\) 和 \(\mathbf c_2\) 分别是表示两个子节点的向量，\(\mathbf p\) 是表示父节点的向量。子节点和父节点组成一个全连接神经网络，也就是子节点的每个神经元都和父节点的每个神经元两两相连。我们用矩阵 \(W\) 表示这些连接上的权重，它的维度将是 \(d\times 2d\) ，其中，\(d\) 表示每个节点的维度。父节点的计算公式可以写成：<br/>
\[<br/>
\begin{equation}<br/>
\mathbf p = \tanh(W\left [ \begin{array}\\\mathbf c_1\\\mathbf c_2\\\end{array} \right ] + \mathbf b) \label{mptw}<br/>
\end{equation}<br/>
\]</p>

<p>在上式中，\(\tanh\) 是激活函数（当然也可以用其他的激活函数），\(\mathbf b\) 是偏置项，它也是一个维度为 \(d\) 的向量。</p>

<p>然后，我们把产生的父节点的向量和其他子节点的向量再次作为网络的输入，再次产生它们的父节点。如此递归下去，直至整棵树处理完毕。最终，我们将得到根节点的向量，我们可以认为它是对整棵树的表示，这样我们就实现了把树映射为一个向量。在下图中，我们使用递归神经网络处理一棵树，最终得到的向量 \(\mathbf p_3\)，就是对整棵树的表示：</p>

<div align="center">
    <img width="320" src="media/15357311876395/15452311936823.jpg" />
</div>

<p>举个例子，我们使用递归神将网络将『两个外语学校的学生』映射为一个向量，如下图所示：</p>

<div align="center">
    <img width="640" src="media/15357311876395/15452314581059.jpg" />
</div>

<p>最后得到的向量 \(\mathbf p_3\) 就是对整个句子『两个外语学校的学生』的表示。由于整个结构是递归的，不仅仅是根节点，事实上每个节点都是以其为根的子树的表示。比如，在左边的这棵树中，向量 \(\mathbf p_2\) 是短语『外语学院的学生』的表示，而向量 \(\mathbf p_1\) 是短语『外语学院的』的表示。</p>

<p>式 \ref{mptw} 就是<strong>递归神经网络</strong>的前向计算算法。它和全连接神经网络的计算没有什么区别，只是在输入的过程中需要根据输入的树结构依次输入每个子节点。</p>

<p>需要特别注意的是，<strong>递归神经网络</strong>的权重 \(\mathbf W\) 和偏置项 \(\mathbf b\) 在所有的节点都是共享的。</p>

<h3 id="toc_2">递归神经网络的训练</h3>

<p><strong>递归神经网络</strong> 的训练算法和 <strong>循环神经网络</strong> 类似，两者不同之处在于，前者需要将残差 \(\delta\) 从根节点反向传播到各个子节点，而后者是将残差 \(\delta\) 从当前时刻 \(t_k\) 反向传播到初始时刻 \(t_1\)。</p>

<p>下面，我们介绍适用于递归神经网络的训练算法，也就是<strong>BPTS</strong>算法。</p>

<h4 id="toc_3">误差项的传递</h4>

<p>首先，我们先推导将误差从父节点传递到子节点的公式，如下图：</p>

<div align="center">
    <img width="260" src="media/15357311876395/15452319372169.jpg" />
</div>

<p>定义 \(\delta_p\) 为误差函数 \(E\) 相对于父节点 \(p\) 的加权输入 \(\mathbf{net}_p\) 的导数，即<br/>
\[<br/>
\delta_p = \frac{\partial E}{\partial \mathbf{net}_p}<br/>
\]</p>

<p>设 \(\mathbf{net}_p\) 是父节点的<strong>加权输入</strong>，则<br/>
\[<br/>
\mathbf{net}_p = W\left[\begin{array}\\\mathbf c_1\\\mathbf c_2\\\end{array}\right ] + \mathbf b<br/>
\]</p>

<p>在上述式子里，\(\mathbf{net}_p\)、\(\mathbf c_1\)、\(\mathbf c_2\) 都是向量，而\(W\) 是矩阵。为了看清楚它们的关系，我们将其展开</p>

<p>\[<br/>
\left[\begin{array}\\\mathbf{net}_{p_1}\\ \mathbf{net}_{p_2}\\\cdots\\\mathbf{net}_{p_n}\\\end{array}\right ] = \left [ \begin{array}\\ w_{p_1 c_{11}} &amp; w_{p_1 c_{12}} &amp; \cdots &amp; w_{p_1 c_{1n}}&amp; w_{p_1 c_{21}} &amp; w_{p_1 c_{22}} &amp; \cdots &amp; w_{p_1 c_{2n}} \\ w_{p_1 c_{11}} &amp; w_{p_1 c_{12}} &amp; \cdots &amp; w_{p_1 c_{1n}}&amp; w_{p_1 c_{21}} &amp; w_{p_1 c_{22}} &amp; \cdots &amp; w_{p_1 c_{2n}} \\ \cdots \\ w_{p_1 c_{11}} &amp; w_{p_1 c_{12}} &amp; \cdots &amp; w_{p_1 c_{1n}}&amp; w_{p_1 c_{21}} &amp; w_{p_1 c_{22}} &amp; \cdots &amp; w_{p_1 c_{2n}} \\ \end{array} \right ] \left [ \begin{array}\\ c_{11} \\ c_{12} \\ \vdots \\ c_{1n} \\ c_{21} \\ c_{22} \\ \cdots \\ c_{2n} \\ \end{array} \right ] + \left [ \begin{array}\\ b_1 \\ b_2 \\ \cdots \\ b_n \\ \end{array} \right ]<br/>
\]</p>

<p>在上面的公式中，\(p_i\) 表示父节点 \(p\) 的第 \(i\) 个分量；\(c_{1i}\) 表示 \(\mathbf c_1\) 子节点的第 \(i\) 个分量；\(c_{2i}\) 表示 \(\mathbf c_2\) 子节点的第 \(i\) 个分量；\(w_{p_1 c_{jk}}\) 表示子节点 \(\mathbf c_j\) 的第 \(k\) 个分量到父节点 \(p\) 的第 \(i\) 个分量的权重。根据上面展开后矩阵乘法，我们不难看出，对于子节点 \(c_{jk}\) 来说，它会影响父节点所有的分量。因此，我们求误差函数 \(E\) 对 \(c_{jk}\) 的导数时，必须使用全导数公式，也就是：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial c_{jk}} &amp;= \sum_{i} \frac{\partial E}{\partial \text{net}_{p_1}} \frac{\partial \text{net}_{p_1}}{\partial c_{jk}} \\<br/>
&amp;= \sum_i \delta_{p_1} w_{p_i c_{jk}}\\<br/>
\end{align*}<br/>
\]</p>

<p>有了上式，我们就可以把它表示为矩阵形式，从而得到一个向量化表达：<br/>
\[<br/>
\frac{\partial E}{\partial \mathbf c_j} = U_j \delta_p <br/>
\]</p>

<p>其中，矩阵 \(U_j\) 是从矩阵 \(W\) 中提取部分元素组成的矩阵。其单元为：<br/>
\[<br/>
U_{j_{ik}} = w_{p_k c_{ji}}<br/>
\]</p>

<p>上式看上去可能会让人晕，从下图，我们可以直观看到 \(U_j\) 到底是什么。首先我们把 \(W\) 拆分成两个矩阵 \(W_1\) 和 \(W_2\)，如下图所示：<br/>
\[<br/>
W =\begin{matrix} W_1\\  \left [\overbrace{\begin{array}\\<br/>
w_{p_1 c_{11}} &amp; w_{p_1 c_{12}} &amp; \cdots &amp; w_{p_1 c_{1n}}\\ <br/>
w_{p_1 c_{11}} &amp; w_{p_1 c_{12}} &amp; \cdots &amp; w_{p_1 c_{1n}}\\ <br/>
\cdots \\ <br/>
w_{p_1 c_{11}} &amp; w_{p_1 c_{12}} &amp; \cdots &amp; w_{p_1 c_{1n}}\\<br/>
\end{array}} \right .\end{matrix} \quad \Bigg | \quad<br/>
\begin{matrix} W_2\\  \left . \overbrace {\begin{array}\\<br/>
w_{p_1 c_{21}} &amp; w_{p_1 c_{22}} &amp; \cdots &amp; w_{p_1 c_{2n}} \\ <br/>
w_{p_1 c_{21}} &amp; w_{p_1 c_{22}} &amp; \cdots &amp; w_{p_1 c_{2n}} \\ <br/>
\cdots \\ <br/>
w_{p_1 c_{21}} &amp; w_{p_1 c_{22}} &amp; \cdots &amp; w_{p_1 c_{2n}} \\<br/>
\end{array}} \right ]\end{matrix}<br/>
\]</p>

<p>显然，子矩阵 \(W_1\) 和 \(W_2\) 分别对应子节点 \(\mathbf c_1\) 和 \(\mathbf c_2\) 到父节点 \(\mathbf p\) 的权重。则矩阵 \(U_j\) 为：<br/>
\[<br/>
U_j = W_j^T<br/>
\]</p>

<p>也就是说，将误差项反向传递到相应子节点 \(\mathbf c_j\) 的矩阵 \(U_j\) 就是其对应权重矩阵 \(W_j\) 的转置。</p>

<p>现在，我们设 \(\mathbf{net}_{c_j}\) 是子节点 \(\mathbf c_j\) 的加权输入，\(f\) 是子节点  \(c\) 的激活函数，则：<br/>
\[<br/>
\mathbf c_j = f(\mathbf{net}_{c_j})<br/>
\]</p>

<p>这样，我们得到<br/>
\[<br/>
\begin{align*}<br/>
\delta_{c_j} &amp;= \frac{\partial E}{\partial \mathbf{net}_{c_j}} \\<br/>
&amp;= \frac{\partial E}{\partial \mathbf c_j} \frac{\partial \mathbf c_j}{\partial \mathbf{net}_{c_j}}\\<br/>
&amp;= W_j^T \delta_p \odot f&#39;(\mathbf{net}_{c_j})<br/>
\end{align*}<br/>
\]</p>

<p>如果我们将不同子节点 \(\mathbf c_j\) 对应的误差项 \(\delta_{c_j}\) 连接成一个向量 \(\delta_c= \left [ \begin{array}\\\delta_{c_1} \\ \delta_{c_2} \\ \end{array} \right ]\)。那么，上式可以写成<br/>
\[<br/>
\begin{equation}<br/>
\delta_c = W^T \delta_p \odot f&#39;(\mathbf{net}_c)\label{dcwtp}<br/>
\end{equation}<br/>
\]</p>

<p>上式就是将误差项从父节点传递到子节点的公式。注意，上式中的 \(\mathbf{net}_c\) 也是将两个子节点的加权输入 \(\mathbf{net}_{c_1}\) 和 \(\mathbf{net}_{c_2}\) 连接到一起的向量。</p>

<p>有了传递一层的公式，我们就可以得到逐层传递的公式。</p>

<div align="center">
    <img width="340" src="media/15357311876395/15456640827877.jpg" />
</div>

<p>上图是树型结构中反向传递误差项的全景图，反复应用式 \ref{dcwtp}，在已知 \(\delta_p^{(3)}\) 的情况下，我们不难算出 \(\delta_p^{(1)}\) 为：<br/>
\[<br/>
\begin{align*}<br/>
\delta^{(2)} &amp;= W^T \delta_p^{(3)} \odot f&#39;(\mathbf{net}^{(2)}) \\<br/>
\delta_p^{(2)} &amp;= [\delta^{(2)}]_p \\<br/>
\delta^{(1)} &amp;= W^T \delta_p^{(2)} \odot f&#39;(\mathbf{net})\\<br/>
\delta_p^{(1)} &amp;= [\delta^{(1)}]_p \\<br/>
\end{align*}<br/>
\]</p>

<p>在上面的公式中，\(\delta^{(2)} = \left [ \begin{array}\\ \delta_c^{(2)}\\ \delta_p^{(2)} \\ \end{array} \right ]\)，\([\delta^{(2)}]_p\) 表示取向量 \(\delta^{(2)}\) 属于节点 \(p\) 的部分。</p>

<h3 id="toc_4">权重梯度的计算</h3>

<p>根据加权输入的计算公式：<br/>
\[<br/>
\mathbf{net}_p^{(l)} = W \mathbf{c}^{(l)} + \mathbf b<br/>
\]</p>

<p>其中，\(\mathbf{net}_p^{(l)}\) 表示第 \(l\) 层的父节点的加权输入，\(\mathbf c^{(l)}\) 表示第 \(l\) 层的子节点。\(W\) 表示权重矩阵，\(\mathbf b\) 是偏置项。将其展开可得：<br/>
\[<br/>
\mathbf{net}_{p_j}^{l} = \sum_i w_{ji} c_i^{l} + b_j<br/>
\]</p>

<p>那么，我们可以求得误差函数在第 \(l\) 层对权重的梯度为：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial w_{ji}^{(l)}} &amp;= \frac{\partial E}{\partial \mathbf{net}_{p_j}^{(l)}} \frac{\partial \mathbf{net}_{p_j}}{\partial w_{ji}^{(l)}}\\<br/>
&amp;= \delta_{p_j}^{(l)} c_i^{(l)}<br/>
\end{align*}<br/>
\]</p>

<p>上式是针对一个权重 \(w_{ji}\) 的公式，现在需要把它扩展对所有的权重项的公式。我们可以吧上式写成矩阵的形式（在下面公式中，\(m=2n\)）：<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial E}{\partial W^{(l)}} &amp;= \left [ \begin{array}\\ <br/>
\frac{\partial E}{\partial w^{(l)}_{11}} &amp; \frac{\partial E}{\partial w^{(l)}_{12}} &amp; \cdots &amp; \frac{\partial E}{\partial w^{(l)}_{1m}} \\<br/>
\frac{\partial E}{\partial w^{(l)}_{21}} &amp; \frac{\partial E}{\partial w^{(l)}_{22}} &amp; \cdots &amp; \frac{\partial E}{\partial w^{(l)}_{2m}} \\<br/>
\vdots&amp;\vdots&amp;\ddots\vdots\\<br/>
\frac{\partial E}{\partial w^{(l)}_{n1}} &amp; \frac{\partial E}{\partial w^{(l)}_{n2}} &amp; \cdots &amp; \frac{\partial E}{\partial w^{(l)}_{nm}} \\<br/>
\end{array} \right ] \nonumber\\<br/>
&amp;= \left [\begin{array}\\<br/>
\delta_{p_1}^{(l)} c_1^l &amp; \delta_{p_1}^{(l)} c_2^l &amp; \cdots &amp; \delta_{p_1}^{(l)} c_m^l\\<br/>
\delta_{p_2}^{(l)} c_1^l &amp; \delta_{p_2}^{(l)} c_2^l &amp; \cdots &amp; \delta_{p_2}^{(l)} c_m^l\\<br/>
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\<br/>
\delta_{p_n}^{(l)} c_1^l &amp; \delta_{p_n}^{(l)} c_2^l &amp; \cdots &amp; \delta_{p_n}^{(l)} c_m^l\\<br/>
\end{array} \right] \nonumber\\<br/>
&amp;= \delta^{(l)} (c^{(l)})^T \label{dlct}<br/>
\end{align}<br/>
\]</p>

<p>式 \ref{dlct} 就是第 \(l\) 层权重项的梯度计算公式。我们知道，由于权重 \(W\) 是在所有层共享的，最终权重梯度是各个层权重梯度之和，即：<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial E}{\partial W} = \sum_{l} \frac{\partial E}{\partial W^{(l)}} \label{fptep}<br/>
\end{equation}<br/>
\]</p>

<p>接下来，我们求偏置项 \(\mathbf b\) 的梯度计算公式。先计算误差函数对第 \(l\) 层偏置项  \(\mathbf b^{(l)}\) 的梯度：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial b^{(l)}_j} &amp;= \frac{\partial E}{\partial \mathbf{net}_{p_j}^{(l)}} \frac{\partial \mathbf{net}_{p_j}^{(l)}}{\partial b_j^{(l)}} \\<br/>
&amp;= \delta_{p_j}^{(l)}<br/>
\end{align*}<br/>
\]</p>

<p>把上式扩展为矩阵的形式：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E}{\partial \mathbf b^{(l)}} &amp;= \left [ \begin{array}\\ \frac{\partial E}{\partial b_1^{(l)}} \\ \frac{\partial E}{\partial b_2^{(l)}} \\ \vdots \\ \frac{\partial E}{\partial b_n^{(l)}} \\ \end{array} \right ] \\<br/>
&amp;= \left [ \begin{array}\\ \delta_{p_1}^{(l)} \\ \delta_{p_2}^{(l)} \\ \vdots \\ \delta_{p_n}^{(l)} \\ <br/>
\end{array} \right ] \\<br/>
&amp;= \delta_p^{(l)}\\<br/>
\end{align*}<br/>
\]</p>

<p>上式是第 \(l\) 层偏置项的梯度，那么最终的偏置项梯度是各个层偏置项梯度之和，即：<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial E}{\partial \mathbf b} = \sum_l \frac{\partial E}{\partial \mathbf b^{(l)}} \label{fptepb}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_5">权重更新</h3>

<p>如果使用梯度下降优化算法，那么权重更新公式为：<br/>
\[<br/>
W \leftarrow W + \eta \frac{\partial E}{\partial W}<br/>
\]</p>

<p>其中，\(\eta\) 是学习速率常数。把式 \ref{fptep} 代入上式，即可完成权重的更新。同理，偏置项的更新公式为：<br/>
\[<br/>
\mathbf b \leftarrow \mathbf b + \eta \frac{\partial E}{\partial \mathbf b}<br/>
\]</p>

<p>把式 \ref{fptepb} 代入上式，即可完成偏置项的更新。</p>

<p>这就是递归神经网络的训练算法BPTS。</p>

<hr/>

<p><a href="https://zybuluo.com/hanbingtao/note/626300">零基础入门深度学习(7) - 递归神经网络</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15348711256289.html">人工神经网络-循环神经网络</a></h1>
			<p class="meta"><time datetime="2018-08-22T01:05:25+08:00" 
			pubdate data-updated="true">2018/8/22</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>循环神经网络（Recurrent Neural Network， RNN）是一类具有短期记忆能力的神经网络。在循环神经网络中，神经元不但可以接受其它神经元的信息，也可以接受自身的信息，形成具有环路的网络结构。和前馈神经网络相比，循环神经网络更加符合生物神经网络的结构。循环神经网络已经被广泛应用在语音识别、语言模型以及自然语言生成等任务上。循环神经网络的参数学习可以通过随时间反向传播算法 [Werbos, 1990] 来学习。随时间反向传播算法即按照时间的逆序将错误信息一步步地往前传递。当输入序列比较长时，会存在梯度爆炸和消失问题[Bengio et al., 1994, Hochreiter and Schmidhuber, 1997, Hochreiteret al., 2001]，也称为长期依赖问题。为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式引入门控机制。</p>

<p>此外，循环神经网络可以很容易地扩展到两种更广义的记忆网络模型： 递归神经网络和图网络。</p>

<h3 id="toc_0">给网络增加记忆功能</h3>

<p>为了处理这些时序数据并利用其历史信息，我们需要让网络具有短期记忆能力。而前馈网络是一个静态网络，不具备这种记忆能力。</p>

<p>一般来讲，我们可以通过以下三种方法来给网络增加短期记忆能力。</p>

<h4 id="toc_1">延时神经网络</h4>

<p>一种简单的利用历史信息的方法是建立一个额外的延时单元，用来存储网络的历史信息（可以包括输入、输出、隐状态等）。比较有代表性的模型是延时神经网络（Time Delay Neural Network， TDNN）。</p>

<p>延时神经网络是在前馈网络中的非输出层都添加一个延时器，记录最近几次神经元的输出。在第 \(t\) 个时刻，第 \(l + 1\) 层神经元和第 \(l\) 层神经元的最近 \(p\) 次输出相关，即<br/>
\[<br/>
h^{(l+1)}_t = f(h_t^{(l)}, h_{t-1}^{(l)},...,h_{t-p+1}^{(l)}. (6.1)<br/>
\]</p>

<p>通过延时器，前馈网络就具有了短期记忆的能力。</p>

<h4 id="toc_2">有外部输入的非线性自回归模型</h4>

<p>自回归模型（Autoregressive Model，AR）是统计学上常用的一类时间序列模型，用一个变量 \(y_t\) 的历史信息来预测自己。<br/>
\[<br/>
y_t = w_0 + \sum^p_{i=1} w_py_{t−p} + \epsilon_t<br/>
\]</p>

<p>其中 \(p\) 为超参数， \(w_p\) 为参数， \(\epsilon_t \sim N(0, \sigma^2)\) 为第 \(t\) 个时刻的噪声，方差 \(\sigma^2\) 和时间无关。</p>

<p>有外部输入的非线性自回归模型（Nonlinear Autoregressive with Exogenous Inputs Model， NARX） [Leontaritis and Billings, 1985] 是自回归模型的扩展，在每个时刻 t都有一个外部输入\(x_t\)，产生一个输出 \(y_t\)。 NARX通过一个延时器记录最近几次的外部输入和输出，第 \(t\) 个时刻的输出 \(y_t\) 为<br/>
\[<br/>
y_t = f(x_t, x_{t−1},..., x_{t−p}, y_{t−1}, y_{t−2},..., y_{t−q})<br/>
\]</p>

<p>其中 \(f(\cdot)\) 表示非线性函数，可以是一个前馈网络， \(p\) 和 \(q\) 为超参数。</p>

<h4 id="toc_3">循环神经网络</h4>

<p>循环神经网络（RNN）通过使用带自反馈的神经元，能够处理任意长度的时序数据。RNN 也经常被翻译为递归神经网络。这里我们使用 RNN 指代循环神经网络。</p>

<p>给定一个输入序列 \(x_{1:T} = (x_1, x_2,..., x_t,..., x_T )\)，循环神经网络通过下面公式更新带反馈边的隐藏层的活性值 h_t<br/>
\[<br/>
h_t = f(h_{t−1}, x_t)<br/>
\]</p>

<p>其中\(h_0 = 0\)， \(f(\cdot)\) 为一个非线性函数，也可以是一个前馈网络。</p>

<div align=center>
    <img src="media/15348711256289/15422003427571.jpg" width="520" />
</div>

<h3 id="toc_4">简单的循环神经网络</h3>

<p>简单循环网络（Simple Recurrent Network，SRN）是一个非常简单的循环神经网络，只有一个隐藏层的神经网络。在一个两层的前馈神经网络中，连接存在相邻的层与层之间，隐藏层的节点之间是无连接的。而简单循环网络增加了从隐藏层到隐藏层的反馈连接。</p>

<p>假设在时刻 \(t\) 时，网络的输入为 \(x_t\)，隐层状态（即隐层神经元活性值）为 \(h_t\) 不仅和当前时刻的输入\(x_t\) 相关，也和上一个时刻的隐层状态 \(h_{t−1}\) 相关。<br/>
\[<br/>
\begin{align}<br/>
z_t &amp;= Uh_{t−1} + Wx_t + b\label{zuhw}\\<br/>
h_t &amp;= f(z_t)\label{zuhw2}\\<br/>
\end{align}<br/>
\] </p>

<p>其中 \(z_t\) 为隐藏层的净输入， \(f(\cdot)\) 是非线性激活函数，通常为 logistic 函数或 tanh 函数， \(U\) 为状态-状态权重矩阵， \(W\) 为状态-输入权重矩阵, \(b\) 为偏置。公式 ( \ref{zuhw} ) 和 ( \ref{zuhw2} ) 也经常直接写为<br/>
\[<br/>
h_t = f(Uh_{t−1} + W x_t + b)<br/>
\]</p>

<p>如果我们把每个时刻的状态都看作是前馈神经网络的一层的话，循环神经网络可以看作是在时间维度上权值共享的神经网络。</p>

<h3 id="toc_5">循环神经网络的计算能力</h3>

<p>由于循环神经网络具有短期记忆能力，相当于存储装置，因此其计算能力十分强大。前馈神经网络可以模拟任何连续函数，而循环神经网络可以模拟任何程序。</p>

<p>我们先定义一个完全连接的循环神经网络，其输入为 \(x_t\)，输出为 \(y_t\)，<br/>
\[<br/>
\begin{align*}<br/>
h_t &amp;= f(U h_{t−1} + W x_t + b)\\<br/>
y_t &amp;= V h_t\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(h\) 为隐藏状态，\(f(\cdot)\) 为非线性激活函数，\(U\)、\(W\)、\(b\) 和\(V\) 为网络参数。</p>

<h3 id="toc_6">应用到机器学习</h3>

<p>循环神经网络可以应用到很多不同类型的机器学习任务。根据这些任务的特点可以分为以下几种模式:<strong>序列到类别模式</strong>、<strong>同步序列到序列模式</strong>、<strong>异步的序列到序列模式</strong>。</p>

<p>下面我们分别来看下这几种应用模式。</p>

<h4 id="toc_7">序列到类别模式</h4>

<p>序列到类别模式主要用于序列数据的分类问题：输入为序列，输出为类别。比如在文本分类中，输入数据为单词的序列，输出为该文本的类别。假设一个样本 \(\mathbf x_{1:T} = (\mathbf x_1,...,\mathbf x_T)\) 为一个长度为 \(T\) 的序列，输出为一个类别 \(y \in {1,...,C}\)。我们可以将样本 \(\mathbf x\) 按不同时刻输入到循环神经网络中，并得到不同时刻的隐藏状态 \(\mathbf h_1,...,\mathbf h_T\)。我们可以将 \(\mathbf h_T\) 看作整个序列的最终表示（或特征），并输入给分类器 \(g(\cdot)\) 进行分类<br/>
\[<br/>
\hat y = g(\mathbf h_T)<br/>
\]</p>

<p>其中 \(g(\cdot)\) 可以是简单的线性分类器（比如 Logistic 回归）或复杂的分类器（比如多层前馈神经网络）。</p>

<div align="center">
    <img src="media/15348711256289/15422029676355.jpg" width="350" />
</div>

<p>除了将最后时刻的状态作为序列表示之外，我们还可以对整个序列的所有状态进行平均，并用这个平均状态来作为整个序列的表示：<br/>
\[<br/>
\hat y  = g(\frac 1 T \sum_{t=1}^T \mathbf h_t)<br/>
\]</p>

<div align="center">
    <img src="media/15348711256289/15422032233597.jpg" width="350" />
</div>

<h4 id="toc_8">同步的序列到序列模式</h4>

<p>同步的序列到序列模式主要用于序列标注（Sequence Labeling）任务，即每一时刻都有输入和输出，输入序列和输出序列的长度相同。比如词性标注（Partof-Speech Tagging）中，每一个单词都需要标注其对应的词性标签。</p>

<p>在同步的序列到序列模式中，输入为一个长度为 \(T\) 的序列 \(\mathbf x_{1:T} = (\mathbf x_1,..., \mathbf x_T)\)，输出为序列 \(y_{1:T} = (y_1,..., y_T)\)。样本 \(\mathbf x\) 按不同时刻输入到循环神经网络中，并得到不同时刻的隐状态 \(\mathbf h_1,...,\mathbf h_T\)。每个时刻的隐状态 \(\mathbf h_t\) 代表了当前时刻和历史的信息，并输入给分类器 \(g(\cdot)\) 得到当前时刻的标签 \(\hat y_t\)。<br/>
\[<br/>
\hat y_t = g(\mathbf h_t), \qquad\qquad \forall  t \in [1,T]<br/>
\]</p>

<div align="center">
    <img src="media/15348711256289/15422043099881.jpg" width="350" />
</div>

<h4 id="toc_9">异步的序列到序列模式</h4>

<p>异步的序列到序列模式也称为编码器-解码器（Encoder-Decoder）模型，即输入序列和输出序列不需要有严格的对应关系，也不需要保持相同的长度。比如在机器翻译中，输入为源语言的单词序列，输出为目标语言的单词序列。</p>

<p>在异步的序列到序列模式中，输入为一个长度为 \(T\) 的序列 \(\mathbf x_{1:T} = (\mathbf x_1,..., \mathbf x_T)\)，输出为长度为 \(M\) 的序列 \(y_{1:M} = (y_1,...,y_M)\)。经常通过先编码后解码的方式来实现。先将样本 \(\mathbf x\) 按不同时刻输入到一个循环神经网络（编码器）中，并得到其编码 \(\mathbf h_T\)。然后在使用另一个循环神经网络（解码器）中，得到输出序列 \(\hat y_{1:M}\)。为了建立输出序列之间的依赖关系，在解码器中通常使用非线性的自回归模型。<br/>
\[<br/>
\begin{align*}<br/>
\mathbf h_t &amp;= f_1( \mathbf h_{t−1}, \mathbf x_t), &amp;\forall t \in [1,T]\\<br/>
\mathbf h_{T+t} &amp;= f_2(\mathbf h_{T+t−1}, \mathbf {\hat y}_{t−1}), &amp;\forall t \in [1, M]\\<br/>
\hat y_t &amp;= g(\mathbf h_{T+t}), &amp;\forall t \in [1, M]\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(f_1(\cdot)\), \(f_2(\cdot)\) 分别为用作编码器和解码器的循环神经网络，\(g(\cdot)\) 为分类器， \(\mathbf {\hat y}_t\) 为预测输出 \(\hat y_t\) 的向量表示。</p>

<div align="center">
    <img src="media/15348711256289/15422062138337.jpg" width="500" />
</div>

<h3 id="toc_10">参数学习</h3>

<p>循环神经网络的参数可以通过梯度下降方法来进行学习。这里我们以同步的序列到序列模式为例来介绍循环神经网络的参数学习。以随机梯度下降为例，给定一个训练样本 \((\mathbf x,\mathbf y)\)，其中 \(\mathbf x_{1:T} = (\mathbf x_1,..., \mathbf x_T)\) 为长度是 \(T\) 的输入序列， \(y_{1:T} = (y_1,..., y_T)\) 是长度为 \(T\) 的标签序列。即在每个时刻 \(t\)，都有一个监督信息 \(y_t\)，我们定义时刻 \(t\) 的损失函数为<br/>
\[<br/>
\mathcal L_t = \mathcal L(y_t, g(\mathbf h_t))<br/>
\]</p>

<p>其中 \(g(\mathbf h_t)\) 为第 \(t\) 时刻的输出，\(\mathcal L\)为可微分的损失函数，比如交叉熵。那么整个序列上损失函数为<br/>
\[<br/>
\mathcal L = \sum_{t=1}^T \mathcal L_t<br/>
\]</p>

<p>整个序列的损失函数 \(\mathcal L\) 关于参数 \(U\) 的梯度为<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial \mathcal L}{\partial U} &amp;= \sum_{t=0}^T \frac{\partial \mathcal L}{\partial \mathcal L_t} \frac{\partial \mathcal L_t}{\partial U}\nonumber\\<br/>
&amp;= \sum_{t=0}^T \frac{\partial \mathcal L_t}{\partial U}\label{stfpm}\\<br/>
\end{align}<br/>
\]</p>

<p>即每个时刻损失 \(\mathcal L_t\) 对参数 \(U\) 的偏导数之和。</p>

<p>循环神经网络中存在一个递归调用的函数 \(f(\cdot)\)，因此其计算参数梯度的方式和前馈神经网络不太相同。在循环神经网络中主要有两种计算梯度的方式：随时间反向传播（BPTT）和实时循环学习（RTRL）算法。</p>

<h4 id="toc_11">随时间反向传播算法</h4>

<p>随时间反向传播（Backpropagation Through Time， BPTT）算法的主要思想是通过类似前馈神经网络的错误反向传播算法 [Werbos, 1990] 来进行计算梯度。</p>

<p>BPTT算法将循环神经网络看作是一个展开的多层前馈网络，其中“每一层”对应循环网络中的“每个时刻”。这样，循环神经网络就可以按照前馈网络中的反向传播算法进行计算参数梯度。在“展开”的前馈网络中，所有层的参数是共享的，因此参数的真实梯度是将所有“展开层”的参数梯度之和。</p>

<p>计算偏导数 \(\frac{\partial \mathcal L}{\partial U}\) ，先来计算公式 ( \ref{stfpm} ) 中第 \(t\) 时刻损失对参数 \(U\) 的偏导数 \(\frac{\partial \mathcal L_t}{\partial U}\) 。</p>

<p>因为参数 \(U\) 和隐藏层在每个时刻 \(k(1 \le k \le t)\) 的净输入 \(\mathbf z_k = U\mathbf h_{k−1} + W \mathbf x_k + \mathbf b\) 有关，因此第 \(t\) 时刻损失的损失函数 \(\mathcal L_t\) 关于参数 \(U_{ij}\) 的梯度为：<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial \mathcal L_t}{\partial U_{ij}} &amp;= \sum^t_{k=1} tr\Big((\frac{\partial \mathcal L_t}{\partial \mathbf z_k})^T \frac{\partial^+ \mathbf z_k}{\partial U_{ij}} \Big)\nonumber\\<br/>
&amp;= \sum_{k=1}^t \Big(\frac{\partial^+ \mathbf z_k}{\partial U_{ij}} \Big)^T \frac{\partial \mathcal L_t}{\partial \mathbf z_k}\label{sktb}\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(\frac{\partial^+ \mathbf z_k}{\partial U_{ij}}\)  表示“直接”偏导数，即公式 \(\mathbf z_k = U\mathbf h_{k−1} +W \mathbf x_k + \mathbf b\) 中保持 \(\mathbf h_{k−1}\) 不变，对 \(U_{ij}\) 进行求偏导数，得到<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial^+ \mathbf z_k}{\partial U_{ij}} = \left [ \begin{array}{c} 0\\ \vdots\\ [\mathbf h_{k-1}]_j\\\vdots\\0\\ \end{array} \right ] \buildrel \Delta \over= \mathbb I_i([\mathbf h_{k-1}]_j)\label{fpmzp}\\<br/>
\end{equation}<br/>
\]</p>

<p>其中 \([\mathbf h_{k-1}]_j\) 为第 \(k - 1\) 时刻隐状态的第 \(j\) 维； \(\mathbb I_i(x)\) 除了第 \(i\) 行值为 \(x\) 外，其余都为0的向量。</p>

<p>定义 \(\delta_{t,k} = \frac{\partial \mathcal L_t}{\partial \mathbf z_k}\) 为第 \(t\) 时刻的损失对第 \(k\) 时刻隐藏神经层的净输入 \(\mathbf z_k\) 的导数，则<br/>
\[<br/>
\begin{align}<br/>
\delta_{t,k} &amp;= \frac{\partial \mathcal L_t}{\partial \mathbf z_k}\nonumber\\<br/>
&amp;= \frac{\partial \mathbf h_k }{\partial \mathbf z_k} \cdot \frac{\partial \mathbf z_{k+1}}{\partial \mathbf h_k} \cdot \frac{\partial \mathcal L_t}{\partial \mathbf z_{k+1}}\nonumber\\<br/>
&amp;= diag(f&#39;(\mathbf z_k)) U^T\delta_{t,k+1}\label{dmzu}\\<br/>
\end{align}<br/>
\]</p>

<p>将公式 ( \ref{fpmzp} )和 ( \ref{dmzu} )代入公式 ( \ref{sktb} )得到<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathcal L_t}{\partial U_{ij}} &amp;= \sum_{k=1}^t [\delta_{t,k}]_i [\mathbf h_{k-1}]_j<br/>
\end{align*}<br/>
\]</p>

<p>将上式写成矩阵形式为<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial \mathcal L_t}{\partial U} = \sum_{k=1}^t \delta_{t,k} \mathbf h_{k-1}^{T}\label{fpmlp}\\<br/>
\end{equation}<br/>
\]</p>

<p>下图给出了误差项随时间进行反向传播算法的示例。</p>

<div align="center">
    <img src="media/15348711256289/15406548476276.jpg" width="600" />
</div>

<p><strong>参数梯度</strong>：将公式 ( \ref{fpmlp} )代入到将公式 ( \ref{stfpm} )得到整个序列的损失函数 \(\mathcal L\) 关于参数 \(U\) 的梯度<br/>
\[<br/>
\frac{\mathcal L}{\partial U} = \sum_{t=1}^T \sum_{k=1}^t \delta_{t,k} h_k^{T-1}<br/>
\]</p>

<p>同理可得， \(\mathcal L\) 关于权重 \(W\) 和偏置 \(\mathbf b\) 的梯度为<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathcal L}{\partial W} &amp;= \sum_{t=1}^T \sum_{k=1}^t \delta_{t,k} \mathbf x_k^T\\<br/>
\frac{\partial \mathcal L}{\partial \mathbf b} &amp;= \sum_{t=1}^T \sum_{k=1}^t \delta_{t,k}<br/>
\end{align*}<br/>
\]</p>

<p><strong>计算复杂度</strong>：在 BPTT 算法中，参数的梯度需要在一个完整的“前向”计算和“反向”计算后才能得到并进行参数更新。</p>

<h4 id="toc_12">实时循环学习算法</h4>

<p>与反向传播的 BPTT 算法不同的是，实时循环学习（Real-Time Recurrent Learning， RTRL）是通过前向传播的方式来计算梯度。</p>

<p>假设循环网络网络中第 \(t + 1\) 时刻的状态 \(\mathbf h_{t+1}\) 为<br/>
\[<br/>
\mathbf h_{t+1} = f(\mathbf z_{t+1}) = f(U\mathbf h_t + W\mathbf x_{t+1} + \mathbf b)<br/>
\]</p>

<p>其关于参数 \(U_{ij}\) 的偏导数为<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial \mathbf h_{t+1}}{\partial U_{ij}} &amp;= \frac{\partial \mathbf h_{t+1}}{\partial \mathbf z_{t+1}} \frac{\partial z_{t+1}}{\partial U_{ij}}\nonumber\\<br/>
&amp;= \frac{\partial \mathbf h_{t+1}}{\partial \mathbf z_{t+1}}\Big(\frac{\partial \mathbf z_{t+1}}{\partial U_{ij}} + \frac{\partial \mathbf z_{t+1}}{\partial \mathbf h_{t}} \frac{\partial \mathbf h_{t}}{\partial U_{ij}} \Big)\nonumber\\<br/>
&amp;= diag(f&#39;(\mathbf z_{t+1}))\Big(\mathbb I_i([\mathbf h_t]_j) + U \frac{\partial \mathbf h_t}{\partial U_{ij}} \Big)\nonumber\\<br/>
&amp;= f&#39;(\mathbf z_{t+1}) \odot \Big(\mathbb I_i([\mathbf h_t]_j) + U \frac{\partial \mathbf h_t}{\partial U_{ij}}\label{fmzo}\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(\mathbb I_i(x)\) 除了第 \(i\) 行值为 \(x\) 外，其余都为0的向量。</p>

<p>RTRL算法从第 1 个时刻开始，除了计算循环神经网络的隐状态之外，还利用公式 ( \ref{fmzo} ) 依次前向计算偏导数 \(\frac{\partial \mathbf h_1}{\partial U_{ij}}\)，\(\frac{\partial \mathbf h_2}{\partial U_{ij}}\)，\(\frac{\partial \mathbf h_3}{\partial U_{ij}}\)，\(\dots\)。</p>

<p>这样，假设第 \(t\) 个时刻存在一个监督信息，其损失函数为 \(\mathcal L_t\)，就可以同时计算损失函数对 \(U_{ij}\) 的偏导数<br/>
\[<br/>
\frac{\partial \mathcal L_t}{\partial U_{ij}} = \Big(\frac{\partial \mathbf h_t}{\partial U_{ij}}\Big)^T \frac{\partial \mathcal L_t}{\partial \mathbf h_t}<br/>
\]</p>

<p>这样在第 \(t\) 时刻，可以实时地计算损失 \(\mathcal L_t\) 关于参数 \(U\) 的梯度，并更新参数。参数 \(W\) 和 \(\mathbf b\) 的梯度也可以同样按上述方法实时计算。</p>

<p><strong>两种算法比较</strong>：BPTT 算法和 RTRL 算法都是基于梯度下降的算法，分别通过前向模式和反向模式应用链式法则来计算梯度。在循环神经网络中，一般网络输出维度远低于输入维度，因此 BPTT算法的计算量会更小，但是 BPTT 算法需要保存所有时刻的中间梯度，空间复杂度较高。 RTRL算法不需要梯度回传，因此非常适合用于需要在线学习或无限序列的任务中。</p>

<h3 id="toc_13">长期依赖问题</h3>

<p>循环神经网络在学习过程中的主要问题是长期依赖问题。在 BPTT 算法中，将公式 ( \ref{dmzu} ) 展开得到<br/>
\[<br/>
\delta_{t,k} = \prod_{i=k}^{t-1} \Big(diag(f&#39;(\mathbf z_i)) U^T\Big) \delta_{t,t}<br/>
\]</p>

<p>如果定义 \(\gamma \cong || diag(f&#39;(\mathbf z_i)) U^T||\) ，则<br/>
\[<br/>
\delta_{t,k} = \gamma^{t-k} \delta_{t,t}<br/>
\]</p>

<p>若 \(\gamma &gt; 1\)，当 \(t-k \rightarrow \infty\) 时， \(\gamma^{t-k} \rightarrow \infty\)，会造成系统不稳定，称为梯度爆炸问题（Gradient Exploding Problem）；相反，若 \(\gamma &lt; 1\)，当 \(t-k \rightarrow \infty\) 时，\(\gamma^{t - k} \rightarrow 0\)，会出现和深度前馈神经网络类似的梯度消失问题（gradient vanishing problem）。</p>

<p>要注意的是，在循环神经网络中的梯度消失不是说 \(\frac{\partial \mathcal L_t}{\partial U}\) 的梯度消失了，而是 \(\frac{\partial \mathcal L_t}{\partial \mathbf h_k}\) 的梯度消失了（当 \(t - k\) 比较大时）。也就是说，参数 \(U\) 的更新主要靠当前时刻 \(k\) 的几个相邻状态 \(\mathbf h_k\) 来更新，长距离的状态对 \(U\) 没有影响。</p>

<p>由于循环神经网络经常使用非线性激活函数为 logistic 函数或 tanh 函数作为非线性激活函数，其导数值都小于 1；并且权重矩阵 \(||U||\) 也不会太大，因此如果时间间隔 \(t - k\) 过大， \(\delta_{t,k}\) 会趋向于 0，因此经常会出现梯度消失问题。</p>

<p>虽然简单循环网络理论上可以建立长时间间隔的状态之间的依赖关系，但是由于梯度爆炸或消失问题，实际上只能学习到短期的依赖关系。这样，如果 \(t\) 时刻的输出 \(y_t\) 依赖于 \(t-k\) 时刻的输入 \(x_{t-k}\)，当间隔 \(k\) 比较大时，简单神经网络很难建模这种长距离的依赖关系，称为长期依赖问题。</p>

<h3 id="toc_14">改进方案</h3>

<p>为了避免梯度爆炸或消失问题，一种最直接的方式就是选取合适的参数，同时使用非饱和的激活函数，尽量使得 \(diag(f′(\mathbf z_i))U^T \approx 1\)，这种方式需要足够的人工调参经验，限制了模型的广泛应用。比较有效的方式通过改进模型或优化方法来缓解循环网络的梯度爆炸和梯度消失问题。</p>

<p><strong>梯度爆炸</strong>：一般而言，循环网络的梯度爆炸问题比较容易解决，一般通过权重衰减或梯度截断来避免。</p>

<p>权重衰减是通过给参数增加 \(\mathcal l_1\) 或 \(\mathcal l_2\) 范数的正则化项来限制参数的取值范围，从而使得 \(\gamma \le 1\)。梯度截断是另一种有效的启发式方法，当梯度的模大于一定阈值时，就将它截断成为一个较小的数。</p>

<p><strong>梯度消失</strong>：梯度消失是循环网络的主要问题。除了使用一些优化技巧外，更有效的方式就是改变模型，比如让 \(U = I\)，同时使用 \(f′(\mathbf z_i) = 1\)，即<br/>
\[<br/>
\begin{equation}<br/>
\mathbf h_t = \mathbf h_{t-1} + g(\mathbf x_t; \theta)\label{mhmh}<br/>
\end{equation}<br/>
\]</p>

<p>其中 \(g(\cdot)\) 是一个非线性函数， \(\theta\) 为参数。公式 ( \ref{mhmh} )中， \(\mathbf h_t\) 和 \(\mathbf h_{t-1}\) 之间为线性依赖关系，且权重系数为1，这样就不存在梯度爆炸或消失问题。但是，这种改变也丢失了神经元在反馈边上的非线性激活的性质，因此也降低了模型的表示能力。</p>

<p>为了避免这个缺点，我们可以采用一个更加有效的改进策略：<br/>
\[<br/>
\begin{equation}<br/>
\mathbf h_t = \mathbf h_{t-1} + g(\mathbf x_t, \mathbf h_{t-1}; \theta)\label{hhgh}<br/>
\end{equation}<br/>
\]</p>

<p>这样 \(\mathbf h_t\) 和 \(\mathbf h_{t-1}\) 之间为既有线性关系，也有非线性关系，在一定程度上可以缓解梯度消失问题。但这种改进依然有一个问题就是记忆容量（memory capacity）。随着 \(\mathbf h_t\) 不断累积存储新的输入信息，会发生饱和现象。假设 \(g(\cdot)\) 为 logistic函数，则随着时间 \(t\) 的增长， \(\mathbf h_t\) 会变得越来越大，从而导致 \(\mathbf h\) 变得饱和。也就是说，隐藏状态 \(\mathbf h_t\) 可以存储的信息是有限的，随着记忆单元存储的内容越来越多，其丢失的信息也越来越多。</p>

<p>为了解决容量问题，可以有两种方法。一种是增加一些额外的存储单元：外部记忆；另一种是进行选择性的遗忘，同时也进行有选择的更新。</p>

<hr/>

<p><a href="https://zybuluo.com/hanbingtao/note/541458">零基础入门深度学习(5) - 循环神经网络</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15345207395945.html">凸函数与严格凸函数、强凸函数</a></h1>
			<p class="meta"><time datetime="2018-08-17T23:45:39+08:00" 
			pubdate data-updated="true">2018/8/17</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>凸函数由于良好的性质，局部最优是全局最优，而有广泛的应用，这里简单做一个介绍。</p>

<h4 id="toc_0">凸函数</h4>

<p>设 \(f(x)\) 为定义 n 维欧氏空间中某个凸集 S 上的函数，若对于任何实数 \(\alpha\)（\(0\alpha 1\)）以及 \(S\) 中的任意不同两点 \(x\) 和 \(y\) ，均有<br/>
\[<br/>
\begin{equation}<br/>
f(\alpha x + (1-\alpha)y) \le \alpha f(x) + (1-\alpha)f(y)\label{fax}<br/>
\end{equation}<br/>
\]</p>

<p>则称 \(f(x)\) 为定义在凸集 \(S\) 上的凸函数。</p>

<p>凸函数的定义也很好理解，任意两点的连线必然在函数的上方，如下是一个典型的凸函数</p>

<div align="center">
    <img width="350" src="media/15345207395945/15379718476129.jpg" />
</div>

<h4 id="toc_1">严格凸函数</h4>

<p>如果将式 ( \ref{fax} ) 不等式中的 \(\le\) 改成 \(\lt\)，则称该函数为严格凸函数。</p>

<h4 id="toc_2">强凸函数</h4>

<p>强凸函数是指 \(\forall m \gt 0\)，\(f-\frac{m}{2} ||x||_2^2\) 也是凸的，其含义就是该凸函数的 “凸性” 比二次函数还要强，即使减去一个二次函数也是凸函数。</p>

<p>相比凸函数，强凸函数可以保证其梯度更大</p>

<div align="center">
    <img width="550" src="media/15345207395945/15380722342531.jpg" />
</div>

<p>如上的左边凸函数在使用梯度下降法收敛到最低点的时候，梯度很慢，甚至难以收敛；但是右图强凸函数可以保证梯度很大（右图下方为二次函数）。</p>

<h4 id="toc_3">凸函数的性质</h4>

<ol>
<li><p><strong>一阶特性（First-order characterization）</strong>：<br/>
\[<br/>
f(y) \ge f(x) + \nabla f(x)(y-x)<br/>
\]</p></li>
<li><p><strong>二阶特性（Second-order characterization）</strong>：<br/>
\[<br/>
\nabla^2 f(x) \ge 0<br/>
\]</p>

<p>这里的 \(\ge\) 表示 Hessian 矩阵是半正定的。</p></li>
<li><p><strong>Jensen不等式</strong>：<br/>
\[<br/>
f(\mathbb E(x)) \le \mathbb E(f(x))<br/>
\]</p></li>
</ol>

<p>其中，一阶特性或二阶特性是一个函数为凸函数的充要条件，通常用来证明一个函数是凸函数。</p>

<hr/>

<p><a href="http://wulc.me/2017/05/20/%E5%87%B8%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/">凸优化总结</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15342500383830.html">矩阵条件数与病态矩阵</a></h1>
			<p class="meta"><time datetime="2018-08-14T20:33:58+08:00" 
			pubdate data-updated="true">2018/8/14</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>矩阵A的条件数等于A的范数与A的逆的范数的乘积，即 \(\text{cond}(A)=‖A‖·‖A^{-1}‖\)，对应矩阵的3种范数，相应地可以定义3种条件数。</p>

<ul>
<li><p>\(\infty\)-条件数：<br/>
\[<br/>
\text{cond}(A) = ||A||\cdot ||A^{-1}||<br/>
\]</p></li>
<li><p>1-条件数<br/>
\[<br/>
\text{cond}(A) = ||A||_1\cdot ||A^{-1}||_1<br/>
\]</p></li>
<li><p>2-条件数<br/>
\[<br/>
\text{cond}(A) = ||A||_2\cdot ||A^{-1}||_2 = \sqrt{\frac{\lambda_1}{\lambda_n}}<br/>
\]</p></li>
</ul>

<p>其中 \(\lambda_1\) 是 \(A^HA\) 的最大特征值，\(\lambda_n\) 是 \(A^HA\) 的最小特征值。</p>

<blockquote>
<p>向量范数的计算，对向量 \(x\)</p>

<ol>
<li>\(||x||_1 = |x_1| + |x_2| + ... + |x_n|\)</li>
<li>\(||x||_2 = \sqrt{|x_1|^2 + |x_2|^2 + ... + |x_n|^2}\)</li>
<li>\(||x||_\infty = \max_{1\le i \le n}(|x_i|)\)</li>
<li>\(||x||_{-\infty} = \min_{1\le i \le n} (|x_i|)\)</li>
</ol>

<p>例如向量 \(z = [-5,6,8,10]\)，则 \(||z||_1 = 29\)，\(||z||_2 = 15\)，\(||z||_\infty = 10\)，\(||z||_{-\infty} = 5\)</p>

<p>矩阵范数的计算，对矩阵 \(A\)</p>

<ol>
<li>矩阵的一阶范数（列范数）：矩阵的每一列上的元素绝对值先求和，再从中取个最大的
\[
|A|_1 = \max_{1\le j \le n}\sum_{i=1}^n |a_{ij}|
\]</li>
<li>矩阵的二阶范数：矩阵 \(A^TA\) 的最大特征值开平方根
\[
|A|_2 = \sqrt{\lambda_{max}(A^T A)}
\]</li>
<li>矩阵的无穷范数（行范数）：矩阵的每一行上的元素绝对值先求和，再从中取个最大的
\[
|A|_1 = \max_{1\le i \le n}\sum_{j=1}^n |a_{ij}|
\]</li>
</ol>

<p>例如矩阵 \(A = \left [ \begin{array}{ccc} -1&amp;2&amp;-3\\ 4&amp;-6&amp;6\\\end{array}\right ]\)，则 \(||A||_1 = 9\)，\(||A||_2 = 10.0623\)，\(||A||_{\infty} = 16\)</p>

<p>另外常用的范数</p>

<ol>
<li><strong>矩阵的L0范数</strong>：矩阵的非0元素的个数，通常用它来表示稀疏，L0范数越小0元素越多，也就越稀疏，上述矩阵A最终结果就是：6</li>
<li><strong>矩阵的L1范数</strong>：矩阵中的每个元素绝对值之和，它是L0范数的最优凸近似，因此它也可以表示稀疏，上述矩阵A最终结果就是：22</li>
<li><strong>矩阵的F范数</strong>：矩阵的各个元素平方之和再开平方根，它通常也叫做矩阵的L2范数，它的有点在它是一个凸函数，可以求导求解，易于计算，上述矩阵A最终结果就是：10.0995</li>
<li><strong>矩阵的L21范数</strong>：矩阵先以每一列为单位，求每一列的F范数（也可认为是向量的2范数），然后再将得到的结果求L1范数（也可认为是向量的1范数），很容易看出它是介于L1和L2之间的一种范数，上述矩阵A最终结果就是：17.1559</li>
</ol>
</blockquote>

<h4 id="toc_0">矩阵条件数的性质</h4>

<ol>
<li><p>\(\text{cond}(A) \ge 1\)</p>

<p>证明：\(\text{cond}(A) = ||A^{-1}||\cdot ||A|| \ge ||A^{-1}A = ||I|| = 1\)</p></li>
<li><p>\(\text{cond}(A) = \text{cond}(A^{-1})\)</p>

<p>证明：\(\text{cond}(A^{-1}) = ||A^{-1}||\cdot ||(A^{-1})^{-1}|| = ||A^{-1}||\cdot ||A|| = \text{cond}(A)\)</p></li>
<li><p>\(\text{cond}(\alpha A) = \text{cond}(A),\alpha \ne 0,\alpha \in \mathbb R\)</p>

<p>证明：\(\text{cond}(\alpha A) = ||\alpha A||\cdot ||(\alpha A)^{-1}|| = |\alpha|\cdot ||A|| \cdot \frac{1}{|\alpha|}\cdot ||A^{-1}|| \\<br/>
= ||A||\cdot ||A^{-1}|| = \text{cond}(A)\)</p></li>
<li><p>如果 \(U\) 是酉矩阵，则<br/>
\[<br/>
\text{cond}_2(U) = 1\\<br/>
\text{cond}_2(UA) = \text{cond}_2(AU) = \text{cond}_2(A)\\<br/>
\]</p></li>
<li><p>A，B可逆\(\text{cond}(AB) \le \text{cond}(A) \cdot \text{cond}(B)\)</p>

<p>证明：\(\text{cond}(AB) = ||AB||\cdot ||(AB)^{-1}|| \le ||A||\cdot ||B||\cdot ||A^{-1}|| \cdot ||B^{-1}|| \\<br/>
= \text{cond}(A)\cdot \text{cond}(B)<br/>
\)</p></li>
</ol>

<h4 id="toc_1">条件数的应用</h4>

<ol>
<li>若条件数 \(\text{cond}(A)\) 较小，就称 \(A\) 关于求逆矩阵或解线性方程组为<strong>良态的</strong>或<strong>好条件的</strong>。</li>
<li><p>若条件数 \(\text{cond}(A)\) 较大，就称 \(A\) 关于求逆矩阵或解线性方程组为<strong>病态的</strong>或<strong>坏条件的</strong>。</p>

<p>注意：\(\text{cond}(A)\) 多大 \(A\) 算病态，通常没有具体的定量标准。</p></li>
</ol>

<p>现有线性系统：\(Ax = b\)，解方程<br/>
\[<br/>
\left[\begin{array}{cc}400&amp;-201\\-800&amp;401\\\end{array}\right ] \left [ \begin{array}{c}x_1\\x_2\\\end{array}\right ] = \left [ \begin{array}{c}200\\-200\\\end{array}\right ]<br/>
\]</p>

<p>很容易得到解为：\(x_1 = -100\), \(x_2 = -200\)。如果在样本采集时存在一个微小的误差，比如，将 \(A\) 矩阵的系数 400 改变成 401：<br/>
\[<br/>
\left[\begin{array}{cc}401&amp;-201\\-800&amp;401\\\end{array}\right ] \left [ \begin{array}{c}x_1\\x_2\\\end{array}\right ] = \left [ \begin{array}{c}200\\-200\\\end{array}\right ]<br/>
\]</p>

<p>则得到一个截然不同的解：\(x_1 = 40000, x_2 = 79800\)。</p>

<p>当解集 x 对 A 和 b 的系数高度敏感，那么这样的方程组就是病态的 (ill-conditioned)。</p>

<h4 id="toc_2">病态的由来</h4>

<p>一个极端的例子，当A奇异时，条件数为无穷，这时即使不改变b，x也可以改变。奇异的本质原因在于矩阵有0特征值，\(x\) 在对应特征向量的方向上运动不改变 \(Ax\) 的值。如果一个特征值比其它特征值在数量级上小很多，\(x\) 在对应特征向量方向上很大的移动才能产生 \(b\) 微小的变化，这就解释了为什么这个矩阵为什么会有大的条件数，事实上，正规阵在二范数下的条件数就可以表示成 abs (最大特征值/最小特征值)。</p>

<h4 id="toc_3">\(L^2\) 范数解救病态</h4>

<p>L2范数有助于处理条件数不好的情况下矩阵求逆很困难的问题。因为目标函数如果是二次的，对于线性回归来说，那实际上是有解析解的，求导并令导数等于零即可得到最优解为：<br/>
\[<br/>
\hat w = (X^TX)X^Ty<br/>
\]</p>

<p>然而，如果当我们的样本 \(X\) 的数目比每个样本的维度还要小的时候，矩阵 \(X^TX\) 将会不是满秩的，即 \(\text{det}(X^TX)=0\)，则 \(X^TX\) 会变得不可逆，所以 \(\hat{w}\) 就没办法直接计算出来了。</p>

<p>但如果加上L2正则项，就变成了下面这种情况，就可以直接求逆了：<br/>
\[<br/>
\hat w = (X^TX + \alpha I)X^T y<br/>
\]</p>

<p>病态矩阵解集的不稳定性是由于解集空间包含了自由度过大的方向，解决这个问题的关键就是将这些方向去掉。其中单位矩阵I的维度为参数向量的维度。自由度太大会造成过拟合泛化能力极差，同时系统又极不稳定。当我们加入正则项之后，A就变成了满秩矩阵，便可以直接求逆了。</p>

<hr/>

<p><a href="https://blog.csdn.net/Michael__Corleone/article/details/75213123">向量和矩阵的各种范数比较（1范数、2范数、无穷范数等等）</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15335638026316.html">多元函数极值与Hessian矩阵的关系</a></h1>
			<p class="meta"><time datetime="2018-08-06T21:56:42+08:00" 
			pubdate data-updated="true">2018/8/6</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>海塞矩阵（Hessian Matrix），又译作海森矩阵，是一个多元函数的二阶偏导数构成的方阵。在机器学习和图像处理（例如SIFT和SURF特征检测）中，经常可以遇到它。</p>

<h3 id="toc_0">一元函数极值问题</h3>

<p>如果我们需要求一个一元函数的极值，比如 \(f(x) = x^2\)，我们必然想到要求函数的一阶导数，并令结果等于0：<br/>
\[<br/>
f&#39;(x) = 2x<br/>
\]</p>

<p>当时一阶导数为0，不总是能求出极值。我们知道在 \(x_0\) 点的一阶导数值在几何意义上表示函数在 \(x_0\) 点的切线。下图中，可以清晰说明导数为0，不一定就是极限值。</p>

<div align="center">
    <img width="350" src="media/15335638026316/15335656524655.jpg" />
</div>

<p>在B点导数为0，该点却不是极值点，而是驻点。</p>

<p>将一元函数 \(f(x)\) 在 \(x_0\) 处用二阶近似得<br/>
\[<br/>
f(x) = f(x_0) + f&#39;(x_0)(x-x_0) + \frac 1 2 f&#39;&#39;(x_0)(x-x_0)^2<br/>
\]</p>

<p>当 \(f&#39;(x_0)=0\) 时，如果二阶导数 \(f&#39;&#39;(x_0) \gt 0\)，可得在 \(x_0\) 旁边任意点有 \(f(x) \gt f(x_0)\)，那么 \(x_0\) 就是该局部极小值。如果二阶导数 \(f&#39;&#39;(x_0) \lt 0\)，可得在 \(x_0\) 旁边任意点有 \(f(x) \lt f(x_0)\)，\(x_0\) 是该局部极大值。如果 \(f&#39;&#39;(x_0)=0\)，则结果仍然是不确定的，我们就不得不再通过其他方式来确定函数的极值性。</p>

<h3 id="toc_1">多元函数极值问题</h3>

<p>类似的，如果在多元函数中求极值点，可以通过一阶导数等于0 和二阶导数来判断。假设 \(f\) 是一个二元函数<br/>
\[<br/>
f=(x,y)<br/>
\]</p>

<p>\(f\) 的一阶导数<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial f}{\partial x} &amp;= 0\\<br/>
\frac{\partial f}{\partial y} &amp;= 0\\<br/>
\end{align*}<br/>
\]</p>

<p>\(f\) 的二阶导数有9个，如果用矩阵形式表示就是<br/>
\[<br/>
H = \left [\begin{array}\\<br/>
\frac{\partial f}{\partial x\partial x}&amp;\frac{\partial f}{\partial x\partial y}\\<br/>
\frac{\partial f}{\partial y\partial x}&amp;\frac{\partial f}{\partial y\partial y}\\<br/>
\end{array} \right ]<br/>
\]</p>

<p>如果将多元函数在 \((x_0,y_0)\) 处二阶近似得<br/>
\[<br/>
f(x,y) = f(x_0,y_0) + [x-x_0,y-y_0]\left [\begin{array}\\\frac{\partial f}{\partial x}\\\frac{\partial}{\partial y}\\\end{array}\right ] + \frac 1 2 [x-x_0,y-y_0] \left [\begin{array}\\<br/>
\frac{\partial f}{\partial x\partial x}&amp;\frac{\partial f}{\partial x\partial y}\\<br/>
\frac{\partial f}{\partial y\partial x}&amp;\frac{\partial f}{\partial y\partial y}\\<br/>
\end{array} \right ] \left[ \begin{array}\\x-x_0\\y-y_0\\\end{array}\right ]<br/>
\]</p>

<p>令 \(\triangle x = [x-x_0,y-y_0]\)，上式简化表示即<br/>
\[<br/>
f(x,y) = f(x_0,y_0) + \triangle x \nabla f + \triangle x H \triangle x^T<br/>
\]</p>

<p>二元函数 \(f(x,y)\) 一阶导数为0，即 \(\triangle x \nabla f = 0\)，所以<br/>
\[<br/>
f(x,y) = f(x_0,y_0) + \triangle x H \triangle x^T<br/>
\]</p>

<p>如果 \(\triangle x H \triangle x^T \gt 0\)，则 \(f(x,y) \gt f(x_0,y_0)\) 即 \((x_0,y_0)\) 是函数局部极小值。因为 \(H\) 是实对称矩阵，当 \(\triangle x H \triangle x^T \gt 0\) 时，可以说 \(H\) 是正定矩阵。所以我们可以得出结论</p>

<ul>
<li>当 \(H\) 是正定矩阵时，\((x_0,y_0)\) 是函数局部极小值；</li>
<li>当 \(H\) 是负定矩阵时，\((x_0,y_0)\) 是函数局部极大值；</li>
<li>当 \(H\) 是不定矩阵时，\((x_0,y_0)\) 不是函数极值点；</li>
</ul>

<hr/>

<p><a href="https://blog.csdn.net/baimafujinji/article/details/51167852">Hessian矩阵与多元函数极值</a><br/>
<a href="https://blog.csdn.net/chduan_10/article/details/78075112">怎么理解二阶偏导与凸函数的Hessian矩阵是半正定的</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15327348574245.html">人工神经网络-卷积神经网络</a></h1>
			<p class="meta"><time datetime="2018-07-28T07:40:57+08:00" 
			pubdate data-updated="true">2018/7/28</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>卷积神经网络是一种<strong>局部连接</strong>、<strong>权重共享</strong>等特性的深层前馈神经网络。卷积神经网络最早是主要用来处理图像信息。如果用全连接来处理图像信息时，会出现几个问题<br/>
1）参数太多。假设一个100 * 100 * 3的图像（高100，宽100,RGB）。在全连接前馈网络中，隐藏层的每一个神经元到输入层的连接有 100 * 100 * 3 = 30000个连接，每个连接对应一个权重参数。随着隐藏层神经元的增多，参数规模会急剧增加。参数过多，也会很容易产生过拟合。<br/>
2）局部不变性：自然图像中的物体具有局部不变特性，比如在尺度缩放、平移、旋转等操作不影响其语义信息。而全连接前馈网络很难提取这些局部不变特征，一般需要进行数据增强来提高性能。</p>

<p>那么，卷积神经网络又是怎样解决这个问题的呢？主要有三个思路：<br/>
1）局部连接：这个是最容易想到的，每个神经元不再和上一层的所有神经元相连，而只和一小部分神经元相连。这样就减少了很多参数。<br/>
2）权值共享：一组连接可以共享同一个权重，而不是每个连接有一个不同的权重，这样又减少了很多参数。<br/>
3）下采样：可以使用Pooling来减少每层的样本数，进一步减少参数数量，同时还可以提升模型的鲁棒性。</p>

<p>卷积神经网络主要使用在图像和视频分析的各种任务上，比如图像分类、人脸识别、物体识别、图像分割等，其准确率一般也远远超出了其它的神经网络模型。近年来卷积神经网络也广泛地应用到自然语言处理、推荐系统等领域。</p>

<h3 id="toc_0">卷积</h3>

<p>卷积是一种重要的运算。在信号处理或图像处理中，经常使用一维或二维卷积。</p>

<h4 id="toc_1">一维卷积</h4>

<p>一维卷积常用于序列模型，自然语言处理领域。一维卷积指的是卷积核是1维的，而不是卷积的输入是1维的。假设一个信号发生器每个时刻 \(t\) 产生一个信号 \(x_t\)，其信息的衰减率为 \(w_k\)，即在 \(k−1\) 个时间步长后，信息为原来的 \(w_k\) 倍。假设 \(w_1=1\),\(w_2 =1/2\),\(w_3 =1/4\)，那么在时刻 \(t\) 收到的信号 \(y_t\) 为当前时刻产生的信息和以前时刻延迟信息的叠加，<br/>
\[<br/>
\begin{align*}<br/>
y_t &amp;= 1\times x_t +1/2\times x_{t−1} + 1/4\times x_{t−2}\\<br/>
&amp;= w_1 \times x_t +w_2 \times x_{t−1} + w_3 \times x_{t−2}\\<br/>
&amp;= \sum^3_{k=1} w_k \cdot x_{t−k+1}\\<br/>
\end{align*}<br/>
\]</p>

<p>我们假设卷积核（滤波器）为 \(\mathbf w = (w_1,...,w_{m})\)，长度为 \(m\) ，它和一个信号序列 \(x_1,...\) 的卷积为<br/>
\[<br/>
y_t = \sum_{k=1}^{m} w_k x_{t-k+1}<br/>
\]</p>

<p>信号序列 \(\mathbf x\) 与滤波器 \(\mathbf w\) 的卷积定义为<br/>
\[<br/>
y = \mathbf w \otimes \mathbf x<br/>
\]</p>

<p>其中 \(\otimes\) 表示卷积操作。</p>

<p>假设如下图，图中的输入的数据维度为8，卷积核的维度为5，卷积步数为1时，卷积后输出的数据维度为8−5+1=4。卷积核为 \((0,1,1,2,-1)\)，输入信号为 \((1,1,2,-1,1,-1,2,1)\)，卷积为<br/>
\[<br/>
\begin{align*}<br/>
y_0 &amp;= \sum_{k=1}^5 w_k x_{1-k} = w_1 x_1 + w_2 x_0 + w_3 x_{-1} + w_4 x_{-2} + w_5 x_{-3} \\<br/>
&amp;= 0 \times  1 + 1 \times (-1) + 1 \times 2 + 2 \times 1 + (-1) \times 1 \\<br/>
&amp;= 0 - 1 + 2 + 2 - 1 \\<br/>
&amp;= 2\\<br/>
y_1 &amp;= \sum_{k=0}^4 w_k x_{5-k} = w_0 x_5 + w_1 x_4 + w_2 x_3 + w_3 x_2 + w_4 x_1 \\<br/>
&amp;= 0 \times  (-1) + 1 \times 1 + 1 \times (-1) + 2 \times 2 + (-1) \times 1 \\<br/>
&amp;= 0 + 1 -1 + 4 - 1\\<br/>
&amp;= 3\\<br/>
y_2 &amp;= \sum_{k=0}^4 w_k x_{6-k} = w_0 x_6 + w_1 x_5 + w_2 x_4 + w_3 x_3 + w_4 x_2 \\<br/>
&amp;= 0 \times  2 + 1 \times (-1) + 1 \times 1 + 2 \times (-1) + (-1) \times 2\\<br/>
&amp;= 0 - 1 + 1 - 2 - 2\\<br/>
&amp;= -4\\<br/>
y_3 &amp;= \sum_{k=0}^4 w_k x_{7-k} = w_0 x_7 + w_1 x_6 + w_2 x_5 + w_3 x_4 + w_4 x_3 \\<br/>
&amp;= 0 \times  1 + 1 \times 2 + 1 \times (-1) + 2 \times 1 + (-1) \times (-1)\\<br/>
&amp;= 0 + 2 - 1 + 2 + 1\\<br/>
&amp;= 4\\<br/>
\end{align*}<br/>
\]</p>

<p>我们可以简单的进行用图表示，先将卷积核反转，然后挨个与信号相乘，结果求和即可，如下：</p>

<div align="center">
    <img width="480" src="media/15327348574245/15395252379933.jpg" />
</div>

<h4 id="toc_2">二维卷积</h4>

<p>二维卷积常用语图像识别等领域。因为图像为一个两维结构，所以需要将一维卷积进行扩展。给定一个图像 \(X \in \mathbb R^{M\times N}\)，和滤波器 \(W \in \mathbb R^{m\times n}\)，一般 \(m \le M,n\le N\)，其卷积为<br/>
\[<br/>
y_{ij} = \sum_{u=1}^{m} \sum_{v=1}^{n} w_{uv}\cdot x_{i-u+1,j-v+1}<br/>
\]</p>

<p>下图给出了二维卷积示例。</p>

<div align="center">
    <img width="480" src="media/15327348574245/15395277611156.jpg" />
</div>

<p>\[<br/>
\begin{align*}<br/>
y_{13} &amp;= \sum_{u=1}^3 \sum_{v=1}^3 w_{uv} \cdot x_{1-u+1,3-v+1} = \sum_{u=1}^3\sum_{v=1}^3 w_{uv} x_{2-u,4-v}\\<br/>
&amp;= w_{11} x_{13} + w_{12} x_{12} + w_{13} x_{11} \\<br/>
&amp;+ w_{10} x_{14} + w_{11} x_{13} + w_{12} x_{12} \\<br/>
&amp;+ w_{20} x_{04} + w_{21} x_{03} + w_{22} x_{02} \\ <br/>
&amp;= 1 \times 0 + 0 \times (-1) + 0 \times 1 \\<br/>
&amp;+ 0 \times 1 + 0 \times 0 + 0 \times (-3) \\<br/>
&amp;+ 0 \times 1 + 0 \times 1 + (-1) \times 1 \\ <br/>
&amp;= -1\\<br/>
\end{align*}<br/>
\]</p>

<p>在图像处理中，卷积经常作为特征提取的有效方法。一幅图像在经过卷积操作后得到结果称为特征映射(feature map)。图给出在图像处理中几种常用的滤波器，以及其对应的特征映射。图中最上面的滤波器是常用的高斯滤波器，可以用来对图像进行平滑去噪;中间和最下面的过滤器可以用来提取边缘特征。</p>

<div align="center">
    <img width=500 src="media/15327348574245/15395313721468.jpg" />
</div>

<h4 id="toc_3">互相关</h4>

<p>在机器学习和图像处理领域，卷积的主要功能是在一个图像（或某种特征）上滑动一个卷积核（即滤波器），通过卷积操作得到一组新的特征。在计算卷积的过程中，需要对卷积核翻转。在具体实现上，一般会以互相关操作来代替卷积，从而减少一些不必要的操作和开销。互相关是衡量两个序列相关性的函数，通常是滑动卷口的点击运算来实现的。给定一个图像 \(X\in \mathbb R^{M\times N}\) 和卷积核 \(W\in\mathbb R^{m\times n}\)，它们的互相关为<br/>
\[<br/>
\begin{align}<br/>
y_{ij} = \sum_{u=1}^m \sum_{v=1}^n w_{uv} x_{i+u-1,j+v-1}\label{yijs}\\<br/>
\end{align}<br/>
\]</p>

<p>和卷积相比，互相关的区别在于卷积核是否进行了翻转，也可以理解为图像是否进行翻转。因此互相关也可以被称为<strong>不翻转卷积</strong>。</p>

<p>在神经网络中使用卷积是为了进行特征抽取，卷积核是否进行了翻转和其特征抽取无关。特别是当卷积核是可学习的参数时，卷积核互相关是等价的。一次，为了实现上的方便起见，我们用互相关来代替卷积。事实上，很多深度学习工具中卷积操作都是互相关操作。</p>

<p>公式 ( \ref{yijs} )可以表述为<br/>
\[<br/>
Y = W \otimes X<br/>
\]</p>

<p>其中 \(Y\in \mathbb R^{M-m+1,N-n+1}\) 为输出矩阵。</p>

<h4 id="toc_4">卷积的变种</h4>

<p>在卷积的标准定义基础上，还可以引入滤波器的滑动步长和零填充来增加卷积的多样性，可以更灵活地进行特征抽取。</p>

<h5 id="toc_5"><strong>滑动步长（stride）</strong>：卷积核在滑动时的间隔。下图给出了步长为2的二维卷积示例。</h5>

<div align=center>
    <img width="500" src="media/15327348574245/15402216516097.jpg" />
</div>

<p><strong>零填充（zero padding）</strong>：输入两端进行补零。因为步长的设置问题，可能导致剩下未扫描的空间不足以提供给卷积核，比如有图大小为5 * 5,卷积核为2 * 2,步长为2,卷积核扫描了两次后，剩下一个元素，不够卷积核扫描了，这个时候就需要补零。更一般地，假设卷积层的输入神经元个数为 \(n\)，卷积大小为 \(m\)，步长（stride）为 \(s\)，输入神经元两端各填补 \(p\) 个零（zero padding），那么该卷积层的神经元数量为 \((n − m + 2p)/s + 1\)。</p>

<div align="center">
    <img width="280" src="media/15327348574245/15402225775512.jpg" />
</div>

<p>一般常用的卷积有以下三类：</p>

<ol>
<li><strong>窄卷积（narrow convolution）</strong>：步长 \(s=1\)，两端不补零 \(p=0\)，卷积后输出长度为 \(n-m+1\)。</li>
<li><strong>宽卷积（wide convolution）</strong>：步长 \(s=1\)，两端补零 \(p=m-1\)，卷积后的长度为 \(n+m-1\)。</li>
<li><strong>等长卷积（equal-width convolution）</strong>：步长 \(s=1\)，两端补零 \(p=(m-1)/2\)，卷积后输出长度为 \(n\)。</li>
</ol>

<p>这里的窄、宽、等长指的都是卷积后与卷积前的大小比较。</p>

<h3 id="toc_6">卷积的数学性质</h3>

<p>卷积有很多很好的数学性质，这些性质不止是二维卷积，也可以适用到一维卷积的情况。</p>

<h4 id="toc_7">交换性</h4>

<p>如果不限制两个卷积信号的长度，卷积是具有交换性的，即 \(x\otimes y = y \otimes x\)。当输入信息和卷积核有固定长度时，它们的宽卷积依然具有交换性。对于两维图像 \(X \in \mathbb R^{M×N}\) 和卷积核 \(W \in \mathbb R^{m×n}\)，对图像 \(X\) 的两个维度进行零填充，两端各补 \(m-1\) 和 \(n-1\) 个零，得到全填充（full padding）的图像 \(\widetilde X\in\mathbb R^{(M+2m−2)\times(N+2n−2)}\)。图像 \(X\) 和卷积核 \(W\) 的宽卷积（wide convolution）定义为<br/>
\[<br/>
W \widetilde \otimes X \buildrel \Delta \over = W \otimes \widetilde X<br/>
\]</p>

<p>其中 \(\widetilde \otimes\) 为宽卷积操作。</p>

<p>宽卷积具有交换性，即<br/>
\[<br/>
W \widetilde \otimes X = X \widetilde \otimes W<br/>
\]</p>

<p>可以用一个简单的例子来看看这个交换操作。</p>

<h4 id="toc_8">导数</h4>

<p>假设 \(Y=W\otimes X\)，其中 \(X \in \mathbb R^{M\times N}\)，\(W\in \mathbb R^{m\times n}\)，\(Y \in \mathbb R^{(M-m+1)\times (N-n+1)}\)，函数 \(f(Y) \in \mathbb R\) 为一个标量函数，则<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial f(Y)}{\partial w_{uv}} &amp;= \sum_{i=1}^{M-m+1} \sum_{j=1}^{M-m+1} \frac{\partial f(Y)}{\partial y_{ij}}\frac{\partial y_{ij}}{\partial w_{uv}}\\<br/>
&amp;= \sum_{i=1}^{M-m+1} \sum_{j=1}^{M-m+1} \frac{\partial f(Y)}{\partial y_{ij}}\frac{\partial}{\partial w_{uv}} \Big(\sum_{u=1}^m \sum_{v=1}^n w_{uv} x_{i+u-1,j+v-1}\Big)\\<br/>
&amp;= \sum_{i=1}^{M-m+1} \sum_{j=1}^{M-m+1} \Big(\frac{\partial f(Y)}{\partial y_{ij}}\Big) x_{i+u-1,j+v-1}\\<br/>
\end{align*}<br/>
\]</p>

<p>上式可以看出， \(f(Y)\) 关于 \(W\) 的偏导数为 \(X\) 和 \(\frac{\partial f(Y)}{\partial Y}\) 的卷积<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial f(Y)}{\partial W} = \frac{\partial f(Y)}{\partial Y} \otimes X\\\label{fpfyp}<br/>
\end{equation}<br/>
\]</p>

<p>同理可得<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial f(Y)}{\partial x_{st}} &amp;= \sum_{i=1}^{M-m+1} \sum_{j=1}^{N-n+1} \frac{\partial y_{ij}}{\partial x_{st}}\frac{\partial f(Y)}{\partial y_{ij}}\nonumber\\<br/>
&amp;= \sum_{i=1}^{M-m+1} \sum_{j=1}^{N-n+1} w_{s-i+1,t-j+1} \frac{\partial f(Y)}{\partial y_{ij}}\label{fpsmi}\\<br/>
\end{align}<br/>
\]</p>

<p>其中当 \((s-i+1) \lt 1\)，或 \((s-i+1) \gt m\)，或 \((t-j+1) \lt 1\)，或 \((t - j + 1) \gt n\) 时， \(w_{s-i+1,t-j+1} = 0\)。即相当于对 \(W\) 进行了 \(p = (M - m, N - n)\) 的零填充。</p>

<p>从公式 \(( \ref{fpsmi} )\) 可以看出， \(f(Y)\) 关于 \(X\) 的偏导数为 \(W\) 和 \(\frac{\partial f(Y)}{\partial Y}\) 的宽卷积。公式 ( \ref{fpsmi} ) 中的卷积是真正的卷积而不是互相关，为了一致性，我们用互相关的“卷积”，即<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial f(Y)}{\partial X} &amp;= \mathbf{rot180}(\frac{f(Y)}{\partial Y})\widetilde \otimes W\\<br/>
&amp;=\mathbf{rot180}(W)\widetilde \otimes \frac{\partial f(Y )}{\partial Y}\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\mathbf{rot180}(\cdot)\) 表示旋转 180度。</p>

<h3 id="toc_9">卷积神经网络</h3>

<p>卷积神经网络一般由卷积层、池化层和全连接层构成。</p>

<h4 id="toc_10">用卷积来代替全连接</h4>

<p>在全连接前馈神经网络中，如果第 \(l\) 层有 \(n^{(l)}\) 个神经元，第 \(l-1\) 层有 \(n^{(l−1)}\) 个神经元，连接边有 \(n^{(l)} \times n^{(l−1)}\) 个，也就是权重矩阵有 \(n^{(l)} \times n^{(l−1)}\) 个参数。此时权重矩阵的参数非常多，训练的效率会非常低。</p>

<p>如果采用卷积来代替全连接，第 \(l\) 层的净输入 \(\mathbf z(l)\) 为第 \(l-1\) 层活性值 \(\mathbf a(l−1)\) 和滤波器 \(\mathbf w^{(l)} \in \mathbb R^m\) 的卷积，即<br/>
\[<br/>
\begin{equation}<br/>
\mathbf z^{(l)} = \mathbf w^{(l)} \otimes \mathbf a^{(l−1)} + b^{(l)}\label{mzlm}\\<br/>
\end{equation}<br/>
\]</p>

<p>其中滤波器 \(\mathbf w^{(l)}\) 为权重向量， \(b^{(l)} \in \mathbb R^{n^{l−1}}\) 为偏置。</p>

<p>根据卷积的定义，卷积层有两个很重要的性质：</p>

<ol>
<li><strong>局部连接</strong>：在卷积层（假设是第 \(l\) 层）中的每一个神经元都只和下一层（第 \(l-1\) 层）中某个局部窗口内的神经元相连，构成一个局部连接网络。如下右图所示，卷积层和下一层之间的连接数大大减少，有原来的 \(n^{(l)} \times n^{(l−1)}\) 个连接变为 \(n^{(l)} \times m\) 个连接，\(m\) 为滤波器大小。</li>
<li><strong>权重共享</strong>：从公式 ( \ref{mzlm} )可以看出，作为参数的滤波器 \(w^{(l)}\) 对于第 \(l\) 层的所有的神经元都是相同的。如下右图中，所有的同颜色连接上的权重是相同的。</li>
</ol>

<p>由于局部连接和权重共享，卷积层的参数只有一个 \(m\) 维的权重 \(w^{(l)}\) 和 1 维的偏置 \(b^{(l)}\)，共 \(m+1\) 个参数。参数个数和神经元的数量无关。此外，第 \(l\) 层的神经元个数不是任意选择的，而是满足 <br/>
\[<br/>
n^{(l)} = n^{(l−1)} − m + 1。<br/>
\]</p>

<h4 id="toc_11">卷积层</h4>

<p>卷积层的作用是提取一个局部区域的特征，不同的卷积核相当于不同的特征提取器。上面描述的卷积层的神经元和全连接网络一样都是一维结构。既然卷积网络主要应用在图像处理上，而图像为两维结构，因此为了更充分地利用图像的局部信息，通常将神经元组织为三维结构的神经层，其大小为高度 \(M\) \(\times\) 宽度 \(N\) \(\times\) 深度 \(D\)，有 \(D\) 个 \(M \times N\) 大小的特征映射构成。</p>

<p><strong>特征映射（feature map）</strong>为一幅图像（或其它特征映射）在经过卷积提取到的特征，每个特征映射可以作为一类抽取的图像特征。为了卷积网络的表示能力，可以在每一层使用多个不同的特征映射，以更好地表示图像的特征。</p>

<p>在输入层，特征映射就是图像本身。如果是灰度图像，就是有一个特征映射，深度 \(D = 1\)；如果是彩色图像，分别有 RGB 三个颜色通道的特征映射，输入层深度 \(D = 3\)。</p>

<p>不失一般性，假设一个卷积层的结构如下：</p>

<ul>
<li>输入特征映射组： \(\mathbf X \in \mathbb R^{M\times N\times D}\) 为三维张量（tensor），其中每个切片(slice )矩阵 \(X^d \in \mathbb R^{M\times N}\) 为一个输入特征映射， \(1 \le d \le D\)；</li>
<li>输出特征映射组： \(\mathbf Y \in \mathbb R^{M&#39; \times N&#39; \times P}\) 为三维张量，其中每个切片矩阵 \(Y^p \in \mathbb R^{M&#39; \times N&#39;}\) 为一个输出特征映射， \(1 \le p \le P\)；</li>
<li>卷积核： \(\mathbf W \in \mathbb R^{m\times n\times D\times P}\) 为四维张量，其中每个切片矩阵 \(W^{p,d} \in \mathbb R^{m×n}\) 为一个两维卷积核， \(1 \le d \le D\), \(1 \le p \le P\)。</li>
</ul>

<p>为了计算输出特征映射 \(Y^p\)，用卷积核 \(W^{p,1}\), \(W^{p,2}\),\(...\), \(W^{p,D}\) 分别对输入特征映射 \(X^1, X^2,..., X^D\) 进行卷积，然后将卷积结果相加，并加上一个标量偏置 \(b\) 得到卷积层的净输入 \(Z^p\)，再经过非线性激活函数后得到输出特征映射 \(Y^p\)。<br/>
\[<br/>
Z^p = \mathbf W^p \otimes \mathbf X + b^p = \sum^D_{d=1} W^{p,d} \otimes X^d + b^p\\<br/>
Y^p = f(Z^p)<br/>
\]</p>

<p>其中 \(\mathbf W^p \in \mathbf R^{m\times n\times D}\) 为三维卷积核， \(f(\cdot)\) 为非线性激活函数，一般用 ReLU 函数。整个计算过程如下图所示。如果希望卷积层输出 \(P\) 个特征映射，可以将上述计算机过程重复 \(P\) 次，得到 \(P\) 个输出特征映射 \(Y^1, Y^2,..., Y^P\)。</p>

<p>在输入为 \(\mathbf X \in \mathbb R^{M\times N\times D}\)，输出为 \(\mathbf Y \in \mathbb R^{M&#39; \times N&#39; \times P}\) 的卷积层中，每一个输入特征映射都需要 \(D\) 个滤波器以及一个偏置。假设每个滤波器的大小为 \(m \times n\)，那么共需要 \(P \times D \times (m\times n) + P\) 个参数。</p>

<h4 id="toc_12">池化层</h4>

<p>池化层（pooling layer）也叫子采样层（subsampling layer），其作用是进行特征选择，降低特征数量，并从而减少参数数量。卷积层虽然可以显著减少网络中连接的数量，但特征映射组中的神经元个数并没有显著减少。如果后面接一个分类器，分类器的输入维数依然很高，很容易出现过拟合。为了解决这个问题，可以在卷积层之后加上一个池化层，从而降低特征维数，避免过拟合。减少特征维数也可以通过增加卷积步长来实现。</p>

<p>假设池化层的输入特征映射组为 \(\mathbf X \in \mathbb R^{M\times N\times D}\)，对于其中每一个特征映射 \(X^d\)，将其划分为很多区域 \(R^d_{m,n}\), \(1 \le m \le M&#39;\), \(1 \le n \le N&#39;\)，这些区域可以重叠，也可以不重叠。池化 (pooling)是指对每个区域进行下采样（down sampling）得到一个值，作为这个区域的概括。</p>

<p>常用的池化函数有两种：</p>

<ol>
<li><p>最大池化（maximum pooling）：一般是取一个区域内所有神经元的最大值。<br/>
\[<br/>
Y^d_{m,n} = \max_{i \in R^d_{m,n}} x_i<br/>
\]</p>

<p>其中 \(x_i\) 为区域 \(R_k^d\) 内每个神经元的激活值。</p></li>
<li><p>平均池化（mean pooling）：一般是取区域内所有神经元的平均值。<br/>
\[<br/>
Y^d_{m,n} = \frac{1}{|R^d_{m,n}|} \sum_{i\in R^d_{m,n}} x_i<br/>
\]</p></li>
</ol>

<p>对每一个输入特征映射 \(X^d\) 的 \(M&#39; \times N&#39;\) 个区域进行子采样，得到汇聚层的输出特征映射 \(Y^d = \{Y_{m,n}^d \}\), \(1 \le m \le M&#39;\) , \(1 \le n \le N&#39;\)。</p>

<p>池化层不但可以有效地减少神经元的数量，还可以使得网络对一些小的局部形态改变保持不变性，并拥有更大的感受野。</p>

<p>目前主流的卷积网络中，池化层仅包含下采样操作。但在早期的一些卷积网络（比如 LeNet-5）中，有时也会在池化层使用非线性激活函数，比如<br/>
\[<br/>
Y&#39;^d = f(w^d \cdot Y^d + b^d)<br/>
\]</p>

<p>其中 \(Y&#39;^d\) 为池化层的输出， \(f(\cdot)\) 为非线性激活函数， \(w^d\) 和 \(b^d\) 为可学习的标量权重和偏置。</p>

<p>典型的池化层是将每个特征映射划分为2 ×2大小的不重叠区域，然后使用最大池化的方式进行下采样。池化层也可以看做是一个特殊的卷积层，卷积核大小为 \(m \times m\)，步长为 \(s \times s\)，卷积核为 max 函数或 mean 函数。过大的采样区域会急剧减少神经元的数量，会造成过多的信息损失。</p>

<h3 id="toc_13">参数学习</h3>

<p>在卷积网络中，参数为卷积核中权重以及偏置。和全连接前馈网络类似，卷积网络也可以通过误差反向传播算法来进行参数学习。</p>

<p>在全连接前馈神经网络中，梯度主要通过每一层的误差项 \(\delta\) 进行反向传播，并进一步计算每层参数的梯度。</p>

<p>在卷积神经网络中，主要有两种不同功能的神经层：卷积层和池化层。而参数为卷积核以及偏置，因此只需要计算卷积层中参数的梯度。</p>

<p>不失一般性，对第 \(l\) 层为卷积层，第 \(l-1\) 层的输入特征映射为 \(\mathbf X^{(l−1)} \in<br/>
\mathbb R^{M\times N\times D}\)，通过卷积计算得到第 \(l\) 层的特征映射净输入 \(\mathbf Z^{(l)}\in \mathbb R^{M&#39;\times N&#39; \times P}\)。第 \(l\) 层的第 \(p(1 \le p \le P)\)个特征映射净输入<br/>
\[<br/>
\begin{equation}<br/>
Z^{(l,p)} = \sum_{d=1}^D W^{(l,p,d)} \otimes X^{(l−1,d)} + b^{(l,p)}\label{zlpsu}\\<br/>
\end{equation}<br/>
\]</p>

<p>其中 \(W^{(l,p,d)}\) 和 \(b^{(l,p)}\) 为卷积核以及偏置。第 \(l\) 层中共有 \(P \times D\) 个卷积核和 \(P\) 个偏置，可以分别使用链式法则来计算其梯度。<br/>
。<br/>
根据公式 ( \ref{fpfyp} )和( \ref{zlpsu} )，损失函数关于第 \(l\) 层的卷积核 \(W^{(l,p,d)}\) 的偏导数为<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \mathcal L(Y, \hat Y)}{\partial W^{(l,p,d)}} &amp;= \frac{\partial \mathcal L(Y,\hat Y)}{Z^{(l,p)}} \otimes X^{(l−1,d)}\\<br/>
&amp;= \delta^{(l,p)} \otimes X^{(l−1,d)}<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\delta^{(l,p)} = \frac{\partial \mathcal L(Y,\hat Y)}{\partial Z^{(l,p)}}\) 为损失函数关于第 \(l\) 层的第 \(p\) 个特征映射净输入 \(Z^{(l,p)}\) 的偏导数。</p>

<p>同理可得，损失函数关于第 \(l\) 层的第 \(p\) 个偏置 \(b^{(l,p)}\) 的偏导数为<br/>
\[<br/>
\frac{\partial \mathcal L(Y,\hat Y)}{\partial b(l,p)} = \sum_{i,j} [\delta^{(l,p)}]_{i,j}<br/>
\]</p>

<p>卷积网络中，每层参数的梯度依赖其所在层的误差项 \(\delta^{(l,p)}\)。</p>

<h4 id="toc_14">误差项的计算</h4>

<p>卷积层和池化层中，误差项的计算有所不同，因此我们分别计算其误差项。</p>

<p><strong>池化层</strong>：当第 \(l + 1\) 层为池化层时，因为池化层是下采样操作， \(l + 1\) 层的每个神经元的误差项 \(\delta\) 对应于第 \(l\) 层的相应特征映射的一个区域。 \(l\) 层的第 \(p\) 个特征映射中的每个神经元都有一条边和 \(l + 1\) 层的第 \(p\) 个特征映射中的一个神经元相连。<br/>
根据链式法则，第 \(l\) 层的一个特征映射的误差项 \(\delta(l,p)\)，只需要将 \(l + 1\) 层对应特征映射的误差项 \(\delta^{(l+1,p)}\) 进行上采样操作（和第 \(l\) 层的大小一样），再和 \(l\) 层特征映射的激活值偏导数逐元素相乘，就得到了 \(\delta^{(l,p)}\)。</p>

<p>第 \(l\) 层的第 \(p\) 个特征映射的误差项 \(\delta^{(l,p)}\) 的具体推导过程如下：<br/>
\[<br/>
\begin{align*}<br/>
\delta^{(l,p)} &amp;\buildrel \Delta \over = \frac{\partial \mathcal L(Y,\hat Y)}{\partial Z^{l,p}}\\<br/>
&amp;= \frac{X^{(l,p)}}{Z^{(l,p)}}\cdot \frac{\partial Z^{(l+1,p)}}{\partial X^{(l,p)}}\cdot \frac{\partial \mathcal L(Y,\hat Y)}{\partial Z^{(l+1,p)}} \\<br/>
&amp;= f&#39;_l(Z^{(l,p)}) \odot \mathbf {up}(\delta^{(l+1,p)})\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(f&#39;_l(\cdot)\) 为第 \(l\) 层使用的激活函数导数， \(\mathbf {up}\) 为上采样函数（upsampling），与池化层中使用的下采样操作刚好相反。如果下采样是最大池化（max pooling），误差项 \(\delta^{(l+1,p)}\) 中每个值会直接传递到上一层对应区域中的最大值所对应的神经元，该区域中其它神经元的误差项的都设为 0。如果下采样是平均汇聚（mean pooling），误差项 \(\delta^{(l+1,p)}\) 中每个值会被平均分配到上一层对应区域中的所有神经元上。</p>

<p><strong>卷积层</strong>：当 \(l + 1\) 层为卷积层时，假设特征映射净输入 \(\mathbf Z^{(l+1)}\in \mathbb R^{M&#39;\times N&#39; \times P}\)，其中第 \(p(1 \le p \le P)\) 个特征映射净输入<br/>
\[<br/>
Z^{(l+1,p)} = \sum^D_{d=1} W^{(l+1,p,d)} \otimes X^{(l,d)} + b^{(l+1,p)}<br/>
\]</p>

<p>其中 \(W^{(l+1,p,d)}\) 和 \(b^{(l+1,p)}\) 为第 \(l+1\) 层的卷积核以及偏置。第 \(l+1\) 层中共有 \(P \times D\) 个卷积核和 \(P\) 个偏置。</p>

<p>第 \(l\) 层的第 \(d\) 个特征映射的误差项 \(\delta^{(l,d)}\) 的具体推导过程如下：<br/>
\[<br/>
\begin{align*}<br/>
\delta^{(l,d)} &amp;\buildrel \Delta \over = \frac{\partial \mathcal L(Y,\hat Y)}{\partial Z^{(l,d)}} \\<br/>
&amp;= \frac{\partial X^{(l,d)}}{\partial Z^{(l,d)}}\cdot \frac{\partial \mathcal L(Y,\hat)}{\partial X^{(l,d)}}\\<br/>
&amp;= f&#39;_l(Z^{(l)}) \odot \sum_{p=1}^P \bigg (\mathbf{rot180}(W^{(l+1,p,d)})\bigg) \widetilde \otimes \frac{\partial \mathcal L(Y,\hat Y)}{\partial Z^{(l+1,p)}}\\<br/>
&amp;= f&#39;_l(Z^{(l)}) \odot \sum_{p=1}^P \bigg (\mathbf{rot180}(W^{(l+1,p,d)})\bigg) \widetilde \otimes \delta^{(l+1,p)}\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\widetilde \otimes\) 为宽卷积。</p>

<h3 id="toc_15">其它卷积方式</h3>

<h4 id="toc_16">转置卷积</h4>

<p>我们一般可以通过卷积操作来实现高维特征到低维特征的转换。比如在一维卷积中，一个 5 维的输入特征，经过一个大小为 3的卷积核，其输出为 3 维特征。如果设置步长大于 1，可以进一步降低输出特征的维数。但在一些任务中，我们需要将低维特征映射到高维特征，并且依然希望通过卷积操作来实现。</p>

<p>假设有一个高维向量为 \(\mathbf x \in \mathbb R^d\) 和一个低维向量为 \(\mathbf z \in \mathbb R^p\)，\(p \lt d\)。如果用仿射变换来实现高维到低维的映射，不失一般性，这里忽略了平移项。<br/>
\[<br/>
\begin{equation}<br/>
\mathbf z = W\mathbf x \label{zwx}<br/>
\end{equation}<br/>
\]</p>

<p>其中 \(W \in \mathbb R^{p\times d}\) 为转换矩阵。我们可以很容易地通过转置 \(W\) 来实现低维到高维的反向映射，即<br/>
\[<br/>
\begin{equation}<br/>
\mathbf x = W^T\mathbf z \label{xwtz}<br/>
\end{equation}<br/>
\]</p>

<p>需要说明的是，公式 ( \ref{zwx} ) 和 ( \ref{xwtz} ) 并不是逆运算，两个映射只是形式上的转置关系。</p>

<p>在全连接网络中，忽略激活函数，前向计算和反向传播就是一种转置关系。比如前向计算时，第 \(l+1\) 层的净输入为 \(\mathbf z^{(l+1)} = W^{(l+1)} \mathbf z^{(l)}\)，反向传播时，第 \(l\) 层的误差项为 \(\delta^{(l)} = (W^{(l+1)})^T \delta^{(l+1)}\)。</p>

<p>卷积操作也可以写为仿射变换的形式。假设一个 5维向量 \(\mathbf x\)，经过大小为 3 的卷积核 \(\mathbf w = [w_1, w_2, w_3]^T\) 进行卷积，得到 3 维向量 \(\mathbf z\)。卷积操作可以写为<br/>
\[<br/>
\begin{align}<br/>
\mathbf z &amp;= \mathbf w \otimes \mathbf x\nonumber\\<br/>
&amp;= \left [ \begin{array}{ccccc} w_1 &amp; w_2 &amp; w_3 &amp; 0 &amp; 0\\ 0 &amp; w_1 &amp; w_2 &amp; w_3 &amp; 0 \\ 0 &amp; 0 &amp; w_1 &amp; w_2 &amp; w_3 \end{array} \right ]\cdot \mathbf x\label{lbacw}\\<br/>
&amp;= C\mathbf x \nonumber\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(C\) 是一个稀疏矩阵，其非零元素来自于卷积核 \(\mathbf w\) 中的元素。</p>

<p>如果要实现 3 维向量 \(z\) 到 5 维向量 \(x\) 的映射，可以通过仿射矩阵的转置来实现。<br/>
\[<br/>
\begin{align}<br/>
\mathbf x &amp;= C^T\mathbf z\nonumber\\<br/>
&amp;= \left [ \begin{array} w_1 &amp; 0 &amp; 0\\w_2 &amp; w_1 &amp; 0 \\ w_3 &amp; w_2 &amp; w_1 \\ 0 &amp; w_3 &amp; w_2 \\ 0 &amp; 0 &amp; w_3\\ \end{array} \right ] \cdot \mathbf z\label{lbw00}\\<br/>
&amp;= \mathbf{rot180(w)} \widetilde \oplus \mathbf z\nonumber\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(\mathbf{rot180}(\cdot)\) 表示旋转180度。</p>

<p>从公式 ( \ref{lbacw} ) 和 ( \ref{lbw00} ) 可以看出，从仿射变换的角度来看两个卷积操作 \(\mathbf z = \mathbf w \otimes \mathbf x\) 和 \(\mathbf x = \mathbf{rot180}(\mathbf w)\widetilde \oplus \mathbf z\) 也是形式上的转置关系。因此，我们将低维特征映射到高维特征的卷积操作称为转置卷积（transposed convolution），也称为反卷积（deconvolution）。</p>

<p>和卷积网络中，卷积层的前向计算和反向传播也是一种转置关系。</p>

<p>对一个 \(p\) 维的向量 \(\mathbf z\)，和大小为 \(m\) 的卷积核，如果希望通过卷积操作来映射到高维向量，只需要对向量 \(\mathbf z\) 进行两端补零 \(p = m − 1\)，然后进行卷积，可以得到 \(p + m − 1\) 维的向量。</p>

<p>转置卷积同样适用于二维卷积。</p>

<div align="center">
    <img width="460" src="media/15327348574245/15427228522286.jpg" />
</div>

<p><strong>微步卷积</strong>：我们可以通过增加卷积操作的步长 \(s &gt; 1\) 来实现对输入特征的降采样操作，大幅降低特征维数。同样，我们也可以通过减少转置卷积的步长 \(s &lt; 1\) 来实现上采样操作，大幅提高特征维数。</p>

<p>步长 \(s &lt; 1\) 的转置卷积也称为微步卷积（fractionally-strided convolution）。为了实现微步卷积，我们可以在输入特征之间插入 0 来间接地使得步长变小。</p>

<p>如果卷积操作的步长为 \(s &gt; 1\)，希望其对应的转置卷积的步长为 \(\frac 1 s\)，需要在输入特征之间插入 \(s − 1\) 个 0 来使得其移动的速度变慢。</p>

<p>以一维转置卷积为例，对一个 \(p\) 维的向量 \(z\)，和大小为 \(m\) 的卷积核，通过对向量 \(z\) 进行两端补零 \(p = m − 1\)，并且在每两个向量元素之间插入 \(s − 1\) 个 0，然后进行步长为 1的卷积，可以得到 \(s \times (p − 1) + m\) 维的向量。</p>

<p>图5.16给出了一个步长 s = 2，无零填充 p = 0的两维卷积和其对应的转置卷积。</p>

<div align="center">
    <img width="500" src="media/15327348574245/15427227998993.jpg" />
</div>

<h3 id="toc_17">空洞卷积</h3>

<p>对于一个卷积层，如果希望增加输出单元的感受野，一般可以通过三种方式实现：（1）增加卷积核的大小;（2）增加层数；（3）在卷积之前进行汇聚操作。前两种操作会增加参数数量，而第三种会丢失一些信息。</p>

<p>空洞卷积（atrous convolutions），也称为膨胀卷积（dilated convolution），是一种不增加参数数量，同时增加输出单元感受野的一种方法。空洞卷积通过给卷积核插入“空洞”来变相地增加其大小。如果在卷积核的每两个元素之间插入 \(d − 1\) 个空洞，卷积核的有效大小为<br/>
\[<br/>
\begin{align*}<br/>
m&#39; = m + (m − 1) \times (d − 1)<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(d\) 称为膨胀率（dilation rate）。当 \(d = 1\) 时卷积核为普通的卷积核。</p>

<div align="center">
    <img width="440" src="media/15327348574245/15427229263490.jpg" />
</div>

<hr/>

<p><a href="https://blog.csdn.net/pudongdong/article/details/60782985">多维卷积与一维卷积的统一性（运算篇）</a><br/>
<a href="http://www.datakit.cn/blog/2016/03/23/bp_cnn.html">CNN基本公式</a><br/>
<a href="https://www.zybuluo.com/hanbingtao/note/485480">零基础入门深度学习(4)-卷积神经网络</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15317530788642.html">人工神经网络-RBF径向基网络</a></h1>
			<p class="meta"><time datetime="2018-07-16T22:57:58+08:00" 
			pubdate data-updated="true">2018/7/16</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>RBF径向基网络全称是 Radical basis function network；RBF network，是一种常见的人工神经网络；在径向基网络先介绍径向基函数（RBF）。</p>

<h3 id="toc_0">径向基函数RBF</h3>

<p>径向基函数是某种沿径向对称的标量函数。通常定义为空间中任一点 \(x\) 到某一中心 \(x_c\) 之间欧氏距离的单调函数，可记作 \(\phi(||x-x_c||)\)，其作用往往是局部的 , 即当 \(x\) 远离 \(x_c\) 时函数取值很小。径向基函数的一般形式为<br/>
\[<br/>
\phi = \exp\big(-(x-x_c)^2\big)<br/>
\]</p>

<p>其中 \(x_c\) 为核函数中心，最常用的径向基函数是高斯核函数，形式为 <br/>
\[<br/>
\phi(||x-x_c||)=\exp\bigg(-\frac{||x-x_c||^2}{2\sigma^2}\bigg) = RBF(x,x_c)<br/>
\] </p>

<p>其中 \(\sigma\) 为函数的宽度参数，控制了函数的径向作用范围。如果 \(x\) 和 \(x_c\) 很相近那么核函数值为1，如果 \(x\) 和 \(x_c\) 相差很大那么核函数值约等于0。由于这个函数类似于高斯分布，因此也称为高斯核函数。它能够把原始特征映射到无穷维。</p>

<div align="center">
    <img width="320" src="media/15317530788642/15382614421727.jpg" />
</div>

<p>上图形象说明离中心点越远，函数值越小；距离值超过一定值后，函数值几乎为0。</p>

<p>简单说明一下为什么采样RBF函数的神经网络学习收敛得比较快。当网络的一个或多个可调参数（权值或阈值）对任何一个输出都有影响时，这样的网络称为全局逼近网络。由于对于每次输入，网络上的每一个权值都要调整，从而导致全局逼近网络的学习速度很慢。BP网络就是一个典型的例子。</p>

<p>如果对于输入空间的某个局部区域只有少数几个连接权值影响输出，大多数连接权重由于和中心点距离远，影响几乎为0，则该网络称为局部逼近网络。常见的局部逼近网络有RBF网络、小脑模型（CMAC）网络、B样条网络等。</p>

<h3 id="toc_1">径向基神经网络</h3>

<p>RBF神经网络，属于前向神经网络类型，它能够以任意精度逼近任意连续函数，特别适合于解决分类问题。</p>

<p>RBF网络的结构与多层前向网络类似，它是一种三层前向网络。第一层为输入层，由信号源结点组成；第二层为隐含层，隐单元数视所描述问题的需要而定，隐单元的变换函数是RBF径向基函数，它是对中心点径向对称且衰减的非负非线性函数；第三层为输出层，它对输入模式的作用作出响应。从输人空间到隐含层空间的变换是非线性的，而从隐含层空间到输出层空间变换是线性的。</p>

<div align="center">
    <img width="400" src="media/15317530788642/15382636777583.jpg" />
</div>

<p>RBF网络的基本思想是：用RBF作为隐单元的“基”构成隐含层空间，这样就可将输入矢量直接（即不需要通过权连接）映射到隐空间。根据Cover定理，低维空间不可分的数据到了高维空间会更有可能变得可分。换句话来说，<strong>RBF网络的隐层的功能就是将低维空间的输入通过非线性函数映射到一个高维空间。然后再在这个高维空间进行曲线的拟合</strong>。它等价于在一个隐含的高维空间寻找一个能最佳拟合训练数据的表面。这点与普通的多层感知机MLP是不同的。</p>

<p>当RBF的中心点确定以后，这种映射关系也就确定了。而隐含层空间到输出空间的映射是线性的，即网络的输出是隐单元输出的线性加权和，此处的权即为网络可调参数。由此可见，从总体上看，网络由输入到输出的映射是非线性的，而网络输出对可调参数而言却又是线性的。这样网络的权就可由线性方程组直接解出，从而大大加快学习速度并具有全局逼近能力，从根本上解决了BP网络的局部最优问题。</p>

<blockquote>
<p>在理论上，RBF网络和BP网络一样能以任意精度逼近任何非线性函数。但由于它们使用的激励函数不同，其逼近性能也不相同。Poggio和Girosi已经证明，RBF网络是连续函数的最佳逼近，而BP网络不是。BP网络使用的Sigmoid函数具有全局特性，它在输入值的很大范围内每个节点都对输出值产生影响，并且激励函数在输入值的很大范围内相互重叠，因而相互影响，因此BP网络训练过程很长。此外，由于BP算法采用梯度下降法，训练时间常，容易陷入局部极小的问题不可能从根本上避免，并且BP网络隐层节点数目的确定依赖于经验和试凑，很难得到最优网络。采用局部激励函数的RBF网络在很大程度上克服了上述缺点，RBF不仅有良好的泛化能力，而且对于每个输入值，只有很少几个节点具有非零激励值，因此只需很少部分节点及权值改变。学习速度可以比通常的BP算法提高上千倍,容易适应新数据，其隐层节点的数目也在训练过程中确定，并且其收敛性也较BP网络易于保证，因此可以得到最优解。</p>
</blockquote>

<p>从另一个方面也可以这样理解，多层感知器（包括BP神经网络）的隐节点基函数采用线性函数，激活函数则采用Sigmoid函数或硬极限函数。而<strong>RBF网络的隐节点的基函数采用距离函数（如欧氏距离），并使用径向基函数（如Gaussian函数）作为激活函数</strong>。径向基函数关于n维空间的一个中心点具有径向对称性，而且神经元的输入离该中心点越远，神经元的激活程度就越低。隐节点的这一特性常被称为“局部特性”。</p>

<p>\[<br/>
g_{RBF}(x_j) = \text{Output}\bigg(\sum_{i=1}^{|h|} w_{ij} \exp\Big(-\frac{||x_i - x_{c_i}||} {2\sigma^2}\Big) + b_{i}\bigg),j=1,2,...,M<br/>
\]</p>

<p>其中 \(|h|\) 表示隐藏层个数，也代表选取中心点的个数，\(M\) 表示输出层个数，\(\sigma\) 表示方差，\(w\) 则是对应的权重。最外层的 \(\text{Output}\) 函数则是根据目的选择不同的函数，如果想做分类的话就可以使用 softmax 或sign等函数，如果打算做回归或函数逼近就不用 \(\text{Output}\) 函数了，RBF Network 可以逼近任意连续的函数。</p>

<p>RBF的设计主要包括两个方面，一个是结构设计，也就是说隐藏层含有几个节点合适。另一个就是参数设计，也就是对网络各参数进行求解。由上面的输入到输出的网络映射函数公式可以看到，网络的参数主要包括三种：径向基函数的中心、方差和隐含层到输出层的权值。到目前为止，出现了很多求解这三种参数的方法，主要可以分为以下两大类：</p>

<h3 id="toc_2">RBF神经网络中心选取方法</h3>

<p>对于RBF神经网络的学习算法，关键问题是隐藏层神经元中心参数的合理确定。常用的方法是从中心参数(或者其初始值)是从给定的训练样本集里按照某种方法直接选取，或者是采用聚类的方法确定。</p>

<h4 id="toc_3">Full RBF network</h4>

<p>Full RBF 网络是指所有的数据节点都作为中心。</p>

<p>\[<br/>
g_{RBF}(x) = \text{Ouput}\bigg(\sum_{m=1}^M \beta_m RBF(x,c_m)\bigg)<br/>
\]</p>

<p>即 \(M=N\)，\(c_m = x_m\)，也就是中心点的个数（隐藏单元的个数）等于输入数据的个数。这样的话，预测新的数据点，就需要计算该点和所有训练数据点的距离，也就是相似度，然后结合权重 \(\beta\) 进行线性组合，此过程就是将所有的训练数据点对预测点的影响聚集到一起，距离越近，影响越大，这样得到最终的结果。</p>

<p>假设有四个元素 \(x_1,x_2,x_3,x_4\) 使用RBF神经网络，这样隐藏点的个数也是4，中心点分别是 \(c_1 = x_1\)，\(c_2 = x_2\)，\(c_3=x_3\) 和 \(c_4 = x_4\)，网络图如下<br/>
<div align=center><br/>
    <img width=360 src="media/15317530788642/15383902217169.jpg" /><br/>
</div></p>

<p>比如用均匀影响做二分类的话，即 \(\beta_m=1\cdot y_m\)，即:<br/>
\[<br/>
g_{RBF}(x) = \text{sign}\bigg(\sum_{m=1}^N y_m \exp(-\gamma ||x-x_m||^2)\bigg )<br/>
\]</p>

<p>就相当于每个训练数据给新数据投票，通过RBF，可以使得距离远的票数大，近的票数小，同时 \(y_m\) 可以控制投票的类别，这样通过统计所有点的观点，就可以得到新数据的类别了。</p>

<p>但是很显然， 这种Full RBF Network是一种偷懒的方式，因为直接将所有的点作为了center，因此如果样本量很大的话，那么计算量就太大了，在实际中，很少使用。</p>

<p>如果我们通过回归的方法学习参数 \(\beta_m\)，full RBF 是如下的形式<br/>
\[<br/>
\begin{align}<br/>
g_{RBF}(x) = \sum_{m=1}^N \beta_m RBF(x,x_m)\label{grsn}<br/>
\end{align}<br/>
\]</p>

<p>假设考虑 \(\mathbf x_i\) 在 RBF 转换后采用线性回归<br/>
\[<br/>
z_i = [RBF(\mathbf x_i,x_1),RBF(\mathbf x_i,x_2),...,RBF(\mathbf x_i,x_N)]<br/>
\]</p>

<p>令 \(\mathbf Z = [z_1,z_2,...,z_n]^T\)，\(\beta = [\beta_1,\beta_2,...,\beta_n]^T\)，用向量化表示式 ( \ref{grsn} )，现在我们要最小化这个函数<br/>
\[<br/>
L = \frac 1 2 \Big(\beta^T \mathbf Z - y\Big)^T(\beta^T \mathbf Z - y)<br/>
\]</p>

<p>用 \(L\) 对 \(\beta\) 求得，令结果为0，解得<br/>
\[<br/>
\begin{align*}<br/>
\beta = (\mathbf Z^T\mathbf Z)^{-1}\mathbf Z^Ty<br/>
\end{align*}<br/>
\]</p>

<p>矩阵 \(\mathbf Z\) 的大小是 \(N\times N\)，是一个方阵。而且，由于 \(\mathbf Z\) 中每个向量 \(z_i\) 表示该点与其它所有点的RBF 距离，所以从形式上来说，\(\mathbf Z\) 也是对称矩阵。如果所有的样本点 \(x_i\) 都不一样，则 \(\mathbf Z\)一定是可逆的。</p>

<p>如果 \(\mathbf Z\) 是对称矩阵<br/>
\[<br/>
\beta = (\mathbf Z^T\mathbf Z)^{-1}\mathbf Z^Ty = (\mathbf Z^T\mathbf Z)^{-1}\mathbf Z^T\mathbf Z^{-1}y = \mathbf Z^{-1}y<br/>
\]</p>

<p>因为 \(\mathbf Z\) 是对称矩阵，所以 \(\mathbf Z^{-1}\) 也是对称矩阵，所以<br/>
\[<br/>
g_{RBF}(x) = \beta^T \mathbf Z = (\mathbf Z^{-1}y)^T \mathbf Z = \mathbf Z^{-1} \mathbf Z y = y<br/>
\]</p>

<p>这里模型的输出与原样本的标签一模一样，所以模型的误差为0，这很有可能会增加模型的复杂度和过拟合。为了解决过拟合，这里可以参考岭回归，使用 \(L^2\) 正则化<br/>
\[<br/>
\beta = (\mathbf Z^T\mathbf Z + \lambda I)\mathbf Z^T y<br/>
\]</p>

<h4 id="toc_4">K-Means 方法</h4>

<p>将上面的方法改变一下，现在我们从训练样本集中随机选择 \(M\)（\(M\lt N\)）个样本作为 \(M\)个径向基函数的中心。更好的办法是这 \(m\) 个样本使用KNN的方式来选取，在Full RBF中，我们计算所有的训练数据与新数据的距离，距离最小的与新数据的相似度最高，而且高斯函数衰减很快，距离新数据远的点对它的影响很小，因此我们可以忽略那些距离较远的点，只需要找到几个最靠近新数据的点，然后只计算它们的贡献即可，假设我们找最近的K个点的话，那就是K近邻算法。这种类型的算法在训练的时候，不用花力气，但是再做测试或者预测的时候，需要对比全部的数据，然后找到几个最近的，计算这几个的贡献得到最后结果，这个过程跟上面的Full RBF 一样，计算量很大。因此这种方式经常在样本数据较少的时候使用。</p>

<p>下面重新给出使用K-Means的RBF Net用来做预测回归的流程:</p>

<ol>
<li>运行 K-Means 获得 \(k=M\) 个中心点 \(c_m\)</li>
<li>使用 RBF 在 \(c_m\) 构造转换 \(\phi(x)\)
\[
\phi(x) = [RBF(x,c_1),RBF(x,c_2),...,RBF(x,c_m)]
\]</li>
<li>在 \(\{\phi(x_i),y_i\}\) 上建立线性模型，获取 \(\beta\)。</li>
<li>返回\[
g_{RBF}(x) = \text{LinearHypothesis}(\beta,\phi(x))
\]</li>
</ol>

<p>这个过程与上面唯一不同的地方就是，开始先使用K-Means得到了中心，然后再计算特征转换的 \(Z\) 矩阵，其余步骤完全相同。</p>

<h3 id="toc_5">RBF神经网络的方差的选择</h3>

<p>RBF神经网络的基函数为高斯函数，方差 \(\sigma_i\) 可由下式求解得出：<br/>
\[<br/>
\sigma_i=\frac{c_{max}}{2M},i=1,2,⋯,M<br/>
\]</p>

<p>其中 \(c_{max}\) 是所选取中心之间的最大距离。</p>

<hr/>

<p><a href="http://www.cnblogs.com/zhangchaoyang/articles/2591663.html">径向基（RBF）神经网络</a><br/>
<a href="https://blog.csdn.net/zouxy09/article/details/13297881">径向基网络（RBF network）之BP监督训练</a><br/>
<a href="https://blog.csdn.net/sunxinyu/article/details/76598446">RBF神经网络与BP神经网络优缺点比较</a><br/>
<a href="https://shomy.top/2017/02/26/rbf-network/">机器学习技法笔记(6)-RBF Network(径向基函数网络)</a><br/>
<a href="https://github.com/ShomyLiu/stat-learn/tree/master/RBFNet">Numpy版KMeans+RBFNet 与 TensorFlow版KMeans+RBFNet的完整代码</a><br/>
<a href="http://read.pudn.com/downloads110/sourcecode/others/454289/Paper/pdf/y9935500004.pdf">第3章 RBF神经网络的基本原理</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15309710071828.html">自动编码器</a></h1>
			<p class="meta"><time datetime="2018-07-07T21:43:27+08:00" 
			pubdate data-updated="true">2018/7/7</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>自动编码（Autoencodes）是一个非常激动人心的无监督学习方法，它们取得的进展已经超过了数十年的研究人员研究的手选编码特征。</p>

<p>当我们试图解决一个256*256像素的灰度图，我们需要面临 65536 维度的数据，这对于很多算法来说，存储计算都不是容易的事。更何况现在动辄就是更高清的图片、语音等数据。</p>

<p>为了解决更高维的问题，出现的线性学习的PCA降维方法，PCA的数学基础无懈可击，但是它的却只对线性数据效果比较好。于是提出更只能的特征提取方法--自动编码器。</p>

<h3 id="toc_0">自动编码器（AutoEncoder）</h3>

<p>自编码器是一种非常有用的无监督学习模型。自编码器由 encoder 和 decoder 组成，前者将原始表示编码成隐层表示，后者将隐层表示解码成原始表示，训练目标为最小化重构误差，而且一般而言，隐层的特征维度低于原始特征维度。</p>

<div align=center>
    <img width=380 src="media/15309710071828/15391710254254.jpg" />
</div>

<p>如上图，我们将input 输入一个encoder编码器，就会得到一个code，这个code也就是输入的一个表示，也就是特征。decoder通过对code的重建会输出一个与input很像的信号，而重构后的信号与input的误差就是调整网络参数（也就是Encoder,Decoder）的校正信号。由于这里不需要input带label，所以是无监督的学习过程，学习的是无监督特征。</p>

<p>假设有一组 \(d\) 维度的样本 \(x^{(n)} \in \mathbb R^d\)，\(1\le n \le N\)，自编码器将这组数据映射到特征空间得到每个样本编码 \(z^{(n)}\in \mathbb R^{p}\)，\(1\le n \le N\)，并且希望这组编码可以重构出原来的样本。</p>

<p>自编码器可以分成两部分：</p>

<p><strong>编码器（encoder）</strong><br/>
\[<br/>
f : \mathbb R^d \rightarrow \mathbb R^p<br/>
\]</p>

<p><strong>解码器（decoder）</strong><br/>
\[<br/>
g : \mathbb R^p \rightarrow \mathbb R^d<br/>
\]</p>

<p>自编码器的学习目标是最小化重构错误（reconstruction errors）<br/>
\[<br/>
\begin{align*}<br/>
\mathcal L &amp;= \sum_{n=1}^N ||x^{(n)} - g(f(x^{(n)}))||^2\\<br/>
\end{align*}<br/>
\]</p>

<p>最简单的自编码器是如下图所示的两层神经网络。输入层到隐藏层用来编码，隐藏层到输出层用来解码，层与层之间是全连接。</p>

<div align="center">
    <img width=360 src="media/15309710071828/15391719034110.jpg" />
</div>

<p>对于样本 \(x\)，中间隐藏层为编码<br/>
\[<br/>
z = s(W^{(1)} x + b^{(1)})<br/>
\]</p>

<p>输出为重构的数据<br/>
\[<br/>
x&#39; = s(w^{(2)} z + b^{(2)})<br/>
\]</p>

<p>其中 \(W,b\) 为网络参数，\(s(\cdot)\) 为激活函数。如果令 \(W^{(2)}\) 等于 \(W^{(1)}\) 的转置，即 \(W^{(2)} = {W^{(1)}}^T\)，称为捆绑权重（tied weights）。最初的编码器确实使用了两组 \((W,b)\)，但是Vincent在2010年的论文中做了研究，发现只要单组 \(W\) 就可以了。</p>

<p>并且我们可以引入正则化项，给定一组样本 \(x^{(n)} \in [0,1]^d\)，\(1\le n \le N\)，其重构错误为<br/>
\[<br/>
\mathcal L = \sum_{n=1}^N ||x^{(n)} - x&#39;^{(n)}||^2 + \lambda ||W||^2_F<br/>
\]</p>

<p>其中 \(\lambda\) 为正则化项系数。通过最小化重构错误，可以有效地学习网络的参数。</p>

<h3 id="toc_1">稀疏自动编码器（Sparse Autoencoder）</h3>

<p>自编码器除了可以学习低维编码之外，也学习高维的稀疏编码。假设中间隐藏层 \(z\) 的维度为 \(p\) 大于输入样本 \(x\) 的维度 \(d\)，并让 \(z\) 尽量稀疏，这就是稀疏自编码器（ Sparse Auto-Encoder）。和稀疏编码一样，稀疏自编码器的优点是有很高的可解释性，并同时进行了隐式的特征选择。</p>

<div align="center">
    <img src="media/15309710071828/15470498102061.jpg" width="460px" />
</div>

<p>如上图，其实就是限制每次得到的表达code尽量稀疏。因为稀疏的表达往往比其他的表达要有效（人脑好像也是这样的，某个输入只是刺激某些神经元，其他的大部分的神经元是受到抑制的）。</p>

<h4 id="toc_2">稀疏编码</h4>

<p>稀疏编码（ Sparse Coding）也是一种受哺乳动物视觉系统中简单细胞感受野而启发的模型。在哺乳动物的初级视觉皮层中，每个神经元仅对处于其感受野中特定的刺激信号做出响应，比如特定方向的边缘、条纹等特征。局部感受野可以被描述为具有空间局部性、方向性和带通性（即不同尺度下空间结构的敏感性）。也就是说，外界信息经过编码后仅有一小部分神经元激活，即外界刺激在视觉神经系统的表示具有很高的稀疏性。编码的稀疏性在一定程度上符合生物学的低功耗特性。</p>

<p>在数学上，（线性）编码是指给一组基向量 \(A = [a_1,...,a_p]\)，将输入样本 \(\mathbf x \in \mathbb R^d\) 表示为这些基向量的线性组合<br/>
\[<br/>
\begin{align*}<br/>
\mathbf x &amp;= \sum_{i=1}^p z_i a_i\\<br/>
&amp;= A\mathbf z\\<br/>
\end{align*}<br/>
\] </p>

<p>其中基向量的系数 \(z = [z_1,..., z_p]\) 称为输入样本 \(\mathbf x\) 的编码（encoding），基向量 \(A\) 也称为字典（dictionary）。</p>

<p>编码是对 \(d\) 维空间中的样本 \(\mathbf x\) 找到其在 \(p\) 维空间中的表示（或投影），其目标通常是编码的各个维度都是统计独立的，并且可以重构出输入样本。编码的关键是找到一组“完备”的基向量 \(A\)，比如主成分分析等。但是主成分分析得到编码通常是稠密向量，没有稀疏性。</p>

<p>如果 \(p\) 个基向量刚好可以支撑 p维的欧氏空间，则这 \(p\) 个基向量是完备的。如果 \(p\) 个基向量可以支撑 \(d\) 维的欧氏空间，并且 \(p &gt; d\)，则这 \(p\) 个基向量是过完备的，冗余的。</p>

<p>为了得到稀疏的编码，我们需要找到一组“超完备”的基向量（即 \(p &gt; d\)）来进行编码。在超完备基向量之间往往会存在一些冗余性，因此对于一个输入样本，会存在很多有效的编码。如果加上稀疏性限制，就可以减少解空间的大小，得到“唯一”的稀疏编码。</p>

<p>给定一组 \(N\) 个输入向量 \(x^{(1)},...,x^{(N)}\)，其稀疏编码的目标函数定义为：<br/>
\[<br/>
L(A, Z) = \sum_{n=1}^N \Big(||x^{(n)} - A\mathbf z^{(n)}||^2 + \eta \rho(\mathbf z^{(n)})\Big)<br/>
\]</p>

<p>其中 \(\rho(\cdot)\) 是一个稀疏性衡量函数， \(\eta\) 是一个超参数，用来控制稀疏性的强度。对于一个向量 \(\mathbf z \in \mathbb R^p\)，其稀疏性定义为非零元素的比例。如果一个向量只有很少的几个非零元素，就说这个向量是稀疏的。严格的稀疏向量有时比较难以得到，因此如果一个向量只有少数几个远大于零的元素，其它元素都接近于 0，我们也称这个向量为稀疏向量。稀疏性衡量函数 \(\rho(\mathbf z)\) 是给向量 \(\mathbf z\) 一个标量分数。 \(\mathbf z\) 越稀疏， \(\rho(\mathbf z)\) 越小。</p>

<p>稀疏性衡量函数有多种选择，最直接的衡量向量 \(\mathbf z\) 稀疏性的函数是 \(\mathcal l^0\) 范式<br/>
\[<br/>
\rho(\mathbf z) = \sum_{i=1}^p \mathbf I(|z_i| \gt 0)<br/>
\]</p>

<p>但 \(\mathcal l^0\) 范数不满足连续可导，因此很难进行优化。在实际中，稀疏性衡量函数通<br/>
常使用 \(\mathcal l^1\) 范数<br/>
\[<br/>
\begin{equation}<br/>
\rho(\mathbf z) = \sum_{i=1}^p |z_i| \label{rhs1}<br/>
\end{equation}<br/>
\]</p>

<p>或对数函数<br/>
\[<br/>
\begin{equation}<br/>
\rho(\mathbf z) = \sum_{i=1}^p \log(1 + z_i^2) \label{rhs2}<br/>
\end{equation}<br/>
\]</p>

<p>或指数函数<br/>
\[<br/>
\begin{equation}<br/>
\rho(\mathbf z) = \sum_{i=1}^p - \exp(-z_i^2) \label{rhs3}<br/>
\end{equation}<br/>
\]</p>

<h5 id="toc_3">稀疏编码的训练</h5>

<p>给定一组 \(N\) 个输入向量 \(x^{(1)},...,x^{(N)}\)，需要同时学习基向量 \(A\) 以及每个输入样本对应的稀疏编码 \(z^{(1)},...,z^{(N)}\)。稀疏编码的训练过程一般用交替优化的方法进行。</p>

<p>1) 固定基向量 \(A\)，对每个输入 \(x^{(n)}\)，计算其对应的最优编码<br/>
\[<br/>
\min_{z^{(n)}} ||x^{(n)} - A z^{(n)}||^2 - \eta\rho(z^{(n)}), \forall n \in [1, N]<br/>
\]</p>

<p>2) 固定上一步得到的编码 \(z^{((1)}, ..., z^{(N)}\)，计算其最优的基向量<br/>
\[<br/>
\min_{A} \sum_{n=1}^N \Big(||x^{(n)} - Az^{(n)}||^2 \Big) + \lambda \frac 1 2||A||^2<br/>
\]</p>

<p>其中第二项为正则化项， \(\lambda\) 为正则化项系数。</p>

<h5 id="toc_4">稀疏编码器</h5>

<p>通过给自编码器中隐藏层单元 \(\mathbf z\) 加上稀疏性限制，自编码器可以学习到数据中一些有用的结构。<br/>
\[<br/>
\mathcal L = \sum_{n=1}^N ||x^{(n)} - x&#39;^{(n)}||^2 + \eta \rho(\mathbf z^{(n)}) + \lambda||W||^2<br/>
\]</p>

<p>其中 \(\rho(\cdot)\) 为稀疏性度量函数， \(W\) 表示自编码器中的参数。</p>

<p>稀疏性度量函数 \(\rho(\cdot)\) 除了可以选择公式 ( \ref{rhs1} )、( \ref{rhs2} ) 和 ( \ref{rhs3} ) 的定义外，还可以定义为一组训练样本中每一个神经元激活的频率。</p>

<p>给定 \(N\) 个训练样本，隐藏层第 \(j\) 个神经元平均活性值为<br/>
\[<br/>
\hat \rho_j = \frac 1 N \sum_{n=1}^N z_j^{(n)}<br/>
\]</p>

<p>\(\hat \rho_j\) 可以近似地看作是第 \(j\) 个神经元激活的概率。我们希望 \(\hat \rho_j\) 接近于一个事先给定的值 \(\rho^*\)，比如0.05，可以通过 KL 距离来衡量 \(\hat \rho_j\) 和 \(\rho^*\) 的差异，即<br/>
\[<br/>
\text{KL}(\rho^*||\hat \rho_j) = \rho^* \log \frac{\rho^*}{\hat \rho_j} + (1 − \rho^*) \log \frac{1-\rho^*}{1-\hat rho_j}<br/>
\]</p>

<p>如果 \(\hat \rho_j = \rho^*\)，则 \(\text{KL}(\rho^*||\hat rho_j) = 0\)。</p>

<p>稀疏性度量函数定义为<br/>
\[<br/>
\rho(\mathbf z^{(n)}) = \sum_{j=1}^p \text{KL}(\rho^*||\hat \rho_j)<br/>
\]</p>

<h3 id="toc_5">堆叠自编码器</h3>

<p>对于很多数据来说，仅使用两层神经网络的自编码器还不足以获取一种好的数据表示。为了获取更好的数据表示，我们可以使用更深层的神经网络。深层神经网络作为自编码器提取的数据表示一般会更加抽象，能够更好地捕捉到数据的语义信息。在实践中经常使用逐层堆叠的方式来训练一个深层的自编码器，称为堆叠自编码器（ Stacked Auto-Encoder， SAE）。堆叠自编码一般可以采用逐层训练（ layer-wise training）来学习网络参数 [Bengio et al., 2007]。</p>

<div align="center">
    <img src="media/15309710071828/15470498951741.jpg" width="560px" />
</div>

<h3 id="toc_6">降噪自动编码器（Denoising Autoencoder）</h3>

<p>降噪自动编码器是在自动编码器的基础之上，为了防止过拟合问题而对输入的数据（网络的输入层）加入噪音，使学习得到的编码器更具有较强的鲁棒性，从而增强模型的泛化能力。</p>

<p>降噪自动编码器的示意图如下，其中 \(x\) 是原始的输入数据，降噪自动编码以一定概率把输入层节点的值设为0，从而得到含有噪音的模型输入 \(\hat x\)。这和 Dropout 很类似，不同的是Dropout是隐含层的神经元设置0。</p>

<div align="center">
    <img width="560" src="media/15309710071828/15472892939349.jpg" />
</div>

<p>以丢失的数据 \(\hat x\) 去计算 \(y\)，计算 \(z\)，并将 \(z\) 与原始 \(x\) 做误差迭代，这样，网络就学习了这个破损的数据。</p>

<p>这个破损的数据是很有用的，原因有二：<br/>
其之一，通过与非破损数据训练的对比，破损数据训练出来的Weight噪声比较小。降噪因此得名。原因不难理解，因为擦除的时候不小心把输入噪声给擦掉了。 <br/>
其之二，破损数据一定程度上减轻了训练数据与测试数据的代沟。由于数据的部分被擦掉了，因而这破损数据一定程度上比较接近测试数据。（训练、测试肯定有同有异，当然我们要求同舍异）。</p>

<p>Denoising Auto-encoder与人的感知机理类似，比如人眼看物体时，如果物体某一小部分被遮住了，人依然能够将其识别出来。 <br/>
人在接收到多模态信息时（比如声音，图像等），少了其中某些模态的信息有时也不会造成太大影响。 <br/>
Autoencoder的本质是学习一个相等函数，即网络的输入和重构后的输出相等，这种相等函数的表示有个缺点就是当测试样本和训练样本不符合同一分布，即相差较大时，效果不好，而Denoising Autoencoder在这方面的处理有所进步。</p>

<hr/>

<p><a href="https://blog.csdn.net/hjimce/article/details/49106869">自编码到栈式自编码</a><br/>
<a href="http://www.360doc.com/content/15/0324/08/20625606_457576675.shtml">深度学习自编码有效应对维数灾难</a><br/>
<a href="https://blog.csdn.net/app_12062011/article/details/54312880">深度学习自编码、DA算法、SDA算法、稀疏自编码</a><br/>
<a href="https://www.jianshu.com/p/f34842a3b19a">用自编码器去噪</a><br/>
<a href="https://blog.csdn.net/cuclxt/article/details/51469080">从反向传播（BP）到去噪自动编码器（DAE）</a><br/>
<a href="http://www.cnblogs.com/neopenx/p/4370350.html">降噪自动编码器</a><br/>
<a href="https://blog.csdn.net/u010089444/article/details/52601193">自动编码器</a><br/>
<a href="https://blog.csdn.net/xiewenbo/article/details/51675287">Deep Learning（深度学习）学习笔记整理系列之（六）AutoEncoder自动编码器</a><br/>
<a href="https://blog.csdn.net/left_la/article/details/9159949">多种范数算法</a><br/>
<a href="https://my.oschina.net/findbill/blog/541143">稀疏自动编码器</a><br/>
<a href="https://www.cnblogs.com/90zeng/p/Autoencoders_and_Sparsity.html">稀疏自动编码之自动编码器和稀疏性</a><br/>
<a href="https://wenku.baidu.com/view/d45e1b726c85ec3a87c2c5ea.html">稀疏自动编码器</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15301151892004.html">离群点检查算法 LOF</a></h1>
			<p class="meta"><time datetime="2018-06-27T23:59:49+08:00" 
			pubdate data-updated="true">2018/6/27</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>离群点又称之为异常点，在数据挖掘方面，经常需要在做特征工程和模型训练之前对数据进行清洗，剔除无效数据和异常数据。异常检测也是数据挖掘的一个方向，用于反作弊、伪基站、金融诈骗等领域。 </p>

<p>LOF算法英文名称是Local Outlier Factor，局部离群因子检测。是基于密度的离群点检测方法中一个比较有代表性的算法。该算法会给数据集中的每个点计算一个离群因子LOF，通过判断LOF是否接近于1来判定是否是离群因子。若LOF远大于1，则认为是离群因子，接近于1，则是正常点。</p>

<div align="center">
    <img width="400" src="media/15301151892004/15370972269076.jpg" />
</div>

<p>上图从直觉上看，我们会觉得点A和点B是异常点，这是因为它们相对周围点的整体密度而言，较为孤立。现在的问题是，如何实现算法的通用性，可以满足将不同种密度分散情况迥异的集合的异常点识别。LOF可以实现我们的目标。</p>

<h3 id="toc_0">LOF 算法</h3>

<p>现在来介绍LOF算法相关概念的定义。</p>

<ol>
<li><strong>\(d( p,q )\)</strong>： 表示点 p 与点 q 之间的距离。</li>
<li><p><strong>k-distance：第k距离</strong><br/>
对于点 p 的第 k 距离 \(d_k(p) = d(p,o)\) 满足</p>

<ul>
<li>在集合中至少有不包括 p 在内的 k 个点 \(q:q\in C\{q\neq p\}\)，满足 \(d(p,q) \le d(p,o)\)；</li>
<li>在集合中最多有不包括 p 在内的 k−1 个点 \(q:q\in C\{q\neq p\}\)，满足\(d(p,q,)\gt d(p,o)\) ；</li>
</ul>

<p>通俗的说就是点 p 的第 k 距离为 \(d(p,q)\) 就是距离点 p 第 k 远的点 q 距离，如下图</p>

<div align="center">
    <img width="150" src="media/15301151892004/15370986721083.jpg" />
</div></li>
<li><p><strong>k-distance neighborhood of p：第k距离邻域</strong><br/>
点 p 的第 k 距离邻域 \(N_k(p)\)，就是 p 的第 k 距离即以内的所有点，包括第 k 距离。 因此 p 的第 k 邻域点的个数 \(|N_k(p)|\ge k\)。</p></li>
<li><p><strong>reach-distance：可达距离</strong><br/>
点 p 到点 o 的第 k 可达距离定义为：<br/>
\[<br/>
\text{reach-}d_k(o,p)=max\{d_k(p),d(p,o)\}<br/>
\]</p>

<p>也就是，点 p 到点 o 的第 k 可达距离，至少是点 p 的第 k 距离，或者为点 p、o间的真实距离。 </p>

<p>这也意味着，离点 p 最近的 k 个点，p 到它们的可达距离被认为相等，且都等于\(d_k(p)\)。如下图，p 到 \(o_2\) 的第5可达距离为 \(d_5(p)\)，p 到 \(o_1\) 的第5可达距离为 \(d(o_1,p)\)。</p>

<div align="center">
    <img src="media/15301151892004/15371883100923.jpg" width="260" />
</div></li>
<li><p><strong>local reachability density：局部可达密度</strong><br/>
点 \(ｐ\) 的局部可达密度表示为<br/>
\[<br/>
lrd_k(p) = 1/\bigg(\frac{\sum_{o\in N_k(p)} \text{reach-}d_k(p,o)}{|N_k(p)|} \bigg)<br/>
\]</p>

<p>表示点 p 的第 k 邻域内点到 p 的平均可达距离的倒数。 <br/>
　　　　<br/>
<strong>注意，是p的邻域点 \(N_k(p)\) 到 p 的可达距离，不是 p 到 \(N_k(p)\) 的可达距离</strong></p>

<p>这个值的含义可以这样理解，首先这代表一个密度，密度越高，我们认为越可能属于同一簇，密度越低，越可能是离群点。如果 p 和周围邻域点是同一簇，那么可达距离越可能为较小的 \(d_k(o)\) ，导致可达距离之和较小，密度值较高；如果 p 和周围邻居点较远，那么可达距离可能都会取较大值 \(d(p,o)\)，导致密度较小，越可能是离群点。</p></li>
<li><p><strong>local outlier factor：局部离群因子</strong><br/>
点 p 的离群因子表示为<br/>
\[<br/>
LOF_k(p) = \frac{\sum_{o \in N_k(p)} \frac{lrd_k(o)}{lrd_k(p)}}{|N_k(p)|}<br/>
\]</p>

<p>表示点 p 的邻域 \(N_k(p)\) 内的点的局部可达密度与点 p 的局部可达密度之比的平均数。</p>

<p>如果这个比值越接近1，说明 p 的其邻域点密度差不多，p 可能和邻域同属一簇；如果这个比值越小于1，说明 p 的密度高于其邻域点密度，p 为密集点；如果这个比值越大于1，说明 p 的密度小于其邻域点密度，p 越可能是异常点。 </p></li>
</ol>

<hr/>

<p><a href="https://blog.csdn.net/wangyibo0201/article/details/51705966">异常点/离群点检测算法——LOF</a> </p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15291690032866.html">数据不平衡问题</a></h1>
			<p class="meta"><time datetime="2018-06-17T01:10:03+08:00" 
			pubdate data-updated="true">2018/6/17</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>现实中有很多类别不均衡问题，它是常见的，并且也是合理的，符合人们期望的。如，在欺诈交易识别中，属于欺诈交易的应该是很少部分，即绝大部分交易是正常的，只有极少部分的交易属于欺诈交易。这就是一个正常的类别不均衡问题。</p>

<p>迄今为止 , 解决不平衡分类问题的策略可以分为两大类。一类是从训练集入手，通过改变训练集样本分布，降低不平衡程度。另一类是从学习算法入手，根据算法在解决不平衡问题时的缺陷，适当地修改算法使之适应不平衡分类问题。平衡训练集的方法主要有训练集重采样(re-sampling)方法和训练集划分方法。学习算法层面的策略包括分类器集成、代价敏感学习和特征选择方法等。</p>

<h3 id="toc_0">数据层面解决数据不平衡问题</h3>

<p>采样方法是通过增加稀有类训练样本数的过采样 (over-sampling)和减少大类样本数的欠采样（under-samplings)使不平衡的样本分布变得比较平衡，从而提高分类器对稀有类的识别率。</p>

<h5 id="toc_1">随机欠采样（Random Under-Sampling）</h5>

<p>随机欠采样的目标是通过随机地消除占多数的类的样本来平衡类分布；直到多数类和少数类的实例实现平衡，目标才算达成。我们可以从多数类 \(S_{max}\) 中随机选择少量样本 \(E\) 再合并原有少数类样本作为新的训练数据集，新数据集为 \(S_{min}+E\)；</p>

<p>随机欠采样有两种类型分别为有放回和无放回两种，无放回欠采样在对多数类某样本被采样后不会再被重复采样，有放回采样则有可能。</p>

<ol>
<li><p>有放回随机欠采样</p>

<p>有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此则自助采样法。对于一个样本，它在某一次含 \(m\) 个样本的训练集的随机采样中，每次被采集到的概率是 \(\frac 1 m\)。不被采集到的概率为 \(1−\frac 1 m\)。如果 \(m\) 次采样都没有被采集中的概率是 \((1−\frac 1 m)^m\)。当 \(m\rightarrow \infty\)时，\((1−\frac 1 m)^m \rightarrow \frac 1 e \simeq 0.368\)。也就是说，在bagging的每轮随机采样中，训练集中大约有36.8%的数据没有被采样集采集中。对于这部分大约36.8%的没有被采样到的数据，我们常常称之为袋外数据(Out Of Bag, 简称OOB)。这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。<a href="http://www.cnblogs.com/pinard/p/6156009.html">Bagging与随机森林算法原理小结</a></p>

<p>放回采样后的数据集会有一些数据重复，一些数据缺失，从 \(N\) 个样本中采样 \(K\) 个样本，不同样本数量的期望为 \(U(K)=N(1−(\frac{N−1}{N})^K)\)。证明：首先，显然有U(1)=1；其次，设从N个样本中采样k−1个样本，不同样本数量的期望为U(k−1)，则第k个样本是未曾抽到的样本的概率为1−U(k−1)N，所以U(k)=1+N−1NU(k−1)=1+N−1N+(N−1N)2+⋯+(N−1N)k−1，根据等比数列求和公式得U(K)=N(1−(N−1N)K)。对于一种特殊情况，当K=N且N足够大时，则有最终不同样本数量是原始样本数量的期望为(1−1e)，大约是23。</p></li>
<li><p>无放回随机欠采样</p></li>
</ol>

<h5 id="toc_2">随机过采样（Random Over-Sampling）</h5>

<h5 id="toc_3">基于聚类的过采样（Cluster-Based Over Sampling）</h5>

<h5 id="toc_4">合成少数类过采样技术（SMOTE）</h5>

<h5 id="toc_5">改进的合成少数类过采样技术（MSMOTE）</h5>

<h3 id="toc_6">算法层面解决数据不平衡问题</h3>

<hr/>

<p><a href="https://blog.csdn.net/yaphat/article/details/60348946">不平衡数据</a><br/>
<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650724464&amp;idx=1&amp;sn=1f34358862bacfb4c7ea17c864d8c44d&amp;chksm=871b1c0eb06c95180e717d8316b0380602f638a764530b4b9e35ac812c7c33799d3357d46f00&amp;scene=0&amp;key=0f5e635eeb6bf20a076ad60d7f11c6ef5c5c1c8f02873bc8b458381b629a1e2ae76174d0d4ba34331c71d095e3b3b92aa7fff5e1e11badeaf6c87ff90fd264f3dc6b1eb074eaccb2ac46e8f2d440cefd&amp;ascene=0&amp;uin=MTU1NTY3MTA0Mg%3D%3D&amp;devicetype=iMac+MacBookPro12%2C1+OSX+OSX+10.11.6+build(15G1217)&amp;version=12010310&amp;nettype=WIFI&amp;fontScale=100&amp;pass_ticket=csWk%2BJXfpl7rA8r5">从重采样到数据合成：如何处理机器学习中的不平衡分类问题？</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15284680615860.html">模拟退火 SA</a></h1>
			<p class="meta"><time datetime="2018-06-08T22:27:41+08:00" 
			pubdate data-updated="true">2018/6/8</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>常拿来和模拟退火算法比较的就是贪心算法，该算法每次从当前解的临近解空间中选择一个最优解作为当前解，直到达到一个局部最优解。</p>

<p>贪心算法实现很简单，其主要缺点是会陷入局部最优解，而不一定能搜索到全局最优解。如下图搜搜最低点：假设 A 点为当前解，贪心算法搜索到 B 点这个局部最优解就会停止搜索，因为在 B 点无论向那个方向小幅度移动都不能得到更优的解。</p>

<div align="center">
    <img width="300" src="media/15284680615860/15371931915786.jpg" />
</div>

<h3 id="toc_0">模拟退火算法</h3>

<p>模拟退火算法，英文名叫 Simulate Anneal，SA。模拟退火其实也是一种贪心算法，但是它的搜索过程引入了随机因素。模拟退火算法以一定的概率来接受一个比当前解要差的解，因此有可能会跳出这个局部的最优解，达到全局的最优解。以上图为例，模拟退火算法在搜索到局部最优解 B 后，会以一定的概率接受到 E 的移动。也许经过几次这样的不是局部最优的移动后会到达 C 点，于是就跳出了局部最大值 B。</p>

<p>这里的一定的概率会随着时间的推移，逐渐衰减。转移概率通过下式给出<br/>
\[<br/>
p = \left \{\begin{array}\\<br/>
1\quad&amp; E(x_{new}) \le E(x_{old})\\<br/>
\exp\Big(-\frac{E(x_{new}) - E(x_{old})}{T}\Big)\quad &amp;E(x_{new}) \gt E(x_{old})\\<br/>
\end{array} \right .<br/>
\]</p>

<p>T 温度（表示接受较差解的意愿）开始时 \(T_0\) 非常高，指数部分接近于0，所以概率几乎为1.随着温度的递减，高成本和低成本值之间的差异越来越重要——差异越大，概率越低。因此此算法只倾向于稍差的解而不会是差很多的解。</p>

<p>而<strong>经典模拟退火</strong>的降温方式式可以采用下式<br/>
\[<br/>
T(t) = \frac{T_0}{lg(t) + 1}<br/>
\]</p>

<p><strong>快速模拟退火算法</strong>的降温方式为<br/>
\[<br/>
T(t) = \frac{T_0}{t+1}<br/>
\]</p>

<p>这两种方式都能够使得模拟退火算法可能收敛于全局最小点。</p>

<p>模拟退火的终止准则主要采用比较直观的方法：</p>

<ul>
<li>零度法： 给定一个比较小的正数 n ，当温度 \(T(t) &lt;= n\) 时，算法终止，表示达到了最低温度；</li>
<li>循环总数控制法：设置温度下降的次数为一定值 \(N\) ，当温度迭代次数达到 \(t\gt N\) 时，算法终止。</li>
<li>基于不改进规则的控制法：在一个温度和给定的迭代次数内没有改进当前的局部最优解，则算法终止；</li>
<li>接受概率终止准则：给定一个较小的概率 \(P\) 。在一个温度和给定的迭代步数内，除当前局部最优解外，其他状态的接受概率都小于 \(P\)，算法终止。</li>
</ul>

<h2 id="toc_1"></h2>

<p><a href="https://chenwenke.cn/Src/%E8%BD%AF%E4%BB%B6%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/%E8%AF%BE%E7%A8%8B%E8%AE%BE%E8%AE%A1/GhostMan/%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99/%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB%E7%AE%97%E6%B3%95.pdf">第二章 模拟退火算法</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15279303888267.html">随机梯度下降法的变化形式</a></h1>
			<p class="meta"><time datetime="2018-06-02T17:06:28+08:00" 
			pubdate data-updated="true">2018/6/2</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>通过反向传播进行的随机梯度下降已经有很好的效果。然而，还有很多其他的观点来优化代价函数，有时候，这些方法能够带来比在小批量的随机梯度下降更好的效果。在这之前，我们先看一下梯度下降法（GD）、批量梯度下降法（BGD）和随机梯度下降法（SGD）。</p>

<h3 id="toc_0">梯度下降法（GD）</h3>

<p>梯度下降算法（Gradient Descent Optimization）是神经网络模型训练最常用的优化算法。目标函数 \(J(w)\) 是关于 \(w\) 的函数，梯度将是目标函数上升最快的方向。对于最小化优化问题，只需要将参数沿着梯度相反的方向前进一个步长，就可以实现目标函数的下降。这个步长又称为学习速率 \(\eta\)。公式如下<br/>
\[<br/>
w \leftarrow w - \eta \frac{\partial J}{\partial w} <br/>
\]</p>

<p>几何意义如下图所示：</p>

<div align="center">
    <img width="300" src="media/15279303888267/15370651197093.jpg" />
</div>

<p>在 H 点的导数小于0，梯度向下，H 点将增大靠近最低点，在 F 点的导数大于0，梯度向上，F 点需要减小靠近最低。点。</p>

<p>关于梯度下降法，我们需要知道：<br/>
1）梯度下降不一定可以收敛到最小值。</p>

<div align="center">
    <img width="400" src="media/15279303888267/15370667266792.jpg" />
</div>

<p>2）学习率的大小要适中。</p>

<div align="center">
    <img width="200" src="media/15279303888267/15370672033462.jpg" />
</div>

<h3 id="toc_1">批量梯度下降法（BGD）</h3>

<p>在神经网络训练中，往往代价函数是多个参数的函数，训练样本也是数以万计的，批量梯度下降法的具体作法是在更新参数时使用所有的样本来进行更新。设 \(h(x)\) 是要拟合的函数，\(m\) 是训练样本的数量，代价函数假设为二次代价函数：<br/>
\[<br/>
\begin{align}<br/>
J(w) = \frac 1 m \sum_{i=1}^m \Big(\frac 1 2  [h(x^i) - y^i]^2\Big)\label{j1m}\\<br/>
w_j \leftarrow w_j - \eta \frac{\partial J(w)}{\partial w_j}\label{wlw}\\<br/>
\end{align}<br/>
\]</p>

<p>其中 \(x^i\) 是第 \(i\) 个训练样本。</p>

<p>以二次代价函数为例，求<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial J(w)}{\partial w_j} &amp;= \frac{\partial}{\partial w_j} \frac{1}{2m} \sum_{i=1}^m [h(x^i) - y^i]^2\\<br/>
&amp;= \frac{1}{m} \sum_{i=1}^m [h(x^i) - y^i]\frac{\partial h(x^i)}{\partial w_j} \\<br/>
&amp;= \frac{1}{m} \sum_{i=1}^m [h(x^i) - y^i]x^i_j \\<br/>
\end{align*}<br/>
\]</p>

<p>上式代入式(\ref{wlw}) 得<br/>
\[<br/>
w_j \leftarrow w_j - \eta \frac{1}{m} \sum_{i=1}^m [h(x^i) - y^i]x^i_j<br/>
\]</p>

<p>由上式知批量梯度下降是对所有样本进行计算，复杂度高，因此引入了另外一种算法。</p>

<h3 id="toc_2">随机梯度下降法（SGD）</h3>

<p>由于批量梯度下降每跟新一个参数的时候，要用到所有的样本数，所以训练速度会随着样本数量的增加而变得非常缓慢。随机梯度下降正是为了解决这个办法而提出的。它是利用每个样本的损失函数对 \(w_j\) 求偏导得到对应的梯度，来更新 \(w_j\) ，还是以二次代价函数为例：</p>

<p>\[<br/>
J(w) = \frac 1 2 [h(x^i) - y^i]^2\\<br/>
\frac{\partial J(w)}{\partial w_j} = [h(x^i) - y^i] x^i_j<br/>
\]</p>

<p>对于训练速度来说，随机梯度下降法由于每次仅仅采用一个样本来迭代，训练速度很快，而批量梯度下降法在样本量很大的时候，训练速度不能让人满意。对于准确度来说，随机梯度下降法用于仅仅用一个样本决定梯度方向，导致解很有可能不是最优（噪音数据处理不好）。对于收敛速度来说，由于随机梯度下降法一次迭代一个样本，导致迭代方向变化很大，不能很快的收敛到局部最优解。</p>

<h3 id="toc_3">小批量梯度下降法（Mini-BGD）</h3>

<p>小批量梯度下降法是批量梯度下降法和随机梯度下降法的折衷，也就是对于 \(m\) 个样本，我们采用 \(n\) 个样子来迭代，\(1&lt;n&lt;m\)。一般可以取 \(n=10\) ，当然根据样本的数据，可以调整这个 \(n\) 的值。以二次代价函数为例，对应的更新公式是：<br/>
\[<br/>
J(w) = \frac 1 n \sum_{i=t}^{t+n-1} [\frac 1 2 h(x^i) - y^i]^2\\<br/>
\frac{\partial J(w)}{\partial w_j} = \frac{1}{n} \sum_{i=t}^{t+n-1} [h(x^i) - y^i]x^i_j<br/>
\]</p>

<p>其中 \(t\) 表示第 \(t\) 次迭代。</p>

<p>现在开始讲解随机梯度下降的变化形式。</p>

<h3 id="toc_4">牛顿法（Hessian 技术）</h3>

<p>代价函数 \(C\) 是多个参数的函数，\(w = (w_1, w_2,...,w_n)^T\)，所以 \(C = C(w)\)。 借助于泰勒展开式，代价函数可以在点 \(w^0=(w^0_1,w^0_2,...,w^0_n)^T\) 处被近似为:</p>

<p>\[<br/>
C(w) = C(w_0) + \sum_j \frac{\partial C}{\partial w_j} (w^j - w_0^j) + \frac{1}{2!} \sum_{j,k} \triangle (w^j - w_0^j)(w^k - w_0^k )\frac{\partial^2 C}{\partial w_j \partial w_k}  + o^n<br/>
\]</p>

<p>令 \(\triangle w = w-w^0\)，我们可以将其压缩为:<br/>
\[<br/>
C(w^0 + \triangle w) = C(w^0) + \nabla C \triangle w + \frac 1 2 \triangle {w}^T H \triangle w + o^n<br/>
\]</p>

<p>其中 \(\nabla C\) 是通常的梯度向量，\(H\) 就是矩阵形式的 <strong>Hessian 矩阵</strong>，其中 jk-th 项就是 \(\frac{\partial^2 C}{\partial w_j \partial w_k}\)<br/>
\[<br/>
H = \left [\begin{array}{cccccc}<br/>
\frac{\partial^2 C}{\partial w_1\partial w_1}&amp;\frac{\partial^2 C}{\partial w_1\partial w_2}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_1\partial w_k}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_1 \partial w_n}\\<br/>
\frac{\partial^2 C}{\partial w_2\partial w_1}&amp;\frac{\partial^2 C}{\partial w_2\partial w_2}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_2\partial w_k}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_2 \partial w_n}\\<br/>
\vdots&amp;\vdots&amp;\ddots&amp;\vdots&amp;\ddots&amp;\vdots\\<br/>
\frac{\partial^2 C}{\partial w_j\partial w_1}&amp;\frac{\partial^2 C}{\partial w_j\partial w_2}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_j\partial w_k}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_j \partial w_n}\\<br/>
\vdots&amp;\vdots&amp;\ddots&amp;\vdots&amp;\ddots&amp;\vdots\\<br/>
\frac{\partial^2 C}{\partial w_n\partial w_1}&amp;\frac{\partial^2 C}{\partial w_n\partial w_2}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_n\partial w_k}&amp;\cdots&amp;\frac{\partial^2 C}{\partial w_n \partial w_n}\\<br/>
\end{array} \right ]<br/>
\]</p>

<p>假设我们通过丢弃更高阶的项来近似 \(C\)：<br/>
\[<br/>
\begin{equation}<br/>
C(w^0 + \triangle w) \approx C(w^0) + \nabla C \triangle w + \frac 1 2 \triangle {w}^T H \triangle w \label{cwap}<br/>
\end{equation}<br/>
\]</p>

<p>由极值条件必要条件可知，\(C(w^0+\triangle w)\) 求得最优解时，\(C′(w^0 + \triangle w)\) 应满足 <br/>
\[<br/>
C′(w^0+\triangle w)=0<br/>
\]</p>

<p>对式(\ref{cwap})两边求导，可以求得 \(\nabla C\)<br/>
\[<br/>
C′(w^0+\triangle w) = \nabla C + H \triangle w = 0<br/>
\]</p>

<blockquote>
<p>对 \(w\) 两边求导<br/>
\[<br/>
\frac{\partial C}{\partial w} = \frac{\partial C}{\partial \triangle w} \frac{\partial \triangle w}{\partial w}  = \frac{\partial C}{\partial \triangle w} \frac{\partial}{\partial w}(w-w^0)  = \frac{\partial C}{\triangle w}<br/>
\]</p>
</blockquote>

<p>如果海森矩阵是正定的<br/>
\[<br/>
\triangle w = -H^{-1}\nabla C<br/>
\]</p>

<p>因此利用牛顿法进行迭代的过程就是</p>

<ol>
<li>选择开始点 \(w^0\)；</li>
<li>更新 \(w^0\) 到新点 \(w^1=w^0−H^{−1}\nabla C\)，其中的 \(H\) 和 \(\nabla C\) 是在 \(w^0\) 处计算出来的；</li>
<li>更新 \(w^1\) 到新点 \(w^2=w^1−H^{−1}\nabla C\)，其中的 \(H\) 和 \(\nabla C\) 是在 \(w^1\) 处计算出来的。</li>
<li>...</li>
</ol>

<p>实际应用中，(\ref{cwap}) 是唯一的近似，并且选择更小的步⻓会更好。我们通过重复地使用改变 量 \(\triangle w = −\eta H^{−1}\nabla C\) 来改变 \(w\)，其中 \(\eta\) 是学习速率。</p>

<p>这个最小化代价函数的方法常常被称为 Hessian 技术或者 Hessian 优化。在理论上和实践中的结果都表明 Hessian 方法比标准的梯度下降方法收敛速度更快。特别地，通过引入代价函数的二阶变化信息，可以让 Hessian 方法避免在梯度下降中常碰到的多路径(pathologies)问题。 而且，反向传播算法的有些版本也可以用于计算 Hessian。</p>

<p>如果 Hessian 优化这么厉害，为何我们这里不使用它呢?不幸的是，尽管 Hessian 优化有很多可取的特性，它其实还有一个不好的地方:在实践中很难应用。这个问题的部分原因在于 Hessian 矩阵的太大了。假设你有一个 \(10^7\) 个权重和偏置的网络。那么对应的 Hessian 矩阵会有 \(10^7 \times 10^7 = 10^{14}\) 个元素。这真的是太大了!所以在实践中，计算 \(H^{−1}\nabla C\) 就极其困难。不过， 这并不表示学习理解它没有用了。实际上，有很多受到 Hessian 优化启发的梯度下降的变种，能避免产生太大矩阵的问题。让我们看看其中一个称为基于 momentum 梯度下降的方法。</p>

<h3 id="toc_5">基于 momentum 的梯度下降</h3>

<p>直觉上看，Hessian 优化的优点是它不仅仅考虑了梯度，而且还包含梯度如何变化的信息。基于 momentum 的梯度下降就基于这个直觉，但是避免了二阶导数的矩阵的出现。为了理解 momentum 技术，想想我们关于梯度下降的原始图片，其中我们研究了一个球滚向山谷的场景。那时候，我们发现梯度下降，除了这个名字外，就类似于球滚向山谷的底部。momentum 技术修改了梯度下降的两处使之类似于这个物理场景。首先，为我们想要优化的参数引入了一个称为速度(velocity)的概念。梯度的作用就是改变速度，而不是直接的改变位置，就如同物理学中的力改变速度，只会间接地影响位置。第二，momentum 方法引入了一种摩擦力的项，用来逐步地减少速度。</p>

<p>让我们给出更加准确的数学描述。我们引入对每个权重 \(w_j\) 设置相应的速度变量 \(v = v_1, v_2,...\)。 注意，这里的权重也可以笼统地包含偏置。然后我们将梯度下降更新规则 \(w \leftarrow w − \eta \nabla C\)，改成<br/>
\[<br/>
\begin{align*}<br/>
v &amp;\leftarrow \mu v - \eta\nabla C\\<br/>
w &amp;\leftarrow w + v<br/>
\end{align*}<br/>
\]</p>

<p>在这些方程中，\(\mu\) 是用来控制阻碍或者摩擦力的量的超参数。为了理解这个公式，可以考虑一下当 \(\mu = 1\) 的时候，对应于没有任何摩擦力。所以，此时你可以看到力 \(\nabla C\) 改变了速度 \(v\)，速度随后再控制 \(w\) 变化率。直觉上看，我们通过重复地增加梯度项来构造速度。这表示，如果梯度在某些学习的过程中几乎在同样的方向，我们可以得到在那个方向上比较大的移动量。</p>

<div align="center">
    <img width="300" src="media/15279303888267/15370754583882.jpg" />
</div>

<p>相比普通梯度向下，在K点可以凭借之前的速度，令其在这部分参数更新的速度得以增加；同样在I点能凭借之前的速度跨过鞍点；最后在局部最小值J点中，也可能凭借之前的速度跨过。所以基于Momentum的梯度下降虽然不能保证得到一个全局最小值，但是至少给了我们可能性。</p>

<p>前面提到，\(\mu\) 可以控制系统中的摩擦力大小;更加准确地说，你应该将 \(1 − \mu\) 看成是摩擦力的量。当 \(\mu = 1\) 时，没有摩擦，速度完全由梯度 \(\nabla C\) 决定。相反，若是 \(\mu = 0\)，就存在很大的摩擦，速度无法叠加，变成普通的梯度下降。使用 0 和 1 之间的 \(\mu\) 值可以给我们避免过量而又能够叠加速度的好处。我们可以使用 hold out 验证数据集来选择合适的 \(\mu\) 值。</p>

<p>关于 momentum 技术的一个很好的特点是它基本上不需要改变太多梯度下降的代码就可以 实现。我们可以继续使用反向传播来计算梯度，就和前面那样，使用随机选择的 minibatch 的方法。</p>

<p>同样这种方法也有着自身的两个缺点：首先容易跨过全局最小点，其次可能因为惯性过大造成在应该改变梯度（主要指的是下降方向）时无法及时改变。</p>

<h5 id="toc_6">Momentum算法步骤</h5>

<p><strong>输入</strong>：学习率 \(\eta\)，动量参数 \(\mu\)，初始参数 \(w\)，初始速度 \(v\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>while 没有达到停止准则 do

<ul>
<li>从训练集中采包含 \(m\) 个样本 \(\{x^{(i)},...,x^{(m)}\}\) 的小批量，对应目标为 \(y^{(i)}\)</li>
<li>计算梯度（在临时点）：\(g\leftarrow \frac 1 m \nabla_{w}\sum_i C(f(x^{(i)};w),y^{(i)})\)</li>
<li>计算速度更新：\(v \leftarrow \mu v - \eta g\)</li>
<li>应用更新：\(w \leftarrow w + v\)</li>
</ul></li>
<li>end while</li>
</ul>

<h3 id="toc_7">NAG（Nesterov&#39;s accelerated gradient 涅斯捷罗夫加速梯度下降）</h3>

<p>从山顶往下滚的球会盲目地选择斜坡。更好的方式应该是在遇到倾斜向上之前应该减慢速度。NAG 不仅增加了动量项，并且在计算参数的梯度时，在损失函数中减去了动量项，即计算<br/>
\[<br/>
\begin{align*}<br/>
g^{(t)} &amp;= \nabla C(w^{(t-1)} + \mu v^{(t-1)})\\<br/>
v^{(t)} &amp;\leftarrow \mu v^{(t-1)} - \eta g^{(t)}\\<br/>
w^{(t)} &amp;\leftarrow w^{(t-1)} + v_t \\<br/>
\end{align*}<br/>
\]</p>

<p>这种方式首先预估了下一次参数所在的位置，再加上动量项，这样可以阻止过快更新来提高响应性。NAG可以看作是Momentum的改进版，对于这个改动，很多文章给出的解释是，能够让算法提前看到前方的地形梯度，如果前面的梯度比当前位置的梯度大，那我就可以把步子迈得比原来大一些，如果前面的梯度比现在的梯度小，那我就可以把步子迈得小一些。这个大一些、小一些，都是相对于原来不看前方梯度、只看当前位置梯度的情况来说的。</p>

<div align="center">
    <img width="270" src="media/15279303888267/15370787141104.jpg" />
</div>

<p>在点H的梯度更新不仅看到当前的梯度和加速度，还能考虑到下一步的梯度，提前做出改变。</p>

<h5 id="toc_8">NAG算法步骤</h5>

<p><strong>输入</strong>：学习率 \(\eta\)，动量参数 \(\mu\)，初始参数 \(w\)，初始速度 \(v\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>while 没有达到停止准则 do

<ul>
<li>从训练集中采包含 \(m\) 个样本 \(\{x^{(i)},...,x^{(m)}\}\) 的小批量，对应目标为 \(y^{(i)}\)</li>
<li>应用临时更新：\(\widetilde w \leftarrow w + \mu v\)</li>
<li>计算梯度（在临时点）：\(g\leftarrow \frac 1 m \nabla_{\widetilde w}\sum_i C(f(x^{(i)};\widetilde w),y^{(i)})\)</li>
<li>计算速度更新：\(v \leftarrow \mu v - \eta g\)</li>
<li>应用更新：\(w \leftarrow w + v\)</li>
</ul></li>
<li>end while</li>
</ul>

<h3 id="toc_9">AdaGrad算法</h3>

<p>在上面的参数更新中，都是固定了学习率 \(\eta\)，而Adagrad方法是通过参数来调整合适的学习率 \(\eta\)，对稀疏参数进行大幅更新和对频繁参数进行小幅更新。因此，Adagrad方法非常适合处理稀疏数据。</p>

<p>对于 AdaGrad 算法而言在 t 时刻对每一个参数 \(w_i\) 都使用了不同的学习率，我们首先介绍 AdaGrad 对每一个参数的更新，然后我们对其向量化。为了简洁，令 \(g_{t,i}\) 表示 t 时刻目标函数关于参数 \(w_i\) 的梯度<br/>
\[<br/>
g_{t,i} = \nabla_w C(w_i)<br/>
\]</p>

<p>在 t 时刻，对每一个参数 \(w_i\) 的更新过程变为：<br/>
\[<br/>
w_{t+1,i} = w_{t,i} - \eta\cdot g_{t,i}<br/>
\]</p>

<p>基于上述对 \(w_i\) 计算过的历史梯度，AdaGrad 修正了对每一个参数 \(w_i\) 的学习率：<br/>
\[<br/>
w_{t+1,i} \leftarrow w_{t,i} - \frac{\eta}{\sqrt{G_{t,ii} + \epsilon}}\cdot g_{t,i}<br/>
\]</p>

<p>\(G_t \in \mathbb R^{d\times d}\) 为一个对角矩阵，<strong>对角线上第 \(i,i\) 个元素为 \(w_i\) 的梯度由开始到当前时刻的平方和</strong>。\(\epsilon\) 通常为 \(10^{-7}\)，这是为了保证分母非0。如果不使用开方的话，该算法性能会差很多。</p>

<p>因为 \(G_t\) 在其对角线上所有参数 \(w\) 的历史梯度的平方和，我们可以通过 \(G_t\) 和 \(g_t\) 向量乘法 \(\odot\)，将我们的表达式向量化：<br/>
\[<br/>
w_{t+1} \leftarrow w_{t} - \frac{\eta}{\sqrt{G_{t} + \epsilon}}\odot g_{t}<br/>
\]</p>

<p>该算法优点是自适应的调整学习率。一般初始学习率设置为0.01。</p>

<p>该算法的缺点是，分母中需要计算每个参数梯度的累计平方和，由于每次均累加一个正数，训练阶段累积和会持续增加，导致训练后期的学习率非常小，以至更新时不能从当前的梯度获取任何有用信息（另外，更新参数时，左右两边的单位不统一）。下面的算法 Adadelta 等可以解决这个问题。</p>

<h5 id="toc_10">AdaGrad算法步骤</h5>

<p><strong>输入</strong>：全局学习率 \(\eta\)，初始参数 \(w\)，小参数  \(\epsilon\)，一般设置为 \(10^{-7}\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>初始化梯度数据 \(r=0\)</li>
<li>while 没有达到体质准则 do

<ul>
<li>从训练集中采样 \(m\) 个样本 \(\{x^{(1)},...,x^{(m)}\}\) 的小批量，对应目标为 \(y^{(i)}\)</li>
<li>计算梯度：\(g\leftarrow \frac 1 m \nabla_{w}\sum_{i} C(f(x^{(i)};w),y^{(i)})\)</li>
<li>累积平方梯度：\(r\leftarrow r+g\odot g\)</li>
<li>计算参数更新：\(\triangle w \leftarrow -\frac{\eta}{\sqrt{r+ \epsilon}}\odot g\)</li>
<li>应用更新：\(w \leftarrow w + \triangle w\)</li>
</ul></li>
<li>end while</li>
</ul>

<h3 id="toc_11">RMSprop算法</h3>

<p>鉴于神经网络都是非凸条件下的，RMSProp在非凸条件下结果更好，改变梯度累积为指数衰减的移动平均以丢弃遥远的过去历史。经验上，RMSProp被证明有效且实用的深度学习网络优化算法。目前 它是深度学习从业者经常采用的优化方法之一。</p>

<p>相比于AdaGrad算法的历史梯度：<br/>
\[<br/>
r \leftarrow r + g\odot g<br/>
\]</p>

<p>RMSProp增加了一个衰减系数来控制历史信息的获取多少： <br/>
\[<br/>
r \leftarrow \rho r + (1-\rho) g\odot g<br/>
\]</p>

<h5 id="toc_12">原生的RMSprop算法</h5>

<p><strong>输入</strong>：全局学习率 \(\eta\)，衰减系数 \(\rho\)（建议设置为0.9），初始参数 \(w\)，小参数  \(\epsilon\)，一般设置为 \(10^{-6}\)（用于被小数除时的数值稳定）<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>初始化累积梯度数据 \(r=0\)</li>
<li>while 没有达到体质准则 do

<ul>
<li>从训练集中采样 \(m\) 个样本 \(\{x^{(1)},...,x^{(m)}\}\) 的小批量，对应目标为 \(y^{(i)}\)</li>
<li>计算梯度：\(g\leftarrow \frac 1 m \nabla_{w}\sum_{i} C(f(x^{(i)};w),y^{(i)})\)</li>
<li>累积平方梯度：\(r \leftarrow \rho r + (1-\rho) g\odot g\)</li>
<li>计算参数更新：\(\triangle w \leftarrow -\frac{\eta}{\sqrt{r + \epsilon}}\odot g\)</li>
<li>应用更新：\(w \leftarrow w + \triangle w\)</li>
</ul></li>
<li>end while</li>
</ul>

<p>再看看结合Nesterov动量的RMSProp，直观上理解就是： <br/>
RMSProp改变了学习率，Nesterov引入动量改变了梯度，从两方面改进更新方式。 </p>

<h5 id="toc_13">加入Nesterov动量的RMSprop算法</h5>

<p><strong>输入</strong>：全局学习率 \(\eta\)，衰减系数 \(\rho\)（建议设置为0.9），动量系数 \(\mu\)，初始参数 \(w\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>初始化累积梯度数据 \(r=0\)</li>
<li>while 没有达到体质准则 do

<ul>
<li>从训练集中采样 \(m\) 个样本 \(\{x^{(1)},...,x^{(m)}\}\) 的小批量，对应目标为 \(y^{(i)}\)</li>
<li>计算临时更新： \(\widetilde w \leftarrow w + \mu v\)</li>
<li>计算梯度（在临时点）：\(g\leftarrow \frac 1 m \nabla_{\widetilde w}\sum_{i} C(f(x^{(i)};\widetilde w),y^{(i)})\)</li>
<li>累积平方梯度：\(r \leftarrow \rho r + (1-\rho) g\odot g\)</li>
<li>计算速度更新：\(v\leftarrow \mu v - \frac{\epsilon}{\sqrt{r}}\odot g\)</li>
<li>应用更新：\(w \leftarrow w + v\)</li>
</ul></li>
<li>end while</li>
</ul>

<h3 id="toc_14">Adadelta算法</h3>

<p>Adadelta 类似于RMSprop也使用小批量随机梯度按元素平方的指数加权移动平均变量 \(r\)，设在时刻 \(t\) (前面的 \(r\) 这里用 \(\mathbb E[g^2]_t\) 表示)：<br/>
\[<br/>
\mathbb E[g^2]_t \leftarrow \rho \mathbb E[g^2]_{t-1} + (1-\rho) g_t\odot g_t<br/>
\]</p>

<p>再求它的平方根，下面记为 \(RMS[g]_t\)<br/>
\[<br/>
RMS[g]_t = \sqrt{\mathbb E[g^2]_t + \epsilon}<br/>
\]</p>

<p>AdaDelta算法的作者注意到SGD、Momentum、AdaGrad和RMSProp等算法在参数更新时，单位并不匹配，他认为更新应该和参数应有相同的假想单位，为了实现这一想法，AdaDelta在RMSProp的基础上，还考虑了参数更新的指数衰减累积平方和<br/>
\[<br/>
\mathbb E[\triangle w^2]_t \leftarrow \rho \mathbb E[\triangle w^2]_{t-1} + (1-\rho) \triangle w_t^2<br/>
\]</p>

<p>同理，记<br/>
\[<br/>
RMS[\triangle w]_t = \sqrt{\mathbb E[\triangle w^2]_t + \epsilon}<br/>
\]</p>

<p>Adadelta 算法使用 \(RMS[\triangle w]_t\) 来代替学习率 \(\eta\)，直接采用<br/>
\[<br/>
\begin{align*}<br/>
\triangle w_t &amp;\leftarrow -\frac{\sqrt{\mathbb E[\triangle w^2]_{t-1} + \epsilon}}{\sqrt{\mathbb E[g^2]_t + \epsilon}}\odot g_t\\<br/>
&amp;= -\frac{RMS[\triangle w]_{t-1}}{RMS[g]_t }\odot g_t\\<br/>
\end{align*}<br/>
\]</p>

<p>最后更新<br/>
\[<br/>
w_{t+1} \leftarrow w_{t} + \triangle w_t<br/>
\]</p>

<h5 id="toc_15">Adadelta算法步骤</h5>

<p><strong>输入</strong>：衰减系数 \(\rho\)（建议设置为0.9），初始参数 \(w\)，小参数  \(\epsilon\)，一般设置为 \(10^{-6}\)（用于被小数除时的数值稳定）<br/>
<strong>算法过程</strong>：</p>

<ul>
<li>初始化累积梯度数据 \(r=0\)</li>
<li>初始化累积参数更新数据 \(s=0\)</li>
<li>while 没有达到体质准则 do

<ul>
<li>从训练集中采样 \(m\) 个样本 \(\{x^{(1)},...,x^{(m)}\}\) 的小批量，对应目标为 \(y^{(i)}\)</li>
<li>计算梯度：\(g\leftarrow \frac 1 m \nabla_{w}\sum_{i} C(f(x^{(i)};w),y^{(i)})\)</li>
<li>累积平方梯度：\(r \leftarrow \rho r + (1-\rho) g\odot g\)</li>
<li>计算参数更新：\(\triangle w \leftarrow -\frac{\sqrt{s+\epsilon}}{\sqrt{r + \epsilon}}\odot g\)</li>
<li>累加平方参数更新：\(s \leftarrow \rho s + (1-\rho) \triangle w^2\)</li>
<li>应用更新：\(w \leftarrow w + \triangle w\)</li>
</ul></li>
<li>end while</li>
</ul>

<h3 id="toc_16">Adam（Adaptive Moment Estimation）</h3>

<p>Adam算法即自适应时刻估计方法（Adaptive Moment Estimation），能计算每个参数的自适应学习率。<strong><font color=red>Adam算法可以看做是修正后的Momentum+RMSProp算法</font></strong>。在实际应用中，Adam方法效果良好。与其他自适应学习率算法相比，其收敛速度更快，学习效果更为有效，而且可以纠正其他优化技术中存在的问题，如学习率消失、收敛过慢或是高方差的参数更新导致损失函数波动较大等问题。学习率建议为0.001。</p>

<h5 id="toc_17">Adam算法步骤</h5>

<p><strong>输入</strong>：步长 \(\eta\)（建议设为0.001），矩估计的指数衰减速率，\(\rho_1\) 和 \(\rho_2\) 在区间 [0,1)内。（建议默认为0.9和0.999），用于数值稳定的小常数 \(\epsilon\)（建议默认为 \(10^-8\)），初始参数 \(w\)<br/>
<strong>算法过程</strong></p>

<ul>
<li>初始化一阶和二阶矩变量 \(s=0,r=0\)</li>
<li>初始化时间 \(t=0\)</li>
<li>while 没有达到停止准则 do

<ul>
<li>从训练集中采样 \(m\) 个样本 \(\{x^{(1)},...,x^{(m)}\}\) 的小批量，对应目标为 \(y^{(i)}\)</li>
<li>计算梯度：\(g\leftarrow \frac 1 m \nabla_{w}\sum_{i} C(f(x^{(i)};w),y^{(i)})\)</li>
<li>\(t \leftarrow t + 1\)</li>
<li>更新有偏一阶矩估计：\(s\leftarrow \rho_1 s + (1-\rho_1)g\)<strong><font color=red>　　　　　Momentum项</font></strong></li>
<li>更新有偏二阶矩估计：\(r\leftarrow \rho_2 r + (1-\rho_2)g\odot g\)<strong><font color=red>　　　RMSProp项</font></strong></li>
<li>修正一阶矩的偏差：\(\hat s\leftarrow \frac{s}{1-\rho_1^2}\)</li>
<li>修正二阶矩的偏差：\(\hat r\leftarrow \frac{s}{1-\rho_2^2}\)</li>
<li>计算参数更新：\(\triangle w = -\frac{\eta}{\sqrt{\hat r}+\epsilon}\hat s\)</li>
<li>应用更新：\(w\leftarrow w + \triangle w\)</li>
</ul></li>
<li>end while</li>
</ul>

<hr/>

<p>神经网络与深度学习<br/>
<a href="https://blog.csdn.net/dugudaibo/article/details/77413071">改变神经网络的学习方法（5）：随机梯度下降的变化形式(Adagrad、RMSProp、Adadelta、Momentum、NAG)</a><br/>
<a href="https://zh.gluon.ai/chapter_optimization/adagrad.html">Adagrad 例子</a><br/>
<a href="http://zh.gluon.ai/chapter_optimization/adadelta.html">Adadelta</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15272663505619.html">深度学习中正则化</a></h1>
			<p class="meta"><time datetime="2018-05-26T00:39:10+08:00" 
			pubdate data-updated="true">2018/5/26</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在神经网络的训练过程中很容易发生过拟合现象，最好的降低过度拟合的方式之一就是增加训练样本的量。有了足够的训练数据，就算是一个规模非常大的网络也不容易过度拟合。不幸的是，训练数据其实是很难或者很昂贵的资源，所以这不是一种太切实际的选择。</p>

<p>还有一种可行的方式就是降低网络的规模。然而，大的网络拥有一种小的网络更强的潜力，所以这里存在一种应用冗余性的选项。幸运的是，还有其他的技术能够缓解过度拟合，即使我们只有一个固定的网络和固定的训练集合。这种技术就是正则化。</p>

<h3 id="toc_0">正则化方法</h3>

<p>正则化技术不仅可以应用在神经网络中，线性模型，如线性回归和逻辑回归都可以使用简单、直接、有效的正则化策略。在SVM中和决策树上就有这方面的应用。</p>

<p>许多正则化方法通过对目标函数 \(J\) 假设一个参数范数惩罚 \(\Omega(\theta)\) 限制模型的学习能力。我们将正则化后的目标函数记为 \(\widetilde J\)：<br/>
\[<br/>
\widetilde J = J + \alpha\Omega(\theta)<br/>
\]</p>

<p>其中 \(\alpha\in [0,\infty)\) 是权衡范数惩罚项 \(\Omega\) 和标准目标函数 \(J\) 相对贡献的超参数。将 \(\alpha\) 设为0表示没有正则化。 \(\alpha\) 越大，对应正则化惩罚越大。</p>

<p>当我们的训练算法最小化正则化后的目标函数 \(\widetilde J\) 时，它会降低原始目标 \(J\) 关于训练数据的误差并同时减小在某些衡量标准下参数 \(\theta\)（或参数子集）的规模。选择不同的参数范数 \(\Omega\) 会偏好不同的解。</p>

<p>在神经网络中，参数包括每一层仿射变换的权重和偏置，我们通常只对权重做惩罚而不对偏置做正则惩罚。精确拟合偏置所需的数据通常比拟合权重少得多。每个权重会指定两个变量如何相互作用。我们需要在各种条件下观察这两个变量才能良好地拟合权重。而每个偏置仅控制一个单变量。这意味着，我们不对其进行正则化也不会导致太大的方差。另外，正则化偏置参数可能会导致明显的欠拟合。因此，我们使用向量 \(w\) 表示所有应受范数惩罚影响的权重，而向量 \(\theta\) 表示所有参数 (包括 \(w\) 和无需正则化的参数)。</p>

<p>在神经网络的情况下，有时希望对网络的每一层使用单独的惩罚，并分配不同的 \(\alpha\) 系数。寻找合适的多个超参数的代价很大，因此为了减少搜索空间，我们会在所有层使用相同的权重衰减。</p>

<h4 id="toc_1">\(L^2\) 正则化（权重衰减）</h4>

<p>\(L^2\)正则化就是在代价函数 \(J\) 后面再加上一个正则化项 \(\Omega(\theta) = \frac{1}{2}||w||_2^2\) ：</p>

<p>\[<br/>
\widetilde J = J + \frac{\alpha}{2}w^T w <br/>
\]</p>

<p>与之对应梯度为：<br/>
\[<br/>
\nabla_w \widetilde J = \nabla_w J + \alpha w<br/>
\]</p>

<p>使用单步梯度下降更新权重，即执行以下更新:<br/>
\[<br/>
w \leftarrow w − \eta(\alpha w + \nabla_w J)<br/>
\]</p>

<p>换种写法就是:<br/>
\[<br/>
w \leftarrow (1 − \eta \alpha)w − \eta \nabla_w J<br/>
\]</p>

<p>我们可以看到，加入权重衰减后会引起学习规则的修改，即在每步执行通常的梯度更新之前先收缩权重向量（将权重向量乘以一个常数因子）。</p>

<p>我们进一步简化分析，令 \(w^∗\) 为未正则化的目标函数取得最小训练误差时的权重向量，即 \(w^∗ = \arg\min_w J (w)\)，并在 \(w^∗\) 的邻域对目标函数做二次近似。如果目标函数确实是二次的（如以均方误差拟合线性回归模型的情况），则该近似是完美的。 近似的 \(\hat J(θ)\) 如下<br/>
\[<br/>
\hat J(θ) = J(w^∗) + \frac 1 2 (w − w^∗)^T H(w − w^∗),<br/>
\]</p>

<p>其中 \(H\) 是 \(J\) 在 \(w^*\) 处计算的 Hessian 矩阵（关于 \(w\)）。因为 \(w^*\) 被定义为最优，即梯度消失为 0，所以该二次近似中没有一阶项。同样地，因为 \(w^*\) 是 \(J\) 中的一个最优点，我们可以得出 \(H\) 是半正定的结论。</p>

<p>当 \(\hat J\) 取得最小时，其梯度<br/>
\[<br/>
\nabla_w \hat J(w) = H(w-w^*) <br/>
\]</p>

<p>为0。</p>

<p>如果我们加上权重衰减梯度之后再来看最小化正则化后的 \(\hat J\)，我们使用 \(\widetilde w\) 表示此时的最优点：<br/>
\[<br/>
\begin{align}<br/>
H(\widetilde w - w^*) + \alpha \widetilde w = 0\nonumber\\<br/>
(H + \alpha I)\widetilde w = Hw^*\nonumber\\<br/>
\widetilde w = (H+\alpha I)^{-1}Hw^*\label{wwha}\\<br/>
\end{align}<br/>
\]</p>

<p>当 \(\alpha\) 趋向于 0 时，正则化的解 \(\widetilde w\) 会趋向于 \(w^*\)。因为 \(H\) 是实对称矩阵，我们可以将其分解为一个对角矩阵 \(\Lambda\) 和一组特征向量的标准正交基 \(Q\)，并且有 \(H=Q\Lambda Q^T\)。应用于式 ( \ref{wwha} ) 得<br/>
\[<br/>
\begin{align}<br/>
\widetilde w &amp;= (Q\Lambda Q^T + \alpha I)^{-1} Q\Lambda Q^T w^*\label{wwqq}\\<br/>
&amp;= [Q(\Lambda + \alpha I)Q^T]^{-1} Q\Lambda Q^Tw^*\label{wwqq2}\\<br/>
&amp;= Q(\Lambda + \alpha I)^{-1} \Lambda Q^T w^*\label{wwqq3}\\<br/>
\end{align}<br/>
\]</p>

<p>从 ( \ref{wwqq} ) 式到 ( \ref{wwqq2} ) 式是因为</p>

<blockquote>
<p>正交矩阵和它的转置的乘积是单位矩阵，即 \(Q\) 是正交矩阵，有 \(QQ^T = I\)</p>
</blockquote>

<p>从 ( \ref{wwqq2} ) 式到 ( \ref{wwqq3} ) 式是因为</p>

<blockquote>
<p>正交矩阵的转置矩阵等于逆矩阵，即 \(Q\) 是正交矩阵，有 \(Q^T = Q^{-1}\)</p>
</blockquote>

<p>现在将 \((\Lambda + \alpha I)^{-1} \Lambda\) 分解结算<br/>
\[<br/>
\begin{align*}<br/>
(\Lambda + \alpha I)\Lambda &amp;= \Bigg(\left [ \begin{array}\\\lambda_{1}&amp;&amp;&amp;\\&amp;\lambda_{2}&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_{n}\\ \end{array} \right ] + \alpha \cdot\left [ \begin{array}\\1&amp;&amp;&amp;\\&amp;1&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;1\\\end{array}\right ] \Bigg)^{-1}\cdot \left [ \begin{array}\\\lambda_{1}&amp;&amp;&amp;\\&amp;\lambda_{2}&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_{n}\\ \end{array} \right ]\\<br/>
&amp;= \left [ \begin{array}\\\lambda_{1}+\alpha&amp;&amp;&amp;\\&amp;\lambda_{2}+\alpha&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_{n}+\alpha\\\end{array}\right ]^{-1}\cdot \left [ \begin{array}\\\lambda_{1}&amp;&amp;&amp;\\&amp;\lambda_{2}&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_{n}\\ \end{array} \right ]\\<br/>
&amp;= \left [ \begin{array}\\\frac{1}{\lambda_{1}+\alpha}&amp;&amp;&amp;\\&amp;\frac{1}{\lambda_{2}+\alpha}&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\frac{1}{\lambda_{n}+\alpha}\\\end{array}\right ]\cdot \left [ \begin{array}\\\lambda_{1}&amp;&amp;&amp;\\&amp;\lambda_{2}&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_{n}\\ \end{array} \right ]\\<br/>
&amp;= \left [ \begin{array}\\\frac{\lambda_1}{\lambda_{1}+\alpha}&amp;&amp;&amp;\\&amp;\frac{\lambda_2}{\lambda_{2}+\alpha}&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\frac{\lambda_n}{\lambda_{n}+\alpha}\\\end{array}\right]<br/>
\end{align*}<br/>
\]</p>

<p>我们可以看到权重衰减的效果是沿着由 \(H\) 的特征向量所定义的轴缩放 \(w^*\)。也就是说，我们会根据 \(\frac{\lambda_i}{\lambda_i + \alpha}\) 因子缩放与 \(H\) 的第 \(i\) 个特征向量对齐的 \(w^*\) 的分量。沿着 \(H\) 特征值较大的方向，\(\lambda_i \gg \alpha\) 时，正则化的影响较小。而 \(\lambda_i \ll \alpha\) 时，此时分量将收缩到几乎为零。</p>

<p>我们借助一张图来看看 \(L^2\) 正则化的效果。</p>

<div align="center">
    <img width="350" src="media/15272663505619/15380583249307.jpg" />
</div>

<p>坐标轴右上方是原始目标函数 \(J(w)\) 的等高线，中心 \(w^∗\) 是没有正则化的原始最优解。图中虚线的同心圆是L2正则化项的等高线。在 \(\widetilde w\) 点，这两个竞争目标达到平衡。目标函数 J 的 Hessian 的 第一维特征值很小，当 \(w^∗\) 沿水平方向移动时，目标函数值不会增加的太多，因为目标函数对这个方向没 有强烈的偏好，所以正则化项对该轴具有强烈的影响，正则化项将 \(w_1\) 拉向零；当 \(w^∗\) 沿竖直方向移动时，目标函数值变化比较剧烈，对应于特征值大的方向，表示高区率。然后对比图中 \(\widetilde w\) 和 \(w^∗\) 的位置，发现 \(\widetilde w\) 在水平方向上移动距离比较大，竖直方向上比较小，这也印证了之前权重衰减的规律。 </p>

<blockquote>
<ol>
<li>Hessian矩阵中，在最大特征值所对应的特征向量的方向上有二阶导数的最大值，事实上，在每一个特征向量方向上，二阶导数都等于相应的特征值。在其他方向上，二阶导数是特征值的加权平均。特征值是相应特征向量方向上的二阶导数。</li>
<li>等高线的疏密与地势的坡度有关。等高线越密集,代表该地区的坡度越陡；等高线越稀疏,说明地势坡度越小越平坦。</li>
<li>假设有一大一小两个特征值，较小曲率（二阶导数）落在小特征值对应的特征向量方向上，这里较平坦；较大曲率（二阶导数）落在大特征值对应的特征向量方向上，这里陡峭；所以说，特征向量被称为函数等高线的主轴。</li>
</ol>

<p>综上：Hessian矩阵的特征值控制了梯度更新步长，对于二维图像的某点的Hessian矩阵，其最大特征值和对应的特征向量对应其邻域二维曲线最大曲率的强度和方向，即山坡陡的那面，最小特征值对应的特征向量对应与其垂直的方向，即平缓的方向。简单来讲，图像某点的 Hessian 矩阵特征值大小和符号决定了该点邻域内的几何结构。三维图像同理。</p>
</blockquote>

<p>如果我们在线性回归的基础上研究权重衰减对二次代价函数的影响。线性回归的代价函数是平方误差之和<br/>
\[<br/>
(Xw - y)^T(Xw - y)<br/>
\]</p>

<p>我们添加 \(L^2\) 正则化项后，目标函数变为<br/>
\[<br/>
(Xw - y)^T(Xw - y) + \frac 1 2 \alpha w^T w<br/>
\]</p>

<p>这将普通方程的解（求导并令结果等于0）从<br/>
\[<br/>
\begin{align}<br/>
w = (X^TX)^{-1} X^T y\label{wx1}\\<br/>
\end{align}<br/>
\]</p>

<p>变为<br/>
\[<br/>
\begin{align}<br/>
w = (X^TX + \alpha I)^{-1} X^T y\label{wx2}<br/>
\end{align}<br/>
\]</p>

<p>式 ( \ref{wx1} ) 中的矩阵 \(X^TX\) 与协方差矩阵 \(\frac 1 m X^TX\) 成正比。\(L^2\) 正则后仅仅是在对角加了 \(\alpha\)。这个矩阵的对角项对应每个输入特征的方差（协方差的定义）。可以看到，\(L^2\) 正则化能让学习算法感知到具有较高方差的输入 \(x\)，因此与输出目标的协方差较小（相对增加方差）的特征的权重将会收缩。</p>

<h4 id="toc_2">\(L^1\)正则化</h4>

<p>\(L^2\)权重衰减是权重衰减最常见的形式，我们还可以使用其他的方法限制模型参数的规模。一个选择是使用\(L^1\)正则化。 形式地，对模型参数 \(w\) 的\(L^1\)正则化被定义为:<br/>
\[<br/>
\Omega(\theta) = ||w||_1 = \sum_{i} |w_i|<br/>
\]</p>

<p>即各个参数的绝对值之和。接着我们将讨论\(L^1\)正则化对简单线性回归模型的影响，与分析\(L^2\)正则化时一样不考虑偏置参数。我们尤其感兴趣的是找出\(L^1\)和\(L^2\)正则化之间的差异。与\(L^2\)权重衰减类似，我们也可以通过缩放惩罚项 \(\Omega\) 的正超参数 \(\alpha\) 来控制\(L^1\)权重衰减的强度。因此，正则化的目标函数 \(\widetilde J\) 如下所示<br/>
\[<br/>
\begin{align}<br/>
\widetilde J = J + \alpha ||w||_1\label{wjj}<br/>
\end{align}<br/>
\]</p>

<p>我们常说 \(L^1\) 正则化的优良性质是能产生稀疏性，导致 \(\mathbf w\) 中许多项变成零。这里我们先直观的看一下 \(L^1\) 的图像（下右图）：</p>

<div align="center">
    <img width="550" src="media/15272663505619/15380584017290.jpg" />
</div>

<p>可以看到，\(L^1\) 与 \(L^2\) 的不同就在于他在和每个坐标轴相交的地方都有“角”出现，而目标函数的测地线除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置为产生稀疏性，例如图中的相交点就有 \(w_1 = 0\)，而更高维的时候除了角点以外，还有很多边的轮廓也是既有很大的概率成为第一次相交的地方，又会产生稀疏性。</p>

<p>相比之下，\(L^2\) 就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小了。这就从直观上来解释了为什么  \(L^1\) 正则化能产生稀疏性，而  \(L^2\) 正则化不行的原因了。</p>

<p>正则化后的目标函数 ( \ref{wjj} )对应的梯度 (实际上是次梯度):<br/>
\[<br/>
\nabla_w \hat J = \nabla_w J + \alpha \text{ sign}(w)<br/>
\]</p>

<p>其中 \(\text{sign}(w)\) 只是简单地取 \(w\) 各个元素的正负号。</p>

<p>由于 \(L^1\) 惩罚项在完全一般化的 Hessian 的情况下，无法得到直接清晰的代数表达式，因此我们将进一步简化假设 Hessian 是对角的，即 \(H = diag([H_{1,1},..., H_{n,n}])\)， 其中每个 \(H_{i,i} &gt; 0\)。如果线性回归问题中的数据已被预处理(如可以使用 PCA)，去 除了输入特征之间的相关性，那么这一假设成立。</p>

<p>我们可以将 \(L^1\) 正则化目标函数的二次近似分解成关于参数的求和（一阶导数为0）:<br/>
\[<br/>
\begin{align}<br/>
J(w) &amp;= J(w^*) + \frac 1 2 (w-w^*)^T H(w-w^*) + \alpha ||w||\nonumber\\<br/>
&amp;= J(w^*) + \frac 1 2 [w_1-w^*_1,w_2 - w^*_2 ,...,w_n-w^*_n]H\left[\begin{array}{c}w_1-w^*_1\\w_2 - w^*_2 \\\vdots\\w_n-w^*_n\\\end{array}\right ]+ \alpha ||w||\nonumber\\<br/>
&amp;= J(w^*) + \frac 1 2 \left [ \begin{array}{cccc}(w_1-w^*_1)H_{1,1}&amp;&amp;&amp;\\&amp;(w_2-w^*_2)H_{2,2}&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;(w_n-w^*_n)H_{n,n}\end{array}\right ]\left[\begin{array}\\w_1-w^*_1\\w_2 - w^*_2 \\\vdots\\w_n-w^*_n\\\end{array}\right ]+ \alpha ||w||\nonumber\\<br/>
&amp;= J(w^*) + \frac 1 2 \Big(\sum_{i=1}^n H_{i,i}(w_i - w^*_i)^2\Big)+ \alpha ||w||\nonumber\\<br/>
&amp;= J(w^*) + \frac 1 2 \sum_{i=1}^n \Big(H_{i,i}(w_i - w^*_i)^2+ \alpha |w_i|\Big)\label{jfs}\\<br/>
\end{align}<br/>
\]</p>

<p>对二次近似的 ( \ref{jfs} ) 式求导，并结果为 0 来求解 \(w_i\)<br/>
\[<br/>
\begin{align}<br/>
&amp;\frac{\partial}{\partial w_i} J(w^*) + \frac 1 2 \sum_{i=1}^n \Big(H_{i,i}(w_i - w^*_i)^2+ \alpha |w_i|\Big) = H_{i,i}(w_i - w^*_i) + \text{sign}(w_i) \alpha\label{fpp}\\<br/>
\end{align}<br/>
\]</p>

<ol>
<li><p>当 \(w_i \gt 0\) 时<br/>
\[<br/>
H_{i,i}(w_i - w^*_i) + \alpha = 0\quad \Rightarrow w_i - w^*_i =- \frac{\alpha}{H_{i,i}} <br/>
\]</p>

<p>因为 \(\alpha \gt 0\) 和 \(H_{i,i} \gt 0\) 所以 \(w_i - w^*_i =- \frac{\alpha}{H_{i,i}} \lt 0\)，得出 \(w^*_i \gt w_i \gt 0\)</p>

<p>结合 \(w_i = w^* - \frac{\alpha}{H_{i,i}} \) 和 \(w_i \gt 0\) 可得 \(w_i = \max\big(w^*_i - \frac{\alpha}{H_{i,i}},0\big)\)</p></li>
<li><p>当 \(w_i \lt 0\) 时<br/>
\[<br/>
\begin{equation}<br/>
H_{i,i}(w_i - w^*_i) - \alpha = 0 \quad \Rightarrow w_i - w^*_i = \frac{\alpha}{H_{i,i}}\label{hiww}<br/>
\end{equation} <br/>
\]</p>

<p>因为 \(\alpha \gt 0\) 和 \(H_{i,i} \gt 0\) 所以 \(w_i - w^*_i =\frac{\alpha}{H_{i,i}} \gt 0\)，得出 \(w^*_i \lt w_i \lt 0\)</p>

<p>等式 ( \ref{hiww} ) 可以写成<br/>
\[<br/>
-w_i = -w^*_i - \frac{\alpha}{H_{i,i}}<br/>
\]</p>

<p>因为 \(-w_i \gt 0\)，所以 \(-w_i = \max\big(-w^*_i - \frac{\alpha}{H_{i,i}},0\big)\)，也就是 \(w_i = -\max\big(-w^*_i - \frac{\alpha}{H_{i,i}},0\big) \)</p></li>
</ol>

<p>结合上面两项<br/>
\[<br/>
w_i = \left \{ \begin{array} -\max\big(-w^*_i - \frac{\alpha}{H_{i,i}},0\big)&amp;\quad w^*_i \gt w_i \gt 0\\ -\max\big(-w^*_i - \frac{\alpha}{H_{i,i}},0\big)&amp;\quad w^*_i \lt w_i \lt 0\\\end{array}\right .<br/>
\]</p>

<p>可以写成一个式子<br/>
\[<br/>
w_i = \text{sign}(w^*_i)\max\big(||w^*_i|| - \frac{\alpha}{H_{i,i}},0\big)<br/>
\]</p>

<p>对每个 \(i\) , 考虑 \(w^∗_i &gt; 0\) 的情形，会有两种可能结果：</p>

<ol>
<li>\(w^*_i \le \frac{\alpha}{H_{i,i}}\) 的情况。正则化后目标中的 \(w_i\) 最优值是 \(w_i = 0\)。这是因为在方向 \(i\) 上的 \(J(w)\) 对 \(\hat J(w)\) 的贡献被抵消，\(L^1\) 正则化项将 \(w_i\) 推至 0。</li>
<li>\(w^∗_i \gt \frac{\alpha}{H_{i,i}}\) 的情况。在这种情况下，正则化不会将 \(w_i\) 的最优值推至 0，而仅仅在那个方向上移动 \(\frac{\alpha}{H_{i,i}}\) 的距离。</li>
</ol>

<p>\(w^*_i \lt 0\) 的情况与之类似，但是 \(L^1\) 正则化项使 \(w_i\) 更接近 0（或增加 \(\frac{\alpha}{H_{i,i}}\)）或等于0。</p>

<p>可以用下图形象表示出来</p>

<div align="center">
    <img width="300" src="media/15272663505619/15380681849481.jpg" />
</div>

<h4 id="toc_3">\(L^1\) 与 \(L^2\) 优点</h4>

<p>相比 \(L^2\) 正则化，\(L^1\) 正则化会产生更稀疏(sparse)的解。此处稀疏性指的是最优值中的一些参数为 0。和 \(L^2\)正则化相比，\(L^1\)正则化的稀疏性具有本质的不同，在 \(L^2\) 中 是对参数做了缩小 \(\widetilde w_i = \frac{H_{i,i}}{H_{i,i}+\alpha} w^*_i\) ，如果 \(w^*_i\) 不是 0，那么 \(\widetilde w_i\) 也会保持非 0，只是更接近0。</p>

<p>由 \(L^1\) 正则化导出的稀疏性质已经被广泛地用于特征选择(feature selection)机制。特征选择从可用的特征子集选择出有意义的特征，化简机器学习问题。著名的 LASSO (Tibshirani, 1995)(Least Absolute Shrinkage and Selection Operator)模型将 \(L^1\) 惩罚和线性模型结合，并使用最小二乘代价函数。\(L^1\) 惩罚使部分子集的权重为零，表明相应的特征可以被安全地忽略。</p>

<p>再来看看 \(L^2\) 正则化，首先 \(L^2\) 正则化可以解决过拟合问题，这是因为 \(L^2\) 正则化趋向于选择更小的参数，而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。越复杂的模型，越是会尝试对所有的样本进行拟合，甚至包括一些异常样本点，这就容易造成在较小的区间里预测值产生较大的波动，这种较大的波动也反映了在这个区间里的导数很大，而只有较大的参数值才能产生较大的导数。因此复杂的模型，其参数值会比较大。</p>

<p>另外，\(L^2\) 正则化之前，我们知道可以通过下式求出权重<br/>
\[<br/>
W = (X^TX)^{-1}X^Ty<br/>
\]</p>

<p>然而，如果当我们的样本 \(X\) 的数目比每个样本的维度还要小的时候，矩阵 \(X^TX\) 将会不是满秩的，也就是 \(X^TX\) 会变得不可逆，所以 \(W\) 就没办法直接计算出来了，或者更确切地说，将会有无穷多个解（因为我们方程组的个数小于未知数的个数），也就是说，我们的数据不足以确定一个解。</p>

<p>但如果加上L2规则项，就变成了下面这种情况，就可以直接求逆了：<br/>
\[<br/>
W = (X^TX + \alpha I)^{-1}X^Ty<br/>
\]</p>

<p>这里面，要得到这个解，我们通常并不直接求矩阵的逆，而是通过解线性方程组的方式（例如高斯消元法）来计算。考虑没有规则项的时候，也就是 \(\lambda=0\) 的情况，如果矩阵 \(X^TX\) 的 condition number 很大的话，解线性方程组就会在数值上相当不稳定，而这个规则项的引入则可以改善 condition number。</p>

<p>另外，如果使用迭代优化的算法，condition number 太大仍然会导致问题：它会拖慢迭代的收敛速度，而规则项从优化的角度来看，实际上是将目标函数变成 \(\lambda\)-strongly convex（\(\lambda\)强凸）的了。</p>

<div align="center">
    <img width="450" src="media/15272663505619/15380731126993.jpg" />
</div>

<p>如图说一个函数是凸函数，指函数曲线位于改点处的切线之上，而强凸则进一步要求位于该处的一个二次函数之上，也就是说要求函数不要太“平坦”而是可以保证有一定的 “向上弯曲” 的趋势。如果我们有“强凸”的话，我们就可以得到一个更好的近似解。效果的好坏取决于 strongly convex性质中的常数 \(\lambda\) 的大小。</p>

<p>所以，如果我们想要获得 \(\lambda\)强凸的话，就是往目标函数里面加上 \(\frac{\alpha}{2}||w||^2\)。</p>

<p>如果我们的函数 \(f(w)\) 如右图红色那个函数，我们取我们的最优解 \(w^*\) 的地方都会位于蓝色虚线的那根二次函数之上，这样就算 \(w_t\) 和 \(w^*\) 离的比较近的时候，\(f(w_t)\) 和 \(f(w^*)\) 的值差别还是挺大的，也就是会保证在我们的最优解 \(w^*\) 附近的时候，还存在较大的梯度值，这样我们才可以在比较少的迭代次数内达到 \(w^*\) 。但对于左图，红色的函数 \(f(w)\) 只约束在一个线性的蓝色虚线之上，假设是如左图的很不幸的情况（非常平坦），那在 \(w_t\) 还离我们的最优点 \(w^*\) 很远的时候，我们的近似梯度 \((f(wt)-f(w*))/(wt-w*)\) 就已经非常小了，在 \(w_t\) 处的近似梯度\(\frac{\partial f}{\partial w}\) 就更小了，这样通过梯度下降得到的结果就是 \(w\) 的变化非常缓慢，非常缓慢的向我们的最优点 \(w^*\) 爬动，那在有限的迭代时间内，它离我们的最优点还是很远。我们有可能会找到一个很远的点。但如果我们有“强凸”的话，就能对情况做一些控制，我们就可以得到一个更好的近似解。</p>

<h3 id="toc_4">数据增强</h3>

<p>理论上来说，数据越多，模型训练得越充分，模型泛化能力越强。但是现实情况是，数据量总是有限的，解决此问题的一个方法是生成一部分的模拟数据。对于一些机器学习任务，创建新的假数据相当简单。</p>

<p>对分类来说这种方法是最简单的。分类器需要一个复杂的高维输入 x，并用单 个类别标识 y 概括 x。这意味着分类面临的一个主要任务是要对各种各样的变换保 持不变。我们可以轻易通过转换训练集中的 x 来生成新的 (x, y) 对。经典的方法有SMOTE方法。</p>

<p>这种方法对于其他许多任务来说并不那么容易。例如，除非我们已经解决了密 度估计问题，否则在密度估计任务中生成新的假数据是很困难的。</p>

<p><strong>图像识别</strong>：图像是高维的并包括各种巨大的变化因素，其中有许多可以轻易地模拟。即使模型已使用卷积和池化技术对部分平移保持不变，沿训练图像每个方向<strong>平移</strong>几个像素的操作通常可以大大改善泛化。许多其他操作如<strong>旋转图像</strong>或<strong>缩放图像</strong>也已被证明非常有效。数据增强用于特定领域分类问题，如图像识别很有效。但是切记，转换数据的时候不要改变图像的正确分类。比如不要将手写字识别图像中的6垂直转换成了9，b 水平翻转成了d。所以对这些任务来说，水平翻转和旋转 180 度并不是合适的数据集增强方式。</p>

<p><strong>语音识别</strong>：语音识别问题中，网络输入数据中也会注入一些随机噪音干扰，这也是一种数据增强（现实生活中语音环境有噪音）。</p>

<p>在神经网络的输入层注入噪声 (Sietsma and Dow, 1991) 也可以被看作是数据增强的一种方式。对于许多分类甚至一些回归任务而言，即使小的随机噪声被加到输入，任务仍应该是能够被解决的。然而，神经网络被证明对噪声不是非常健壮 (Tang and Eliasmith, 2010)。改善神经网络健壮性的方法之一是简单地将随机噪声添加到输入再进行训练。输入噪声注入是一些无监督学习算法的一部分，如去噪自编码器(Vincent et al., 2008a)。向隐藏单元施加噪声也是可行的，这可以被看作在多个抽象层上进行的数据集增强。Poole et al. (2014) 最近表明，噪声的幅度被细心调整后，该方法是非常高效的。正则化策略 Dropout 可以被看作是通过与噪声相乘构建新输入的过程。</p>

<p>在比较机器学习基准测试的结果时，考虑其采取的数据集增强是很重要的。通常情况下，人工设计的数据集增强方案可以大大减少机器学习技术的泛化误差。将一个机器学习算法的性能与另一个进行对比时，对照实验是必要的。在比较机器学习算法 A 和机器学习算法 B 时，应该确保这两个算法使用同一人工设计的数据集增强方案。假设算法 A 在没有数据集增强时表现不佳，而 B 结合大量人工转换的数据后表现良好。在这样的情况下，很可能是合成转化引起了性能改进，而不是机器学习算法 B 比算法 A 更好。有时候，确定实验是否已经适当控制需要主观判断。例如，向输入注入噪声的机器学习算法是执行数据集增强的一种形式。通常，普适操作(例如，向输入添加高斯噪声)被认为是机器学习算法的一部分，而特定于一个应用领域(如随机地裁剪图像)的操作被认为是独立的<strong>预处理</strong>步骤。</p>

<h3 id="toc_5">噪声鲁棒性</h3>

<p>上面我们说过想神经网络的输入层注入噪声可以作为数据增强，对于某些模型而言，想输入添加方差极小的噪声等价于对权重事假范数惩罚。在一般情况下，注入噪声远比简单地收缩参数强大，特别是噪声被添加到隐藏单元时会更加强大。向隐藏单元添加噪声是值得讨论的话题，后面所述 Dropout 算法是这种做法的主要发展方向。</p>

<p>另一种正则化模型的噪声使用方式是将其加到权重。这项技术主要用于循环神经网络（Jim et al., 1996; Graves, 2011）。在某些假设下，施加于权重的噪音可以被解释为与更传统的正则化形式等同，鼓励要学习的函数保持稳定。在回归的情形下，训练将一组特征 \(\mathbf x\) 映射成一个标量的函数 \(\hat y(x)\)，并使用最小二乘代价函数衡量模型预测值 \(\hat y(x)\) 与真实值 \(y\) 的误差<br/>
\[<br/>
J = \mathbb E_{p(x,y)}[\hat y(\mathbb x) - y)^2]<br/>
\]</p>

<p>训练集包含 \(m\) 对标注样例 \(\{(\mathbf x^{(1)},y^{(1)}),...,(\mathbf x^{(m)},y^{(m)})\}\)。</p>

<p>现在我们假设对每个输入表示，网络权重添加随机扰动 \(\epsilon_w\sim \mathcal N(\epsilon;9,\eta I)\)。想象一下我们有个一个标准的 \(l\) 层 MLP。我们将扰动模型记为 \(\hat y_{\epsilon w}(x)\)。尽管有噪声注入，我们仍然希望减少网络输出误差的平方。因此目标函数变为：<br/>
\[<br/>
\begin{align*}<br/>
\widetilde J_{\mathbf w} &amp;= \mathbb E_{p(x,y,\epsilon \mathbf w)}[(\hat y_{\epsilon \mathbf w}(x) - y)^2]\\<br/>
&amp;= \mathbb E_{p(x,y,\epsilon \mathbf w)}[\hat y^2_{\epsilon \mathbf w}(x) - 2y\hat y_{\epsilon \mathbf w}(x) + y^2]\\<br/>
\end{align*}<br/>
\]</p>

<p>对于小的 \(\eta\)，最小化带权重噪声（方差为 \(\eta I\)）的 \(J\) 等同于最小化附加正则化项: \(\eta \mathbb E_{p(x,y)}[||\nabla_{\mathbf W} \hat y(x)||^2]\) 的 \(J\)。这种形式的正则化鼓励参数进入权重小扰动对输出相对影响较小的参数空间区域。换句话说，它推动模型进入对权重小的变化相对不敏感的区域，找到的点不只是极小点，还是由平坦区域所包围的极小点 (Hochreiter and Schmidhuber, 1995)。在简化的线性回归中（例如，\(\hat y(x) = w^T x + b）\)，正则项退化为 \(\eta \mathbb E_{p(x)}[||x||^2]\)，这与函数的参数无关，因此不会对 \(\widetilde J_w\) 关于模型参数的梯度有影响。 </p>

<h4 id="toc_6">向输出目标注入噪声</h4>

<p>大多数数据集的 \(y\) 标签都有一定错误。错误的 \(y\) 不利于最大化 \(\log p(y | \mathbf x)\)。避免这种情况的一种方法是显式地对标签上的噪声进行建模。例如，我们可以假设，对于一些小常数 \(\epsilon\)，训练集标记 \(y\) 是正确的概率是 \(1 − \epsilon\)，(以 \(\epsilon\) 的概率)任何其他可能的标签也可能是正确的。这个假设很容易就能解析地与代价函数结合，而不用显式地抽取噪声样本。例如，<strong>标签平滑</strong>(label smoothing)通过把确切分类目标从 0 和 1 替换成 \(\epsilon\) 和 \(1 − \epsilon\)，正则化具有 \(k\) 个输出的 softmax 函数 的模型。标准交叉熵 \(k−1\) 损失可以用在这些非确切目标的输出上。使用 softmax 函数和明确目标的最大似然学习可能永远不会收敛——softmax 函数永远无法真正预测 0 概率或 1 概率，因此它会继续学习越来越大的权重，使预测更极端。使用如权重衰减等其他正则化策略能够防止这种情况。标签平滑的优势是能够防止模型追求确切概率而不影响模型学习正确分类。这种策略自 20 世纪 80 年代就已经被使用，并在现代神经网络继续保持显著特色 (Szegedy et al., 2015)。</p>

<h3 id="toc_7">提前终止</h3>

<p>当训练有足够的表示能力甚至会过拟合的大模型时，我们经常观察到，训练误差会随着时间的推移逐渐降低但验证集的误差会再次上升。</p>

<p>这意味着我们只要返回使验证集误差最低的参数设置，就可以获得验证集误差更低的模型(并且因此有希望获得更好的测试误差)。在每次验证集误差有所改善后，我们存储模型参数的副本。当训练算法终止时，我们返回这些参数而不是最新的参数。当验证集上的误差在事先指定的循环次数内没有进一步改善时，算法就会终止。</p>

<p>这种策略被称为<strong>提前终止（early stopping）</strong>。这可能是深度学习中最常用的正则化形式。它的流行主要是因为有效性和简单性。</p>

<div align="center">
    <img width="550" src="media/15272663505619/15472738666106.jpg" />
</div>

<p>我们可以认为提前终止是非常高效的超参数选择算法。按照这种观点，训练步数仅是另一个超参数。这个超参数在验证集上具有 U 型性能曲线。很多控制模型容量的超参数在验证集都是这样的 U 型性能曲线，在提前终止的情况下，我们通过控制拟合训练集的步数来控制模型的有效容量。大多数超参数的选择必须使用高代价的猜测和检查过程，我们需要再训练开始时超参数的选择必须使用高代价的猜测和检查过程，我们需要再训练开始时猜测一个超参数，然后运行几个步骤检查它的训练效果。“训练时间”是唯一只要跑一次训练就能尝试很多值得超参数。通过提前终止自动选择超参数的唯一显著代价是训练期间要定期评估验证集。在理想情况下，这可以并行在与主训练过程分离的机器上，或独立的CPU，或独立的 GPU 上完成。如果没有这些额外的资源，可以使用比训练集小的验证集或较不频繁地评估验证集来减小评估代价，较粗略地估算取得最佳的训练时间。</p>

<p>另一个提前终止的额外代价是需要保持最佳的参数副本。这种代价一般是可忽略的，因为可以将它储存在较慢较大的存储器上(例如，在 GPU 内存中训练，但将最佳参数存储在主存储器或磁盘驱动器上)。由于最佳参数的写入很少发生而且从不在训练过程中读取，这些偶发的慢写入对总训练时间的影响不大。</p>

<p>提前终止是一个非常不显眼的正则化形式，它几乎不需要改变基本训练过程、目标函数或一组允许的参数值。这意味着，无需破坏学习动态就能很容易地使用提前终止。相对于权重衰减，必须小心不能使用太多的权重衰减，以防网络陷入不良局部极小点（对应于病态的小权重）。</p>

<p>提前终止可单独使用或与其他正则化策略结合使用。即使为鼓励更好泛化，使用正则化策略改进目标函数，在训练目标的局部极小点达到最好泛化也是罕见的。</p>

<p>提前终止需要验证集，这意味着某些训练数据不能被馈送到模型。为了更好地利用这一额外的数据，我们可以在完成提前终止的首次训练之后，进行额外的训练。在第二轮，即额外的训练步骤中，所有的训练数据都被包括在内。有两个基本的策略都可以用于第二轮训练过程。</p>

<p>一个策略是再次初始化模型，然后使用所有数据再次训练。在这个第二轮训练过程中，我们使用第一轮提前终止训练确定的最佳步数。此过程有一些细微之处。例如，我们没有办法知道重新训练时，对参数进行相同次数的更新和对数据集进行相同次数的遍历哪一个更好。由于训练集变大了，在第二轮训练时，每一次遍历数据集将会更多次地更新参数。</p>

<div align="center">
    <img width="550" src="media/15272663505619/15472789633704.jpg" />
</div>

<p>另一个策略是保持从第一轮训练获得的参数，然后使用全部的数据继续训练。在这个阶段，已经没有验证集指导我们需要在训练多少步后终止。取而代之，我们 可以监控验证集的平均损失函数，并继续训练，直到它低于提前终止过程终止时的目标值。此策略避免了重新训练模型的高成本，但表现并没有那么好。例如，验证集的目标不一定能达到之前的目标值，所以这种策略甚至不能保证终止。</p>

<div align="center">
    <img width="550" src="media/15272663505619/15472790713118.jpg" />
</div>

<hr/>

<p><a href="">deep learn</a><br/>
<a href="https://www.jianshu.com/p/36312582478f">神经网络性能曲面与最优点</a><br/>
<a href="https://blog.csdn.net/zouxy09/article/details/24971995">机器学习中的范数规则化之（一）L0、L1与L2范数</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15264839728559.html">神经网络的代价函数</a></h1>
			<p class="meta"><time datetime="2018-05-16T23:19:32+08:00" 
			pubdate data-updated="true">2018/5/16</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>代价函数是衡量模型预测输出值与目标真实值之间差距的一类函数，在一些场景中也称为目标函数。我们常用的代价函数是二次代价函数、交叉熵代价函数和对数似然函数。</p>

<h4 id="toc_0">二次代价函数</h4>

<p>考虑 \(n\) 个样本的输入 \(x_1,x_2,...,x_n\)，对应的真实值为 \(y_1,y_2,...,y_n\)，对应的输出为 \(o(x_i)\)，则二次代价函数可定义为： <br/>
\[<br/>
C = \frac{1}{2n} \sum_{i=1}^n ||y_i−o(x_i)||^2<br/>
\]</p>

<p>其中，\(C\) 表示代价函数，\(n\) 表示样本总数。</p>

<ul>
<li>以一个样本为例</li>
</ul>

<p>假设在神经网络中，上一层每个神经元的输出为 \(a_j\)，权值为 \(w_j\)，偏置值为 \(b\) 。当前输出神经元的激活函数为 \(\sigma(\cdot)\)。则该神经元的输出值为：<br/>
\[<br/>
\text{net} = \sum_j w_j a_j + b\\<br/>
o = \sigma(\text{net})\\<br/>
\]</p>

<p>此时二次代价函数为： <br/>
\[<br/>
C = \frac{1}{2} (y−o)^2<br/>
\]</p>

<p>其中，\(y\) 为真实值。</p>

<ul>
<li>考虑权值和偏置值更新</li>
</ul>

<p>假如使用梯度下降法(Gradient descent)来调整权值和偏置值大小，则对 \(w\) 和 \(b\) 求偏导得： <br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial w_j} &amp;= \frac{\partial C}{\partial o}\frac{\partial o}{\partial \text{net}}\frac{\partial \text{net}}{\partial w_j}\\<br/>
&amp;= (o-y)\cdot a_j \cdot \frac{\partial o}{\partial \text{net}}\\<br/>
&amp;= a_j(\sigma(\text{net}) - y) \sigma&#39;(\text{net})\\<br/>
\frac{\partial C}{\partial b} &amp;= (\sigma(\text{net}) - y) \sigma&#39;(\text{net})\\<br/>
\end{align*}<br/>
\]</p>

<p>该偏导数乘以学习率 \(\eta\) 就变成了每次调整权值和偏置值得步长。当 \(\eta\) 一定时，可以看出 \(w\) 和 \(b\) 的梯度跟激活函数的梯度成正比，激活函数的梯度（导数）越大，则 \(w\) 和 \(b\) 调整得就越快，训练收敛得就越快。</p>

<ul>
<li>结合激活函数</li>
</ul>

<p>假设神经网络使用的是sigmoid激活函数<br/>
\[<br/>
\sigma(x) = \frac{1}{1+e^{-x}}<br/>
\]</p>

<p>图像如下</p>

<div align="center">
    <img width=400 src="media/15264839728559/15369428123803.jpg" />
</div>

<p>考虑A点和B点，权值调整大小与sigmoid函数的梯度（导数）有关。<br/>
1）当真实值 \(y=1\) 时，则输出值目标是收敛至1。A离目标比较远，权值调整大；B离目标比较近，权值调整小。调整方案合理。<br/>
2）当真实值 \(y=0\) 时，则输出值目标是收敛至0。A离目标比较近，权值调整大；B离目标比较远，权值调整小。调整方案不合理。换句话说，很难调整到目标值0。</p>

<p>从图可以观察的出，学习在神经元犯了明显的错误的时候却比学习快接近真实值的时候缓慢。这是因为在\(\sigma(\cdot)\) 的值等于1或0的时候 \(\sigma&#39;(\cdot)\) 的值会很小很小。从而也就导致了\(\frac{\partial C}{\partial w}\) 和 \(\frac{\partial C}{\partial b}\) 会非常小。这也就是学习缓慢的原因所在。</p>

<h4 id="toc_1">交叉熵代价函数</h4>

<p>考虑 \(n\) 个样本的输入 \(x_1,x_2,...,x_n\)，对应的真实值为 \(y_1,y_2,...,y_n\)，对应的输出为 \(o_i\)，则交叉熵代价函数可定义为： <br/>
\[<br/>
C = -\frac 1 n \sum_{i=1}^n [y_i \ln o_i + (1 -y_i)\ln(1-o_i)]\\<br/>
\]</p>

<p>其中，\(C\) 表示代价函数，\(n\) 表示样本总数。</p>

<ul>
<li>以一个样本为例</li>
</ul>

<p>假设在神经网络中，上一层每个神经元的输出为 \(a_j\)，权值为 \(w_j\)，偏置值为 \(b\) 。当前输出神经元的激活函数为 \(\sigma(\cdot)\)。则该神经元的输出值为：<br/>
\[<br/>
\text{net} = \sum_j w_j a_j + b<br/>
o = \sigma(\text{net})<br/>
\]</p>

<p>此时考虑 \(n\) 个神经元，交叉熵代价函数为： <br/>
\[<br/>
C = -\frac 1 n \sum_{i=1}^n [y_i \ln o_i + (1 -y_i)\ln(1-o_i)]\\<br/>
\]</p>

<p>其中，\(y_i\) 为真实值。</p>

<ul>
<li>考虑权值和偏置值更新</li>
</ul>

<p>假设神经网络使用的是sigmoid激活函数，我们知道 \(\sigma(x)\) 对 \(x\) 求导得<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \sigma(x)}{\partial x} &amp;= \frac{e^{-x}}{(1 + e^{-x})^2} \\<br/>
&amp;= \frac{1 + e^{-x} - 1}{(1 + e^{-x})^2} \\<br/>
&amp;= \frac{1}{1 + e^{-x}} - \frac{1}{(1 + e^{-x})^2}\\<br/>
&amp;= \sigma(x) - \sigma(x)^2 \\<br/>
&amp;= \sigma(x)[1 - \sigma(x)]\\<br/>
\end{align*}<br/>
\]</p>

<p>假如使用梯度下降法(Gradient descent)来调整权值和偏置值大小，则对 \(w\) 和 \(b\) 求偏导得： <br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial w_j} &amp;= -\frac 1 n \sum_{i=1}^n \frac{\partial C}{\partial o_j}\frac{\partial o_j}{\partial net_j}\frac{\partial net_j}{\partial w_j}\\<br/>
&amp;= -\frac 1 n \sum_{i=1}^n \Big(\frac{y_j}{o_j} - \frac{1-y_j}{1-o_j} \Big)\cdot \Big( \sigma(\text{net_j})(1 - \sigma(\text{net_j}))  \Big)\cdot a_j\\<br/>
&amp;= -\frac 1 n \sum_{i=1}^n \frac{y_j(1 - o_j) - o_j(1-y_j)}{o_j(1- o_j)}\cdot \Big( \sigma(\text{net_j})(1 - \sigma(\text{net_j}))  \Big)\cdot a_j\\<br/>
&amp;= -\frac 1 n \sum_{i=1}^n \frac{y_j- o_j}{o_j(1- o_j)}\cdot \Big( \sigma(\text{net_j})(1 - \sigma(\text{net_j}))  \Big)\cdot a_j\\<br/>
&amp;= -\frac 1 n \sum_{i=1}^n \frac{y_j- o_j}{\sigma(\text{net_j})(1- \sigma(\text{net_j}))}\cdot \Big( \sigma(\text{net_j})(1 - \sigma(\text{net_j}))  \Big)\cdot a_j\\<br/>
&amp;= \frac 1 n \sum_{i=1}^n (o_j - y_j) a_j<br/>
\end{align*}<br/>
\]</p>

<p>同理，偏置值 \(b\) 的梯度(更新步长)为：<br/>
\[<br/>
\frac{\partial C}{\partial b} = \frac 1 n \sum_{i=1}^n (o_j − y_j)<br/>
\]</p>

<p>可以看出，权值和偏置值的调整与 \(\sigma&#39;(\)\text{net}_j)\( 无关，而与 \)\sigma(\text{net}_j)\( 有关。此外，\)o_j - y_j\( 表示真实值与输出值之间的误差。当误差越大时，梯度就越大，\)w\( 和 \)b$ 的调整就越快，训练速度就越快。</p>

<p>对比二次代价函数可以发现，代价函数的选择与激活函数有关。当输出神经元的激活函数是线性时例如，ReLU函数）二次代价函数是一种合适的选择；当输出神经元的激活函数是S型函数（例如sigmoid、tanh函数）时，选择交叉熵代价函数则比较合理。</p>

<h4 id="toc_2">对数似然代价函数</h4>

<p>考虑 \(n\) 个样本的输入 \(x_1,x_2,...,x_n\)，对应的真实值为 \(y_1,y_2,...,y_n\) 取值为0或1，对应的第i个神经元输出为 \(o_i\)，则对数log似然代价函数可定义为：<br/>
\[<br/>
C=-\sum_{i=1}^n y_i \log o_i<br/>
\]</p>

<p>其中，\(C\) 表示代价函数，\(n\) 表示样本总数。</p>

<ul>
<li>考虑softmax激活函数</li>
</ul>

<p>在深度学习中，对数似然函数常用来搭配softmax激活函数使用。</p>

<p>假定神经网络的每个输出层神经元（假设共 \(n\) 个）都使用softmax激活函数：<br/>
\[<br/>
o_j=\frac{e^{\text{net}_j}}{\sum_k e^{\text{net}_k}}<br/>
\]</p>

<p>其中，\(\text{net}_j\) 表示输出层第 \(j\) 个神经元的净激活输入，\(o_j\) 表示第 \(j\) 输出神经元的输出。\(\sum_k e^{\text{net}_k}\) 表示所有输出层神经元的净激活输入之和。</p>

<p><strong>softmax函数的特点</strong></p>

<p>1）它把每个神经元的输入占当前层所有神经元输入之和的比值，当作该神经元的输出。这使得输出更容易被解释：神经元的输出值越大，则该神经元对应的类别是真实类别的可能性更高。<br/>
2）此外，softmax的输出是一个<strong>归一化</strong>的概率分布，能够衡量输出分布与真实分布之间的差距。</p>

<p><strong>softmax函数求导</strong></p>

<p>1）当 \(j\neq i\) 时<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial o_j}{\partial \text{net}_i} &amp;= \frac{\partial}{\partial \text{net}_j} \Big(\frac{e^{\text{net}_i}}{\sum_k e^{\text{net}_k}}\Big)\\<br/>
&amp;= -\frac{e^{\text{net}_j} e^{\text{net}_i} }{(\sum_k e^{\text{net}_k})^2}\\<br/>
&amp;= -o_j o_i<br/>
\end{align*}<br/>
\]</p>

<p>2）当 \(j= i\) 时<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial o_j}{\partial \text{net}_i} &amp;= \frac{\partial}{\partial \text{net}_j} \Big(\frac{e^{\text{net}_i}}{\sum_k e^{\text{net}_k}}\Big)\\<br/>
&amp;= \frac{e^{\text{net}_j} \sum_k e^{\text{net}_k} - e^{\text{net}_j} e^{\text{net}_i}}{(\sum_k e^{\text{net}_k})^2}\\<br/>
&amp;= \frac{e^{\text{net}_j}}{\sum_k e^{\text{net}_k}} - \frac{e^{\text{net}_j} e^{\text{net}_i}}{(\sum_k e^{\text{net}_k})^2}\\<br/>
&amp;= o_j - o_j o_i\\<br/>
&amp;= o_j(1 - o_j)<br/>
\end{align*}<br/>
\]</p>

<p><strong>考虑权值和偏置更新</strong></p>

<p>对权值 \(w_{jk}\) （节点 \(k\) 到节点 \(j\) 的权值）求偏导得权值更新步长为：</p>

<p>\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial w_{jk}} &amp;= \frac{\partial}{\partial w_{jk}}\Big( -\sum_i y_i \log o_i \Big)\\<br/>
&amp;= -\sum_i \frac{y_i}{o_i} \frac{\partial o_i}{\partial w_{jk}}\\<br/>
&amp;= -\frac{y_j}{o_j} \frac{\partial o_j}{\partial w_{jk}} - \sum_{i\neq j} \frac{y_i}{o_i} \frac{\partial o_i}{\partial w_{jk}}\\<br/>
&amp;= -\frac{y_j}{o_j} \frac{\partial o_j}{\partial \text{net}_j} \frac{\partial \text{net}_j}{\partial w_{jk}} - \sum_{i\neq j} \frac{y_i}{o_i} \frac{\partial o_i}{\partial w_{jk}}\\<br/>
&amp;= -\frac{y_j}{o_j} o_j(1-o_j) x_k - \sum_{i\neq j} \frac{y_i}{o_i} \frac{\partial o_i}{\partial w_{jk}}\\<br/>
&amp;= -y_j(1-o_j) x_k - \sum_{i\neq j} \frac{y_i}{o_i} \frac{\partial o_i}{\partial \text{net}_j} \frac{\partial \text{net}_j}{\partial w_{jk}}\\<br/>
&amp;= -y_j(1-o_j) x_k + \sum_{i\neq j} \frac{y_i}{o_i} o_i o_j x_k \\<br/>
&amp;= -y_j(1-o_j) x_k + o_j x_k\sum_{i\neq j} y_i \\<br/>
&amp;= o_j x_k \sum_{i} y_i - y_j x_k\\<br/>
&amp;= o_j x_k - y_j x_k\\<br/>
&amp;= (o_j - y_j) x_k<br/>
\end{align*}<br/>
\] </p>

<p>同理得偏置值更新步长为：<br/>
\[ <br/>
\frac{\partial C}{\partial b_j} =o_j−y_j<br/>
\]</p>

<p>可以看出，权值和偏置得更新与输出值和真实值之间得误差有关，误差越大，权值和偏置更新得速度越快，训练得速度也就越快。</p>

<p>根据上述分析可得，对数似然代价函数配合softmax函数和交叉熵代价函数配合 S 型函数的原理相似，都能有效地解决权值和偏置值更新速度慢导致得训练速度慢的问题。二者联系：对数似然代价函数在二分类时，可以简化为交叉熵代价函数的形式。</p>

<hr/>

<p><a href="https://blog.csdn.net/weixin_40170902/article/details/80032669">机器学习：神经网络代价函数总结</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15254702833482.html">反向传播</a></h1>
			<p class="meta"><time datetime="2018-05-05T05:44:43+08:00" 
			pubdate data-updated="true">2018/5/5</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>现在，我们需要知道一个神经网络的每个连接上的权值是如何得到的。我们可以说神经网络是一个模型，那么这些权值就是模型的参数，也就是模型要学习的东西。然而，一个神经网络的连接方式、网络的层数、每层的节点数这些参数，则不是学习出来的，而是人为事先设置的。对于这些人为设置的参数，我们称之为超参数(Hyper-Parameters)。</p>

<p>接下来，我们将要介绍神经网络的训练算法：反向传播算法。</p>

<h3 id="toc_0">反向传播算法(Back Propagation)</h3>

<p>假设有如下的神经网络</p>

<div align="center">
    <img width=500 src="media/15254702833482/15254707153853.jpg" />
</div>

<p>每个训练样本为 \((\vec x,\vec t)\)，其中向量\(\vec x\) 是训练样本的特征，而 \(\vec t\) 是样本的目标值。</p>

<p>我们使用下面的方式计算出每个节点的误差项 \(\delta_i\)：</p>

<ul>
<li>对于输出节点 \(i\)
\[
\begin{equation}
\delta_i = y_i(1-y_i)(t_i - y_i)\label{diy}\\
\end{equation}
\]</li>
</ul>

<p>其中，\(\delta_i\) 是节点的误差项，\(y_i\) 是节点的输出值，\(t_i\) 是样本对应于节点 \(i\) 的目标值。举个例子，根据上图，对于输出层节点8来说，它的输出值是 \(y_1\) ，而样本的目标值是 \(t_1\)，带入上面的公式得到节点8的误差项应该是：<br/>
\[<br/>
\delta_8 = y_1(1-y_1)(t_1 - y_1)<br/>
\]</p>

<ul>
<li>对于隐藏层节点
\[
\begin{equation}
\delta_i = a_i(1-a_i) \sum_{k\in \text{outputs}} w_{ki} \delta_k\label{dia}
\end{equation}
\]</li>
</ul>

<p>其中，\(a_i\) 是节点的输出值，\(w_{ki}\) 是节点 \(i\) 到它的下一层节点 \(k\) 的连接的权重，\(\delta_k\) 是节点 \(i\) 的下一层节点 \(k\) 的误差项。例如，对于隐藏层节点4来说，计算方法如下：<br/>
\[<br/>
\delta_4 = a_4(1-a_4)(w_{84}\delta_8 + w_{94}\delta_9)<br/>
\]</p>

<p>最后，更新每个连接上的权值：<br/>
\[<br/>
\begin{equation}<br/>
w_{ji} \leftarrow w_{ji} + \eta \delta_j x_{ji}\label{wedx}<br/>
\end{equation}<br/>
\]</p>

<p>其中，\(w_{ji}\) 是节点 \(i\) 到节点 \(j\) 的权重，\(\eta\) 是一个成为学习速率的常数，\(\delta_j\) 是节点 \(j\) 的误差项，\(x_{ji}\) 是节点 \(i\) 传递给节点 \(j\) 的输入。例如，权重 \(w_{84} 的更新方法如下：<br/>
\)\(<br/>
w_{84} \leftarrow w_{84} + \eta \delta_8 a_4<br/>
\)$</p>

<p>类似的，权重 \(w_{41}\) 的更新方法如下：<br/>
\[<br/>
w_{41} \leftarrow w_{41} + \eta \delta_4 x_1<br/>
\]</p>

<p>偏置项的输入值永远为1。例如，节点4的偏置项 \(w_{40}\) 应该按照下面的方法计算：<br/>
\[<br/>
w_{40} \leftarrow w_{40} + \eta \delta_4<br/>
\]</p>

<p>我们已经介绍了神经网络每个节点误差项的计算和权重更新方法。显然，计算一个节点的误差项，需要先计算每个与其相连的下一层节点的误差项。这就要求误差项的计算顺序必须是从输出层开始，然后反向依次计算每个隐藏层的误差项，直到与输入层相连的那个隐藏层。这就是反向传播算法的名字的含义。</p>

<h3 id="toc_1">反向传播推导</h3>

<p>按照机器学习的通用套路，我们先确定神经网络的目标函数，然后用随机梯度下降优化算法去求目标函数最小值时的参数值。</p>

<p>我们取网络所有输出层节点的误差平方和作为目标函数：<br/>
\[<br/>
E_d = \frac 1 2 \sum_{i\in \text{outputs}}(t_i - y_i)^2<br/>
\]</p>

<p>使用随机梯度下降算法对目标函数进行优化：<br/>
\[<br/>
w_{ji} \leftarrow w_{ji} - \eta \frac{\partial E_d}{\partial w_{ji}}<br/>
\]</p>

<div align="center">
    <img width=500 src="media/15254702833482/15254707153853.jpg" />
</div>

<p>观察上图，我们发现权重 \(w_{ji}\) 仅能通过影响节点 \(j\) 的输入值影响网络的其它部分，设 \(net_j\) 是节点 \(j\) 的加权输入，\(x_{ji}\) 是节点 \(i\) 传递给节点 \(j\) 的输入值，也就是节点 \(i\) 的输出值，即<br/>
\[<br/>
net_j = \vec w_j \cdot \vec x_j = \sum_{i} w_{ji} x_{ji}<br/>
\]</p>

<p>\(E_d\) 是 \(net_j\) 的函数，而 \(net_j\) 是 \(w_{ji}\) 的函数。根据链式求导法则，可以得到：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E_d}{\partial w_{ji}} &amp;= \frac{\partial E_d}{\partial net_j}\frac{\partial net_j}{\partial w_{ji}}\\<br/>
&amp;= \frac{\partial E_d}{\partial net_j}\frac{\partial \sum_i w_{ji} x_{ji}}{\partial w_{ji}}\\<br/>
&amp;= \frac{\partial E_d}{\partial net_j} x_{ji} \\<br/>
\end{align*}<br/>
\]</p>

<p>对于 \(\frac{\partial E_d}{\partial net_j}\) 的推导，需要区分输出层和隐藏层两种情况。</p>

<p><strong>输出层权值训练</strong>：</p>

<p>对于输出层来说，\(net_j\) 仅能通过节点 \(j\) 的输出值 \(y_j\) 来影响网络其它部分，也就是说 \(E_d\) 是 \(y_j\) 的函数，而 \(y_j\) 是 \(net_j\) 的函数，其中 \(y_j = \text{sigmoid}(net_j)\) 。所以我们可以再次使用链式求导法则：<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial E_d}{\partial net_j} = \frac{\partial E_d}{\partial y_j}\frac{\partial y_j}{\partial net_j}\label{fpep}<br/>
\end{equation}<br/>
\]</p>

<p>考虑上式第一项：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E_d}{\partial y_j} &amp;= \frac{\partial}{\partial y_j} \frac 1 2 \sum_{i\in \text{outputs}}(t_i - y_i)^2\\<br/>
&amp;= \frac{\partial}{\partial y_j} \frac 1 2 (t_i - y_i)^2\\<br/>
&amp;= -(t_j - y_j)<br/>
\end{align*}<br/>
\]</p>

<p>考虑上式第二项：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial y_j}{\partial net_j} &amp;= \frac{\partial}{\partial net_j} \text{sigmoid}(net_j)\\<br/>
&amp;= y_j(1-y_j)<br/>
\end{align*}<br/>
\]</p>

<p>将第一项，第二项代入(\ref{fpep})得<br/>
\[<br/>
\frac{\partial E_d}{\partial net_j} = -(t_j - y_j)y_j(1-y_j) <br/>
\]</p>

<p>如果令 \(\delta_j = - \frac{\partial E_d}{\partial net_j}\)，也就是一个节点的误差项 \(\delta\) 是网络误差对这个节点输入的偏导数的相反数。带入上式，得到：<br/>
\[<br/>
\delta_j = y_i(1-y_i)(t_i - y_i)<br/>
\]</p>

<p>也就是式(\ref{diy})，将上述推导带入随机梯度下降公式，得到</p>

<p>\[<br/>
\begin{align*}<br/>
w_{ji} &amp;\leftarrow w_{ji} - \eta \frac{\partial E_d}{\partial w_{ji}}\\<br/>
&amp;= w_{ji} - \eta \frac{\partial E_d}{\partial net_j}\frac{\partial net_j}{\partial w_{ji}}\\<br/>
&amp;= w_{ji} + \eta (t_j - y_j)y_j(1-y_j) x_{ji}\\<br/>
&amp;= w_{ji} + \eta\delta_j x_{ji}<br/>
\end{align*}<br/>
\]</p>

<p>也就是式(\ref{wedx})</p>

<p><strong>隐藏层权值训练</strong>：</p>

<p>现在开始推导隐藏层的 \(\frac{\partial E_d}{\partial net_j}\)。</p>

<div align="center">
    <img width="300" src="media/15254702833482/15254723302672.jpg" />
</div>

<p>首先，我们需要定义节点 \(j\) 的所有直接下游节点的集合 \(\text{Downstream}(j)\) 。例如，对于节点4来说，它的直接下游节点是节点8、节点9。可以看到 \(net_j\) 只能通过影响 \(\text{Downstream}(j)\) 再影响 \(E_d\) 。设 \(net_j\) 是节点 \(j\) 的下游节点的输入，则 \(E_d\) 是 \(net_k\) 的函数，而 \(net_k\) 是 \(net_j\) 的函数。因为 \(net_k\) 有多个，我们应用全导数公式，可以做出如下推导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial E_d}{\partial net_j} &amp;= \sum_{k\in \text{Downstream}(j)} \frac{\partial E_d}{\partial net_k}\frac{\partial net_k}{\partial net_j}\\<br/>
&amp;= \sum_{k\in \text{Downstream}(j)} - \delta_k \frac{\partial net_k}{\partial net_j}\\<br/>
&amp;= \sum_{k\in \text{Downstream}(j)} - \delta_k \frac{\partial net_k}{\partial a_j} \frac{\partial a_j}{\partial net_j}\\<br/>
&amp;= \sum_{k\in \text{Downstream}(j)} - \delta_k w_{kj} \frac{\partial a_j}{\partial net_j}\\<br/>
&amp;= \sum_{k\in \text{Downstream}(j)} - \delta_k w_{kj} a_j (1-a_j)\\<br/>
&amp;= - a_j (1-a_j)\sum_{k\in \text{Downstream}(j)} \delta_k w_{kj} \\<br/>
\end{align*}<br/>
\]</p>

<p>因为 \(\delta_j=-\frac{\partial E_d}{\partial net_j}\)，代入上式得：<br/>
\[<br/>
\delta_j = a_j(1-a_j)\sum_{k \in \text{Downstream}(j)} \delta_k w_{kj}<br/>
\]</p>

<p>上式就是式(\ref{dia})。至此，我们已经推导出了反向传播算法。需要注意的是，我们刚刚推导出的训练规则是根据激活函数是sigmoid函数、平方和误差、全连接网络、随机梯度下降优化算法。如果激活函数不同、误差计算方式不同、网络连接结构不同、优化算法不同，则具体的训练规则也会不一样。但是无论怎样，训练规则的推导方式都是一样的，应用链式求导法则进行推导即可。</p>

<h3 id="toc_2">梯度检查</h3>

<p>总体误差函数为<br/>
\[<br/>
f(x) = \frac 1 2 \sum_{i\in \text{outputs}}(t_i - y_i)^2<br/>
\]</p>

<p>对于梯度下降算法：<br/>
\[<br/>
w_{ji} \leftarrow w_{ji} - \eta\frac{\partial E_d}{\partial w_{ji}}<br/>
\]</p>

<p>来说，这里关键之处在于 \(\frac{\partial E_d}{\partial w_{ji}}\) 的计算一定要正确，而它是 \(E_d\) 对 \(w_{ji}\) 的偏导数。而根据导数的定义：<br/>
\[<br/>
f&#39;(\theta) = \lim_{\epsilon\rightarrow 0}\frac{f(\theta + \epsilon) - f(\theta - \epsilon)}{2\epsilon}<br/>
\]</p>

<p>对于任意 \(\theta\) 的导数值，我们都可以用等式右边来近似计算。我们把 \(E_d\) 看做是 \(w_ji\) 的函数，即 \(E_d(w_{ji})\)，那么根据导数定义，\(\frac{\partial E_d(w_{ji})}{\partial w_{ji}}\) 应该等于：<br/>
\[<br/>
\frac{\partial E_d(w_{ji})}{\partial w_{ji}} = \lim_{\epsilon \rightarrow 0}\frac{f(w_{ji} + \epsilon) - f(w_{ji} - \epsilon)}{2\epsilon}<br/>
\]</p>

<p>如果把 \(\epsilon\) 设置为一个很小的数（比如 \(10^{-4}\)），那么上式可以写成：<br/>
\[<br/>
\begin{equation}<br/>
\frac{\partial E_d(w_{ji})}{\partial w_{ji}} \approx \frac{f(w_{ji} + \epsilon) - f(w_{ji} - \epsilon)}{2\epsilon}\label{fpew}<br/>
\end{equation}<br/>
\]</p>

<p>我们可以利用该式来计算梯度 \(\frac{\partial E_d(w_{ji})}{\partial w_{ji}}\) 的值，然后同我们神经网络代码中计算出来的梯度值进行比较。如果两者的差别非常的小，那么就说明我们的代码是正确的。</p>

<p>下面是梯度检查的代码。如果我们想检查参数 \(w_{ji}\) 的梯度是否正确，我们需要以下几个步骤：</p>

<ol>
<li>首先使用一个样本 \(d\) 对神经网络进行训练，这样就能获得每个权重的梯度。</li>
<li>将 \(w_{ji}\) 加上一个很小的值(\(10^{-4}\))，重新计算神经网络在这个样本下的。</li>
<li>将 \(w_{ji}\) 减上一个很小的值(\(10^{-4}\))，重新计算神经网络在这个样本下的。</li>
<li>根据式(\ref{fpew})计算出期望的梯度值，和第一步获得的梯度值进行比较，它们应该几乎想等(至少4位有效数字相同)。</li>
</ol>

<p>当然，我们可以重复上面的过程，对每个权重 \(w_{ji}\) 都进行检查。也可以使用多个样本重复检查。</p>

<hr/>

<p><a href="https://www.zybuluo.com/hanbingtao/note/476663">零基础入门深度学习(3) - 神经网络和反向传播算法</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15249262782494.html">神经网络</a></h1>
			<p class="meta"><time datetime="2018-04-28T22:37:58+08:00" 
			pubdate data-updated="true">2018/4/28</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在介绍神经网络之前，我们先来介绍一些S型神经元。</p>

<h3 id="toc_0">S型神经元</h3>

<p>我们⽤描绘感知器的相同⽅式来描绘 S 型神经元：</p>

<div align="center">
    <img width="300" src="media/15249262782494/15368696909674.jpg" />
</div>

<p>正如一个感知器，S 型神经元有多个输入，\(x_1,x_2,...\)。但是这些输入可以取 0 和 1 中的任意值，不仅仅是 0 或 1。例如，0.638...是一个 S 型神经元的有效输入。同样，S 型神经元对每个输入有权重，\(w1,w2,...\)，和一个总的偏置，\(b\)。S 型神经元采用的激活函数是 S 型函数，定义为<br/>
\[<br/>
\sigma(z) = \frac{1}{1 + e^{-z}}<br/>
\]</p>

<p>把它们放在一起可以更清楚的说明，一个具有输入 \(x_1,x_2,...\)，权重 \(w_1,w_2,...\) 和偏置 \(b\) 的 S 型神经元的输出是<br/>
\[<br/>
\frac{1}{1 + \exp(-\sum_{j} w_j x_j - b)}<br/>
\]</p>

<p>初看上去，S 型神经元和感知器有很大区别，但是主要区别还是在 S 型函数上，我们可以看看 S 型函数的几何意义。假设 \(z=\mathbf w \mathbf x + b\) 是一个很大的正数，S 型神经元的输出近似为1；当 \(z=\mathbf w \mathbf x + b\) 是一个较大的负数，S 型神经元的输出近似为0；\(\sigma\) 的函数形状如下图：</p>

<div align="center">
    <img width=400 src="media/15249262782494/15368701242065.jpg" />
</div>

<p>很明显，感知器和 S 型神经元之间的一个很大的不同是 S 型神经元不仅仅输出 0 或 1。它可以是 0 到 1 之间的任何实数，比如 0.1773 等。但是有时候在一些分类问题上，输出为 0 或 1 是最简单的，但是如果输出的是一个浮点数，将没法判断，因此我们需要设定一个约定来解决这个问题，例如，约定任何至少为 0.5 的输出为表示真，小于 0.5 表示假。</p>

<h3 id="toc_1">神经网络</h3>

<p>假设我们有如下的网络结构</p>

<div align="center">
    <img width=500 src="media/15249262782494/15368703446770.jpg" />
</div>

<p>前面提过，这个网络中最左边的称为<strong>输入层</strong>，其中的神经元称为输入神经元。最右边的为<strong>输出层</strong>，包含有输出神经元。在本例中，输出层只有一个神经元。中间层，这层中的神经元既不是输入也不是输出，也被称为<strong>隐藏层</strong>。“隐藏”这个术语也许听上去有些神秘，但它实际上仅仅意味着“既非输入也非输出”。上面的网络仅有一个隐藏层，但有些网络有多个隐藏层。</p>

<p>由于历史的原因，尽管神经网络是由 S 型神经元而不是感知器构成，但是多层神经网络有时候会被称为<strong>多层感知器</strong>或者<strong>MLP</strong>。</p>

<p>神经网络的输入输出层通常是比较直接的。例如，假设我们尝试确定一张手写数字的图像上是否写的是“9”。很自然地，我们可以将图片像素的强度进行编码作为神经网络的输入。如果图像是一个 64 \(\times\) 64 的灰度图像，那么我们会需要 64 \(\times\) 64 = 4096 个输入神经元，每一个强度取 0 和 1 之间合适的值。输出层只需要包含一个神经元，当输出值小于 0.5时表示“输入图像不是9”，大于 0.5 时表示“输入图像是9”。</p>

<p>相比神经网络中输入输出层的直观设计，隐藏层的设计尤为重要，隐藏层层数和数量等选择的不同，直接会影响算法的效率。目前为止，我们讨论的神经网络都是以上一层的输出作为下一层的输入。这种网络被称为“<strong>前馈</strong>神经网络**。这意味着网络中是没有回路的，信息总是向前进行反馈。</p>

<p>然而后面我们也会学习一些神经网络，反馈环路是可行的，这被称之为递归神经网络。关于递归神经网络暂且不说。</p>

<h4 id="toc_2">神经网络的输出</h4>

<p>神经网络实际上就是一个输入向量 \(\vec x\) 到输出向量 \(\vec y\) 的函数，即<br/>
\[<br/>
\vec y = f_{network}(\vec x)<br/>
\]</p>

<p>接下来用一个例子来说明这个过程，我们先给神经网络的每个单元写上编号。</p>

<div align="center">
    <img width="400" src="media/15249262782494/15368749617164.jpg" />
</div>

<p>如上图，输入层有三个节点，隐藏层有4个节点，输出层有2个节点。因为我们这个神经网络是全连接网络，所以每一层都与上一层的所有节点两两相连。假设隐藏节点4与输入层三个节点1、2、3之间都有连接，其连接上的权重分别为 \(w_{41}\)，\(w_{42}\)，\(w_{43}\)。现在来计算节点4的输出值。节点1、2、3是输入层，他们的输出值就是输入向量 \(\vec x\) 本身。假设节点1、2、3的输出值为 \(x_1,x_2,x_3\)。我们要求<strong>输入向量的维度与输入层神经元个数相同</strong>，而输入向量的某个元素对应到哪个输入节点是可以自由决定的，你偏非要把赋值给节点2也是完全没有问题的，但这样除了把自己弄晕之外，并没有什么价值。</p>

<p>一旦我们有了节点1、2、3的输出值，我们就可以计算节点4的输出值 \(a_4\)：<br/>
\[<br/>
\begin{align*}<br/>
a_4 &amp;= \text{sigmoid}({\vec w}^T \vec x)\\<br/>
&amp;= \text{sigmoid}(w_{41} x_1 + w_{42} x_2 + w_{43} x_3 + b_4)<br/>
\end{align*}<br/>
\]</p>

<p>上式中 \(b_4\) 代表节点4的偏置项。同理我们可以计算节点5、6、7的输出值 \(a_5,a_6,a_7\)。这样，隐藏层4个节点的输出值就计算完成了，可以计算输出层的节点8的输出值 \(y_1\)：<br/>
\[<br/>
\begin{align*}<br/>
y_1 &amp;= \text{sigmoid}({\vec w}^T \vec a)\\<br/>
&amp;= \text{sigmoid}(w_{84} a_4 + w_{85} a_5 + w_{86} a_6 + w_{87} a_7 + b_8)\\<br/>
\end{align*}<br/>
\]</p>

<p>同理，还可以计算出 \(y_2\) 的值。这样输出层所有节点的输出值计算完毕，我们就得到了在输入向量 \(\vec x\) 为 \(\left [\begin{array}\\x_1\\x_2\\x_3\\\end{array}\right ]\) 时，神经网络的输出向量 \(\vec y = \left [ \begin{array}\\ y_1 \\y_2 \\\end{array}\right ]\)。显然，输出向量的维度等于输出神经元的个数。</p>

<h4 id="toc_3">神经网络的矩阵表示</h4>

<p>神经网络如果用矩阵表示会很方便，首先我们看隐藏层4个节点的计算（偏置项看成输入为1的权重，\(b_4\) 写成 \(w_{40}\)）：<br/>
\[<br/>
\begin{align*}<br/>
a_4 &amp;= \text{sigmoid}(w_{40}+w_{41} x_1 + w_{42} x_2 + w_{43} x_3 )\\<br/>
a_5 &amp;= \text{sigmoid}(w_{50}+w_{51} x_1 + w_{52} x_2 + w_{53} x_3 )\\<br/>
a_6 &amp;= \text{sigmoid}(w_{60}+w_{61} x_1 + w_{62} x_2 + w_{63} x_3 )\\<br/>
a_7 &amp;= \text{sigmoid}(w_{70}+w_{71} x_1 + w_{72} x_2 + w_{73} x_3 )\\<br/>
\end{align*}<br/>
\]</p>

<p>接着，输入层 \(\vec x\) 和隐藏层每个节点权重向量 \(\vec w_j\)。令<br/>
\[<br/>
\begin{align*}<br/>
\vec x &amp;= \left [ \begin{array}\\ 1\\x_1 \\x_2\\x_3\\\end{array} \right ]\\<br/>
\vec w_4 &amp;= [w_{40},w_{41},w_{42},w_{43}]\\<br/>
\vec w_5 &amp;= [w_{50},w_{51},w_{52},w_{53}]\\<br/>
\vec w_6 &amp;= [w_{60},w_{61},w_{62},w_{63}]\\<br/>
\vec w_7 &amp;= [w_{70},w_{71},w_{72},w_{73}]\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(f\) 表示 S 型 sigmoid 函数，代入前面式子得：<br/>
\[<br/>
a_4 = f(\vec w_4\cdot \vec x)\\<br/>
a_5 = f(\vec w_5\cdot \vec x)\\<br/>
a_6 = f(\vec w_6\cdot \vec x)\\<br/>
a_7 = f(\vec w_7\cdot \vec x)\\<br/>
\]</p>

<p>将 \(a_4,a_5,a_6,a_7\) 表示成矩阵，并将 \(\vec w_4,\vec w_5,\vec w_6,\vec w_7\) 表示成一个矩阵的形式，令<br/>
\[<br/>
\vec a = \left [\begin{array}\\a_4\\a_5\\a_6\\a_7\\\end{array}\right ],\quad W = \left [ \begin{array}\\\vec w_4\\\vec w_5\\\vec w_6\\\vec w_7\\\end{array}\right ] = \left [\begin{array}\\w_{40},w_{41},w_{42},w_{43}\\w_{50},w_{51},w_{52},w_{53}\\w_{60},w_{61},w_{62},w_{63}\\w_{70},w_{71},w_{72},w_{73}\\\end{array} \right ],\quad f\left(\begin{array}\\x_1\\x_2\\x_3\\\vdots\end{array}\right) = \left [\begin{array} \\f(x_1)\\f(x_2)\\f(x_3)\\\vdots\end{array} \right ]<br/>
\]</p>

<p>所以隐藏层计算可以写成<br/>
\[<br/>
\vec a = f(W \cdot \vec x)<br/>
\]</p>

<p>每一层的算法都是一样的。比如，对于包含一个输入层，一个输出层和三个隐藏层的神经网络，我们假设其权重矩阵分别为 \(W_1,W_2,W_3,W_4\)，每个隐藏层的输出分别是 \(\vec a_1,\vec a_2,\vec a_3\)，神经网络的输入为 \(\vec x\)，神经网络的输入为 \(\vec y\)，如下图所示：</p>

<div align="center">
    <img width="500" src="media/15249262782494/15368748602021.jpg" />
</div>

<p>则每一层的输出向量的计算可以表示为<br/>
\[<br/>
\begin{align*}\\<br/>
\vec a_1 &amp;= f(W_1\cdot \vec x)\\<br/>
\vec a_2 &amp;= f(W_2\cdot \vec a_1)\\<br/>
\vec a_3 &amp;= f(W_3\cdot \vec a_2)\\<br/>
\vec y &amp;= f(W_4\cdot \vec a_3)<br/>
\end{align*}<br/>
\]</p>

<p>这就是神经网络输出值的计算方法。</p>

<h3 id="toc_4">神经网络超参数的估计</h3>

<p>以手写数字识别为例，首先需要确定网络的层数和每层的节点数。实际并没有什么理论指导，一般靠经验获取，或者可以多试几个值，训练不同层数的神经网络，看哪个结果最好。我们知道网络层数越多越好，也知道层数越多训练难度越大。对于全连接网络，隐藏层最好<strong>不要超过三层</strong>。</p>

<p>输入层节点数是确定的。因为手写数字数据集每个训练数据是28*28的图片，共784个像素，因此，输入层节点数应该是784，每个像素对应一个输入节点。</p>

<p>输出层节点数也是确定的。因为是10分类，我们可以用10个节点，每个节点对应一个分类。输出层10个节点中，输出最大值的那个节点对应的分类，就是模型的预测结果。</p>

<p>隐藏层节点数量是不好确定的，从1到100万都可以。下面有几个经验公式：<br/>
\[<br/>
\begin{align*}<br/>
m &amp;= \sqrt{n + l} + \alpha\\<br/>
m &amp;= \log_2 n\\<br/>
m &amp;= \sqrt{nl}\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(m\) 表是隐藏层节点数，\(n\) 表示输入层节点数，\(l\) 表示输出层节点数，\(\alpha\) 表示1到10自己的常数。</p>

<p>因此，我们可以先根据上面的公式设置一个隐藏层节点数。如果有时间，我们可以设置不同的节点数，分别训练，看看哪个效果最好就用哪个。</p>

<p>假设设隐藏节点数为300，则对于3层 \(784\times 300 \times 10\) 的全连接网络，总共有 \(300\times(784+1) + 10 \times (300+1) = 238510 \) 个参数！神经网络之所以强大，是它提供了一种非常简单的方法去实现大量的参数。</p>

<hr/>

<p><a href="https://www.zybuluo.com/hanbingtao/note/476663">零基础入门深度学习(3) - 神经网络和反向传播算法</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15239854483603.html">感知器</a></h1>
			<p class="meta"><time datetime="2018-04-18T01:17:28+08:00" 
			pubdate data-updated="true">2018/4/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在学习神经网络之前，先来看看一个基础的结构-感知器，可以理解为一个最基础的人工神经元。感知器在 20 世纪五、六十年代由科学家 Frank Rosenblatt 发明，其受到 Warren McCulloch 和 Walter Pitts 早期的工作的影响。</p>

<p>类似于生物中的神经元，感知器从接受一段信号，经过处理后传入下一个感知器。如下图</p>

<div align="center">
    <img width="500" src="media/15239854483603/15368141404791.jpg" />
</div>

<p>上图中每一个圆圈都可以代表一个感知器，上面的感知器被分成了多层，这称为多层感知器(Multi-Layer Perception)。层与层之间的感知器有连接，而层内之间的感知器没有连接。最左边的层叫做<strong>输入层</strong>，这层负责接收输入数据；最右边的层叫<strong>输出层</strong>，我们可以从这层获取多层感知器输出数据。输入层和输出层之间的层叫做<strong>隐藏层</strong>。</p>

<p>我们先了解一下单层感知器。</p>

<p>一个单层感知器会接受几个二进制的输入 \(x_1,x_2,...,x_n\)，并产生一个二进制的输出</p>

<div align="center">
    <img width="500" src="media/15239854483603/15368151260680.jpg" />
</div>

<p>对于每一个输入信息都有它的重要程度，于是引入了<strong>权重</strong>的概念，用 \(w_i\) 表示输入 \(x_i\) 的权重。为了对每个感知器的结果进行调节，引入了<strong>偏置</strong>的概念，用 \(b\) 表示（对应图中的 \(w_0\)）<br/>
\[<br/>
net = \sum_{i} w_i x_i + b<br/>
\]</p>

<p>感知器的输出 \(y\) 为 0 或 1，是由输入加权和和偏置相加后的结果 \(net\) 再经过激活函数得到的结果。激活函数有很多种，这里使用最简单的<strong>跃阶函数</strong>，即当 \(f(x) \ge 0\) 时，输出 \(y=1\)，否则 \(y=0\)：<br/>
\[<br/>
y = f(net)<br/>
\]</p>

<h3 id="toc_0">感知器的结构</h3>

<p>一个基本的感知器包含三个基本的部分组成</p>

<p><strong>输入权值</strong>：对于感知器的每一个输入都有一个对应的权重 \(w_i\)，除权重之外还有一个偏置 \(b\)，它可以看成默认输入 \(1\) 的权重，用 \(w_0\) 表示。<br/>
<strong>激活函数</strong>：激活函数可以将线性模型映射到非线性模型。<br/>
<strong>输出</strong>：感知器的输出可以由下面的公式得到<br/>
\[<br/>
\begin{equation}<br/>
y = f(\mathbf w \cdot \mathbf x + b)\label{yfm}\\<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_1">感知器的训练</h3>

<p>现在，你可能困惑前面的权重项和偏置项的值是如何获得的呢？这就要用到感知器训练算法：将权重项和偏置项初始化为0，然后，利用下面的感知器规则迭代的修改 \(w_i\) 和 \(b\)，直到训练完成。<br/>
\[<br/>
\begin{align*}<br/>
w_i &amp;\leftarrow w_i + \triangle w_i\\<br/>
b &amp;\leftarrow b + \triangle b\\<br/>
\end{align*}<br/>
\]</p>

<p>其中: <br/>
\[<br/>
\begin{align*}<br/>
\triangle w_i &amp;= \eta (t-y) x_i\\<br/>
\triangle b &amp;= \eta(t-y)\\<br/>
\end{align*}<br/>
\]</p>

<p>\(w_i\) 是与输入 \(x_i\) 对应的权重项，\(b\) 是偏置项。事实上，可以把 \(b\) 看作是值永远为1的输入 \(x_b\) 所对应的权重。\(t\) 是训练样本的实际值，一般称之为label。而 \(y\) 是感知器的输出值，它是根据公式(\ref{yfm})计算得出。\(eta\) 是一个称为学习速率的常数，其作用是控制每一步调整权的幅度。</p>

<p>每次从训练数据中取出一个样本的输入向量 \(\mathbf x\)，使用感知器计算其输出 \(y\)，再根据上面的规则来调整权重。每处理一个样本就调整一次权重。经过多轮迭代后（即全部的训练数据被反复处理多轮），就可以训练出感知器的权重，使之实现目标函数。</p>

<hr/>

<p><a href="https://www.zybuluo.com/hanbingtao/note/433855">零基础入门深度学习(1) - 感知器</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15230159235437.html">算法稳定性 stability</a></h1>
			<p class="meta"><time datetime="2018-04-06T19:58:43+08:00" 
			pubdate data-updated="true">2018/4/6</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>无论是基于 VC 维还是 Rademacher 复杂度来推导泛化误差界，所得到的结果均与具体学习算法无关，对所有学习算法都适用。这使得人们能够脱离具体学习算法的设计来考虑学习问题本身的性质，但在另一方面，若希望获得与算法有关的分析结果，则需另辟蹊径。稳定性分析是这方面的一个值得关注的方向。</p>

<p>顾名思义，算法的“稳定性”考察的是算法在输入发生变化时，输出是否会随之发生较大的变化。学习算法的输入是训练集，因此下面我们先定义训练集的两种变化。</p>

<p>给定 \(D=\{z_1=(x_1,y_1),z_2=(x_2,y_2),...,z_m=(x_m,y_m)\}\)，\(x_i\in\mathcal X\) 是来自分布 \(\mathcal D\) 的独立同分布示例，\(y_i=\{-1,+1\}\)。对假设空间 \(\mathcal H:\mathcal X\rightarrow\{-1,+1\}\) 和学习算法 \(\mathcal L\)，令 \(\mathcal L_D\in\mathcal H\) 表示基于训练集 \(D\) 从假设空间 \(\mathcal H\) 中学得的假设。考虑 \(D\) 的以下变化：</p>

<ul>
<li><p>\(D^{\backslash i}\) 表示移除 \(D\) 中第 \(i\) 个样例得到的集合<br/>
\[<br/>
D^{\backslash i} = \{z_1,z_2,...,z_{i-1},z_{i+1},...,z_m\},<br/>
\]</p></li>
<li><p>\(D^i\) 表示替换 \(D\) 中第 \(i\) 个样例得到的集合<br/>
\[<br/>
D^i = \{z_1,z_2,...,z_{i-1},z&#39;_i,z_{i+1},...,z_m\},<br/>
\]</p></li>
</ul>

<p>其中 \(z&#39;_i=(x&#39;_i,y&#39;_i)\)，\(x&#39;_i\) 服从分布 \(\mathcal D\) 并独立于 \(D\)。</p>

<p>损失函数 \(\ell(\mathcal L_D(x),y):\mathcal Y\times \mathcal Y\rightarrow \mathbb R^{+}\) 刻画了假设 \(\mathcal L_D\) 的预测标记 \(\mathcal L_D(x)\) 与真实标记 \(y\) 之间的差别，简记为 \(\ell(\mathcal L_D,z)\)。下面定义关于假设 \(\mathcal L_D\) 的几种损失。</p>

<ul>
<li><p>泛化损失<br/>
\[<br/>
\ell(\mathcal L_D,\mathcal D) = \mathbb E_{x\in\mathcal X,z=(x,y)}[\ell(\mathcal L_D,z)]<br/>
\]</p></li>
<li><p>经验损失<br/>
\[<br/>
\hat \ell(\mathcal L,D) = \frac 1 m\sum_{i=1}^m \ell(\mathcal L_D,z_i)<br/>
\]</p></li>
<li><p>留一 (leave-one-out) 损失<br/>
\[<br/>
\ell_{loo}(\mathcal L,D) = \frac 1 m \sum_{i=1}^m \ell(\mathcal L_{D^{\backslash i}},z_i)<br/>
\]</p></li>
</ul>

<p>下面定义算法的均匀稳定性（uniform stability)：<br/>
<strong>均匀稳定性</strong>：对任何 \(x\in\mathcal X\)，\(z=(x,y)\)，若学习算法 \(\mathcal L\) 满足<br/>
\[<br/>
|\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i},z})| \le \beta,\quad i=1,2,...,m<br/>
\]</p>

<p>则称 \(\mathcal L\) 关于损失函数 \(\ell\) 满足 \(\beta\)-均匀稳定性。</p>

<p>显然，若算法 \(\mathcal L\) 关于损失函数 \(\ell\) 满足 \(\beta\)-均匀稳定性，则有：<br/>
\[<br/>
\begin{align*}<br/>
&amp;|\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{i}},z)|\\<br/>
&amp;\le |\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i}},z)| + |\ell(\mathcal L_{D^i},z) - \ell(\mathcal L_{D^{\backslash i}},z)|\\<br/>
&amp;\le 2\beta<br/>
\end{align*}<br/>
\]</p>

<p>也就是说移除示例的稳定性包含替换示例的稳定性。</p>

<p>再来看几个稍弱一点的概念：</p>

<p><strong>误差稳定性</strong>：对任意 \(D\)，对于所有 \(i\in [0,m]\)，都有：<br/>
\[<br/>
\begin{align*}<br/>
|\ell(\mathcal L_D,\mathcal D) - \ell(\mathcal L_{D^{\backslash i}},\mathcal D)| &amp;=  \Big|\mathbb E\big[\ell(\mathcal L_D,z)\big] - \mathbb E\big[\ell(\mathcal L_{D^{\backslash i}},z)\big]\Big| \\<br/>
&amp;= \Big|\mathbb E\big[\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i}},z)\big]\Big|\\<br/>
&amp;\le \beta<br/>
\end{align*}<br/>
\] </p>

<p><strong>假设稳定性</strong>：对于任意 \(i\in [0,m]\)，当训练数据集 \(D\) 被移除后有：<br/>
\[<br/>
\begin{align*}<br/>
|\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{\backslash i}) | &amp;= \frac 1 m\sum_{j\neq i}\Big| \ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{\backslash i}},z_j)\Big| + \frac 1 m \ell(\mathcal L_{D},z_i)\\<br/>
&amp;\le \frac{(m-1)\beta}{m} + \frac{M}{m}\\<br/>
&amp;\le \beta + \frac M m<br/>
\end{align*}<br/>
\]</p>

<p>若损失函数 \(\ell\) 有界，即对所有 \(D\) 和 \(z=(x,y)\) 有 \(0\le \ell(\mathcal L_D,z) \le M\)，则有</p>

<p><strong>定理1</strong>：给定从分布 \(\mathcal D\) 上独立同分布采样得到的大小为 \(m\) 的示例集 \(D\)，若学习算法 \(\mathcal L\) 满足关于损失函数 \(L\) 的 \(\beta\)-均匀稳定性，且损失函数 \(L\) 的上界为 \(M\)，\(0\lt \delta\lt 1\)，则对任意 \(m\ge 1\)，以至少 \(1-\delta\) 的概率有<br/>
\[<br/>
\begin{align}<br/>
\ell(\mathcal L_D,\mathcal D) &amp;\le \hat \ell(\mathcal L,D) + 2\beta + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\label{lmlm1}\\<br/>
\ell(\mathcal L_D,\mathcal D) &amp;\le \ell_{loo}(\mathcal L,D) + \beta + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\label{lmlm2}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：类比<strong>误差稳定性</strong>，我们可以通过三角不等式得出：<br/>
\[<br/>
\begin{align*}<br/>
|\ell(\mathcal L_D,\mathcal D) - \ell(\mathcal L_{D^{i}},\mathcal D)| &amp;= \Big|\mathbb E\big[\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{i}},z) \big]\Big| \\<br/>
&amp;\le \Big|\mathbb E\big[\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i}},z) \big]\Big| + \Big|\mathbb E\big[\ell(\mathcal L_{D^i},z) - \ell(\mathcal L_{D^{\backslash i}},z) \big]\Big|\\<br/>
&amp;\le 2\beta\\<br/>
\end{align*}<br/>
\]</p>

<p>而使用<strong>假设稳定性</strong>，我们可以得出<br/>
\[<br/>
\begin{align*}<br/>
|\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{i}) | &amp;\le |\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{\backslash i})| + |\hat \ell(\mathcal L,D^{\backslash i}) - \hat \ell(\mathcal L,D^{i})|\\<br/>
&amp;\le 2(\beta + \frac M m)\\<br/>
&amp;= 2\beta + 2\frac M m\\<br/>
\end{align*}<br/>
\]</p>

<p>实际上我们还有更好的上界表示：<br/>
\[<br/>
\begin{align*}<br/>
|\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{i}) |&amp;= \frac 1 m\sum_{j\neq i}\Big| \ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{i}},z_j)\Big| + \frac 1 m \Big(\ell(\mathcal L_{D},z_i) - \ell(\mathcal L_{D},z&#39;_i)\Big)\\<br/>
&amp;\le \frac 1 m \sum_{j\neq i}\Big(|\ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{\backslash i}},z_j)| + |\ell(\mathcal L_{D^{\backslash i}},z_j) - \ell(\mathcal L_{D^{i}},z_j)| \Big)+ \frac 1 m \Big(\ell(\mathcal L_{D},z_i) - \ell(\mathcal L_{D},z&#39;_i)\Big)\\<br/>
&amp;= \frac 1 m \sum_{j\neq i}|\ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{\backslash i}},z_j)| +\frac 1 m \sum_{j\neq i} |\ell(\mathcal L_{D^{\backslash i}},z_j) - \ell(\mathcal L_{D^{i}},z_j)|+ \frac 1 m \Big(\ell(\mathcal L_{D},z_i) - \ell(\mathcal L_{D},z&#39;_i)\Big)\\<br/>
&amp;\le 2\beta + \frac M m<br/>
\end{align*}<br/>
\]</p>

<p>定义随机变量 \(Z\) 为<br/>
\[<br/>
Z = \ell(\mathcal L_D,\mathcal D) - \hat \ell(\mathcal L,D)<br/>
\]</p>

<p>则 \(Z^i\) 是 \(D\) 被替换为 \(D^{i}\) 的随机变量<br/>
\[<br/>
Z^i = \ell(\mathcal L_{D^i},\mathcal D) - \hat \ell(\mathcal L,D^i)<br/>
\]</p>

<p>所以有<br/>
\[<br/>
\begin{align*}<br/>
|Z-Z^{i}| &amp;= \Big|\big(\ell(\mathcal L_D,\mathcal D) - \hat \ell(\mathcal L,D)\big) - \big(\ell(\mathcal L_{D^{i}},\mathcal D) - \hat \ell(\mathcal L,D^{i})\big) \Big|\\<br/>
&amp;= \Big|\big(\ell(\mathcal L_D,\mathcal D) -\hat \ell(\mathcal L_{D^{i}},\mathcal D)\big) + \big(\ell(\mathcal L,D^{i}) -  \hat \ell(\mathcal L,D)\big) \Big|\\<br/>
&amp;\le \Big|\ell(\mathcal L_D,\mathcal D) -\ell(\mathcal L_{D^{i}},\mathcal D)\Big| + \Big|\hat \ell(\mathcal L,D^{i}) -  \hat \ell(\mathcal L,D)\Big|\\<br/>
&amp;\le 2\beta + 2\beta + \frac M m\\<br/>
&amp;\le 4\beta + \frac M m\\<br/>
\end{align*}<br/>
\]</p>

<p>在 Mcdiarmid 不等式中有 \(c_i = 4\beta + \frac M m\)。</p>

<p>为了求随机变量期望值的边界，我们需要两个特性：</p>

<ul>
<li>\(\mathbb E_D[\ell(\mathcal L_D,z_i)] = \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^{j}},z&#39;)]\)：这个特性成立是因为 \(z_i\) 是从 \(\mathcal D\) 中取样的，\(P(D) = P(D^j)\)。</li>
<li>\(\mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^j},z&#39;)] = \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^{i}},z&#39;)]\)：为了看这个特性成立，我们令 \(D&#39;\) 是一个和 \(D\) 包含相同元素的集合，但是交换 \(z_i\) 和 \(z_j\) 的位置。因为学习算法是顺序要求的，所以 \(\mathcal L_D = \mathcal L_{D&#39;}\)，结合 \(P(D) = P(D&#39;)\) 和上一个特性可以得到此特性。</li>
</ul>

<p>用这两个特性，我们有<br/>
\[<br/>
\begin{align}<br/>
\mathbb E(Z) &amp;= \mathbb E_D[\ell(\mathcal L_D,\mathcal D) - \hat \ell(\mathcal L,D)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;) - \hat \ell(\mathcal L,D)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \mathbb E_{D}[\hat \ell(\mathcal L,D)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \mathbb E_{D}[\frac 1 m \sum_{i=1}^m \ell(\mathcal L_D,z_i)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \frac 1 m \sum_{i=1}^m \mathbb E_{D}[\ell(\mathcal L_D,z_i)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \frac 1 m \sum_{i=1}^m \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^j},z&#39;)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \frac 1 m m \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^j},z&#39;)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^i},z&#39;)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;) - \ell(\mathcal L_{D^i},z&#39;)]\nonumber\\<br/>
&amp;\le 2\beta\label{mb2b}\\<br/>
\end{align}<br/>
\]</p>

<p>通过 Mcdiarmid 不等式，有<br/>
\[<br/>
\begin{align*}<br/>
P\big[Z - \mathbb E[Z] \le \epsilon\big] &amp;\ge 1- \exp\bigg(\frac{-2\epsilon^2}{\sum_{i=1}^m c_i^2 } \bigg)\\<br/>
&amp;= 1- \exp\bigg(\frac{-2\epsilon^2}{\sum_{i=1}^m (4\beta+\frac M m)^2 } \bigg)\\<br/>
&amp;= 1- \exp\bigg(\frac{-2\epsilon^2}{m (4\beta+\frac M m)^2 } \bigg)\\<br/>
&amp;= 1- \exp\bigg(\frac{-2m\epsilon^2}{(4m\beta+M)^2 } \bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>令<br/>
\[<br/>
\delta = \exp\bigg(\frac{-2m\epsilon^2}{(4m\beta+M)^2 } \bigg)<br/>
\]</p>

<p>如果我们用 \(\delta\) 来表示 \(\epsilon\) 便有<br/>
\[<br/>
\epsilon = (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}<br/>
\]</p>

<p>所以我们知<br/>
\[<br/>
\begin{align*}<br/>
&amp;Z - \mathbb E[Z] \le (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
\end{align*}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立。</p>

<p>结合(\ref{mb2b})可得<br/>
\[<br/>
\begin{align*}<br/>
&amp;Z \le \mathbb E[Z] + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\le 2\beta + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
\end{align*}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立。再将 \(Z\) 的定义代入，便可以证明式(\ref{lmlm1})。</p>

<p>类比可以得出式(\ref{lmlm2})的证明，这里不再叙述。</p>

<p>本文<strong>定理1</strong>给出了基于稳定性分析推导出的学习算法 \(\mathcal L\) 学得假设的泛化误差界。从(\ref{lmlm1})可以看出，经验损失与泛化损失之间差别的收敛率为 \(\beta\sqrt{m}\)；若令 \(\beta=O(\frac 1 m)\)，则可保证收敛率为 \(O(\frac{1}{\sqrt{m}})\)，这与VC维(该文章中的<strong>定理1</strong>)和Rademacher复杂度(该文章中的<strong>定理1</strong>)得到的收敛率一致。</p>

<p>需注意，学习算法稳定性分析所关注的是 \(|\hat\ell(\mathcal L,D)-\ell(\mathcal L,\mathcal D)|\)，而假设空间复杂度分析所关注的是 \(\sup_{h\in \mathcal H}|\hat E(h) - E(h)|\)；也就是说稳定性分析不必考虑假设空间所有可能的假设，只需根据自身的特性（稳定性）来讨论输出假设 \(\mathcal L_D\) 的泛化误差界。那么稳定性与可学习性之间有什么关系呢？</p>

<p>首先，必须假设 \(\beta\sqrt{m} \rightarrow 0\)，这样才能保证稳定的学习算法 \(\mathcal L\) 具有一定的泛化能力，即经验损失等于泛化损失，否则可学习性无从谈起。为了方便计算，假定 \(\beta = \frac 1 m\)，代入式(\ref{lmlm1})可得：<br/>
\[<br/>
\begin{equation}<br/>
\ell(\mathcal L,\mathcal D) \le \hat \ell(\mathcal L,D) + \frac 2 m + (4+M)\sqrt{\frac{\ln(1/\delta)}{2m}}\label{lmlm3}\\<br/>
\end{equation}<br/>
\]</p>

<p>对损失函数 \(\ell\) ，若学习算法 \(\mathcal L\) 所输出的假设满足经验损失最小化，则称算法 \(\mathcal L\) 满足经验损失最小化原则，简称算法是 ERM 的。关于学习算法的稳定性和可学习性，有如下定理：</p>

<p><strong>定理2</strong>：若学习算法 \(\mathcal L\) 是 ERM 且稳定的，则假设空间 \(\mathcal H\) 可学习。</p>

<p>证明：令 \(g\) 表示 \(\mathcal H\) 中具有最小泛化损失的假设，即<br/>
\[<br/>
\ell(g,\mathcal D) = \min_{h\in\mathcal H}\ell(h,\mathcal D)<br/>
\]</p>

<p>再令<br/>
\[<br/>
\begin{align*}<br/>
\epsilon&#39; &amp;= \frac{\epsilon}{2},\\<br/>
\frac{\delta}{2} &amp;= 2\exp\Big(-2m(\epsilon&#39;)^2 \Big)<br/>
\end{align*}<br/>
\]</p>

<p>由 Hoeffding 不等式可知，当 \(m\le \frac{2}{\epsilon^2}\ln\frac 4 \delta\) 时<br/>
\[<br/>
|\ell(g,\mathcal D) - \hat \ell(g,D) | \le \frac \epsilon 2<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。令式(\ref{lmlm3})中<br/>
\[<br/>
\frac 2 m + (4+M)\sqrt{\frac{\ln(2/\delta)}{2m}} = \frac \epsilon 2<br/>
\]</p>

<p>解得 \(m=O(\frac{1}{\epsilon^2} \ln \frac 1 \delta)\) 使<br/>
\[<br/>
\ell(\mathcal L,\mathcal D) \le \hat\ell(\mathcal L,D) + \frac \epsilon 2<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 得概率成立，从而可得<br/>
\[<br/>
\begin{align*}<br/>
\ell(\mathcal L,\mathcal D) - \ell(g,\mathcal D) &amp;\le \hat\ell(\mathcal L,D) + \frac{\epsilon}{2} - \bigg(\hat \epsilon(g,D) - \frac \epsilon 2 \bigg)\\<br/>
&amp;\le \hat\ell(\mathcal L,D) - \hat\ell(g,D) + \epsilon\\<br/>
&amp;\le \epsilon<br/>
\end{align*}<br/>
\]</p>

<p>以至少 \(1-\delta\) 得概率成立。<strong>定理2</strong>成立。</p>

<hr/>

<p><a href="">周志华 机器学习</a><br/>
<a href="http://www.jmlr.org/papers/volume2/bousquet02a/bousquet02a.pdf">Stability and Generalization</a><br/>
<a href="https://courses.cs.washington.edu/courses/cse522/11wi/scribes/lecture19.pdf">Algorithmic Stability</a><br/>
<a href="http://101.96.10.64/www.mit.edu/%7E9.520/spring08/Classes/class14.pdf">Generalization Bounds and Stability</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15225424238056.html">数学期望与条件期望</a></h1>
			<p class="meta"><time datetime="2018-04-01T08:27:03+08:00" 
			pubdate data-updated="true">2018/4/1</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在概率论和统计学中，数学期望(Expectation)（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和，是最基本的数学特征之一。它反映随机变量平均取值的大小。</p>

<p>需要注意的是，期望值并不一定等同于常识中的“期望”——“期望值”也许与每一个结果都不相等。期望值是该变量输出值的平均数。期望值并不一定包含于变量的输出值集合里。</p>

<p>大数定律规定，随着重复次数接近无穷大，数值的算术平均值几乎肯定地收敛于期望值。</p>

<h3 id="toc_0">离散型数学期望</h3>

<p>离散型随机变量 \(X\) 的取值为 \(X_1,X_2,...,X_n\)，\(P(X_1),P(X_2),...,P(X_n)\) 为 \(X\) 对应取值的概率，则：<br/>
\[<br/>
\mathbb E(X) = X_1\cdot P(X_1) + X_2 \cdot P(X_2) + ... + X_n\cdot P(X_n) = \sum_{i=1}^n X_i P(X_i)<br/>
\]</p>

<p>若随机变量 \(Y\) 符合函数 \(Y=g(x)\)，则有：<br/>
\[<br/>
\mathbb E(Y) = \mathbb E[g(x)] = \sum_x g(x) f(x)<br/>
\]</p>

<h3 id="toc_1">连续型数学期望</h3>

<p>设连续性随机变量 \(X\) 的概率密度函数为 \(f(x)\)，若积分绝对收敛，则随机变量 \(X\) 的数学期望为：<br/>
\[<br/>
\mathbb E(x) = \int_{-\infty}^{\infty} x f(x) \mathbf dx<br/>
\]</p>

<p><strong>定理</strong>：若随机变量 \(Y\) 符合函数 \(Y=g(x)\)，且 \(\int_{-\infty}^{\infty} g(x)f(x) dx\) 绝对收敛，则有：<br/>
\[<br/>
\mathbb E(Y) = \mathbb E[g(x)] = \int_{-\infty}^{\infty} g(x)f(x) \mathbf dx<br/>
\]</p>

<p>该定理的意义在于：我们求 \(Y\) 时不需要算出 \(Y\) 的分布律或者概率密度，只要利用 \(X\) 的分布律或概率密度即可。</p>

<p>上述定理还可以推广到两个或以上随机变量的函数情况。<br/>
设 \(Z\) 是随机变量 \(X\)、\(Y\) 的函数（\(g\) 是连续函数），\(Z\) 是一个一维随机变量，二维随机变量（\(X\)，\(Y\)）的概率密度为 \(f(x,y)\)，则有：<br/>
\[<br/>
\mathbb E(Z) = \mathbb E[g(X,Y)] = \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x,y)f(x,y) \mathbf dx\mathbf dy<br/>
\]</p>

<h3 id="toc_2">性质</h3>

<ol>
<li>\(\mathbb E(C) = C\)</li>
<li>\(\mathbb E(CX) = C\mathbb E(X)\)</li>
<li>\(\mathbb E(X+Y) = \mathbb E(X) + \mathbb E(Y)\)</li>
<li>当 \(X\) 与 \(Y\) 相互独立时，\(\mathbb E(X,Y) = \mathbb E(X)\mathbb E(Y)\)</li>
</ol>

<h3 id="toc_3">条件期望 Conditional Exceptation</h3>

<p>定义在给定 \(Y\) 下随机变量 \(X\) 的条件期望为：<br/>
\[<br/>
\mathbb E(X|Y) = \left \{\begin{array}\\<br/>
\sum_{x} x f_{X|Y}(x|Y)\quad&amp;\text{if } X \text{ is discrete}\\[10pt]<br/>
\int_{\infty}^{\infty} xf_{X|Y}(x|Y) \mathbf dx\quad&amp;\text{if }X \text{ is continuous}\\[10pt]<br/>
\end{array} \right .<br/>
\]</p>

<p>注意因为 \(f_{X|Y}(x|Y)\) 中在参数中包含随机变量 \(Y\)，所以条件期望也是个随机变量。我们可以定义在特定 \(Y\) 值的 \(X\) 的条件期望，如果 \(Y\) 是连续型随机变量：<br/>
\[<br/>
\mathbb E[X|Y=y] = \left \{\begin{array}\\<br/>
\sum_{x} x f_{X|Y}(x|y)\quad&amp;\text{if } X \text{ is discrete}\\[10pt]<br/>
\int_{\infty}^{\infty} xf_{X|Y}(x|y) \mathbf dx\quad&amp;\text{if }X \text{ is continuous}\\[10pt]<br/>
\end{array} \right .<br/>
\] </p>

<p>其中：<br/>
\[<br/>
f_{X}(x|y) = \frac{f_{X,Y}(x,y)}{f_Y(y)}<br/>
\]</p>

<p>如果 \(Y\) 是离散型随机变量，条件期望为：<br/>
\[<br/>
\mathbb E[X|Y=y] = \left \{\begin{array}\\<br/>
\sum_{x} x f_{X}(x|Y=y)\quad&amp;\text{if } X \text{ is discrete}\\[10pt]<br/>
\int_{\infty}^{\infty} xf_{X}(x|Y=y) \mathbf dx\quad&amp;\text{if }X \text{ is continuous}\\[10pt]<br/>
\end{array} \right .<br/>
\] </p>

<p>其中<br/>
\[<br/>
f_{X}(x|Y=y) = \frac{f_{X,Y}(x,y)}{P(Y=y)}<br/>
\]</p>

<h4 id="toc_4">条件期望性质</h4>

<ol>
<li><p><strong>线性</strong>：假设 \(X\)，\(Y\) 是连续随机变量：<br/>
\[<br/>
\mathbb E[\alpha X+ \beta Z|Y] = \alpha \mathbb E(X|Y) + \beta\mathbb E(Z|Y)<br/>
\]</p>

<p>其中 \(\alpha\) 和 \(\beta\) 是常量。</p></li>
<li><p><strong>独立性</strong>：如果 \(X\) 与 \(Y\) 独立，则有：<br/>
\[<br/>
\mathbb E(X|Y) = \mathbb E(X)<br/>
\]</p>

<p>证明：假设 \(X\)，\(Y\) 都是连续随机变量，<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E(X|Y) &amp;= \int_{-\infty}^{\infty} x f_{X|Y}(x|y) \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{\infty} x \frac{f_{X,Y}(x,y)}{f_Y(y)} \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{\infty} x \frac{f_{X}(x) f_{Y}(y)}{f_Y(y)} \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{\infty} x f_{X}(x) \mathbf dx\\<br/>
&amp;= \mathbb E(X)<br/>
\end{align*}<br/>
\]</p></li>
<li><p><strong>稳定性</strong>：如果 \(Y\) 是一个随机变量，<br/>
\[<br/>
\mathbb E[Xg(Y)|Y] = g(Y)\mathbb E(X|Y)<br/>
\]</p>

<p>特例：\(\mathbb E[g(Y) | Y] = g(Y)\)</p>

<p>证明：假设 \(X\) 和 \(Y\) 是连续随机变量，<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E[Xg(Y)|Y=y] &amp;= \int_{-\infty}^{\infty} x g(y)f_{X|Y}(x|y) \mathbf dx\\<br/>
&amp;= g(y)\int_{-\infty}^{\infty} x f_{X|Y}(x|y) \mathbf dx\\<br/>
&amp;= g(y) \mathbb E[X|Y=y]<br/>
\end{align*}<br/>
\]</p></li>
<li><p><strong>迭代期望法则</strong>：英文 Law of Iterated Expectations，LIE，如果 \(Y\) 是一个随机变量，期望是 \(\mathbb E(Y)\)，\(X\) 是相同概率空间的随机变量，有：<br/>
\[<br/>
\mathbb E[\mathbb E(Y|X)] = \mathbb E(Y)<br/>
\]</p>

<p>也就是给定 \(X\) 下的 \(Y\) 的条件期望值的期望等于 \(Y\) 的期望。</p>

<p>证明：假设 \(X\) 和 \(Y\) 是连续型随机变量，令 \(g(x) = \mathbb E(Y|X=x)\)，<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E[g(X)] &amp;= \int_{-\infty}^{-\infty} g(x) f_X(x) \mathbf dx = \int_{-\infty}^{-\infty} \mathbb E(Y|X=x) f_X(x) \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{-\infty} \bigg( \int_{-\infty}^{-\infty} y f_{Y|X}(y|x) \mathbf dy \bigg) f_X(x) \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{-\infty} \bigg( \int_{-\infty}^{-\infty} y \frac{f_{Y,X}(y,x)}{f_X(x)} \mathbf dy \bigg) f_X(x) \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{-\infty}\int_{-\infty}^{-\infty} y f_{X,Y}(x,y) \mathbf dy\mathbf dx\\<br/>
&amp;= \int_{-\infty}^{-\infty} y\bigg(\int_{-\infty}^{-\infty} f_{X,Y}(x,y) \mathbf dx\bigg) \mathbf dy\\<br/>
&amp;= \int_{-\infty}^{-\infty} y f_Y(y) \mathbf dy\\<br/>
&amp;= \mathbb E(Y)<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>\[<br/>
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x,y) dx<br/>
\]</p>
</blockquote>

<p>再看另外一个：<br/>
\[<br/>
\mathbb E[\mathbb E[g(X,Y) | Y]] = \mathbb E[g(X,Y)]<br/>
\]</p>

<p>证明：假设 \(X\) 和 \(Y\) 是随机变量，<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E[\mathbb E[g(X,Y) | Y]] &amp;= \int_{-\infty}^{\infty} \mathbb E[g(X,Y)|Y=y] f_Y(y) \mathbf dy\\<br/>
&amp;= \int_{-\infty}^{\infty} \bigg(\int_{-\infty}^{\infty} g(x,y) f_{X|Y}(x|y) \mathbf dx \bigg) f_Y(y) \mathbf dy\\<br/>
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x,y) f_{X|Y}(x|y) f_Y(y) \mathbf dx \mathbf dy\\<br/>
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x,y) f_{X,Y}(x,y) \mathbf dx \mathbf dy\\<br/>
&amp;= \mathbb E[g(X,Y)]<br/>
\end{align*}<br/>
\]</p></li>
<li><p><strong>Tower property</strong>：对于随机变量 \(X\)、\(Y\) 和 \(Z\)：<br/>
\[<br/>
\mathbb E[\mathbb E(X|Y,Z)|Y] = \mathbb E(X|Y)<br/>
\]</p>

<p>证明：假设 \(X\)、\(Y\) 和 \(Z\) 是连续型随机变量，令 \(g(y,z) = \mathbb E(X|Y,Z)\) ，<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E[\mathbb E(X|Y,Z)|Y=y] &amp;= \int_{-\infty}^{\infty} \mathbb E(X|Y=y,Z=z) f_{Z|Y}(z|y) \mathbf dz\\<br/>
&amp;= \int_{-\infty}^{\infty} \bigg[\int_{-\infty}^{\infty} x f_{X|Y,Z}(x|y,z) \mathbf dx \bigg] f_{Z|Y}(z|y) \mathbf dz\\<br/>
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x f_{X|Y,Z}(x|y,z) f_{Z|Y}(z|y) \mathbf dx \mathbf dz\\<br/>
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x \frac{f_{X,Y,Z}(x,y,z)}{f_{Y,Z}(y,z)}\frac{f_{Z,Y}(z,y)}{f_{Y}(y)} \mathbf dx \mathbf dz\\<br/>
&amp;= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x \frac{f_{X,Y,Z}(x,y,z)}{f_{Y}(y)} \mathbf dx \mathbf dz\\<br/>
&amp;= \int_{-\infty}^{\infty} x \frac{\int_{-\infty}^{\infty} f_{X,Y,Z}(x,y,z) \mathbf dz}{f_{Y}(y)} \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{\infty} x \frac{f_{X,Y}(x,y) }{f_{Y}(y)} \mathbf dx\\<br/>
&amp;= \int_{-\infty}^{\infty} x {f_{X|Y}(x|y)} \mathbf dx\\<br/>
&amp;= \mathbb E(X|Y=y)\\<br/>
\end{align*}<br/>
\]</p></li>
</ol>

<h4 id="toc_5">期望的一般形式</h4>

<p>普通期望：<br/>
\[<br/>
\mathbb E[X] = \left\{ \begin{array}\\<br/>
\int_{\mathcal X} x dF_X(x) = \int_{\mathcal X} x f_X(x) dx\quad&amp;\text{if }X\text{ is continuous}\\[10pt]<br/>
\int_{\Omega} X(\omega) dP(\omega)\quad&amp;\text{if }X\text{ is discrete}\\[10pt]<br/>
\end{array} \right .<br/>
\]</p>

<p>条件期望：<br/>
\[<br/>
\mathbb E[g(X|Y)|Y=y] = \left\{\begin{array}\\<br/>
\int_{\mathcal X} g(x,y) dF_{X|Y}(x|y) = \int_{\mathcal X} g(x,y) f_{X|Y}(x|y) dx\quad&amp;\text{if }X\text{ is continuous}\\[10pt]<br/>
\int_{\Omega} g(X(\omega),y) dP(\omega|Y=y)\quad&amp; \text{if }X\text{ is discrete}\\[10pt]<br/>
\end{array} \right.<br/>
\]</p>

<hr/>

<p><a href="https://en.wikipedia.org/wiki/Conditional_expectation">Conditional expectation</a><br/>
<a href="http://math.arizona.edu/%7Etgk/464_07/cond_exp.pdf">Conditional expectation</a><br/>
<a href="https://nptel.ac.in/courses/111103022/module5/lec2.pdf">Conditional expectation</a><br/>
<a href="https://people.maths.bris.ac.uk/%7Emb13434/cont_cond.pdf">Continuous conditional distributions</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15225083436209.html">Mcdiarmid 不等式</a></h1>
			<p class="meta"><time datetime="2018-03-31T22:59:03+08:00" 
			pubdate data-updated="true">2018/3/31</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>假设 \(Z_1,Z_2,...,Z_m\) 是集合 \(\mathcal Z\) 中的独立随机变量。进一步，假设 \(f:\mathcal Z_m\rightarrow \mathbb R\) 是关于 \(Z_1,Z_2,...,Z_n\) 的函数，对于所有的 \(i\) ，都有 \(z_1,z_2,...,z_n,z&#39;_i\in \mathcal X\) 满足：<br/>
\[<br/>
\sup_{z_1,...,z_n,z&#39;_i}|f(z_1,z_2,...,z_i,...,z_n) - f(z_1,z_2,...,z&#39;_i,...,z_n)| \le c_i<br/>
\]</p>

<p>对于所有的 \(\epsilon \gt 0\) 有：<br/>
\[<br/>
\begin{equation}<br/>
P\bigg[\bigg|f(Z_1,...,Z_n) - \mathbb E\Big(f(Z_1,...,Z_n)\Big)\bigg| \ge \epsilon\bigg] \le 2\exp\bigg(\frac{-2\epsilon^2}{\sum_{i=1}^n c_i^2 } \bigg)\label{pbb}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_0">证明</h3>

<p>令 \(Y = f(Z_1,...,Z_n)\) 和 \(\mu = \mathbb E(f(Z_1,...,Z_n))\) ，有：<br/>
\[<br/>
P(|Y-\mu| \ge \epsilon) = P(Y-\mu \ge \epsilon) + P(Y-\mu \le -\epsilon)<br/>
\]</p>

<p>我们现在来求不等式右边第一项的边界，第二项可以用相似的方法。</p>

<p>令 \(V_i = \mathbb E(Y|Z_1,...,Z_i) - \mathbb E(Y|Z_1,...,Z_{i-1})\) ，有：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^n V_i &amp;= V_1 + V_2 + ... + V_n\\<br/>
&amp;=  \mathbb E(Y|Z_1) - \mathbb E(Y) + \mathbb E(Y|Z_1,Z_2) - \mathbb E(Y|Z_1) + ... + \mathbb E(Y|Z_1,...,Z_n) - \mathbb E(Y|Z_1,...,Z_{n-1})\\[6pt]<br/>
&amp;= \mathbb E(Y|Z_1,...,Z_n) - \mathbb E(Y)\\[6pt]<br/>
&amp;= \mathbb E(f(Z_1,...,Z_n)|Z_1,...,Z_n) - \mathbb E(f(Z_1,...,Z_n)\\[6pt]<br/>
&amp;= f(Z_1,...,Z_n) - \mathbb E(f(Z_1,...,Z_n))\\<br/>
\end{align*}<br/>
\]</p>

<p>要证明的原式 \ref{pbb} 等价于证明下式：<br/>
\[<br/>
\begin{align}<br/>
P\bigg[f(Z_1,...,Z_n) - \mathbb E\Big(f(Z_1,...,Z_n)\Big) \ge \epsilon\bigg] &amp;= P\bigg(\sum_{i=1}^n V_i \ge \epsilon\bigg) \label{pbbf1}\\<br/>
&amp;= P\Big(e^{t\sum_{i=1}^n V_i} \ge e^{t\epsilon}\Big) \label{pbbf2}\\<br/>
&amp;= e^{-t\epsilon} \mathbb E\Big(e^{t\sum_{i=1}^n V_i}\Big) \label{pbbf3}\\<br/>
&amp;= e^{-t\epsilon} \mathbb E\Big(\mathbb E\big[ e^{t\sum_{i=1}^n V_i} \big |Z_1,...,Z_{n-1}\big]\Big) \label{pbbf4}\\<br/>
&amp;= e^{-t\epsilon} \mathbb E\Big(\mathbb E\big[ e^{t\sum_{i=1}^{n-1} V_i + tV_n} \big |Z_1,...,Z_{n-1}\big]\Big) \label{pbbf5}\\<br/>
&amp;= e^{-t\epsilon} \mathbb E\Big(\mathbb E\big[ e^{t\sum_{i=1}^{n-1} V_i} e^{tV_n} \big |Z_1,...,Z_{n-1}\big]\Big) \label{pbbf6}\\<br/>
&amp;= e^{-t\epsilon} \mathbb E\Big(e^{t\sum_{i=1}^{n-1} V_i} \mathbb E \big[e^{tV_n} \big |Z_1,...,Z_{n-1}\big]\Big) \label{pbbf7}\\<br/>
\end{align}<br/>
\]</p>

<p>上式中 \ref{pbbf2} 到 \ref{pbbf3} 是利用了马尔可夫不等式得到。从 \ref{pbbf3} 到 \ref{pbbf4} 式应用了条件期望的 LIE 的性质。式 \ref{pbbf6} 中可以将 \(e^{t\sum_{i=1}^{n-1} V_i}\) 看成关于 \(Z_1,Z_2,...,Z_{n-1}\) 的函数，将 \(e^{tV_n}\) 看成关于 \(V_1,...,V_n\) 的函数，利用条件期望的稳定性可得。 </p>

<p>现在需要证明的式中 \(\mathbb E[e^{tV_n} \big |Z_1,...,Z_{n-1}\big]\) 和霍夫丁不等式形式一样，考虑到：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E[V_i|Z_1,...,Z_{i-1}] &amp;= \mathbb E\Big[\mathbb E(Y|Z_1,...,Z_i) - \mathbb E(Y|Z_1,...,Z_{i-1})\Big|Z_1,...,Z_{i-1}\Big]\\<br/>
&amp;= \mathbb E\Big[\mathbb E(Y|Z_1,...,Z_i)\Big|Z_1,...,Z_{i-1}\Big] - \mathbb E\Big[\mathbb E(Y|Z_1,...,Z_{i-1}) \Big |Z_1,...,Z_{i-1} \Big]\\<br/>
&amp;= \mathbb E(Y|Z_1,...,Z_{i-1}) - \mathbb E(Y|Z_1,...,Z_{i-1}) \\<br/>
&amp;= 0<br/>
\end{align*}<br/>
\]</p>

<p>为了使用霍夫丁引理还需要知道 \((V_i|Z_1,...,Z_{i-1})\) 的上下界，已知：<br/>
\[<br/>
V_i|Z_1,...,Z_{i-1} = \Big[\mathbb E(Y|Z_1,...,Z_i) - \mathbb E(Y|Z_1,...,Z_{i-1})\Big]\Big| Z_1,...,Z_{i-1}<br/>
\]</p>

<p>令：<br/>
\[<br/>
\begin{align*}<br/>
U_i &amp;= \sup_u \mathbb E\big[Y|Z_1,...,Z_{i-1},u \big]-\mathbb E\big[Y|Z_1,...,Z_{i-1}\big]\\<br/>
L_i &amp;= \inf_l  \mathbb E\Big[Y|Z_1,...,Z_{i-1},l \big]-\mathbb E\big[Y|Z_1,...,Z_{i-1}\big]\\<br/>
\end{align*}<br/>
\]</p>

<p>所以有：<br/>
\[<br/>
L_i \le V_i|Z_1,...,Z_{i-1} \le U_i<br/>
\]</p>

<p>现在：<br/>
\[<br/>
\begin{align}<br/>
U_i - L_i &amp;= \sup_{u} \mathbb E[f(Z_1,...,Z_n)|Z_1,...,Z_{i-1},u] - \inf_{l} \mathbb E[f(Z_1,...,Z_n)|Z_1,...,Z_{i-1},l] \nonumber\\<br/>
&amp;= \sup_{u} \int f(Z_1,...Z_{i-1},u,z_{i+1},...,z_n) \mathbf dP(z_{i+1},...,z_n|Z_1,...Z_{i-1},u) - \inf_{l} \int f(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n)\mathbf dP(z_{i+1},...,z_n|Z_1,...Z_{i-1},l)\nonumber\\<br/>
&amp;= \sup_{u} \int f(Z_1,...Z_{i-1},u,z_{i+1},...,z_n) \mathbf d\frac{P(Z_1,...Z_{i-1},u,z_{i+1},...,z_n)}{P(Z_1,...,Z_{i-1},u)}  - \inf_{l} \int f(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n)\mathbf d\frac{P(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n)}{P(Z_1,...,Z_{i-1},l)}\nonumber\\<br/>
&amp;= \sup_{u} \int f(Z_1,...Z_{i-1},u,z_{i+1},...,z_n) \mathbf d\frac{P(Z_1,...Z_{i-1},u)\cdot P(z_{i+1},...,z_n)}{P(Z_1,...,Z_{i-1},u)}  - \inf_{l} \int f(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n)\mathbf d\frac{P(Z_1,...,Z_{i-1},l)\cdot P(z_{i+1},...,z_n)}{P(Z_1,...,Z_{i-1},l)}\nonumber\\<br/>
&amp;= \sup_{u} \int f(Z_1,...Z_{i-1},u,z_{i+1},...,z_n) \mathbf d P(z_{i+1},...,z_n) - \inf_{l} \int f(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n)\mathbf d P(z_{i+1},...,z_n)\nonumber\\<br/>
&amp;\le \sup_{u,l} \bigg [\int f(Z_1,...Z_{i-1},u,z_{i+1},...,z_n)\mathbf d P(z_{i+1},...,z_n) - \int f(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n) \mathbf d P(z_{i+1},...,z_n)\bigg ]\nonumber\\<br/>
&amp;=  \sup_{u,l} \int \bigg [f(Z_1,...Z_{i-1},u,z_{i+1},...,z_n) - f(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n) \bigg ]\mathbf d P(z_{i+1},...,z_n)\nonumber\\<br/>
&amp;\le  \int \sup_{u,l} \Big[f(Z_1,...Z_{i-1},u,z_{i+1},...,z_n) - f(Z_1,...,Z_{i-1},l,z_{i+1},...,z_n) \Big]\mathbf d P(z_{i+1},...,z_n)\nonumber\\<br/>
&amp;\le \int c_i \mathbf d P(z_{i+1},...,z_n)\nonumber\\<br/>
&amp;= c_i\nonumber\\<br/>
\end{align}<br/>
\]</p>

<p>上式倒数第四行因为 sup 是下凸函数，使用 Jensen不等式可以交换 sup 与积分顺序。</p>

<blockquote>
<p>上确界函数的凸性：假设 \(X\) 是任意随机变量，对于任意的 \(f\) 都有<br/>
\[<br/>
\sup_{y\in Y} \int f(X,y) \le \int \sup_{y\in Y} f(X,y)<br/>
\]</p>

<p>证明很简单，因为<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad f(X,y) \le \sup_{y\in Y} f(X,y)\\<br/>
&amp;\therefore\quad \int f(X,y) \le \int \sup_{y\in Y} f(X,y)\\<br/>
&amp;\therefore\quad \sup_{y\in Y} \int f(X,y) \le \int \sup_{y\in Y} f(X,y)<br/>
\end{align*}<br/>
\]</p>
</blockquote>

<p>若令 \(a = L_i\)，\(b = a + c_i\)，则 \(a \le V_i|Z_1,...,Z_{i-1} \le b\)，应用霍夫丁引理：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E\big[e^{tV_n} \big |Z_1,...,Z_{n-1}\big] &amp;\le \exp\Big(\frac{t^2(b-a)^2}{8} \Big)\\<br/>
&amp;= \exp\Big(\frac{t^2(a+c_n-a)^2}{8} \Big)\\<br/>
&amp;= \exp\Big(\frac{t^2 c_n^2}{8} \Big)\\<br/>
\end{align*}<br/>
\]</p>

<p>代入 \ref{pbbf7} 式可得：<br/>
\[<br/>
\begin{align*}<br/>
e^{-t\epsilon} \mathbb E\Big(e^{t\sum_{i=1}^{n-1} V_i} \mathbb E \big[e^{tV_n} \big |Z_1,...,Z_{n-1}\big]\Big) &amp;\le e^{-t\epsilon} \mathbb E\Big(e^{t\sum_{i=1}^{n-1} V_i} \exp\Big(\frac{t^2 c_n^2}{8} \Big)\Big)\\<br/>
&amp;= e^{-t\epsilon} \exp\Big(\frac{t^2 c_n^2}{8} \Big)\mathbb E\Big(e^{t\sum_{i=1}^{n-1} V_i}\Big)\\<br/>
&amp;= e^{-t\epsilon} \exp\Big(\sum_{n-1}^n \frac{t^2 c_n^2}{8} \Big)\mathbb E\Big(e^{t\sum_{i=1}^{n-2} V_i}\Big)\\<br/>
&amp;= \cdots \\<br/>
&amp;= e^{-t\epsilon} \exp\Big(\sum_{i=1}^n \frac{t^2 c_i^2}{8} \Big)\\<br/>
&amp;= \exp\Big(\sum_{i=1}^n \frac{t^2 c_i^2}{8} -t\epsilon\Big)<br/>
\end{align*}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
P\bigg[f(Z_1,...,Z_n) - \mathbb E\Big(f(Z_1,...,Z_n)\Big) \ge \epsilon\bigg] \le \exp\Big(\sum_{i=1}^n \frac{t^2 c_i^2}{8} -t\epsilon\Big)<br/>
\]</p>

<p>取<br/>
\[<br/>
t= \frac{4\epsilon}{\sum_{i=1}^n c_i^2}<br/>
\]</p>

<p>时，<br/>
\[<br/>
P\bigg[f(Z_1,...,Z_n) - \mathbb E\Big(f(Z_1,...,Z_n)\Big) \ge \epsilon\bigg] \le \exp\Big(-\frac{2\epsilon^2}{\sum_{i=1}^n c_i^2}\Big)<br/>
\]</p>

<p>原不等式为：<br/>
\[<br/>
P\bigg[\bigg|f(Z_1,...,Z_n) - \mathbb E\Big(f(Z_1,...,Z_n)\Big)\bigg| \ge \epsilon\bigg] \le 2\exp\Big(-\frac{2\epsilon^2}{\sum_{i=1}^n c_i^2}\Big)<br/>
\]</p>

<hr/>

<p><a href="https://cs.nyu.edu/%7Erostami/ml/2007/ashish-mcdiarmid.pdf">ashish-mcdiarmid</a><br/>
<a href="http://www.stat.cmu.edu/%7Elarry/=sml/Concentration.pdf">Concentration of Measure</a><br/>
<a href="https://stats.stackexchange.com/questions/21362/understanding-proof-of-mcdiarmids-inequality">understanding proof of mcdiarmids inequality</a><br/>
<a href="http://web.eecs.umich.edu/%7Ecscott/past_courses/eecs598w14/notes/09_bounded_difference.pdf">The Bounded Difference Inequality</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15218222204104.html">Rademacher 复杂度</a></h1>
			<p class="meta"><time datetime="2018-03-24T00:23:40+08:00" 
			pubdate data-updated="true">2018/3/24</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>VC 维的泛化误差是分布无关、数据独立的，也就是对于任何数据分布都成立，这使得基于 VC 维的可学习分析结果具有一定的“普适性”；但从另一方面来说，由于没有考虑数据自身，基于 VC 维得到的泛化误差界通常比较 “松”，对那些与学习问题的典型情况相差甚远的较“坏”分布尤其如此。</p>

<p>Rademacher 复杂度是另一种刻画假设空间复杂度的途径，与 VC 维不同的是，它在一定程度上考虑了数据分布。</p>

<p>给定训练集 \(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)，假设 \(h\) 的经验误差为：<br/>
\[<br/>
\begin{align*}\\<br/>
\hat E(h) &amp;= \frac 1 m \sum_{i=1}^m \mathbf I(h(x_i) \neq y_i )\\<br/>
&amp;= \frac 1 m \sum_{i=1}^m \frac{1-y_ih(x_i)}{2}\\<br/>
&amp;= \frac 1 {2} - \frac 1{2m} \sum_{i=1}^m y_i h(x_i)<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\frac 1 m \sum_{i=1}^m y_ih(x_i)\) 体现了预测值 \(h(x_i)\) 和样例真实标记 \(y_i\) 之间的一致性，若对于所有的 \(i\in\{1,2,...,m\}\) 都有 \(y_i = h(x_i)\) ，则 \(\frac 1 m \sum_{i=1}^m y_ih(x_i)\) 取最大值 1 。也就是说，经验误差最小的假设是：<br/>
\[<br/>
\begin{equation}<br/>
{\arg\min}_{h\in \mathcal H}\frac 1 m \sum_{i=1}^m y_i h(x_i)\label{ahm}\\<br/>
\end{equation}<br/>
\]</p>

<p>在现实任务中，样本标记可能受到噪音影响，即对某些样例 \((x_i,y_i)\)，\(y_i\) 可能或许已经受到影响，不再是 \(x_i\) 的真实标记，在此情形下，选择假设空间 \(\mathcal H\) 中表现最好的假设，有时还不如选择 \(\mathcal H\) 中事先考虑了随机噪声影响的假设。</p>

<p>考虑随机变量 \(\sigma_i\) ，它以 0.5 的概率取值 -1，以 0.5 的概率取值 +1，称为 Radermacher 随机变量：<br/>
\[<br/>
P(\sigma_i = 1) = P(\sigma_i = -1) = 0.5<br/>
\]</p>

<p>基于 \(\sigma_i\)，可将式 \ref{ahm} 重写为：<br/>
\[<br/>
\begin{equation}<br/>
\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \label{shm}<br/>
\end{equation}<br/>
\]</p>

<p>\(\mathcal H\) 是无限假设空间，有可能取不到最大值，因此使用上确界带条最大值。</p>

<p>考虑 \(\mathcal H\) 中的所有假设，对 \ref{shm} 式取期望可得：<br/>
\[<br/>
\begin{equation}<br/>
\mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \bigg] \label{eshm}\\<br/>
\end{equation}<br/>
\]</p>

<p>其中 \(\mathbb \sigma=\{\sigma_1,\sigma_2,...,\sigma_m\}\) ，式 \ref{eshm} 的取值范围为 \([0,1]\)，它体现了假设空间 \(\mathcal H\) 的表达能力，例如当 \(|\mathcal H| =1 \) 时，\(\mathcal H\) 中仅有一个假设，这时可计算出式 \ref{eshm} 的值为0：<br/>
\[<br/>
\mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \bigg] = 0.5 \cdot h(x_i) - 0.5\cdot h(x_i) = 0<br/>
\]</p>

<p>当 \(|\mathcal H|=2^m\) 且 \(\mathcal H\) 能打散 \(D\) 时，对于任意的 \(\mathbb \sigma\) 都存在一个假设 \(h(x_i) = \sigma_i;i=1,2,...,m\)，这时可计算出式 \ref{eshm} 的值为1：<br/>
\[<br/>
\mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \bigg] =  \frac 1 m\bigg(\sum_{h(x_i)=1} 1\cdot h(x_i) + \sum_{h(x_i) = -1} (-1)\cdot h(x_i)\bigg) = \frac 1 m \sum_{i=1}^m |h(x_i)| = 1<br/>
\]</p>

<p>考虑实值函数空间 \(\mathcal F:\mathcal Z\rightarrow \mathbb R\)。令 \(Z=\{z_1,z_2,...,z_m \}\)，其中 \(z_i \in \mathcal Z\)，将 \ref{eshm} 中的 \(\mathcal X\) 和 \(\mathcal H\) 替换为 \(\mathcal Z\) 和 \(\mathcal F\) 可得</p>

<p><strong>定义1</strong>：函数空间 \(\mathcal F\) 关于 \(Z\) 的经验 Rademacher 复杂度：<br/>
\[<br/>
\begin{equation}<br/>
\hat R_Z(\mathcal F) = \mathbb E_\sigma\bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i f(z_i) \bigg]\label{hrme}\\<br/>
\end{equation}<br/>
\]</p>

<p>经验 Rademacher 复杂度衡量了函数空间 \(\mathcal F\) 与随机噪声在集合 \(Z\) 中的相关性。通常我们希望了解函数空间 \(\mathcal F\) 在 \(\mathcal Z\) 上关于 \(\mathcal D\) 的相关性，因此，对所有从 \(\mathcal D\) 独立同分布采样而得的大小为 \(m\) 的集合 \(Z\) 求期望可得：</p>

<p><strong>定义2</strong>：函数空间 \(\mathcal F\) 关于 \(\mathcal Z\) 上分布 \(\mathcal D\) 的 Rademacher 复杂度：<br/>
\[<br/>
\begin{equation}<br/>
R_m(\mathcal F) = \mathbb E_{Z\subset \mathcal Z:|Z|=m}\bigg[ \hat R_Z(\mathcal F) \bigg] \label{rmmm}\\<br/>
\end{equation}<br/>
\]</p>

<p>基于 Rademacher 复杂度可得关于函数空间 \(\mathcal F\) 的泛化误差界。</p>

<p><strong>定理1</strong> 对实数函数空间 \(\mathcal F:\mathcal Z\rightarrow[0,1]\)，根据分布 \(\mathcal D\) 从 \(\mathcal Z\) 中独立同分布采样得到示例集集 \(Z=\{z_1,z_2,...,z_m\}\)，\(z_i \in \mathcal Z\)，\(0\lt \delta \lt 1\)，对任意的 \(f\in \mathcal F\)，以至少 \(1-\delta\) 的概率有：<br/>
\[<br/>
\begin{align}<br/>
\mathbb E[f(z)] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\label{mdl1}\\<br/>
\mathbb E[f(z)] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2\hat R_Z(\mathcal F) + 3\sqrt{\frac{\ln(1/\delta)}{2m}}\label{mdl2}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：令<br/>
\[<br/>
\begin{align}<br/>
\hat E_Z(f) &amp;= \frac 1 m \sum_{i=1}^m f(z_i)\label{hate}\\<br/>
\Phi(Z) &amp;= \sup_{f\in\mathcal F}\mathbb E[f] - \hat E_Z(f)\label{phiz}<br/>
\end{align}<br/>
\]</p>

<p>同时令 \(Z&#39;\) 为只与 \(Z\) 有一个示例不同的训练集，不妨设 \(z_m\in Z\) 和 \(z_m&#39;\in Z&#39;\) 为不同示例，可得：<br/>
\[<br/>
\begin{align*}<br/>
\Phi(Z&#39;) - \Phi(Z) = \bigg(\sup_{f\in \mathcal F}\mathbb E[f] - \hat E_{Z&#39;}(f) \bigg) - \bigg (\sup_{f \in \mathcal F} \mathbb E[f] - \hat E_Z(f) \bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(f&#39; = {\arg\max}_{f\in \mathcal F} E[f] - \hat E_{Z&#39;}(f)\) 代入上式：<br/>
\[<br/>
\begin{align*}<br/>
\Phi(Z&#39;) - \Phi(Z) &amp;= \bigg(\sup_{f\in \mathcal F}\mathbb E[f] - \hat E_{Z&#39;}(f) \bigg) - \bigg (\sup_{f \in \mathcal F} \mathbb E[f] - \hat E_Z(f) \bigg)\\<br/>
&amp;\le \bigg(\mathbb E[f&#39;] - \hat E_{Z&#39;}(f&#39;) \bigg) - \bigg(\mathbb E[f&#39;] - \hat E_Z(f&#39;) \bigg)\\<br/>
&amp;\le \hat E_Z(f&#39;) - \hat E_{Z&#39;}(f&#39;)\\<br/>
&amp;\le \sup_{f\in \mathcal F} \hat E_Z(f) - \hat E_{Z&#39;}(f)\\<br/>
&amp;= \sum_{f\in\mathcal F} \frac {f(z_m) - f(z&#39;_m)}{m}\\<br/>
&amp;\le \frac 1 m<br/>
\end{align*}<br/>
\]</p>

<p>同理可得：<br/>
\[<br/>
\begin{align*}<br/>
\Phi(Z) - \Phi(Z&#39;) &amp;\le \frac 1 m\\<br/>
|\Phi(Z) - \Phi(Z&#39;)| &amp;\le \frac 1 m\\<br/>
\end{align*}<br/>
\]</p>

<p>根据 McDiarmid 不等式可知，对任意的 \(\delta \in (0,1)\)，<br/>
\[<br/>
\begin{align}<br/>
\Phi(Z) \le \mathbb E_Z[\Phi(Z)] + \sqrt{\frac{\ln(1/\delta)}{2m}}\label{phil}<br/>
\end{align}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立，下面来估计 \(\mathbb E_Z[\Phi(Z)]\) 的上界：<br/>
\[<br/>
\begin{align}<br/>
\mathbb E_Z[\Phi(Z)] &amp;= \mathbb E_Z\bigg[\sup_{f \in \mathcal F}\mathbb E[f] - \hat E_Z(f) \bigg]\label{mep1}\\<br/>
&amp;= \mathbb E_Z\bigg[ \sup_{f\in \mathcal F} \mathbb E_{Z&#39;}[\hat E_{Z&#39;}(f) - \hat E_Z(f)] \bigg]\label{mep2}\\<br/>
&amp;\le \mathbb E_{Z,Z&#39;} \bigg[\sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f) \bigg] \label{mep3}\\<br/>
&amp;= \mathbb E_{Z,Z&#39;} \bigg[\sup_{f\in \mathcal F} \frac 1 m \sum_{i=1}^m (f(z&#39;_i) - f(z_i))\bigg]\label{mep4}\\<br/>
&amp;= \mathbb E_{\mathbf \sigma,Z,Z&#39;} \bigg[\sup_{f\in \mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i(f(z&#39;_i) - f(z_i))\bigg]\label{mep5}\\<br/>
&amp;\le \mathbb E_{\mathbf \sigma,Z&#39;} \bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i f(z&#39;_i) \bigg] + \mathbb E_{\mathbf \sigma,Z} \bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m -\sigma_i f(z_i) \bigg]\label{mep6}\\<br/>
&amp;= 2\mathbb E_{\mathbf \sigma,Z} \bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i f(z_i) \bigg] = 2R_m(\mathcal F) \label{mep7}\\<br/>
\end{align}<br/>
\]</p>

<p>等式 \ref{mep1} 变成 \ref{mep2} 是因为 \(Z&#39;\) 是独立同分布采样于 \(\mathcal Z\) 所以 \(\mathbb E[f] = \mathbb E_{Z&#39;} \bigg[\hat E_{Z&#39;}(f)\bigg]\)。等式 \ref{mep3} 利用 Jensen 不等式和上确界函数的凸性可以得到。在等式 \ref{mep5} 中，我们引入了 Rademacher 变量 \(\sigma_i\) ，它是在 \([-1,1]\) 之间的均匀分布独立随机变量，并不会改变等式 \ref{mep4} 中的期望。当 \(\sigma_i=1\) 时，原式不变；当 \(\sigma_i=-1\) 关联的加数符号翻转，也就相当于交换在 \(Z\) 和 \(Z&#39;\) 中交换 \(z_i\) 和 \(z&#39;_i\)。因为我们是在所有可能的 \(Z\) 和 \(Z&#39;\) 上求期望，因此交换并不会影响最终期望。我们可以利用上确界加法的特性 \(\sup(U+V) \le \sup(U) + \sup(V)\) 得到等式 \ref{mep6}。最后等式 \ref{mep7} 是来源于 Rademacher 复杂度的定义和 \(\sigma_i\) 和 \(-\sigma_i\) 是同一个分布。</p>

<blockquote>
<p><strong>上确界函数的凸性</strong>：假设 \(X\) 是任意随机变量，对于任意的 \(f\) 都有<br/>
\[<br/>
\sup_{y\in Y} \mathbb E[f(X,y)] \le \mathbb E[\sup_{y\in Y} f(X,y)]<br/>
\]</p>

<p>证明很简单，因为<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad f(X,y) \le \sup_{y\in Y} f(X,y)\\<br/>
&amp;\therefore\quad \mathbb E[f(X,y)] \le \mathbb E[\sup_{y\in Y} f(X,y)]\\<br/>
&amp;\therefore\quad \sup_{y\in Y} \mathbb E[f(X,y)] \le \mathbb E[\sup_{y\in Y} f(X,y)]<br/>
\end{align*}<br/>
\]</p>

<p>等式 \ref{mep3} 可以同样由这样得到<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad \hat E_{Z&#39;}(f) - \hat E_Z(f) \le \sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f)\\<br/>
&amp;\therefore\quad \mathbb E_{Z&#39;}[\hat E_{Z&#39;}(f) - \hat E_Z(f)] \le \mathbb E_{Z&#39;}[\sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f)]\\<br/>
&amp;\therefore\quad \sup_{f\in \mathcal F}\mathbb E_{Z&#39;}[\hat E_{Z&#39;}(f) - \hat E_Z(f)] \le \mathbb E_{Z&#39;}[\sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f)]\\<br/>
\end{align*}<br/>
\]</p>
</blockquote>

<p>将式 \ref{mep7} 、\ref{hate} 和 \ref{phiz} 代入式 \ref{phil} 可得：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sup_{f\in\mathcal F}\mathbb E[f] - \frac 1 m \sum_{i=1}^m f(z_i) \le 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
&amp;\Rightarrow \sup_{f\in\mathcal F}\mathbb E[f] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
&amp;\Rightarrow \mathbb E[f] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
\end{align*}<br/>
\]</p>

<p>至此，式 \ref{mdl1} 得证。</p>

<p>由<strong>定义2</strong>可知，改变 \(Z\) 中的一个示例对 \(\hat R_Z(\mathcal F)\) 的值所造成的改变最多为 \(1/m\)。由 McDiarmid 不等式可知：<br/>
\[<br/>
\begin{equation}<br/>
R_m(\mathcal F) \le \hat R_Z(\mathcal F) + \sqrt{\frac{\ln(2/\delta)}{2m}}\label{rmmf}<br/>
\end{equation}<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。再由 \ref{phil} 可知：<br/>
\[<br/>
\begin{equation}<br/>
\Phi(Z) \le \mathbb E_Z[\Phi(Z)] + \sqrt{\frac{\ln(2/\delta)}{2m}}\label{plme}\\<br/>
\end{equation}<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。</p>

<p>将式 \ref{mep7} 代入式 \ref{plme} 可得：<br/>
\[<br/>
\begin{align}<br/>
\Phi(Z) &amp;\le 2R_m(\mathcal F) + \sqrt{\frac{\ln(2/\delta)}{2m}}\nonumber\\<br/>
&amp;\le 2\big( \hat R_Z(\mathcal F) + \sqrt{\frac{\ln(2/\delta)}{2m}} \big) + \sqrt{\frac{\ln(2/\delta)}{2m}}\nonumber\\<br/>
&amp;= 2\hat R_Z(\mathcal F) + 3\sqrt{\frac{\ln(2/\delta)}{2m}}\label{2hrz}\\<br/>
\end{align}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立。</p>

<p>将 \ref{2hrz} 、\ref{hate} 和 \ref{phiz} 代入式 \ref{phil} 得式 \ref{mdl2} 得证。</p>

<p>上面证明的<strong>定理1</strong>的函数空间 \(\mathcal F\) 是区间 \([0,1]\) 上的实值函数，因此该定理只适用于回归问题。对二分类问题，我们有下面的定理：</p>

<p><strong>定理2</strong>：对假设空间 \(\mathcal H:\mathcal X\rightarrow \{-1,+1\}\)，根据分布 \(\mathcal D\) 从 \(\mathcal X\) 中独立同分布采样得到示例集 \(D=\{x_1,x_2,...,x_m \}\)，\(x_i\in \mathcal X\)，\(0\lt \delta \lt 1\)，对任意 \(h \in \mathcal H\)，以至少 \(1-\delta\) 的概率有：<br/>
\[<br/>
\begin{align}<br/>
E(h) &amp;\le \hat E(h) + R_m(\mathcal H) + \sqrt{\frac{\ln(1/\delta)}{2m}}\label{elhe1}\\<br/>
E(h) &amp;\le \hat E(h) + R_D(\mathcal H) + 3\sqrt{\frac{\ln(1/\delta)}{2m}}\label{elhe2}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：对二分类问题的假设空间 \(\mathcal H\)，令\(\mathcal Z=\mathcal X\times \{-1,+1\}\)，对 \(\mathcal H\) 中假设 \(h\) 变形为：<br/>
\[<br/>
f_h(z) = f_h(x,y) = \mathbf I(h(x) \neq y)<br/>
\]</p>

<p>于是就可以将值域在 \(\{-1,1\}\) 的假设空间 \(\mathcal H\) 转换为值域为 \([0,1]\) 的函数空间 \(\mathcal F_{\mathcal H} = \{f_h:h\in \mathcal H\}\)，由Radermacher 复杂度的<strong>定义1</strong> 有：<br/>
\[<br/>
\begin{align}<br/>
\hat R_Z(\mathcal F_{\mathcal H}) &amp;= \mathbb E_\sigma\bigg[\sup_{f_h\in\mathcal F_{\mathcal H}} \frac 1 m \sum_{i=1}^m \sigma_i f_h(x_i,y_i) \bigg]\nonumber\\<br/>
&amp;= \mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i \mathbf I(h(x_i)\neq y_i) \bigg]\nonumber\\<br/>
&amp;= \mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i \frac{1-y_i h(x_i)}{2} \bigg]\nonumber\\<br/>
&amp;= \frac 1 2\mathbb E_\sigma\bigg[ \frac 1 m \sum_{i=1}^m \sigma_i + \sup_{h\in \mathcal H} \frac 1 m \sum_{i=1}^m(-y_i\sigma_i h(x_i)) \bigg]\nonumber\\<br/>
&amp;= \frac 1 2\mathbb E_\sigma\bigg[\sup_{h\in \mathcal H} \frac 1 m \sum_{i=1}^m(-y_i\sigma_i h(x_i)) \bigg]\label{f12m}\\<br/>
&amp;= \frac 1 2\mathbb E_\sigma\bigg[\sup_{h\in \mathcal H} \frac 1 m \sum_{i=1}^m(\sigma_i h(x_i)) \bigg]\label{f12m2}\\<br/>
&amp;= \frac 1 2 \hat R_D(\mathcal H)\label{f12m3}\\<br/>
\end{align}<br/>
\]</p>

<p>在式 \ref{f12m} 中由于 \(-y_i\sigma_i\) 与 \(\sigma_i\) 的分布相同，所以可以转换成式 \ref{f12m2} 结果不变。</p>

<p>对上式取期望后可得<br/>
\[<br/>
\begin{align}<br/>
R_m(\mathcal F_{\mathcal H}) = \frac 1 2R_m(\mathcal H)\label{rmmfm}<br/>
\end{align}<br/>
\]</p>

<p>由<strong>定理1</strong>和式(\ref{f12m3})和(\ref{rmmfm})可知<strong>定理2</strong>成立。</p>

<p><strong>定理2</strong>给出了基于 Rademacher 复杂度的泛化误差界。我们知道VC维的泛化误差界式分布无关、数据独立的，而基于 Rademacher 复杂度的泛化误差界(\ref{mdl1})与分布 \(\mathcal D\) 有关，式(\ref{mdl2})与数据 \(D\) 有关。换言之，基于 Rademacher 复杂度的泛化误差界依赖于具体学习问题上的数据分布，有点类似于为该学习问题“量身定制”的，因此它通常比基于VC维的泛化误差界更紧一些。</p>

<p><strong>Massart引理</strong>：用 \(A\subseteq \mathbb R^m\) 是一个有限集，有 \(R=\max_{x\in A}||x||_2\)，然后满足下式：<br/>
\[<br/>
E_{\sigma} \bigg[\frac 1 m \sup_{x\in A} \sum_{i=1}^m \sigma_i x_i \bigg] \le \frac{R\sqrt{2\ln|A|}}{m}<br/>
\]</p>

<p>其中 \(\sigma_i\) 是一系列在 \(\{−1,+1\}\) 上取值的独立的符合平均分布的随机变量。</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\exp\bigg(t E_{\sigma} \bigg[\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg]\bigg) &amp;\le E_{\sigma} \bigg[\exp\bigg(t\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg)\bigg]\quad\big(\text{Jensen Inequality}\big)\\<br/>
&amp;= E_{\sigma} \bigg[\sup_{x\in A} \exp\bigg(t\sum_{i=1}^m \sigma_i x_i  \bigg)\bigg]\\<br/>
&amp;\le \sum_{x\in A} E_{\sigma} \bigg[\exp\bigg(t\sum_{i=1}^m \sigma_i x_i  \bigg)\bigg]\\ <br/>
&amp;= \sum_{x\in A} \prod_{i=1}^m E_{\sigma} \big[\exp\big(t\sigma_i x_i  \big)\big]\\ <br/>
&amp;\le \sum_{x\in A} \prod_{i=1}^m \exp\bigg( \frac{t^2(2x_i)^2}{8} \bigg)\quad\big(\text{Hoeffding Inequality}\big)\\<br/>
&amp;= \sum_{x\in A} \exp\bigg(\frac{4\sum_{i=1}^m t^2(x_i)^2}{8} \bigg)\\<br/>
&amp;= \sum_{x\in A} \exp\bigg(\frac{t^2}{2} \sum_{i=1}^m (x_i)^2\bigg)\\<br/>
&amp;\le |A| \exp\bigg(\frac{t^2R^2}{2} \bigg)<br/>
\end{align*}<br/>
\]</p>

<p>对两边取对数<br/>
\[<br/>
\begin{align*}<br/>
E_{\sigma} \bigg[\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg] &amp;\le \frac 1 t\log\bigg[|A| \exp\bigg(\frac{t^2R^2}{2} \bigg) \bigg]\\<br/>
&amp;= \frac{\ln|A|}{t} + \frac{tR^2}{2}<br/>
\end{align*}<br/>
\]</p>

<p>对上式右边对 \(t\) 取导数，并令其等于 0，可得令不等式最小的 \(t\)<br/>
\[<br/>
t = \frac{\sqrt{2\ln|A|}}{R}<br/>
\]</p>

<p>所以不等式<br/>
\[<br/>
E_{\sigma} \bigg[\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg] \le R\sqrt{2\ln|A|}<br/>
\]</p>

<p><strong>Massart引理</strong>得证。</p>

<p><strong>定理3</strong>：假设空间 \(\mathcal H\)的 Ramacher 复杂度 \(R_m(\mathcal H)\) 与增长函数 \(\Pi_\mathcal H(m)\) 满足<br/>
\[<br/>
R_m(\mathcal H) \le \sqrt{\frac{2\ln\Pi_\mathcal H(m)}{m}}<br/>
\]</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\hat R_Z(\mathcal H) &amp;= \mathbb E_\sigma\bigg[\sup_{f\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i f(z_i) \bigg]\\<br/>
&amp;\le \frac{\sqrt{m} \sqrt{2\ln|\{(h(x_i),...,h(x_m)):h\in \mathcal H|\}}}{m}\quad\big(\text{Massart Lemma}\big)\\<br/>
&amp;= \frac{\sqrt{m} \sqrt{2\ln \Pi_\mathcal H(m)}}{m}\\<br/>
&amp;= \sqrt{\frac{2\ln \Pi_\mathcal H(m)}{m}}<br/>
\end{align*}<br/>
\]</p>

<p>式中 \(R=\sqrt{m}\) 是因为 \(R=\max_{h\in \mathcal H}||h||_2\)，因为 \(h\) 的取值是 \(\{-1,+1\}\)，所以 \(||h||_2 = \sqrt{m}\)。</p>

<p>由式(\ref{elhe1}) 和<strong>定理3</strong>可得<br/>
\[<br/>
E(h) \le \hat E(h) + \sqrt{\frac{2d\ln(em/d)}{m}} + \sqrt{\frac{\ln(1/\delta)}{2m}}<br/>
\]</p>

<p>也就是说，我们从 Rademacher 复杂度和增长函数就能推导出基于 VC 维的泛化误差界。</p>

<hr/>

<p><a href="">周志华 机器学习</a><br/>
<a href="https://math.stackexchange.com/questions/2230255/supremum-of-expectation-le-expectation-of-supremum">supremum of expectation and expectation of supremum</a><br/>
<a href="http://www.it610.com/article/1342038.htm">FML 学习笔记三</a><br/>
<a href="https://cs.nyu.edu/%7Emohri/mls/ml_learning_with_infinite_hypothesis_sets.pdf">Foundations of Machine Learning</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15205961685497.html">隐马尔可夫模型 Hidden Markov Model</a></h1>
			<p class="meta"><time datetime="2018-03-09T19:49:28+08:00" 
			pubdate data-updated="true">2018/3/9</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>关于隐马尔可夫模型有个很生动的例子，假设有一个隐士，他不能够直接获取到天气的观察情况，但是他有一些水藻。民间传说告诉我们水藻的状态与天气状态有一定的概率关系——天气和水藻的状态是紧密相关的。在这个例子中我们有两组状态，观察的状态（水藻的状态）和隐藏的状态（天气的状态）。我们希望为隐士设计一种算法，在不能够直接观察天气的情况下，通过水藻和马尔科夫假设来预测天气。</p>

<p>在这种情况下，观察到的状态序列与隐藏过程有一定的概率关系。我们使用隐马尔科夫模型对这样的过程建模，这个模型包含了一个底层隐藏的随时间改变的马尔科夫过程，以及一个与隐藏状态某种程度相关的可观察到的状态集合。</p>

<p>下图是隐藏状态（天气）与观察序列的示意图，假设隐藏状态由一个简单的一阶马尔可夫过程描述，那么他们之间都相互连接。</p>

<div align="center">
    <img src="media/15205961685497/15366882957510.jpg" width="500" />
</div>

<p>隐藏状态和观察状态之间的连接表示：在给定的马尔可夫过程中，一个隐藏状态生成特定的观察状态的概率。可以很清晰知道一个隐藏状态到所有观察状态的概率之和为1，即图中：<br/>
\[<br/>
\begin{align*}<br/>
P(\text{Dry,Dryish,Damp,Soggy|Sun}) &amp;= 1\\<br/>
P(\text{Dry,Dryish,Damp,Soggy|Cloud}) &amp;= 1\\<br/>
P(\text{Dry,Dryish,Damp,Soggy|Rain}) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p>

<p>除了定义了马尔科夫过程的概率关系，我们还有另一个矩阵，定义为混淆矩阵（confusion matrix），它包含了给定一个隐藏状态后得到的观察状态的概率。对于天气例子，混淆矩阵是<br/>
\[<br/>
\begin{array}{c|cccc}<br/>
&amp;\quad \text{Dry}\quad &amp;\quad \text{Dryish}\quad &amp;\quad \text{Damp}\quad &amp;\quad \text{Soggy}\quad \\\hline<br/>
\text{Sun}\quad  &amp;\quad \text{0.60}\quad &amp;\quad \text{0.20}\quad &amp;\quad \text{0.15}\quad &amp;\quad \text{0.05}\quad \\<br/>
\text{Cloud}\quad &amp;\quad \text{0.25}\quad &amp;\quad \text{0.25}\quad &amp;\quad \text{0.25}\quad &amp;\quad \text{0.25}\quad \\<br/>
\text{Rain}\quad &amp;\quad \text{0.05}\quad &amp;\quad \text{0.10}\quad &amp;\quad \text{0.35}\quad &amp;\quad \text{0.50}\quad \\<br/>
\end{array}<br/>
\]</p>

<p>注意矩阵的每一行之和是 1。</p>

<h3 id="toc_0">隐马尔可夫模型</h3>

<p>一个隐马尔可夫模型通常需要三组参数组成：</p>

<ol>
<li><p>状态转移概率：模型在各个状态间转换的概率，通常记为矩阵 \(\mathbb A = [a_{ij}]_{N\times N}\)，其中：<br/>
\[<br/>
a_{ij} = P(x_{t+1} = s_j|x_t = s_i),\quad 1\le i,j\le N<br/>
\]</p>

<p>表示在任意时刻 \(t\)，状态 \(s_i\) 转移到状态 \(s_j\) 的概率。</p></li>
<li><p>输出观察概率：模型根据当前隐藏状态获得各个观察值的概率，通常记为矩阵 \(\mathbb B = [b_{ij}]_{N\times M}\)，其中<br/>
\[<br/>
b_{i}(j) = P(y_t = o_j|x_t = s_i),\quad i\le i\le N,1\le j\le M<br/>
\]</p>

<p>表示在任意时刻 \(t\)，若状态为 \(s_i\)，则观察值 \(o_j\) 被获取的概率。</p></li>
<li><p>初始状态概率：模型在初始时刻各状态出现的概率，通常记为 \(\mathbb\pi=(\pi_1,\pi_2,...,\pi_N)\)，其中：<br/>
\[<br/>
\pi_i = P(x_1 = s_i),\quad 1\le i\le N<br/>
\]</p>

<p>表示模型初始状态为 \(s_i\) 的概率。</p></li>
</ol>

<p>通过指定状态空间 \(\mathcal Y\)、观察空间 \(\mathcal X\) 和上述三组参数，就能确定一个隐马尔可夫模型，通常用其参数 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 来指代。给定隐马尔可夫模型 \(\lambda\)，它按如下过程产生观察序列 \(\{y_1,y_2,...,y_n\}\)：</p>

<p>(1)、设置 \(t=1\)，并根据初始状态概率 \(\mathbb \pi\) 选择初始状态 \(x_1\)；</p>

<p>(2)、根据状态 \(x_t\) 和输出观测概率 \(B\) 选择观测变量取值 \(y_t\)；</p>

<p>(3)、根据状态 \(x_t\) 和状态转移矩阵 \(A\) 转移模型隐藏状态，即确定 \(x_{t+1}\)；</p>

<p>(4)、若 \(t\lt n\)，设置 \(t=t+1\)，并转移到第 (2) 步，否则停止。</p>

<p>其中 \(x_t\in\{s_1,s_2,...,s_N \}\) 和 \(y_t\in\{o_1,o_2,...,o_M \}\) 分别为第 \(t\) 时刻的隐藏状态和观测状态。</p>

<p>在实际应用中，人们常关注隐马尔可夫模型的三个基本问题：</p>

<ul>
<li><p>给定模型 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\)，如何有效计算其产生观测序列 \(\mathbb y=\{y_1,y_2,...,y_n \}\) 的概率 \(P(\mathbb x|\lambda)\)，换言之，如何评估模型与观测序列之间的匹配程度？</p></li>
<li><p>给定模型 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 和观测序列 \(\mathbb y=\{y_1,y_2,...,y_n \}\)，如何找到与此观测序列最匹配的隐藏状态序列 \(\mathbb y=\{ y_1,y_2,...,y_n \}\)？换言之，如何根据观测序列推断出一串的模型状态？</p></li>
<li><p>给定模型 \(\mathbb x = \{x_1,x_2,...,x_n \}\)，如何调整模型参数 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 使得该序列出现的概率 \(\pi(\mathbb x,\lambda)\)？换言之，如何训练模型使其能最好的描述观测数据？</p></li>
</ul>

<p>现在简单说一下如何解决这三个问题：</p>

<h4 id="toc_1">评估</h4>

<p>计算模型 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 产生观测序列的状态通常有三种方法：</p>

<ol>
<li><p><strong>穷举法</strong>：</p>

<p>一种计算观察序列概率的方法是找到每一个可能的隐藏状态，并且将这些隐藏状态下的观察序列概率相加。考虑到之前的例子，隐藏状态集合为 \(S=\{\text{Sun},\text{Cloud},\text{Rain}\}\)，观测状态为 \(V=\{\text{Dry},\text{Dryish},\text{Damp},\text{Soggy}\}\)，假设现在观测序列只有一个元素“\(\text{Dry}\)”，我们知道观测值“\(\text{Dry}\)”对应的隐藏状态可能是 \(S\) 中的任意元素，所以观测序列的概率可以表示为：<br/>
\[<br/>
\begin{align*}<br/>
P(\text{Dry}) &amp;= P(\text{Dry},\{\text{Sun},\text{Cloud},\text{Rain}\})\\<br/>
&amp;= P(\text{Dry}|\text{Sun})P(\text{Sun}) + P(\text{Dry}|\text{Cloud})P(\text{Cloud}) + P(\text{Dry}|\text{Rain})P(\text{Rain})\\<br/>
&amp;= \sum_{\text{h} \in |S|} P(\text{Dry}|\text{h})\\<br/>
\end{align*}<br/>
\]</p>

<p>假设现在观测序列有两个元素 \(\{\text{Dry},\text{Soggy}\}\)，类比上面我们首先找出所有可能的隐藏状态序列：<br/>
\[<br/>
\{(\text{Sun},\text{Sun}),(\text{Sun},\text{Cloud}),(\text{Sun},\text{Rain}),(\text{Cloud},\text{Sun}),\\<br/>
  (\text{Cloud},\text{Cloud}),(\text{Cloud},\text{Rain}),(\text{Rain},\text{Sun}),(\text{Rain},\text{Cloud}),(\text{Rain},\text{Rain})\}<br/>
\]</p>

<p>总共是3*3 = 9 种可能，根据每种可能的隐藏状态序列，计算其生成观测序列的概率，比如 \((\text{Sun},\text{Cloud})\)：<br/>
\[<br/>
\begin{align}<br/>
P(\text{Dry},\text{Soggy}|\text{Sun},\text{Cloud}) &amp;= \underbrace{P(\text{Sun})P(\text{Dry}|\text{Sun})}_{t=1} \underbrace{P(\text{Sun}\rightarrow\text{Cloud})P(\text{Soggy}|\text{Cloud})}_{t=2}\nonumber\\<br/>
&amp;= \underbrace{P(\text{Sun})}_{\text{初始概率}} \underbrace{P(\text{Sun}\rightarrow\text{Cloud})}_{\text{转移概率}} \underbrace{P(\text{Dry}|\text{Sun})P(\text{Soggy}|\text{Cloud})}_{\text{观测概率}}\label{uttu}\\<br/>
\end{align}<br/>
\]</p>

<p>同理可以求出其他可能的隐藏状态序列生成观测序列的概率，将9 种可能概率加起来便是观测序列的概率。</p>

<p>由式(\ref{uttu})可以知道状态序列到观测序列的概率分成三个部分，初始概率、状态转移概率和观测概率（对应位置隐藏状态表现为观测值的概率）。现在我们推广到一般形式，列举所有可能的长度为 \(T\) 的状态序列 \(I=(i_1,i_2,...,i_T)\)，求各个状态序列 \(I\) 与观测序列 \(O=(o_1,o_2,...,o_T)\) 的联合概率 \(P(O,I,\lambda)\) ，然后对所有可能的状态序列求和得到 \(P(O|\lambda)\)。</p>

<p>状态序列 \(I=(i_1,i_2,...,i_T)\) 的初始概率为 \(\pi_{i_1}\)；<br/>
状态序列 \(I=(i_1,i_2,...,i_T)\) 的转移概率为 \(a_{i_1 i_2}a_{i_2 i_3}\cdots a_{i_{T-1} i_T}\)；</p>

<p>这两部分合起来就是状态序列 \(I=(i_1,i_2,...,i_T)\) 的概率：<br/>
\[<br/>
P(I|\lambda) = \pi_{i_1}a_{i_1 i_2}a_{i_2 i_3}\cdots a_{i_{T-1} i_T}<br/>
\]</p>

<p>对固定状态序列 \(I=(i_1,i_2,...,i_T)\) ，得到观测序列 \(O=(o_1,o_2,...,o_T)\) 的观测概率：<br/>
\[<br/>
P(O|I,\lambda) = b_{i_1}(o_1)b_{i_2}(o_2)\cdots b_{i_T}(o_T)<br/>
\]</p>

<p>所以 \(O\) 和 \(I\) 同时出现的联合概率为：<br/>
\[<br/>
\begin{align*}<br/>
P(O,I|\lambda) &amp;= \sum_{I} P(I|\lambda) P(O|I,\lambda)\\<br/>
&amp;= \sum_{I} \pi_{i_1}b_{i_1}(o_1) a_{i_1 i_2} b_{i_2}(o_2)\cdots a_{i_{T-1} i_T}b_{i_T}(o_T)<br/>
\end{align*}<br/>
\]</p>

<p>但是，利用上面公式计算量巨大，是 \(O(TN^T)\) 阶的，这种算法不可行的。</p></li>
<li><p><strong>前向算法</strong>：</p>

<p>前向算法定义局部概率 \(\alpha_t(i)\) 表示观测时刻 \(t\) 之前观测状态的序列为 \(o_1,o_2,...o_t\)的概率为前向概率。记为：<br/>
\[<br/>
\alpha_t(i) = P(o_1,o_2,...,o_t,i_t = s_i|\lambda)<br/>
\]</p>

<p>递推关系为<br/>
\[<br/>
\alpha_{t+1}(i) = \bigg[\sum_{j=1}^N \alpha_t(j) a_{ji}\bigg] b_{i}(o_{t+1})<br/>
\]</p>

<p>算法步骤为</p>

<p><strong>输入</strong>：假设隐马尔可夫模型 \(\lambda=(\mathbb A,\mathbb B,\pi)\)，观测序列 \(O=(o_1,o_2,...,o_T)\)，隐藏状态总共包含 N 种状态 \(S = (s_1,s_2,...,s_N)\)；<br/>
<strong>输出</strong>：观测序列概率 \(P(O|\lambda)\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li><p>初值<br/>
\[<br/>
\alpha_1(i) = \pi_{i}b_i(o_1),\quad i=1,2,\cdots,N<br/>
\]</p></li>
<li><p>递推 对 \(t=1,2,\cdots,T-1\)<br/>
\[<br/>
\alpha_{t+1}(i) = \bigg[ \sum_{j=1}^N \alpha_t(j)a_{ji} \bigg] b_i(o_{t+1}),\quad i=1,2,\cdots,N<br/>
\]</p></li>
<li><p>终止<br/>
\[<br/>
P(O|\lambda) = \sum_{i=1}^N \alpha_T(i)<br/>
\]</p></li>
</ul>

<p>还是以天气的例子，假设 \(T=3\)，\(O=(\text{Dry,Dryish,Soggy})\)，状态转移矩阵如下图：<br/>
\[<br/>
\begin{array}{c|ccc}<br/>
&amp;\quad \text{Sun}\quad &amp;\quad \text{Cloud}\quad &amp;\quad \text{Rain}\quad \\\hline<br/>
\text{Sun}\quad  &amp;\quad \text{0.5}\quad &amp;\quad \text{0.2}\quad &amp;\quad \text{0.3}\quad \\<br/>
\text{Cloud}\quad &amp;\quad \text{0.3}\quad &amp;\quad \text{0.5}\quad &amp;\quad \text{0.2}\quad\\<br/>
\text{Rain}\quad &amp;\quad \text{0.2}\quad &amp;\quad \text{0.3}\quad &amp;\quad \text{0.5}\quad\\<br/>
\end{array}<br/>
\]</p>

<p>初始值概率为\(\pi=(\text{Sun,Cloud,Rain})=(0.2,0.4,0.4)\)</p>

<p>按照算法，（1）计算初值<br/>
\[<br/>
\alpha_1(1) = \pi_1b_1(o_1) = 0.2*0.6 = 0.12\\<br/>
\alpha_1(2) = \pi_2b_2(o_1) = 0.4*0.25 = 0.1\\<br/>
\alpha_1(3) = \pi_3b_3(o_1) = 0.4*0.05 = 0.02\\<br/>
\]</p>

<p>（2）递推计算<br/>
\[<br/>
\alpha_2(1) = \bigg[\sum_{i=1}^3 \alpha_1(i) a_{i1} \bigg] b_1(o_2) = \bigg[ 0.12 * 0.5 + 0.1 * 0.3 + 0.02 * 0.2\bigg ] * 0.2 = 0.0188 \\<br/>
\alpha_2(2) = \bigg[\sum_{i=1}^3 \alpha_1(i) a_{i2} \bigg] b_2(o_2) = \bigg[ 0.12 * 0.2 + 0.1 * 0.5 + 0.02 * 0.3\bigg ] * 0.25 =  0.02 \\<br/>
\alpha_2(3) = \bigg[\sum_{i=1}^3 \alpha_1(i) a_{i3} \bigg] b_3(o_2) = \bigg[ 0.12 * 0.3 + 0.1 * 0.2 + 0.02 * 0.5\bigg ] * 0.10  = 0.0066\\<br/>
\\<br/>
\alpha_3(1) = \bigg[\sum_{i=1}^3 \alpha_2(i) a_{i1} \bigg] b_1(o_3) = \bigg[ 0.0188 * 0.5 + 0.02 * 0.3 + 0.0066 * 0.2 \bigg] * 0.05 = 0.000836 \\<br/>
\alpha_3(2) = \bigg[\sum_{i=1}^3 \alpha_2(i) a_{i2} \bigg] b_2(o_3) = \bigg[ 0.0188 * 0.2 + 0.02 * 0.5 + 0.0066 * 0.3 \bigg] * 0.25 = 0.003935 \\<br/>
\alpha_3(3) = \bigg[\sum_{i=1}^3 \alpha_2(i) a_{i3} \bigg] b_3(o_3) = \bigg[ 0.0188 * 0.3 + 0.02 * 0.2 + 0.0066 * 0.5 \bigg] * 0.5 = 0.00647 \\<br/>
\]</p>

<p>（3）终止：<br/>
\[<br/>
P(O|\lambda) = \sum_{i=1}^3 \alpha_3(i) = 0.000836+0.003935 + 0.00647 = 0.011241<br/>
\]</p></li>
<li><p><strong>后向算法</strong></p>

<p>后向算法与前向算法原理，定义局部概率 \(\beta_t(i)\) 表示观测时刻 \(t\) 之后的观测序列 \(o_{t+1},o_{t+2},...,o_T\) 的概率为后向概率。记为：<br/>
\[<br/>
\beta_t(i) = P(o_{t+1},o_{t+2},...,o_T|i_t=s_i,\lambda)<br/>
\]</p>

<p>后向算法的递推公式为<br/>
\[<br/>
\beta_t(i-1) = \sum_{j=1}^N \beta_t(j) a_{ij} b_{j}(o_{t+1})<br/>
\]</p>

<p>算法初始时，\(t=T\)，此时不存在后续时刻观测序列，此时 \(\beta_T(i) = 1\)。</p>

<p><strong>输入</strong>：假设隐马尔可夫模型 \(\lambda=(A,B,\pi)\)，观测序列 \(O=(o_1,o_2,...,o_T)\)。隐藏状态总共包含 \(m\) 种状态 \(S = (s_1,s_2,...,s_m)\)；<br/>
<strong>输出</strong>：观测序列概率 \(P(O|\lambda)\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li><p>初值<br/>
\[<br/>
\beta_T(i) = 1,\quad i=1,2,\cdots,T<br/>
\]</p></li>
<li><p>递推 对 \(t=T-1,T-2,\cdots,1\)<br/>
\[<br/>
\beta_{t-1}(i) = \sum_{j=1}^N \beta_t(j)a_{ij} b_j(o_{t+1}),\quad i=1,2,\cdots,N<br/>
\]</p></li>
<li><p>终止<br/>
\[<br/>
P(O|\lambda) = \sum_{i=1}^N \beta_1(i)\pi(i)b_i(o_1)<br/>
\]</p></li>
</ul>

<p>以天气的例子，假设 \(T=3\)，\(O=(\text{Dry,Dryish,Soggy})\)，状态转移矩阵如前向算法所示。初始值概率为\(\pi=(\text{Sun,Cloud,Rain})=(0.2,0.4,0.4)\)</p>

<p>按照算法，（1）计算初值<br/>
\[<br/>
\beta_3(1) = 1\\<br/>
\beta_3(2) = 1\\<br/>
\beta_3(3) = 1\\<br/>
\]</p>

<p>（2）递推计算<br/>
\[<br/>
\begin{align*}<br/>
\beta_2(1) &amp;= \sum_{j=1}^3 \beta_3(j)a_{1j}b_{j}(o_t)\\<br/>
&amp;= 1 * 0.5 * 0.05 + 1 * 0.2 * 0.25 + 1 * 0.3 * 0.5 \\<br/>
&amp;= 0.225\\<br/>
\beta_2(2) &amp;= \sum_{j=1}^3 \beta_3(j)a_{2j}b_{j}(o_t)\\<br/>
&amp;= 1 * 0.3 * 0.05 + 1 * 0.5 * 0.25 + 1 * 0.2 * 0.5 \\<br/>
&amp;= 0.24\\<br/>
\beta_2(3) &amp;= \sum_{j=1}^3 \beta_3(j)a_{3j}b_{j}(o_t)\\<br/>
&amp;= 1 * 0.2 * 0.05 + 1 * 0.3 * 0.25 + 1 * 0.5 * 0.5 \\<br/>
&amp;= 0.335\\<br/>
\beta_1(1) &amp;= \sum_{j=1}^3 \beta_2(j)a_{1j}b_{j}(o_t)\\<br/>
&amp;= 0.225 * 0.5 * 0.20 + 0.24 * 0.2 * 0.25 + 0.335 * 0.3 * 0.10 \\<br/>
&amp;= 0.04455\\<br/>
\beta_1(2) &amp;= \sum_{j=1}^3 \beta_2(j)a_{2j}b_{j}(o_t)\\<br/>
&amp;= 0.225 * 0.3 * 0.20 + 0.24 * 0.5 * 0.25 + 0.335 * 0.2 * 0.10 \\<br/>
&amp;= 0.0502\\<br/>
\beta_1(3) &amp;= \sum_{j=1}^3 \beta_2(j)a_{3j}b_{j}(o_t)\\<br/>
&amp;= 0.225 * 0.2 * 0.20 + 0.24 * 0.3 * 0.25 + 0.335 * 0.5 * 0.10 \\<br/>
&amp;= 0.04375\\<br/>
\end{align*}<br/>
\]</p>

<p>（3）终止：<br/>
\[<br/>
\begin{align*}<br/>
P(O|\lambda) &amp;= \sum_{i=1}^3 \beta_1(i) \pi(i) b_i(o_1) \\<br/>
&amp;= 0.04455 * 0.2 * 0.6 + 0.0502 * 0.4 * 0.25 + 0.04375 * 0.4 * 0.05\\<br/>
&amp;= 0.011241<br/>
\end{align*}<br/>
\]</p></li>
</ol>

<h4 id="toc_2">解码</h4>

<p>对于一个特殊的隐马尔科夫模型(HMM)及一个相应的观察序列，我们常常希望能找到生成此序列最可能的隐藏状态序列。</p>

<ol>
<li><p><strong>穷举法</strong></p>

<p>类似前面的穷举法，对于观测序列 \(O=(o_1,o_2,...,o_t)\)，总共有 \(N^t\) 个可能的隐藏状态序列，其中 \(N\) 是隐藏状态 \(S\) 的个数。然后对于每一个可能隐藏状态序列，计算生成观测序列的状态的概率，再从中选出最大的概率的隐藏状态序列。这种方法可行，但是复杂度很高，不推荐使用。</p></li>
<li><p><strong>维特比算法</strong></p>

<p>关于维特比算法可以看之前的一篇文章介绍，这里直接介绍如何用维比特算法求解解码问题。</p>

<p>导入两个变量 \(\delta\) 和 \(\psi\)，定义在时刻 \(t\) 状态为 \(i\) 的所有单个路径 \((i_1,i_2,...,i_t)\) 中的概率最大值为<br/>
\[<br/>
\delta_t(i) = \max_{i_1,i_2,...,i_{t-1}} P(i_t=i,i_{t-1},...,i_1,o_t,...,o_1|\lambda),\quad i=1,2,...,N<br/>
\]</p>

<p>由定义可得变量 \(\delta\) 的递推公式：<br/>
\[<br/>
\begin{align*}<br/>
\delta_{t+1}(i) &amp;= \max_{i_1,i_2,...,i_{t}} P(i_{t+1}=i,i_{t},...,i_1,o_{t+1},...,o_1|\lambda)\\<br/>
&amp;= \max_{1\le j\le N}[\delta_t(j) a_{ji}]b_i(o_{t+1}),\quad i=1,2,...,N<br/>
\end{align*}<br/>
\]</p>

<p>定义在时刻 \(t\) 状态为 \(i\) 的所有单个路径 \((i_1,i_2,...,i_{t-1},i)\) 中概率最大的路径的第 \(t-1\) 个结点为<br/>
\[<br/>
\psi_t(i) = \arg\max_{1\le j\le N}[\delta_{t-1}(j) a_{ji}],\quad i=1,2,...,N<br/>
\]</p>

<p>下面介绍维比特算法。</p>

<p><strong>输入</strong>：模型 \(\lambda=(A,B,\pi)\) 和观测 \(O=(o_1,o_2,...,o_T)\)；<br/>
<strong>输出</strong>：最优状态序列 \(I=(i^*_1,i^*_2,...,i^*_T)\)；<br/>
<strong>算法过程</strong>：</p>

<ul>
<li><p>初始化<br/>
\[<br/>
\delta_1(i) = \pi_i b_i(o_1),\quad i=1,2,...,N\\<br/>
\psi_1(i) = 0<br/>
\]</p></li>
<li><p>递推，对 \(t=2,3,...,T\)<br/>
\[<br/>
\delta_t(i) = \max_{1\le j\le N}[\delta_t(j) a_{ji}]b_i(o_{t+1}),\quad i=1,2,...,N\\<br/>
\psi_t(i) = \arg\max_{1\le j\le N}[\delta_{t-1}(j) a_{ji}],\quad i=1,2,...,N<br/>
\]</p></li>
<li><p>终止<br/>
\[<br/>
P^* = \max_{1\le i\le N} \delta_{T}(i)\\<br/>
i^*_T = \arg\max_{1\le i\le N}[\delta_T(i)]<br/>
\]</p></li>
<li><p>最优路径回溯，对 \(t=T-1,T-2,...,1\)<br/>
\[<br/>
i^*_t = \psi_{t+1}(i^*_{t+1})<br/>
\]</p></li>
</ul>

<p>求得最优路径 \(I^* = (i^*_1,i^*_2,...,i^*_T)\)。</p>

<p>还是以天气的例子，假设 \(T=3\)，\(O=(\text{Dry,Dryish,Soggy})\)，状态转移矩阵同前向算法中所示，初始值概率为\(\pi=(\text{Sun,Cloud,Rain})=(0.2,0.4,0.4)\)。</p>

<p>按照算法，（1） 初始化，当 \(t=1\) 时，对每一个状态 \(i\)，\(i=1,2,3\)，求状态为 \(i\) 观测 \(o_1\) 为 Dry 的概率，记此概率为 \(\delta_1(i)\)，则：<br/>
\[<br/>
\delta_1(i) = \pi_ib_i(o_i) = \pi_ib_i(\text{Dry}),\quad i=1,2,3<br/>
\]</p>

<p>代入实际数据<br/>
\[<br/>
\delta_1(1) = \pi_1b_1(o_1) = 0.2*0.6 = 0.12\\<br/>
\delta_1(2) = \pi_2b_2(o_1) = 0.4*0.25 = 0.1\\<br/>
\delta_1(3) = \pi_3b_3(o_1) = 0.4*0.05 = 0.02\\<br/>
\]</p>

<p>记录 \(\psi_1(i) = 0\)，\(i=1,2,3\)。</p>

<p>（2）在 \(t=2\) 时，对每一个状态 \(i\)，\(i=1,2,3\)，求在 \(t=1\) 时状态为 \(j\) 观测为 Dry 并在 \(t=2\) 时状态为 \(i\) 观测 \(o_2\) 为 Dryish 的最大概率，记此最大概率为 \(\delta_2(i)\)，则<br/>
\[<br/>
\delta_2(i) = \max_{1\le j\le 3}[\delta_1(j) a_{ji}] b_i(o_2)<br/>
\]</p>

<p>同时，对每一个状态 \(i\)，\(i=1,2,3\)，记录概率最大路径的前一个状态：<br/>
\[<br/>
\psi_2(i) = \arg\max_{1\le j\le 3}[\delta_1(j)a_{ji}],\quad i=1,2,3<br/>
\]</p>

<p>计算：<br/>
\[<br/>
\begin{align*}<br/>
\delta_2(1) &amp;= \max_{1\le j\le 3}[\delta_1(j)a_{j1}] b_1(o_2)\\<br/>
&amp;= \max{j}\{0.12* 0.5,0.1 * 0.3,0.02*0.2 \}*0.2\\<br/>
&amp;= 0.012\\<br/>
\psi_2(1) &amp;= 1\\<br/>
\delta_2(2) &amp;= \max_{1\le j\le 3}[\delta_1(j)a_{j2}] b_2(o_2)\\<br/>
&amp;= \max{j}\{0.12* 0.2,0.1 * 0.5,0.02*0.3 \}*0.25\\<br/>
&amp;= 0.0125\\<br/>
\psi_2(2) &amp;= 2\\<br/>
\delta_2(3) &amp;= \max_{1\le j\le 3}[\delta_1(j)a_{j3}] b_3(o_2)\\<br/>
&amp;= \max{j}\{0.12* 0.3,0.1 * 0.2,0.02*0.5 \}*0.1\\<br/>
&amp;= 0.0036\\<br/>
\psi_2(3) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p>

<p>同样在 \(t=3\) 时，<br/>
\[<br/>
\begin{align*}<br/>
\delta_3(1) &amp;= \max_{1\le j\le 3}[\delta_2(j)a_{j1}] b_1(o_3)\\<br/>
&amp;= \max{j}\{0.012* 0.5,0.0125 * 0.3,0.0036*0.2 \}*0.05\\<br/>
&amp;= 0.0003\\<br/>
\psi_3(1) &amp;= 1\\<br/>
\delta_3(2) &amp;= \max_{1\le j\le 3}[\delta_2(j)a_{j2}] b_2(o_3)\\<br/>
&amp;= \max{j}\{0.012* 0.2,0.0125 * 0.5,0.0036*0.3 \}*0.25\\<br/>
&amp;= 0.0015625\\<br/>
\psi_3(2) &amp;= 2\\<br/>
\delta_3(3) &amp;= \max_{1\le j\le 3}[\delta_2(j)a_{j3}] b_3(o_3)\\<br/>
&amp;= \max{j}\{0.012* 0.3,0.0125 * 0.2,0.0036*0.5 \}*0.5\\<br/>
&amp;= 0.0018\\<br/>
\psi_3(3) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p>

<p>（3）以 \(P^*\) 表示最优路径的概率，则<br/>
\[<br/>
P^* = \max_{1\le i\le 3}\delta_3(i) = 0.0018<br/>
\]</p>

<p>最优路径终点是 \(i^*_3\)：<br/>
\[<br/>
i^*_3 = \arg\max_{i}[\delta_3(i)] = 3<br/>
\]</p>

<p>（4）由最优路径的终点 \(i^*_3\) ，逆向找到 \(i^*_2\) 和 \(i^*_1\)：<br/>
\[<br/>
i^*_2 = \psi_3(i^*_3) = 1\\<br/>
i^*_1 = \psi_2(i^*_2) = 1\\<br/>
\]</p>

<p>最优路径为 \(I=(i^*_1,i^*_2,i^*_3) = (1,1,3)\)</p></li>
</ol>

<h4 id="toc_3">学习</h4>

<p>与HMM模型相关的“有用”的问题是评估（前向算法）和解码（维特比算法）——它们一个被用来测量一个模型的相对适用性，另一个被用来推测模型隐藏的部分在做什么（“到底发生了”什么）。可以看出它们都依赖于隐马尔科夫模型（HMM）参数这一先验知识——状态转移矩阵，混淆（观察）矩阵，以及 \(\pi\) 向量（初始化概率向量）。可以分为监督学习算法和非监督学习算法--Baum-Welch算法。</p>

<ol>
<li><p><strong>监督学习算法</strong></p>

<p>假设已给出训练数据包含 \(S\) 个长度相同的观测序列和对应的状态序列 \(\{(O_1,I_1),(O_2,I_2),...,(O_S,I_S)\}\)，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数。具体方法如下.</p>

<p>（1）转移概率 \(a_{ij}\) 的估计</p>

<p>设样本中时刻 \(t\) 处于 \(i\) 状态，时刻 \(t+1\) 转移到 \(j\) 状态的频数为 \(A_{ij}\) ，那么转移概率 \(a_{ij}\) 的估计为：<br/>
\[<br/>
\hat a_{ij} = \frac{A_{ij}}{\sum_{j=1}^M A_{ij}},\quad i=1,2,...,N;j=1,2,...,N <br/>
\]</p>

<p>（2）观测概率 \(b_j(k)\) 的估计<br/>
设样本汇总状态为 \(j\) 并观测为 \(k\) 的频数为 \(B_{jk}\)，那么状态为 \(j\) 观测为 \(k\) 的概率 \(b_j(k)\) 为<br/>
\[<br/>
\hat b_j(k) = \frac{B_{jk}}{\sum_{k=1}^N B_{jk}},\quad j=1,2,...,N,k=1,2,...,M<br/>
\]</p>

<p>（3）初始状态概率 \(\pi_i\) 的估计 \(\hat \pi_i\) 为 \(S\) 个样本中初始状态为 \(q_i\) 的频率。</p>

<p>由于监督学习需要使用训练数据，而人工标注训练数据往往代价很高，有时候就会利用非监督学习的方法。</p></li>
<li><p><strong>Baum-Welch算法</strong></p>

<blockquote>
<p>在讲解Baum-Welch算法之前，我们先讲解一下单个状态和两个状态的计算公式<br/>
( a ) 给定模型 \(\lambda\) 和观测 \(O\)，在时刻 \(t\) 处于状态 \(s_i\) 的概率，记<br/>
\[<br/>
\gamma_t(i) = P(i_t = s_i|O,\lambda)<br/>
\]</p>

<p>容易得<br/>
\[<br/>
\gamma_t(i) = \frac{P(i_t = s_i,O|\lambda)}{P(O|\lambda)}<br/>
\]</p>

<p>前向概率 \(\alpha_t(i)\) 的定义为<br/>
\[<br/>
\alpha_t(i) = P(o_1,o_2,...,o_t,i_t = s_i|\lambda)<br/>
\]</p>

<p>后向概率 \(\beta_t(i)\) 的定义为<br/>
\[<br/>
\beta_t(i) = P(o_{t+1},o_{t+2},...,o_T|i_t=s_i,\lambda)<br/>
\]</p>

<p>由前向概率和后向概率的定义可知：<br/>
\[<br/>
\alpha_t(i) \beta_t(i) = P(O,i_t = s_i|\lambda)<br/>
\]</p>

<p>考虑到<br/>
\[<br/>
P(O|\lambda) = \sum_{j=1}^N P(O,i_t=s_j|\lambda)<br/>
\]</p>

<p>于是可得<br/>
\[<br/>
\begin{equation}<br/>
\gamma_t(i) = \frac{P(O,i_t=s_j|\lambda)}{P(O|\lambda)} = \frac{\alpha_t(i) \beta_t(i)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}\label{gtf1}<br/>
\end{equation}<br/>
\]</p>

<p>( b ) 给定模型 \(\lambda\) 和观测 \(O\)，在时刻 \(t\) 处于状态 \(s_i\) 在下一时刻处于 \(s_j\) 的概率，记为<br/>
\[<br/>
\begin{align*}<br/>
\xi_t(i,j) = P(i_t=s_i,i_{t+1}=s_j|O,\lambda) &amp;= \frac{P(i_t=s_i,i_{t+1}=s_j,O|\lambda)}{P(O|\lambda)}\\<br/>
&amp;= \frac{P(i_t=s_i,i_{t+1}=s_j,O|\lambda)}{\sum_{i=1}^N \sum_{j=1}^N P(i_t=s_i,i_{t+1}=s_j,O|\lambda)}<br/>
\end{align*}<br/>
\]</p>

<p>而<br/>
\[<br/>
\begin{align*}<br/>
P(i_t=s_i,i_{t+1}=s_j,O|\lambda) &amp;= P(i_t=s_i,o_1,o_2,...,o_t|\lambda)a_{ij}b_j(o_{t+1}) P(o_{t+2},o_{t+3},...,o_T|i_{t+1} = s_j,\lambda) \\<br/>
&amp;= \alpha_t(i)a_{ij} b_j(o_{t+1})\beta_{t+1}(j)<br/>
\end{align*}<br/>
\]</p>

<p>于是<br/>
\[<br/>
\begin{equation}<br/>
\xi_t(i,j) = \frac{\alpha_t(i)a_{ij} b_j(o_{t+1})\beta_{t+1}(j)}{\sum_{i=1}^N \sum_{j=1}^N \alpha_t(i)a_{ij} b_j(o_{t+1})\beta_{t+1}(j)}\label{gtf2}<br/>
\end{equation}<br/>
\]</p>

<p>( c ) 将 \(\gamma_t(i)\) 和 \(\xi_t(i,j)\) 对各个时刻 \(t\) 求和，可以得到一些有用的期望值：</p>

<ul>
<li><p>在观测 \(O\) 下状态 \(i\) 出现的期望值<br/>
\[<br/>
\sum_{t=1}^T \gamma_t(i)<br/>
\]</p></li>
<li><p>在观测 \(O\) 下由状态 \(i\) 转移的期望值<br/>
\[<br/>
\sum_{t=1}^{T-1} \gamma_t(i)<br/>
\]</p></li>
<li><p>在观测 \(O\) 下由状态 \(i\) 转移到状态 \(j\) 的期望值<br/>
\[<br/>
\sum_{t=1}^{T-1} \xi_t(i,j)<br/>
\]</p></li>
</ul>
</blockquote>

<p>假设给定训练数据只包含 \(S\) 个长度为 \(T\) 的观测序列 \(\{O_1,O_2,...,O_S\}\) 而没有对应的状态序列，目标是学习隐马尔可夫模型 \(\lambda=(\mathbb A,\mathbb B,\pi)\) 的参数，我们将观测序列看做观测数据 \(O\) ，状态序列看做不可观测的隐数据 \(I\) ，那么隐马尔可夫模型事实上是一个含有隐变量的概率模型<br/>
\[<br/>
P(O|\lambda) = \sum_{I} P(O|I,\lambda) P(I|\lambda)<br/>
\]</p>

<p>它的学习参数可以由 EM 算法实现。</p>

<p>（1）确定完全数据的对数似然函数</p>

<p>所有观测数据写成 \(O=(o_1,o_2,...,o_T)\)，所有隐数据写成 \(I=(i_1,i_2,...,i_T)\)，完全数据是 \((O,I)=(o_1,o_2,...,o_T,i_1,i_2,...,i_T)\)。完全数据的对数似然函数是 \(\log P(O,I|\lambda)\)。</p>

<p>（2）EM 的E步：求Q函数 \(Q(\lambda,\overline \lambda)\)：<br/>
\[<br/>
\begin{align}<br/>
Q(\lambda,\overline \lambda) &amp;= \mathbb E_I[\log P(O,I|\lambda)|O,\overline \lambda]\nonumber\\<br/>
&amp;= \sum_I \log P(O,I|\lambda) P(I|O,\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I \log P(O,I|\lambda) \frac{P(O,I|\overline \lambda)}{P(O|I,\overline \lambda)}\label{silp}\\<br/>
\end{align}<br/>
\] </p>

<p>其中，\(\overline \lambda\) 是隐马尔可夫模型参数的当前估计值，\(\lambda\) 是要极大化的隐马尔可夫模型参数。式(\ref{silp})中 \(P(O|I,\overline \lambda)\) 我们知道对于已知模型和隐状态序列这个概率是固定常数，可以略去。</p>

<p>Q函数可以写成<br/>
\[<br/>
\begin{equation}<br/>
Q(\lambda,\overline \lambda) = \sum_I \log P(O,I|\lambda){P(O,I|\overline \lambda)}\label{qlol}\\<br/>
\end{equation}<br/>
\]</p>

<p>在前文中，我们已经知道已知 \(\lambda\) 模型，可以通过前向算法得出给定观测序列的概率：<br/>
\[<br/>
\begin{align*}<br/>
P(O,I|\lambda) = \pi_{i_1} b_{i_1}(o_1) a_{i_1i_2}b_{i_2}(o_2) \cdots a_{i_{T-1} i_T}b_{i_T}(o_T)<br/>
\end{align*}<br/>
\]</p>

<p>于是函数 \(Q(\lambda,\overline \lambda)\) 可以写成：<br/>
\[<br/>
\begin{align}<br/>
Q(\lambda,\overline \lambda) &amp;= \sum_I \log P(O,I|\lambda){P(O,I|\overline \lambda)}\\<br/>
&amp;= \sum_I \log\Big[ \pi_{i_1} b_{i_1}(o_1) a_{i_1i_2}b_{i_2}(o_2) \cdots a_{i_{T-1} i_T}b_{i_T}(o_T) \Big]P(O,I|\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I \log\Big[ \pi_{i_1} \prod_{t=1}^{T-1} a_{i_ti_{t+1}}  \prod_{t=1}^T b_{i_t}(o_t)\Big]P(O,I|\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I \bigg\{\log\pi_{i_1} + \log\Big[\prod_{t=1}^{T-1} a_{i_ti_{t+1}}\Big] + \log\Big[\prod_{t=1}^T b_{i_t}(o_t)\Big]\bigg\}P(O,I|\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I P(O,I|\overline \lambda) \log \pi_{i_1} + \sum_I P(O,I|\overline \lambda) \log\Big[\prod_{t=1}^{T-1} a_{i_ti_{t+1}}\Big] + \sum_I P(O,I|\overline \lambda) \log\Big[\prod_{t=1}^T b_{i_t}(o_t)\Big]\nonumber\\<br/>
&amp;= \sum_I P(O,I|\overline \lambda) \log \pi_{i_1} + \sum_I P(O,I|\overline \lambda) \sum_{t=1}^{T-1} \log a_{i_ti_{t+1}} + \sum_I P(O,I|\overline \lambda) \sum_{t=1}^T \log b_{i_t}(o_t)\label{sipo}\\<br/>
\end{align}<br/>
\]</p>

<p>式中求和都是对所有训练数据的序列总长度 \(T\) 进行的。</p>

<p>（3）EM算法的M步：极大化Q函数 \(Q(\lambda,\overline \lambda)\) 的模型参数 \(\mathbb A,\mathbb B,\pi\)。</p>

<p>可以看到，我们将三项中分别的对 \(I\) 的求和进行了划分。由于隐变量 \(I=(i_1,i_2,...,i_T)\) 。原来的求和需要遍历所有 \(I\) 的取值，然后进行求和，然而这基本是不可能完成的任务。改写后，我们将遍历的空间进行了划分，同时很好地将 \(P(O,I|,\overline \lambda)\) 部分改写后也融入到求和其中。比如第一项，对 \(I\) 的遍历等价于先固定状态 \(i_1\)，使其分别取值所有可能的状态（共有S个可取的离散状态），而 \(i_2,...,i_T\) 仍然像原来一样随便取值。这样，就把 \(I\) 空间划分成了S个更小的空间。然后再把这N个空间的结果相加，等价于原来对空间 \(I\) 进行遍历。</p>

<p><strong>a.式(\ref{sipo})的第一项</strong>可以写成<br/>
\[<br/>
\sum_I P(O,I|\overline \lambda) \log \pi_{i_1} = \sum_{i=1}^N P(O,i_1=i|\overline \lambda) \log \pi_{i}<br/>
\]</p>

<blockquote>
<p>之前一直很纠结为什么可以这么转换，后面通过一个小例子让我明白了，假设我们有长度为3，即 \(S=3\) 的观测数据 \(O=(o_1,o_2,o_3)\)，隐藏状态的个数为2，即 \(N=2\)，可能的隐藏状态序列有<br/>
\[<br/>
s_1 s_1 s_1;\\<br/>
s_1 s_1 s_2;\\<br/>
s_1 s_2 s_1;\\<br/>
s_1 s_2 s_2;\\<br/>
s_2 s_1 s_1;\\<br/>
s_2 s_1 s_2;\\<br/>
s_2 s_2 s_1;\\<br/>
s_2 s_2 s_2;\\<br/>
\]</p>

<p>第一项可以写成<br/>
\[<br/>
\begin{align*}<br/>
\sum_I P(O,I|\overline \lambda) \log \pi_{i_1} &amp;= P(O,\{s_1 s_1 s_1\}|\lambda)\log \pi_{s_1}  + P(O,\{s_1 s_1 s_2\}|\lambda)\log \pi_{s_1}  + P(O,\{s_1 s_2 s_1\}|\lambda)\log \pi_{s_1}  + P(O,\{s_1 s_2 s_2\}|\lambda)\log \pi_{s_1} + P(O,\{s_2,s_1,s_1\}|\pi_{s_2} + P(O,\{s_2,s_1,s_2\}|\pi_{s_2} + P(O,\{s_2,s_2,s_1\}|\pi_{s_2} + P(O,\{s_2,s_2,s_2\}|\pi_{s_2} \\<br/>
&amp;= P(O,{s_i,s_?,s_?}|\lambda)\log \pi_{s_i} \quad(i=1,2)\\<br/>
&amp;= \sum_{i=1}^2 P(O,s_i|\lambda)\log \pi_{s_i} <br/>
\end{align*}<br/>
\]</p>

<p>所以我们可以看出这样转换是可以的。</p>
</blockquote>

<p>我们又考虑到 \(\pi_i\) 满足约束条件 \(\sum_{i=1}^N \pi_i = 1\)，利用拉格朗日乘子法，写出拉格朗日函数：<br/>
\[<br/>
\sum_{i=1}^N P(O,i_1=i|\overline \lambda) \log \pi_{i} + \gamma\bigg(\sum_{i=1}^N \pi_i - 1 \bigg)<br/>
\]</p>

<p>对其求偏导并令结果为0<br/>
\[<br/>
\frac{\partial}{\partial \pi_i}\bigg[ \sum_{i=1}^N P(O,i_1=i|\overline \lambda) \log \pi_{i} + \gamma\bigg(\sum_{i=1}^N \pi_i - 1 \bigg) \bigg] = 0<br/>
\]</p>

<p>得<br/>
\[<br/>
\begin{align}<br/>
P(O,i_1=i|\overline \lambda) + \gamma \pi_i = 0\label{poli}<br/>
\end{align}<br/>
\]</p>

<p>对 \(i\) 求和得到 \(\lambda\)<br/>
\[<br/>
\lambda = -P(O|\overline \lambda)<br/>
\]</p>

<p>代入(\ref{poli})式得<br/>
\[<br/>
\pi_i = \frac{P(O,i_1=i|\overline \lambda)}{P(O|I)}<br/>
\]</p>

<p><strong>b.式(\ref{sipo})的第二项</strong>可以写成<br/>
\[<br/>
\sum_I P(O,I|\overline \lambda) \sum_{t=1}^{T-1} \log a_{i_ti_{t+1}} = \sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) \log a_{ij}<br/>
\]</p>

<p>应用具有约束条件 \(\sum_{j=1}^N a_{ij} = 1\) 的拉格朗日乘子法可以求出<br/>
\[<br/>
\sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) \log a_{ij} + \gamma\bigg(\sum_{j=1}^N a_{ij} - 1\bigg)<br/>
\]</p>

<p>对 \(a_{ij}\) 求偏导并令结果为0<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial}{\partial a_{ij}}\bigg[\sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) \log a_{ij} + \gamma\bigg(\sum_{j=1}^N a_{ij} - 1\bigg) \bigg]\\<br/>
&amp;= \frac{\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) }{a_{ij}} + \gamma = 0 \\<br/>
\end{align*}<br/>
\]</p>

<p>得<br/>
\[<br/>
\begin{equation}<br/>
\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) = \gamma a_{ij}\label{stto}<br/>
\end{equation}<br/>
\]</p>

<p>对 \(j\) 求和可得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) = \sum_{j=1}^N \gamma a_{ij}\\<br/>
&amp;\Rightarrow \sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda) = \gamma\\<br/>
\end{align*}<br/>
\]</p>

<p>上式代入(\ref{stto})得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) = \sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda) a_{ij}\\<br/>
&amp;\Rightarrow a_{ij} = \frac{\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda)}{\sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda)}<br/>
\end{align*}<br/>
\]</p>

<p><strong>c.式(\ref{sipo})的第三项</strong>可以写成<br/>
\[<br/>
\sum_I P(O,I|\overline \lambda) \sum_{t=1}^T \log b_{i_t}(o_t) = \sum_{j=1}^N\sum_{t=1}^T  P(O,i_t=j|\overline \lambda) \log b_j(o_t)<br/>
\]</p>

<p>同样用拉格朗日乘子法，约束条件是 \(\sum_{k=1}^M b_j(k) = 1\)，拉格朗日方程为<br/>
\[<br/>
\sum_{j=1}^N \sum_{t=1}^TP(O,i_t=j|\overline \lambda)  \log b_j(o_t) + \gamma\bigg(\sum_{k=1}^M b_j(k) - 1 \bigg)<br/>
\]</p>

<p>对 \(b_j(k)\) 求导得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial}{\partial b_j(k)}\bigg[\sum_{j=1}^N \sum_{t=1}^T P(O,i_t=j|\overline \lambda) \log b_j(o_t) + \gamma\bigg(\sum_{k=1}^M b_j(k) - 1 \bigg)\bigg]\\<br/>
&amp;= \frac{\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k)}{b_j(k)}+ \gamma<br/>
\end{align*}<br/>
\]</p>

<p>这里只有在 \(o_t = k\) 时 \(b_j(o_t)\) 对 \(b_j(k)\) 的偏导数才不为0，以指示函数 \(\mathbf I(o_t = k)\) 表示。</p>

<p>令上式偏导结果为0得<br/>
\[<br/>
\begin{align}<br/>
\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k) = b_j(k) \gamma\label{stoto}<br/>
\end{align}<br/>
\]</p>

<p>对上式 \(k\) 求和，可得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{k=1}^N \sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k) = \sum_{k=1}^N b_j(k) \gamma\\<br/>
&amp;\Rightarrow \sum_{t=1}^T P(O,i_t=j|\overline \lambda) = \gamma<br/>
\end{align*}<br/>
\]</p>

<p>代入(\ref{stoto})式得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k) = b_j(k) \sum_{t=1}^T P(O,i_t=j|\overline \lambda)\\ <br/>
&amp;\Rightarrow b_j(k) = \frac{\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k)}{\sum_{t=1}^T P(O,i_t=j|\overline \lambda)}<br/>
\end{align*}<br/>
\]</p>

<p>到现在我们已经推出了 \(\pi_i\)、\(a_{ij}\) 和 \(b_{j}(k)\) 的迭代公式<br/>
\[<br/>
\begin{align*}<br/>
\pi_i &amp;= \frac{P(O,i_1=i|\overline \lambda)}{P(O|I)}\\<br/>
a_{ij} &amp;= \frac{\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda)}{\sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda)}\\<br/>
b_j(k) &amp;= \frac{\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k)}{\sum_{t=1}^T P(O,i_t=j|\overline \lambda)}\\<br/>
\end{align*}<br/>
\]</p>

<p>将式(\ref{gtf1})和式(\ref{gtf2}) 代入<br/>
\[<br/>
\begin{align*}<br/>
\pi_i &amp;= \gamma_1(i)\\<br/>
a_{ij} &amp;= \frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i) }\\<br/>
b_j(k) &amp;= \frac{\sum_{t=1}^T \gamma_t(j) \mathbf I(o_t=k)}{\sum_{t=1}^T \gamma_t(j)}\\<br/>
\end{align*}<br/>
\]</p>

<p>现在Baum-Welch算法可以描述为<br/>
<strong>输入</strong>：观测数据 \(O=(o_1,o_2,...,o_T)\)；<br/>
<strong>输出</strong>：隐马尔可夫模型参数<br/>
<strong>算法过程</strong></p>

<ul>
<li>初始化，对 \(n=0\)，选取 \({a_{ij}}^{(0)}\)，\({b_j(k)}^{(0)}\) 和 \({\pi_i}^{(0)}\)，得到模型 \(\lambda^{(0)} = (\mathbb A^{(0)},\mathbb B^{(0)},\pi^{(0)})\)</li>
<li><p>递推，对 \(n=1,2,...,\)<br/>
\[<br/>
\begin{align*}<br/>
{a_{ij}^{(n+1)}} &amp;= \frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i) }\\<br/>
{b_j(k)}^{(n+1)} &amp;= \frac{\sum_{t=1}^T \gamma_t(j) \mathbf I(o_t=k)}{\sum_{t=1}^T \gamma_t(j)}\\<br/>
{\pi_i}^{(n+1)} &amp;= \gamma_1(i)\\<br/>
\end{align*}<br/>
\]</p>

<p>右侧各值按观测 \(O=(o_1,o_2,...,o_T)\) 和模型 \(\lambda^{(n)} = (\mathbb A^{(n)},\mathbb B^{(n)},\pi^{(n)})\) 计算。式中 \(\gamma_t(i)\) 和 \(\xi_t(i,j)\) 由式(\ref{gtf1})和式(\ref{gtf2})给出。</p></li>
<li><p>终止。得到模型 \(\lambda^{(n+1)} = (\mathbb A^{(n+1)},\mathbb B^{(n+1)},\pi^{(n+1)})\)</p></li>
</ul></li>
</ol>

<hr/>

<p>[李航 统计学习方法]<br/>
<a href="http://www.52nlp.cn/category/hidden-markov-model">HMM相关文章索引</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15200089476142.html">正态分布的累积分布函数 Cumulative distribution function of Normal distribution</a></h1>
			<p class="meta"><time datetime="2018-03-03T00:42:27+08:00" 
			pubdate data-updated="true">2018/3/3</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>标准正态分布（均值为0，方差为1）<br/>
\[<br/>
\mathcal N(0,1) = \frac 1 {\sqrt{2\pi}} \exp(-\frac{x^2}{2})<br/>
\]</p>

<p>的累积分布函数常用大写希腊字母 \(\Phi\) 表示：<br/>
\[<br/>
\Phi(x) = P(X \le x) = \frac 1 {\sqrt{2\pi}} \int^x_{-\infty}\exp(-\frac{t^2}{2}) \mathbb dt<br/>
\]</p>

<p>这个积分不能使用基础函数表示，被认为是一个特殊函数。我们先来看另一个定义误差函数。</p>

<h3 id="toc_0">误差函数</h3>

<p>在数学中，误差函数（经常被称为高斯误差函数）是一个特殊函数（非基础），它是 sigmoid 形状，常出现在概率学、统计学中。定义为：<br/>
\[<br/>
\begin{align*}<br/>
\mathbf{Erf}(x) &amp;= \frac{1}{\sqrt{\pi}} \int_{-x}^x \exp(-{t^2}) \mathbb dt\\<br/>
&amp;= \frac{2}{\sqrt{\pi}} \int_0^x \exp(-{t^2}) \mathbb dt\\<br/>
\end{align*}<br/>
\]</p>

<p>在统计学中，对于非负 \(x\) ，误差函数的解释是：对于通常分布在均值为 0，方差为 \(\frac 1 2\) 的随机变量 \(Y\)，\(\mathbf{Erf}(x)\) 描述为 \(Y\) 落在范围 \([-x,x]\) 之间的概率，所以：<br/>
\[<br/>
\mathbf{Erf}(x) = \int_{-x}^{x} \frac{1}{\sqrt{2\pi}\cdot \sqrt{1/2}} \exp(-\frac{t^2}{2\cdot \frac 1 2}) \mathbb dt= \frac{1}{\sqrt{\pi}} \int_{-x}^x \exp(-{t^2}) \mathbb dt<br/>
\]</p>

<h3 id="toc_1">累积分布函数与误差函数</h3>

<p>比较正态分布的累积分布函数与误差函数，可以发现非常相像<br/>
\[<br/>
\begin{align}<br/>
\Phi(x) &amp;= P(X \le x) = \frac 1 {\sqrt{2\pi}} \int^x_{-\infty}\exp(-\frac{t^2}{2}) \mathbb dt\label{px}\\<br/>
\mathbf{Erf}(x) &amp;= \frac{2}{\sqrt{\pi}} \int_{0}^x \exp(-{t^2}) \mathbb dt\label{erfx}\\<br/>
\end{align}<br/>
\]</p>

<p>对于误差函数 \(\mathbf{Erf}(x)\)，令 \(t^2 = {s^2}/{2}\)，也就是 \(t = {s}/{\sqrt{2}}\)（ \(t\) 是非负数），由此 \(\mathbb dt = \mathbb d({s}/{\sqrt{2}})\)，令 \(t=0\) 和 \(t=x\) 得 \(s=0\) 和 \(s = \sqrt{2}x\)，代入 \ref{erfx} 式可得：<br/>
\[<br/>
\begin{align*}<br/>
\mathbf{Erf}(x) &amp;= \frac{2}{\sqrt{\pi}} \int_{0}^{\sqrt{2}x} \exp(-\frac{s^2}{2}) \mathbb d(s/\sqrt{2})\\<br/>
&amp;= \frac{2}{\sqrt{\pi}} \int_{0}^{\sqrt{2}x} \frac{1}{\sqrt{2}} \exp(-\frac{s^2}{2}) \mathbb ds\\<br/>
&amp;= \frac{2}{\sqrt{2\pi}} \int_{0}^{\sqrt{2}x}\exp(-\frac{t^2}{2}) \mathbb dt\\<br/>
&amp;= 2\bigg(\frac{1}{\sqrt{2\pi}} \int_{0}^{\sqrt{2}x}\exp(-\frac{t^2}{2}) \mathbb dt \bigg)\\<br/>
&amp;= 2\bigg(\frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\sqrt{2}x}\exp(-\frac{t^2}{2}) \mathbb dt  - \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{0}\exp(-\frac{t^2}{2}) \mathbb dt\bigg)\\<br/>
&amp;= 2\bigg(\Phi(\sqrt{2}x)- \Phi(0)\bigg)\\<br/>
&amp;= 2\bigg(\Phi(\sqrt{2}x)- \frac 1 2\bigg)\\<br/>
&amp;= 2\Phi(\sqrt{2}x) - 1<br/>
\end{align*}<br/>
\]</p>

<p>现在很容易用误差函数来表示高斯分布的CDF：<br/>
\[<br/>
\Phi(\sqrt{2}x) = \frac 1 2 \bigg[{ \mathbf{Erf}(x) + 1}\bigg]\\<br/>
\Rightarrow \Phi(x) = \frac 12 \bigg[{\mathbf{Erf}\bigg(\frac{x}{\sqrt{2}}\bigg) + 1}\bigg]<br/>
\]</p>

<p>对于一般均值为 \(\mu\)，方差为 \(\sigma\) 的正态分布 \(f(x)\)，其 CDF 为：<br/>
\[<br/>
{\displaystyle F(x)=\Phi \left({\frac {x-\mu }{\sigma }}\right)={\frac {1}{2}}\left[1+\mathbf {Erf} \left({\frac {x-\mu }{\sigma {\sqrt {2}}}}\right)\right]}<br/>
\] </p>

<p>那现在我们可以绘制出<font color="#006400"> <strong>正态分布</strong> </font>和对应的 <font color="#cc0000"><strong>CDF</strong></font> 图像：</p>

<div align="center">
    <img src="media/15200089476142/15350352677388.jpg" width="240" />
</div>

<p>高斯分布的 CDF 函数的反函数被称为反误差函数，为：<br/>
\[<br/>
\Phi^{-1}(p)=\sqrt2\;\mathbf{Erf}^{-1} \left(2p - 1 \right). \quad p \in (0,1)<br/>
\]</p>

<p>该分位数函数有时也被称为probit函数。probit函数已被证明没有初等原函数。</p>

<hr/>

<p><a href="https://en.wikipedia.org/wiki/Error_function">Error Function</a><br/>
<a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal Distribution</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15199171411644.html">GeoGebra 中英文指令对照表</a></h1>
			<p class="meta"><time datetime="2018-03-01T23:12:21+08:00" 
			pubdate data-updated="true">2018/3/1</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>\[<br/>
\renewcommand\arraystretch{2}<br/>
\begin{array}{|l|l|}\hline<br/>
\quad\text{英文指令}\quad&amp;\quad\text{中文指令}\quad\\\hline<br/>
\quad\text{ANOVA}\quad&amp;\quad\text{方差分析}\quad\\\hline<br/>
\quad\text{AffineRatio}\quad&amp;\quad\text{仿射比λ}\quad\\\hline<br/>
\quad\text{Angle}\quad&amp;\quad\text{角度}\quad\\\hline<br/>
\quad\text{AngularBisector}\quad&amp;\quad\text{角平分线}\quad\\\hline<br/>
\quad\text{Append}\quad&amp;\quad\text{添加}\quad\\\hline<br/>
\quad\text{ApplyMatrix}\quad&amp;\quad\text{应用矩阵}\quad\\\hline<br/>
\quad\text{Arc}\quad&amp;\quad\text{圆弧}\quad\\\hline<br/>
\quad\text{AreCollinear}\quad&amp;\quad\text{共线}\quad\\\hline<br/>
\quad\text{AreConcurrent}\quad&amp;\quad\text{共点}\quad\\\hline<br/>
\quad\text{AreConcyclic}\quad&amp;\quad\text{共圆}\quad\\\hline<br/>
\quad\text{AreCongruent}\quad&amp;\quad\text{全等}\quad\\\hline<br/>
\quad\text{AreEqual}\quad&amp;\quad\text{相等}\quad\\\hline<br/>
\quad\text{AreParallel}\quad&amp;\quad\text{平行}\quad\\\hline<br/>
\quad\text{ArePerpendicular}\quad&amp;\quad\text{垂直}\quad\\\hline<br/>
\quad\text{Area}\quad&amp;\quad\text{面积}\quad\\\hline<br/>
\quad\text{Asymptote}\quad&amp;\quad\text{渐近线}\quad\\\hline<br/>
\quad\text{AttachCopyToView}\quad&amp;\quad\text{附加副本}\quad\\\hline<br/>
\quad\text{Axes}\quad&amp;\quad\text{轴线}\quad\\\hline<br/>
\quad\text{AxisStepX}\quad&amp;\quad\text{x轴步长}\quad\\\hline<br/>
\quad\text{AxisStepY}\quad&amp;\quad\text{y轴步长}\quad\\\hline<br/>
\quad\text{BarChart}\quad&amp;\quad\text{条形图}\quad\\\hline<br/>
\quad\text{BarCode}\quad&amp;\quad\text{条形码}\quad\\\hline<br/>
\quad\text{Barycenter}\quad&amp;\quad\text{质心}\quad\\\hline<br/>
\quad\text{Bernoulli}\quad&amp;\quad\text{伯努利分布}\quad\\\hline<br/>
\quad\text{Binomial}\quad&amp;\quad\text{二项式系数}\quad\\\hline<br/>
\quad\text{BinomialDist}\quad&amp;\quad\text{二项分布}\quad\\\hline<br/>
\quad\text{Bottom}\quad&amp;\quad\text{下底}\quad\\\hline<br/>
\quad\text{BoxPlot}\quad&amp;\quad\text{箱线图}\quad\\\hline<br/>
\quad\text{Button}\quad&amp;\quad\text{按钮}\quad\\\hline<br/>
\quad\text{CFactor}\quad&amp;\quad\text{复数因式分解}\quad\\\hline<br/>
\quad\text{CIFactor}\quad&amp;\quad\text{复杂无理数因式分解}\quad\\\hline<br/>
\quad\text{CSolutions}\quad&amp;\quad\text{复数解集}\quad\\\hline<br/>
\quad\text{CSolve}\quad&amp;\quad\text{复数解}\quad\\\hline<br/>
\quad\text{Cauchy}\quad&amp;\quad\text{柯西分布}\quad\\\hline<br/>
\quad\text{Cell}\quad&amp;\quad\text{单元格}\quad\\\hline<br/>
\quad\text{CellRange}\quad&amp;\quad\text{单元格区域数字列表}\quad\\\hline<br/>
\quad\text{Center}\quad&amp;\quad\text{中心}\quad\\\hline<br/>
\quad\text{CenterView}\quad&amp;\quad\text{中心定位}\quad\\\hline<br/>
\quad\text{Centroid}\quad&amp;\quad\text{重心}\quad\\\hline<br/>
\quad\text{Checkbox}\quad&amp;\quad\text{复选框}\quad\\\hline<br/>
\quad\text{ChiSquared}\quad&amp;\quad\text{卡方分布}\quad\\\hline<br/>
\quad\text{ChiSquaredTest}\quad&amp;\quad\text{卡方检验}\quad\\\hline<br/>
\quad\text{Circle}\quad&amp;\quad\text{圆形}\quad\\\hline<br/>
\quad\text{CircleArc}\quad&amp;\quad\text{圆弧过圆心与两点}\quad\\\hline<br/>
\quad\text{CircleSector}\quad&amp;\quad\text{圆扇形}\quad\\\hline<br/>
\quad\text{CircumcircleArc}\quad&amp;\quad\text{圆弧过三点}\quad\\\hline<br/>
\quad\text{CircumcircleSector}\quad&amp;\quad\text{扇形过三点}\quad\\\hline<br/>
\quad\text{Circumference}\quad&amp;\quad\text{圆周长}\quad\\\hline<br/>
\quad\text{Classes}\quad&amp;\quad\text{组限列表}\quad\\\hline<br/>
\quad\text{ClosestPoint}\quad&amp;\quad\text{最近点}\quad\\\hline<br/>
\quad\text{ClosestPointRegion}\quad&amp;\quad\text{区域内最近点}\quad\\\hline<br/>
\quad\text{Coefficients}\quad&amp;\quad\text{系数列表}\quad\\\hline<br/>
\quad\text{Column}\quad&amp;\quad\text{列序}\quad\\\hline<br/>
\quad\text{ColumnName}\quad&amp;\quad\text{列名称}\quad\\\hline<br/>
\quad\text{Command}\quad&amp;\quad\text{指令}\quad\\\hline<br/>
\quad\text{CommonDenominator}\quad&amp;\quad\text{公分母}\quad\\\hline<br/>
\quad\text{CompetitionRank}\quad&amp;\quad\text{竞争排名}\quad\\\hline<br/>
\quad\text{CompleteSquare}\quad&amp;\quad\text{配方式}\quad\\\hline<br/>
\quad\text{ComplexRoot}\quad&amp;\quad\text{复数根}\quad\\\hline<br/>
\quad\text{Cone}\quad&amp;\quad\text{圆锥}\quad\\\hline<br/>
\quad\text{Conic}\quad&amp;\quad\text{圆锥曲线}\quad\\\hline<br/>
\quad\text{ConstructionStep}\quad&amp;\quad\text{作图步序}\quad\\\hline<br/>
\quad\text{ContingencyTable}\quad&amp;\quad\text{列联表}\quad\\\hline<br/>
\quad\text{ContinuedFraction}\quad&amp;\quad\text{连分式}\quad\\\hline<br/>
\quad\text{ContourPlot}\quad&amp;\quad\text{等高线}\quad\\\hline<br/>
\quad\text{ConvexHull}\quad&amp;\quad\text{凸包}\quad\\\hline<br/>
\quad\text{CopyFreeObject}\quad&amp;\quad\text{复制自由对象}\quad\\\hline<br/>
\quad\text{Corner}\quad&amp;\quad\text{角落}\quad\\\hline<br/>
\quad\text{CountIf}\quad&amp;\quad\text{条件计数}\quad\\\hline<br/>
\quad\text{Covariance}\quad&amp;\quad\text{协方差}\quad\\\hline<br/>
\quad\text{Cross}\quad&amp;\quad\text{叉积}\quad\\\hline<br/>
\quad\text{CrossRatio}\quad&amp;\quad\text{交比}\quad\\\hline<br/>
\quad\text{Cube}\quad&amp;\quad\text{正六面体}\quad\\\hline<br/>
\quad\text{Cubic}\quad&amp;\quad\text{三次曲线}\quad\\\hline<br/>
\quad\text{Curvature}\quad&amp;\quad\text{曲率}\quad\\\hline<br/>
\quad\text{CurvatureVector}\quad&amp;\quad\text{曲率向量}\quad\\\hline<br/>
\quad\text{CurveCartesian}\quad&amp;\quad\text{曲线}\quad\\\hline<br/>
\quad\text{Cylinder}\quad&amp;\quad\text{圆柱}\quad\\\hline<br/>
\quad\text{DataFunction}\quad&amp;\quad\text{数据函数}\quad\\\hline<br/>
\quad\text{Defined}\quad&amp;\quad\text{定义否}\quad\\\hline<br/>
\quad\text{Degree}\quad&amp;\quad\text{次数}\quad\\\hline<br/>
\quad\text{DelauneyTriangulation}\quad&amp;\quad\text{Delaunay三角网}\quad\\\hline<br/>
\quad\text{Delete}\quad&amp;\quad\text{删除}\quad\\\hline<br/>
\quad\text{Denominator}\quad&amp;\quad\text{分母}\quad\\\hline<br/>
\quad\text{DensityPlot}\quad&amp;\quad\text{密度图}\quad\\\hline<br/>
\quad\text{Derivative}\quad&amp;\quad\text{导数}\quad\\\hline<br/>
\quad\text{Determinant}\quad&amp;\quad\text{行列式}\quad\\\hline<br/>
\quad\text{Diameter}\quad&amp;\quad\text{共轭直径}\quad\\\hline<br/>
\quad\text{Difference}\quad&amp;\quad\text{差异}\quad\\\hline<br/>
\quad\text{Dilate}\quad&amp;\quad\text{位似}\quad\\\hline<br/>
\quad\text{Dimension}\quad&amp;\quad\text{维度}\quad\\\hline<br/>
\quad\text{Direction}\quad&amp;\quad\text{方向向量}\quad\\\hline<br/>
\quad\text{Directrix}\quad&amp;\quad\text{准线}\quad\\\hline<br/>
\quad\text{Distance}\quad&amp;\quad\text{距离}\quad\\\hline<br/>
\quad\text{Div}\quad&amp;\quad\text{整商}\quad\\\hline<br/>
\quad\text{Division}\quad&amp;\quad\text{除法}\quad\\\hline<br/>
\quad\text{Divisors}\quad&amp;\quad\text{因数个数}\quad\\\hline<br/>
\quad\text{DivisorsList}\quad&amp;\quad\text{因数}\quad\\\hline<br/>
\quad\text{DivisorsSum}\quad&amp;\quad\text{因数和}\quad\\\hline<br/>
\quad\text{Dodecahedron}\quad&amp;\quad\text{正十二面体}\quad\\\hline<br/>
\quad\text{Dot}\quad&amp;\quad\text{点积}\quad\\\hline<br/>
\quad\text{DotPlot}\quad&amp;\quad\text{点阵图}\quad\\\hline<br/>
\quad\text{DynamicCoordinates}\quad&amp;\quad\text{动态坐标}\quad\\\hline<br/>
\quad\text{Eccentricity}\quad&amp;\quad\text{离心率}\quad\\\hline<br/>
\quad\text{Element}\quad&amp;\quad\text{元素}\quad\\\hline<br/>
\quad\text{Eliminate}\quad&amp;\quad\text{消元}\quad\\\hline<br/>
\quad\text{Ellipse}\quad&amp;\quad\text{椭圆}\quad\\\hline<br/>
\quad\text{Ends}\quad&amp;\quad\text{两底}\quad\\\hline<br/>
\quad\text{Envelope}\quad&amp;\quad\text{包络}\quad\\\hline<br/>
\quad\text{Erlang}\quad&amp;\quad\text{爱尔朗分布}\quad\\\hline<br/>
\quad\text{Evaluate}\quad&amp;\quad\text{计算}\quad\\\hline<br/>
\quad\text{Excentricity}\quad&amp;\quad\text{半焦距}\quad\\\hline<br/>
\quad\text{Execute}\quad&amp;\quad\text{执行}\quad\\\hline<br/>
\quad\text{Expand}\quad&amp;\quad\text{展开}\quad\\\hline<br/>
\quad\text{Exponential}\quad&amp;\quad\text{指数分布}\quad\\\hline<br/>
\quad\text{Extremum}\quad&amp;\quad\text{极值点}\quad\\\hline<br/>
\quad\text{FDistribution}\quad&amp;\quad\text{F分布}\quad\\\hline<br/>
\quad\text{Factor}\quad&amp;\quad\text{因式分解}\quad\\\hline<br/>
\quad\text{Factors}\quad&amp;\quad\text{因式集簇}\quad\\\hline<br/>
\quad\text{FillCells}\quad&amp;\quad\text{填充单元格}\quad\\\hline<br/>
\quad\text{FillColumn}\quad&amp;\quad\text{填充列}\quad\\\hline<br/>
\quad\text{FillRow}\quad&amp;\quad\text{填充行}\quad\\\hline<br/>
\quad\text{First}\quad&amp;\quad\text{最前项}\quad\\\hline<br/>
\quad\text{FirstAxis}\quad&amp;\quad\text{长轴}\quad\\\hline<br/>
\quad\text{FirstAxisLength}\quad&amp;\quad\text{半长轴长}\quad\\\hline<br/>
\quad\text{Fit}\quad&amp;\quad\text{拟合曲线}\quad\\\hline<br/>
\quad\text{FitExp}\quad&amp;\quad\text{指数拟合}\quad\\\hline<br/>
\quad\text{FitGrowth}\quad&amp;\quad\text{生长曲线拟合}\quad\\\hline<br/>
\quad\text{FitImplicit}\quad&amp;\quad\text{隐函数拟合}\quad\\\hline<br/>
\quad\text{FitLineX}\quad&amp;\quad\text{拟合直线X}\quad\\\hline<br/>
\quad\text{FitLineY}\quad&amp;\quad\text{拟合直线Y}\quad\\\hline<br/>
\quad\text{FitLog}\quad&amp;\quad\text{对数拟合}\quad\\\hline<br/>
\quad\text{FitLogistic}\quad&amp;\quad\text{逻辑斯蒂曲线拟合}\quad\\\hline<br/>
\quad\text{FitPoly}\quad&amp;\quad\text{多项式拟合}\quad\\\hline<br/>
\quad\text{FitPow}\quad&amp;\quad\text{幂函数拟合}\quad\\\hline<br/>
\quad\text{FitSin}\quad&amp;\quad\text{正弦拟合}\quad\\\hline<br/>
\quad\text{Flatten}\quad&amp;\quad\text{扁平列表}\quad\\\hline<br/>
\quad\text{Focus}\quad&amp;\quad\text{焦点}\quad\\\hline<br/>
\quad\text{FractionText}\quad&amp;\quad\text{分数文本}\quad\\\hline<br/>
\quad\text{Frequency}\quad&amp;\quad\text{频数列表}\quad\\\hline<br/>
\quad\text{FrequencyPolygon}\quad&amp;\quad\text{频数多边形}\quad\\\hline<br/>
\quad\text{FrequencyTable}\quad&amp;\quad\text{频数表}\quad\\\hline<br/>
\quad\text{FromBase}\quad&amp;\quad\text{十进制形式}\quad\\\hline<br/>
\quad\text{Function}\quad&amp;\quad\text{函数}\quad\\\hline<br/>
\quad\text{FutureValue}\quad&amp;\quad\text{未来值}\quad\\\hline<br/>
\quad\text{GCD}\quad&amp;\quad\text{最大公约数}\quad\\\hline<br/>
\quad\text{Gamma}\quad&amp;\quad\text{伽玛分布}\quad\\\hline<br/>
\quad\text{GeometricMean}\quad&amp;\quad\text{几何平均数}\quad\\\hline<br/>
\quad\text{GetTime}\quad&amp;\quad\text{系统时间}\quad\\\hline<br/>
\quad\text{GroebnerDegRevLex}\quad&amp;\quad\text{分次反字典序Groebner基}\quad\\\hline<br/>
\quad\text{GroebnerLex}\quad&amp;\quad\text{字典序Groebner基}\quad\\\hline<br/>
\quad\text{GroebnerLexDeg}\quad&amp;\quad\text{分次字典序Groebner基}\quad\\\hline<br/>
\quad\text{HarmonicMean}\quad&amp;\quad\text{调和平均数}\quad\\\hline<br/>
\quad\text{Height}\quad&amp;\quad\text{高度}\quad\\\hline<br/>
\quad\text{HideLayer}\quad&amp;\quad\text{隐藏图层}\quad\\\hline<br/>
\quad\text{Histogram}\quad&amp;\quad\text{直方图}\quad\\\hline<br/>
\quad\text{HistogramRight}\quad&amp;\quad\text{直方图右}\quad\\\hline<br/>
\quad\text{HyperGeometric}\quad&amp;\quad\text{超几何分布}\quad\\\hline<br/>
\quad\text{Hyperbola}\quad&amp;\quad\text{双曲线}\quad\\\hline<br/>
\quad\text{IFactor}\quad&amp;\quad\text{无理数因式分解}\quad\\\hline<br/>
\quad\text{Icosahedron}\quad&amp;\quad\text{正二十面体}\quad\\\hline<br/>
\quad\text{Identity}\quad&amp;\quad\text{单位矩阵}\quad\\\hline<br/>
\quad\text{If}\quad&amp;\quad\text{如果}\quad\\\hline<br/>
\quad\text{ImplicitCurve}\quad&amp;\quad\text{隐式曲线}\quad\\\hline<br/>
\quad\text{ImplicitDerivative}\quad&amp;\quad\text{隐式微分}\quad\\\hline<br/>
\quad\text{Incircle}\quad&amp;\quad\text{内切圆}\quad\\\hline<br/>
\quad\text{IndexOf}\quad&amp;\quad\text{索引}\quad\\\hline<br/>
\quad\text{InfiniteCone}\quad&amp;\quad\text{无限长圆锥}\quad\\\hline<br/>
\quad\text{InfiniteCylinder}\quad&amp;\quad\text{无限长圆柱}\quad\\\hline<br/>
\quad\text{Insert}\quad&amp;\quad\text{插入}\quad\\\hline<br/>
\quad\text{Integral}\quad&amp;\quad\text{积分}\quad\\\hline<br/>
\quad\text{IntegralBetween}\quad&amp;\quad\text{区域积分}\quad\\\hline<br/>
\quad\text{Intersect}\quad&amp;\quad\text{交点}\quad\\\hline<br/>
\quad\text{IntersectConic}\quad&amp;\quad\text{相交曲线}\quad\\\hline<br/>
\quad\text{IntersectPath}\quad&amp;\quad\text{相交路径}\quad\\\hline<br/>
\quad\text{Intersection}\quad&amp;\quad\text{交集}\quad\\\hline<br/>
\quad\text{InverseBinomial}\quad&amp;\quad\text{逆二项分布}\quad\\\hline<br/>
\quad\text{InverseCauchy}\quad&amp;\quad\text{逆柯西分布}\quad\\\hline<br/>
\quad\text{InverseChiSquared}\quad&amp;\quad\text{逆卡方分布}\quad\\\hline<br/>
\quad\text{InverseExponential}\quad&amp;\quad\text{逆指数分布}\quad\\\hline<br/>
\quad\text{InverseFDistribution}\quad&amp;\quad\text{逆F分布}\quad\\\hline<br/>
\quad\text{InverseGamma}\quad&amp;\quad\text{逆伽玛分布}\quad\\\hline<br/>
\quad\text{InverseHyperGeometric}\quad&amp;\quad\text{逆超几何分布}\quad\\\hline<br/>
\quad\text{InverseLaplace}\quad&amp;\quad\text{拉普拉斯逆变换}\quad\\\hline<br/>
\quad\text{InverseLogNormal}\quad&amp;\quad\text{逆对数正态分布}\quad\\\hline<br/>
\quad\text{InverseLogistic}\quad&amp;\quad\text{逆逻辑分布}\quad\\\hline<br/>
\quad\text{InverseNormal}\quad&amp;\quad\text{逆正态分布}\quad\\\hline<br/>
\quad\text{InversePascal}\quad&amp;\quad\text{逆帕斯卡分布}\quad\\\hline<br/>
\quad\text{InversePoisson}\quad&amp;\quad\text{逆泊松分布}\quad\\\hline<br/>
\quad\text{InverseTDistribution}\quad&amp;\quad\text{逆T分布}\quad\\\hline<br/>
\quad\text{InverseWeibull}\quad&amp;\quad\text{逆威布尔分布}\quad\\\hline<br/>
\quad\text{InverseZipf}\quad&amp;\quad\text{逆齐普夫分布}\quad\\\hline<br/>
\quad\text{Invert}\quad&amp;\quad\text{逆反}\quad\\\hline<br/>
\quad\text{IsInRegion}\quad&amp;\quad\text{在区域内}\quad\\\hline<br/>
\quad\text{IsInteger}\quad&amp;\quad\text{整数}\quad\\\hline<br/>
\quad\text{IsPrime}\quad&amp;\quad\text{质数}\quad\\\hline<br/>
\quad\text{Iteration}\quad&amp;\quad\text{迭代}\quad\\\hline<br/>
\quad\text{IterationList}\quad&amp;\quad\text{迭代列表}\quad\\\hline<br/>
\quad\text{Join}\quad&amp;\quad\text{合并}\quad\\\hline<br/>
\quad\text{KeepIf}\quad&amp;\quad\text{条件子列}\quad\\\hline<br/>
\quad\text{LCM}\quad&amp;\quad\text{最小公倍数}\quad\\\hline<br/>
\quad\text{LaTeX}\quad&amp;\quad\text{公式文本}\quad\\\hline<br/>
\quad\text{Laplace}\quad&amp;\quad\text{拉普拉斯变换}\quad\\\hline<br/>
\quad\text{Last}\quad&amp;\quad\text{最后项}\quad\\\hline<br/>
\quad\text{LeftSide}\quad&amp;\quad\text{左边}\quad\\\hline<br/>
\quad\text{LeftSum}\quad&amp;\quad\text{左和}\quad\\\hline<br/>
\quad\text{Length}\quad&amp;\quad\text{长度}\quad\\\hline<br/>
\quad\text{LetterToUnicode}\quad&amp;\quad\text{字母到统一码}\quad\\\hline<br/>
\quad\text{Limit}\quad&amp;\quad\text{极限}\quad\\\hline<br/>
\quad\text{LimitAbove}\quad&amp;\quad\text{右极限}\quad\\\hline<br/>
\quad\text{LimitBelow}\quad&amp;\quad\text{左极限}\quad\\\hline<br/>
\quad\text{Line}\quad&amp;\quad\text{直线}\quad\\\hline<br/>
\quad\text{LineBisector}\quad&amp;\quad\text{中垂线}\quad\\\hline<br/>
\quad\text{Locus}\quad&amp;\quad\text{轨迹}\quad\\\hline<br/>
\quad\text{LocusEquation}\quad&amp;\quad\text{轨迹方程}\quad\\\hline<br/>
\quad\text{LogNormal}\quad&amp;\quad\text{对数正态分布}\quad\\\hline<br/>
\quad\text{Logistic}\quad&amp;\quad\text{逻辑分布}\quad\\\hline<br/>
\quad\text{LowerSum}\quad&amp;\quad\text{下和}\quad\\\hline<br/>
\quad\text{MatrixPlot}\quad&amp;\quad\text{矩阵图}\quad\\\hline<br/>
\quad\text{MatrixRank}\quad&amp;\quad\text{矩阵的秩}\quad\\\hline<br/>
\quad\text{Max}\quad&amp;\quad\text{最大值}\quad\\\hline<br/>
\quad\text{Maximize}\quad&amp;\quad\text{最大值点}\quad\\\hline<br/>
\quad\text{Mean}\quad&amp;\quad\text{平均数}\quad\\\hline<br/>
\quad\text{MeanX}\quad&amp;\quad\text{横坐标平均数}\quad\\\hline<br/>
\quad\text{MeanY}\quad&amp;\quad\text{纵坐标平均数}\quad\\\hline<br/>
\quad\text{Median}\quad&amp;\quad\text{中位数}\quad\\\hline<br/>
\quad\text{Midpoint}\quad&amp;\quad\text{中点}\quad\\\hline<br/>
\quad\text{Min}\quad&amp;\quad\text{最小值}\quad\\\hline<br/>
\quad\text{Minimize}\quad&amp;\quad\text{最小值点}\quad\\\hline<br/>
\quad\text{MinimumSpanningTree}\quad&amp;\quad\text{最小生成树}\quad\\\hline<br/>
\quad\text{Mirror}\quad&amp;\quad\text{对称}\quad\\\hline<br/>
\quad\text{MixedNumber}\quad&amp;\quad\text{带分数}\quad\\\hline<br/>
\quad\text{Mod}\quad&amp;\quad\text{余式}\quad\\\hline<br/>
\quad\text{Mode}\quad&amp;\quad\text{众数}\quad\\\hline<br/>
\quad\text{NDerivative}\quad&amp;\quad\text{数值导数}\quad\\\hline<br/>
\quad\text{NIntegral}\quad&amp;\quad\text{定积分}\quad\\\hline<br/>
\quad\text{NSolutions}\quad&amp;\quad\text{近似解集}\quad\\\hline<br/>
\quad\text{NSolve}\quad&amp;\quad\text{近似解}\quad\\\hline<br/>
\quad\text{NSolveODE}\quad&amp;\quad\text{解常微分方程组}\quad\\\hline<br/>
\quad\text{Name}\quad&amp;\quad\text{名称}\quad\\\hline<br/>
\quad\text{Net}\quad&amp;\quad\text{展开图}\quad\\\hline<br/>
\quad\text{NextPrime}\quad&amp;\quad\text{后一质数}\quad\\\hline<br/>
\quad\text{Normal}\quad&amp;\quad\text{正态分布}\quad\\\hline<br/>
\quad\text{NormalQuantilePlot}\quad&amp;\quad\text{正态分位数图}\quad\\\hline<br/>
\quad\text{Normalize}\quad&amp;\quad\text{归一化}\quad\\\hline<br/>
\quad\text{Numerator}\quad&amp;\quad\text{分子}\quad\\\hline<br/>
\quad\text{Numeric}\quad&amp;\quad\text{近似数}\quad\\\hline<br/>
\quad\text{Object}\quad&amp;\quad\text{对象}\quad\\\hline<br/>
\quad\text{Octahedron}\quad&amp;\quad\text{正八面体}\quad\\\hline<br/>
\quad\text{Ordinal}\quad&amp;\quad\text{序数}\quad\\\hline<br/>
\quad\text{OrdinalRank}\quad&amp;\quad\text{序数列表}\quad\\\hline<br/>
\quad\text{OrthogonalLine}\quad&amp;\quad\text{垂线}\quad\\\hline<br/>
\quad\text{OrthogonalPlane}\quad&amp;\quad\text{垂面}\quad\\\hline<br/>
\quad\text{OrthogonalVector}\quad&amp;\quad\text{法向量}\quad\\\hline<br/>
\quad\text{OsculatingCircle}\quad&amp;\quad\text{密切圆}\quad\\\hline<br/>
\quad\text{PMCC}\quad&amp;\quad\text{相关系数}\quad\\\hline<br/>
\quad\text{Pan}\quad&amp;\quad\text{平移视图}\quad\\\hline<br/>
\quad\text{Parabola}\quad&amp;\quad\text{抛物线}\quad\\\hline<br/>
\quad\text{Parameter}\quad&amp;\quad\text{焦参数}\quad\\\hline<br/>
\quad\text{ParametricDerivative}\quad&amp;\quad\text{参数导数}\quad\\\hline<br/>
\quad\text{ParseToFunction}\quad&amp;\quad\text{解析为函数}\quad\\\hline<br/>
\quad\text{ParseToNumber}\quad&amp;\quad\text{解析为数}\quad\\\hline<br/>
\quad\text{PartialFractions}\quad&amp;\quad\text{分项分式}\quad\\\hline<br/>
\quad\text{Pascal}\quad&amp;\quad\text{帕斯卡分布}\quad\\\hline<br/>
\quad\text{PathParameter}\quad&amp;\quad\text{路径值}\quad\\\hline<br/>
\quad\text{Payment}\quad&amp;\quad\text{每期付款额}\quad\\\hline<br/>
\quad\text{Percentile}\quad&amp;\quad\text{百分位数}\quad\\\hline<br/>
\quad\text{Perimeter}\quad&amp;\quad\text{周长}\quad\\\hline<br/>
\quad\text{Periods}\quad&amp;\quad\text{期数}\quad\\\hline<br/>
\quad\text{Plane}\quad&amp;\quad\text{平面}\quad\\\hline<br/>
\quad\text{PlaneBisector}\quad&amp;\quad\text{中垂面}\quad\\\hline<br/>
\quad\text{PlaySound}\quad&amp;\quad\text{播放声音}\quad\\\hline<br/>
\quad\text{Point}\quad&amp;\quad\text{描点}\quad\\\hline<br/>
\quad\text{PointIn}\quad&amp;\quad\text{内点}\quad\\\hline<br/>
\quad\text{PointList}\quad&amp;\quad\text{点列}\quad\\\hline<br/>
\quad\text{Poisson}\quad&amp;\quad\text{泊松分布}\quad\\\hline<br/>
\quad\text{Polar}\quad&amp;\quad\text{极线}\quad\\\hline<br/>
\quad\text{PolyLine}\quad&amp;\quad\text{折线}\quad\\\hline<br/>
\quad\text{Polygon}\quad&amp;\quad\text{多边形}\quad\\\hline<br/>
\quad\text{Polynomial}\quad&amp;\quad\text{多项式函数}\quad\\\hline<br/>
\quad\text{PresentValue}\quad&amp;\quad\text{现值}\quad\\\hline<br/>
\quad\text{PreviousPrime}\quad&amp;\quad\text{前一质数}\quad\\\hline<br/>
\quad\text{PrimeFactors}\quad&amp;\quad\text{质因数}\quad\\\hline<br/>
\quad\text{Prism}\quad&amp;\quad\text{棱柱}\quad\\\hline<br/>
\quad\text{Product}\quad&amp;\quad\text{乘积}\quad\\\hline<br/>
\quad\text{Prove}\quad&amp;\quad\text{证明}\quad\\\hline<br/>
\quad\text{ProveDetails}\quad&amp;\quad\text{证明过程}\quad\\\hline<br/>
\quad\text{Pyramid}\quad&amp;\quad\text{棱锥}\quad\\\hline<br/>
\quad\text{Q1}\quad&amp;\quad\text{第一四分位数}\quad\\\hline<br/>
\quad\text{Q3}\quad&amp;\quad\text{第三四分位数}\quad\\\hline<br/>
\quad\text{QuadricSide}\quad&amp;\quad\text{侧面}\quad\\\hline<br/>
\quad\text{RSquare}\quad&amp;\quad\text{可决系数R方}\quad\\\hline<br/>
\quad\text{Radius}\quad&amp;\quad\text{半径}\quad\\\hline<br/>
\quad\text{Random}\quad&amp;\quad\text{区间随机数}\quad\\\hline<br/>
\quad\text{RandomBinomial}\quad&amp;\quad\text{随机二项分布数}\quad\\\hline<br/>
\quad\text{RandomDiscrete}\quad&amp;\quad\text{离散随机数}\quad\\\hline<br/>
\quad\text{RandomElement}\quad&amp;\quad\text{随机元素}\quad\\\hline<br/>
\quad\text{RandomNormal}\quad&amp;\quad\text{正态分布随机数}\quad\\\hline<br/>
\quad\text{RandomPointIn}\quad&amp;\quad\text{随机内点}\quad\\\hline<br/>
\quad\text{RandomPoisson}\quad&amp;\quad\text{泊松分布随机数}\quad\\\hline<br/>
\quad\text{RandomPolynomial}\quad&amp;\quad\text{随机多项式}\quad\\\hline<br/>
\quad\text{RandomUniform}\quad&amp;\quad\text{均匀分布随机数}\quad\\\hline<br/>
\quad\text{Rate}\quad&amp;\quad\text{利率}\quad\\\hline<br/>
\quad\text{Rationalize}\quad&amp;\quad\text{有理化}\quad\\\hline<br/>
\quad\text{Ray}\quad&amp;\quad\text{射线}\quad\\\hline<br/>
\quad\text{RectangleSum}\quad&amp;\quad\text{矩形和}\quad\\\hline<br/>
\quad\text{ReducedRowEchelonForm}\quad&amp;\quad\text{简化行梯阵式}\quad\\\hline<br/>
\quad\text{Relation}\quad&amp;\quad\text{关系}\quad\\\hline<br/>
\quad\text{Remove}\quad&amp;\quad\text{移除}\quad\\\hline<br/>
\quad\text{RemoveUndefined}\quad&amp;\quad\text{移除未定义对象}\quad\\\hline<br/>
\quad\text{Rename}\quad&amp;\quad\text{重命名}\quad\\\hline<br/>
\quad\text{Repeat}\quad&amp;\quad\text{重复}\quad\\\hline<br/>
\quad\text{ResidualPlot}\quad&amp;\quad\text{残差图}\quad\\\hline<br/>
\quad\text{Reverse}\quad&amp;\quad\text{逆序排列}\quad\\\hline<br/>
\quad\text{RightSide}\quad&amp;\quad\text{右边}\quad\\\hline<br/>
\quad\text{RigidPolygon}\quad&amp;\quad\text{刚体多边形}\quad\\\hline<br/>
\quad\text{Root}\quad&amp;\quad\text{零点}\quad\\\hline<br/>
\quad\text{RootList}\quad&amp;\quad\text{零值点列}\quad\\\hline<br/>
\quad\text{RootMeanSquare}\quad&amp;\quad\text{均方根}\quad\\\hline<br/>
\quad\text{Roots}\quad&amp;\quad\text{零值点}\quad\\\hline<br/>
\quad\text{Rotate}\quad&amp;\quad\text{旋转}\quad\\\hline<br/>
\quad\text{RotateText}\quad&amp;\quad\text{旋转文本}\quad\\\hline<br/>
\quad\text{Row}\quad&amp;\quad\text{行序}\quad\\\hline<br/>
\quad\text{RunClickScript}\quad&amp;\quad\text{运行单击脚本}\quad\\\hline<br/>
\quad\text{RunUpdateScript}\quad&amp;\quad\text{运行更新脚本}\quad\\\hline<br/>
\quad\text{SD}\quad&amp;\quad\text{标准差}\quad\\\hline<br/>
\quad\text{SDX}\quad&amp;\quad\text{横坐标标准差}\quad\\\hline<br/>
\quad\text{SDY}\quad&amp;\quad\text{纵坐标标准差}\quad\\\hline<br/>
\quad\text{SVD}\quad&amp;\quad\text{奇异值分解}\quad\\\hline<br/>
\quad\text{Sample}\quad&amp;\quad\text{样本}\quad\\\hline<br/>
\quad\text{SampleSD}\quad&amp;\quad\text{样本标准差}\quad\\\hline<br/>
\quad\text{SampleSDX}\quad&amp;\quad\text{样本横坐标标准差}\quad\\\hline<br/>
\quad\text{SampleSDY}\quad&amp;\quad\text{样本纵坐标标准差}\quad\\\hline<br/>
\quad\text{SampleVariance}\quad&amp;\quad\text{样本方差}\quad\\\hline<br/>
\quad\text{ScientificText}\quad&amp;\quad\text{科学记数法}\quad\\\hline<br/>
\quad\text{SecondAxis}\quad&amp;\quad\text{短轴}\quad\\\hline<br/>
\quad\text{SecondAxisLength}\quad&amp;\quad\text{半短轴长}\quad\\\hline<br/>
\quad\text{Sector}\quad&amp;\quad\text{扇形}\quad\\\hline<br/>
\quad\text{Segment}\quad&amp;\quad\text{线段}\quad\\\hline<br/>
\quad\text{SelectObjects}\quad&amp;\quad\text{选择}\quad\\\hline<br/>
\quad\text{SelectedElement}\quad&amp;\quad\text{选定的元素}\quad\\\hline<br/>
\quad\text{SelectedIndex}\quad&amp;\quad\text{选定的索引}\quad\\\hline<br/>
\quad\text{Semicircle}\quad&amp;\quad\text{半圆}\quad\\\hline<br/>
\quad\text{Sequence}\quad&amp;\quad\text{序列}\quad\\\hline<br/>
\quad\text{SetActiveView}\quad&amp;\quad\text{活动视图}\quad\\\hline<br/>
\quad\text{SetAxesRatio}\quad&amp;\quad\text{坐标轴比例}\quad\\\hline<br/>
\quad\text{SetBackgroundColor}\quad&amp;\quad\text{背景色}\quad\\\hline<br/>
\quad\text{SetCaption}\quad&amp;\quad\text{标题}\quad\\\hline<br/>
\quad\text{SetColor}\quad&amp;\quad\text{颜色}\quad\\\hline<br/>
\quad\text{SetConditionToShowObject}\quad&amp;\quad\text{显示条件}\quad\\\hline<br/>
\quad\text{SetConstructionStep}\quad&amp;\quad\text{作图步骤}\quad\\\hline<br/>
\quad\text{SetCoords}\quad&amp;\quad\text{坐标}\quad\\\hline<br/>
\quad\text{SetDynamicColor}\quad&amp;\quad\text{动态颜色}\quad\\\hline<br/>
\quad\text{SetFilling}\quad&amp;\quad\text{填充}\quad\\\hline<br/>
\quad\text{SetFixed}\quad&amp;\quad\text{固定}\quad\\\hline<br/>
\quad\text{SetLabelMode}\quad&amp;\quad\text{标签模式}\quad\\\hline<br/>
\quad\text{SetLayer}\quad&amp;\quad\text{图层}\quad\\\hline<br/>
\quad\text{SetLineStyle}\quad&amp;\quad\text{线型}\quad\\\hline<br/>
\quad\text{SetLineThickness}\quad&amp;\quad\text{线径}\quad\\\hline<br/>
\quad\text{SetPerspective}\quad&amp;\quad\text{格局}\quad\\\hline<br/>
\quad\text{SetPointSize}\quad&amp;\quad\text{点径}\quad\\\hline<br/>
\quad\text{SetPointStyle}\quad&amp;\quad\text{点型}\quad\\\hline<br/>
\quad\text{SetSeed}\quad&amp;\quad\text{设定种子}\quad\\\hline<br/>
\quad\text{SetSpinSpeed}\quad&amp;\quad\text{转速}\quad\\\hline<br/>
\quad\text{SetTooltipMode}\quad&amp;\quad\text{工具提示模式}\quad\\\hline<br/>
\quad\text{SetTrace}\quad&amp;\quad\text{跟踪}\quad\\\hline<br/>
\quad\text{SetValue}\quad&amp;\quad\text{赋值}\quad\\\hline<br/>
\quad\text{SetViewDirection}\quad&amp;\quad\text{指定视向}\quad\\\hline<br/>
\quad\text{SetVisibleInView}\quad&amp;\quad\text{显示对象}\quad\\\hline<br/>
\quad\text{Shear}\quad&amp;\quad\text{切变}\quad\\\hline<br/>
\quad\text{ShortestDistance}\quad&amp;\quad\text{最短距离}\quad\\\hline<br/>
\quad\text{ShowAxes}\quad&amp;\quad\text{显示坐标轴}\quad\\\hline<br/>
\quad\text{ShowGrid}\quad&amp;\quad\text{显示网格}\quad\\\hline<br/>
\quad\text{ShowLabel}\quad&amp;\quad\text{显示标签}\quad\\\hline<br/>
\quad\text{ShowLayer}\quad&amp;\quad\text{显示图层}\quad\\\hline<br/>
\quad\text{Shuffle}\quad&amp;\quad\text{随机排列}\quad\\\hline<br/>
\quad\text{SigmaXX}\quad&amp;\quad\text{横坐标平方和}\quad\\\hline<br/>
\quad\text{SigmaXY}\quad&amp;\quad\text{横纵坐标乘积和}\quad\\\hline<br/>
\quad\text{SigmaYY}\quad&amp;\quad\text{纵坐标平方和}\quad\\\hline<br/>
\quad\text{Simplify}\quad&amp;\quad\text{化简}\quad\\\hline<br/>
\quad\text{Slider}\quad&amp;\quad\text{滑动条}\quad\\\hline<br/>
\quad\text{Slope}\quad&amp;\quad\text{斜率}\quad\\\hline<br/>
\quad\text{SlopeField}\quad&amp;\quad\text{斜率场}\quad\\\hline<br/>
\quad\text{SlowPlot}\quad&amp;\quad\text{缓慢绘制}\quad\\\hline<br/>
\quad\text{Solutions}\quad&amp;\quad\text{解集}\quad\\\hline<br/>
\quad\text{Solve}\quad&amp;\quad\text{精确解}\quad\\\hline<br/>
\quad\text{SolveCubic}\quad&amp;\quad\text{解三次多项式}\quad\\\hline<br/>
\quad\text{SolveODE}\quad&amp;\quad\text{解常微分方程}\quad\\\hline<br/>
\quad\text{SolveQuartic}\quad&amp;\quad\text{解四次多项式}\quad\\\hline<br/>
\quad\text{Sort}\quad&amp;\quad\text{升序排列}\quad\\\hline<br/>
\quad\text{Spearman}\quad&amp;\quad\text{秩相关系数}\quad\\\hline<br/>
\quad\text{Sphere}\quad&amp;\quad\text{球面}\quad\\\hline<br/>
\quad\text{Spline}\quad&amp;\quad\text{样条曲线}\quad\\\hline<br/>
\quad\text{StartAnimation}\quad&amp;\quad\text{启动动画}\quad\\\hline<br/>
\quad\text{StartLogging}\quad&amp;\quad\text{启动日志}\quad\\\hline<br/>
\quad\text{StartRecord}\quad&amp;\quad\text{开始记录}\quad\\\hline<br/>
\quad\text{StemPlot}\quad&amp;\quad\text{茎叶图}\quad\\\hline<br/>
\quad\text{StepGraph}\quad&amp;\quad\text{阶梯图}\quad\\\hline<br/>
\quad\text{StickGraph}\quad&amp;\quad\text{棒图}\quad\\\hline<br/>
\quad\text{StopLogging}\quad&amp;\quad\text{停止日志}\quad\\\hline<br/>
\quad\text{Stretch}\quad&amp;\quad\text{伸缩}\quad\\\hline<br/>
\quad\text{Substitute}\quad&amp;\quad\text{代入}\quad\\\hline<br/>
\quad\text{Sum}\quad&amp;\quad\text{总和}\quad\\\hline<br/>
\quad\text{SumSquaredErrors}\quad&amp;\quad\text{误差平方和}\quad\\\hline<br/>
\quad\text{SurdText}\quad&amp;\quad\text{根式文本}\quad\\\hline<br/>
\quad\text{Surface}\quad&amp;\quad\text{曲面}\quad\\\hline<br/>
\quad\text{TDistribution}\quad&amp;\quad\text{T分布}\quad\\\hline<br/>
\quad\text{TMean2Estimate}\quad&amp;\quad\text{双样本均值T估计}\quad\\\hline<br/>
\quad\text{TMeanEstimate}\quad&amp;\quad\text{单均值T估计}\quad\\\hline<br/>
\quad\text{TTest}\quad&amp;\quad\text{T检验}\quad\\\hline<br/>
\quad\text{TTest2}\quad&amp;\quad\text{双样本T检验}\quad\\\hline<br/>
\quad\text{TTestPaired}\quad&amp;\quad\text{配对T检验}\quad\\\hline<br/>
\quad\text{TableText}\quad&amp;\quad\text{表格文本}\quad\\\hline<br/>
\quad\text{Take}\quad&amp;\quad\text{提取}\quad\\\hline<br/>
\quad\text{Tangent}\quad&amp;\quad\text{切线}\quad\\\hline<br/>
\quad\text{TaylorSeries}\quad&amp;\quad\text{泰勒公式}\quad\\\hline<br/>
\quad\text{Tetrahedron}\quad&amp;\quad\text{正四面体}\quad\\\hline<br/>
\quad\text{Text}\quad&amp;\quad\text{文本}\quad\\\hline<br/>
\quad\text{TextToUnicode}\quad&amp;\quad\text{文本到统一码}\quad\\\hline<br/>
\quad\text{Textfield}\quad&amp;\quad\text{输入框}\quad\\\hline<br/>
\quad\text{TiedRank}\quad&amp;\quad\text{平秩列表}\quad\\\hline<br/>
\quad\text{ToBase}\quad&amp;\quad\text{进制形式}\quad\\\hline<br/>
\quad\text{ToComplex}\quad&amp;\quad\text{复数形式}\quad\\\hline<br/>
\quad\text{ToExponential}\quad&amp;\quad\text{指数形式}\quad\\\hline<br/>
\quad\text{ToPoint}\quad&amp;\quad\text{点形式}\quad\\\hline<br/>
\quad\text{ToPolar}\quad&amp;\quad\text{极坐标形式}\quad\\\hline<br/>
\quad\text{ToolImage}\quad&amp;\quad\text{工具图像}\quad\\\hline<br/>
\quad\text{Top}\quad&amp;\quad\text{上底}\quad\\\hline<br/>
\quad\text{Translate}\quad&amp;\quad\text{平移}\quad\\\hline<br/>
\quad\text{Transpose}\quad&amp;\quad\text{转置}\quad\\\hline<br/>
\quad\text{TrapezoidalSum}\quad&amp;\quad\text{梯形和}\quad\\\hline<br/>
\quad\text{TravelingSalesman}\quad&amp;\quad\text{旅行商问题}\quad\\\hline<br/>
\quad\text{TriangleCenter}\quad&amp;\quad\text{三角形中心}\quad\\\hline<br/>
\quad\text{TriangleCurve}\quad&amp;\quad\text{三角曲线}\quad\\\hline<br/>
\quad\text{Triangular}\quad&amp;\quad\text{三角形分布}\quad\\\hline<br/>
\quad\text{TrigCombine}\quad&amp;\quad\text{三角函数积化和差}\quad\\\hline<br/>
\quad\text{TrigExpand}\quad&amp;\quad\text{三角函数和差化积}\quad\\\hline<br/>
\quad\text{TrigSimplify}\quad&amp;\quad\text{三角函数化简}\quad\\\hline<br/>
\quad\text{Trilinear}\quad&amp;\quad\text{三线坐标点}\quad\\\hline<br/>
\quad\text{TurningPoint}\quad&amp;\quad\text{拐点}\quad\\\hline<br/>
\quad\text{Turtle}\quad&amp;\quad\text{海龟}\quad\\\hline<br/>
\quad\text{TurtleBack}\quad&amp;\quad\text{后退}\quad\\\hline<br/>
\quad\text{TurtleDown}\quad&amp;\quad\text{落笔}\quad\\\hline<br/>
\quad\text{TurtleForward}\quad&amp;\quad\text{前进}\quad\\\hline<br/>
\quad\text{TurtleLeft}\quad&amp;\quad\text{左转}\quad\\\hline<br/>
\quad\text{TurtleRight}\quad&amp;\quad\text{右转}\quad\\\hline<br/>
\quad\text{TurtleUp}\quad&amp;\quad\text{抬笔}\quad\\\hline<br/>
\quad\text{UnicodeToLetter}\quad&amp;\quad\text{统一码到字母}\quad\\\hline<br/>
\quad\text{UnicodeToText}\quad&amp;\quad\text{统一码到文本}\quad\\\hline<br/>
\quad\text{Uniform}\quad&amp;\quad\text{均匀分布}\quad\\\hline<br/>
\quad\text{Union}\quad&amp;\quad\text{并集}\quad\\\hline<br/>
\quad\text{Unique}\quad&amp;\quad\text{互异}\quad\\\hline<br/>
\quad\text{UnitOrthogonalVector}\quad&amp;\quad\text{单位法向量}\quad\\\hline<br/>
\quad\text{UnitVector}\quad&amp;\quad\text{单位向量}\quad\\\hline<br/>
\quad\text{UpdateConstruction}\quad&amp;\quad\text{更新作图}\quad\\\hline<br/>
\quad\text{UpperSum}\quad&amp;\quad\text{上和}\quad\\\hline<br/>
\quad\text{Variance}\quad&amp;\quad\text{方差}\quad\\\hline<br/>
\quad\text{Vector}\quad&amp;\quad\text{向量}\quad\\\hline<br/>
\quad\text{Vertex}\quad&amp;\quad\text{顶点}\quad\\\hline<br/>
\quad\text{VerticalText}\quad&amp;\quad\text{竖排文本}\quad\\\hline<br/>
\quad\text{Volume}\quad&amp;\quad\text{体积}\quad\\\hline<br/>
\quad\text{Voronoi}\quad&amp;\quad\text{Voronoi图}\quad\\\hline<br/>
\quad\text{Weibull}\quad&amp;\quad\text{威布尔分布}\quad\\\hline<br/>
\quad\text{ZMean2Estimate}\quad&amp;\quad\text{双样本均值Z估计}\quad\\\hline<br/>
\quad\text{ZMean2Test}\quad&amp;\quad\text{双样本均值Z检验}\quad\\\hline<br/>
\quad\text{ZMeanEstimate}\quad&amp;\quad\text{单均值Z估计}\quad\\\hline<br/>
\quad\text{ZMeanTest}\quad&amp;\quad\text{单均值Z检验}\quad\\\hline<br/>
\quad\text{ZProportion2Estimate}\quad&amp;\quad\text{双样本比例Z估计}\quad\\\hline<br/>
\quad\text{ZProportion2Test}\quad&amp;\quad\text{双样本比例Z检验}\quad\\\hline<br/>
\quad\text{ZProportionEstimate}\quad&amp;\quad\text{单比例Z估计}\quad\\\hline<br/>
\quad\text{ZProportionTest}\quad&amp;\quad\text{单比例Z检验}\quad\\\hline<br/>
\quad\text{Zip}\quad&amp;\quad\text{映射}\quad\\\hline<br/>
\quad\text{Zipf}\quad&amp;\quad\text{齐普夫分布}\quad\\\hline<br/>
\quad\text{ZoomIn}\quad&amp;\quad\text{放大}\quad\\\hline<br/>
\quad\text{ZoomOut}\quad&amp;\quad\text{缩小}\quad\\\hline<br/>
\quad\text{nPr}\quad&amp;\quad\text{排列数}\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<hr/>

<p><a href="http://jiaoshiqun.cn/geogebra/zhiling">GeoGebra 中英文指令对照表</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15198236385746.html">极坐标计算二重积分</a></h1>
			<p class="meta"><time datetime="2018-02-28T21:13:58+08:00" 
			pubdate data-updated="true">2018/2/28</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在平面里取一个顶点 \(O\)，叫做极点。引一条射线 \(OX\)，叫做极轴，这样便建立了极坐标系。对于平面里任意一点M</p>

<div align="center">
    <img src="media/15198236385746/15349443539184.jpg" width="230" />
</div>

<p>其中 \(|OM|=r\)，\(\angle XOM = \theta\)，这样 \(M\) 点的极坐标便是 \((r,\theta)\)。以 \(O\) 点为原点，\(OX\) 为 \(X\) 轴，过 \(O\) 点垂直 \(X\) 轴，作射线 \(OY\) 为 \(Y\) 轴，这样可以将极坐标转为平面坐标，如下图：</p>

<div align="center">
    <img src="media/15198236385746/15349451158772.jpg" width="280" />
</div>

<p>图中显然 \(|OA| = |OM| \sin\theta = r\sin\theta\)，\(|OB| = |OM|\cos\theta = r\cos\theta\)，所以 \(M\) 点的平面坐标为 \((r\cos\theta,r\sin\theta)\)。同理如果给出了点 \(N\) 的平面坐标为 \((x,y)\)，那么：<br/>
\[<br/>
\tan\theta = \frac{y}{x}\\<br/>
r^2 = x^2+y^2<br/>
\]</p>

<p>通过这样可以进行转换平面坐标转极坐标。</p>

<h3 id="toc_0">极坐标下的面积</h3>

<p>如下图的圆中：</p>

<div align="center">
    <img src='media/15198236385746/15349482178114.jpg' width="200" />
</div>

<p>在扇形夹角和半径已知的情况下，很容易求出扇形的面积：<br/>
\[<br/>
\Delta \mathbf A = \pi r^2 \frac{\Delta \theta}{2\pi} = \frac 1 2 r^2\Delta \theta\\<br/>
\]</p>

<p>现在来看一个无规则形状：</p>

<div align="center">
    <img src="media/15198236385746/15349533671011.jpg" width="230" />
</div>

<p>我们可以利用黎曼和的知识对其进行切分，形成一个个小扇形，这个小扇形如果角度足够小可以将其当做半径为 \(r\) 圆形里面的一个扇形：<br/>
\[<br/>
\Delta \mathbf A \approx \pi r^2 \frac{\Delta \theta}{2\pi} = \frac 1 2 r^2\Delta \theta\\<br/>
\mathbb d\mathbf A = \frac 1 2 r^2\mathbb d \theta\\<br/>
\]</p>

<p>曲线内的任意扇形面积：<br/>
\[<br/>
\mathbf A_{part} = \int_{\theta_2}^{\theta_1} \frac 1 2 r^2\mathbb d \theta<br/>
\]</p>

<p>整个面积：<br/>
\[<br/>
\mathbf A = \int_{-{\pi}/{2}}^{{\pi}/{2}} \frac 1 2 r^2\mathbb d \theta<br/>
\]</p>

<h3 id="toc_1">二重积分的极坐标转换</h3>

<p>二重积分的被积函数为 \(f(x,y)\)，令 \(x=r\cos\theta\)，\(y=r\sin\theta\)，所以被积函数可以转换为 \(f(r\cos\theta,r\sin\theta)\)，现在来看极坐标下的积分元素 \(d\sigma\) 的表示方法。设积分区域 \(D\) 为平面有界区域, 并且从原点发出的射线与 \(D\) 的边界线交点不多于两个, 则区域 \(D\) 被分割情形见下图. </p>

<div align="center">
    <img width="280" src="media/15198236385746/15349528135200.jpg" />
</div>

<p>图中分割的其中一小块的面积为：<br/>
\[<br/>
\begin{align*}<br/>
\triangle \sigma &amp;= \frac 1 2 (r+\triangle r)^2 \triangle \theta - \frac 1 2 r^2 \triangle \theta \\<br/>
&amp;= r \triangle r \triangle \theta + \frac 1 2 \triangle r^2\triangle \theta<br/>
\end{align*}<br/>
\]</p>

<p>去掉高阶无穷小 \(\frac 1 2 \triangle r^2\triangle \theta\)，可得：<br/>
\[<br/>
\triangle \sigma \approx r\triangle r\triangle \theta<br/>
\]</p>

<p>故：<br/>
\[<br/>
\mathbb d\sigma = r\mathbb d r\mathbb d\theta<br/>
\]</p>

<p>于是，二重积分<br/>
\[<br/>
\iint\limits_D f(x,y) \mathbb dx \mathbb dy = \iint\limits_D f(r\cos\theta,r\sin\theta) r\mathbb dr\mathbb d\theta<br/>
\]</p>

<h4 id="toc_2">极坐标下极坐标转化为累次积分的三种形式</h4>

<p>如下区域特征：<br/>
    <div align="center"><br/>
        <img src="media/15198236385746/15349545736898.jpg" width="250" /><br/>
    </div></p>

<p>其中：<br/>
    \[<br/>
    D = \left \{ \begin{array}\\<br/>
    \alpha\le\theta\le\beta\\<br/>
    \varphi_1(\theta)\le r\le \varphi_2(\theta)<br/>
    \end{array} \right .<br/>
    \]</p>

<p>现在区间 \([\alpha,\beta]\) 上任意取定一个 \(\theta\) 值，\(D\) 上的极径 \(r\) 从 \(\varphi_1(\theta)\) 变到 \(\varphi_2(\theta)\) 。又 \(\theta\) 是在 \([\alpha,\beta]\) 上任意取定的，所以 \(\theta\) 的变化范围是 \([\alpha,\beta]\) 。这样就可看出，极坐标系中的二重积分的公式为：<br/>
\[<br/>
\begin{align*}<br/>
\iint\limits_D f(x,y) \mathbb dx \mathbb dy &amp;= \iint\limits_D f(r\cos\theta,r\sin\theta) r\mathbb dr\mathbb d\theta\\<br/>
&amp;= \int_{\alpha}^{\beta}\Big[\int_{\varphi_1(\theta)}^{\varphi_2(\theta)} f(r\cos\theta,r\sin\theta)r\mathbb dr\Big]\mathbb d\theta\\<br/>
&amp;= \int_{\alpha}^{\beta} \mathbb d\theta \int_{\varphi_1(\theta)}^{\varphi_2(\theta)} f(r\cos\theta,r\sin\theta)r\mathbb dr\\<br/>
\end{align*}<br/>
\]</p>

<p>再看两个上图的特例情况：</p>

<ol>
<li><p>\(0\le r \le \varphi(\theta)\)，\(\alpha\le \theta\le\beta\)：<br/>
<div align="center"><br/>
    <img src="media/15198236385746/15349556750495.jpg" width="220" /><br/>
</div></p>

<p>\[<br/>
\begin{align*}<br/>
\iint\limits_D f(x,y) \mathbb dx \mathbb dy = \int_{\alpha}^{\beta} \mathbb d\theta \int_0^{\varphi(\theta)} f(r\cos\theta,r\sin\theta)r\mathbb dr\\<br/>
\end{align*}<br/>
\]</p></li>
<li><p>\(0\le r \le \varphi(\theta)\)，\(0\le\theta\le 2\pi\)：<br/>
<div align="center"><br/>
    <img src="media/15198236385746/15349558131970.jpg" width="220" /><br/>
</div></p>

<p>\[<br/>
\begin{align*}<br/>
\iint\limits_D f(x,y) \mathbb dx \mathbb dy = \int_{0}^{2\pi} \mathbb d\theta \int_0^{\varphi(\theta)} f(r\cos\theta,r\sin\theta)r\mathbb dr\\<br/>
\end{align*}<br/>
\]</p></li>
</ol>

<hr/>

<p><a href="https://wenku.baidu.com/view/d2c27c0510661ed9ac51f325.html">极坐标下二重积分的计算</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15195107498771.html">马尔科夫链蒙特卡罗方法 Markov Chain Monte Carlo，MCMC</a></h1>
			<p class="meta"><time datetime="2018-02-25T06:19:09+08:00" 
			pubdate data-updated="true">2018/2/25</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>对于一般的分布的采样，之前已经有一些方法可以解决，但是对于一些复杂分布的采样，却没有很好的函数实现，本文将介绍 MCMC 方法提供解决方法。</p>

<h3 id="toc_0">马尔科夫链 Markov Chain</h3>

<p>设 \(X_t\) 表示随机变量 \(X\) 在时刻 \(t\) 的取值，若该变量随时间变化的转移概率仅仅依赖于它的当前取值，与过去状态无关，所谓的“遗忘性”，即：<br/>
\[<br/>
P(X_{t+1}=s_{t+1}|X_0=s_0,X_1=s_1,...,X_t=s_t) = P(X_{t+1}=s_{t+1}|X_t=s_t)<br/>
\]</p>

<p>也就是说状态转移仅仅依赖于前一个状态，其中 \(s_0,s_1,...,s_i,...\) 表示随机变量 \(X\) 的可能状态，这个性质称为马尔科夫性质。具有马尔科夫性质的随机过程叫马尔科夫过程，其中变量称为马尔科夫变量。</p>

<p>马尔可夫链指的是在一段时间内随机变量X的取值序列 \((X_0,X_1,...,X_m)\) ，它们满足如上的马尔可夫性质。</p>

<ol>
<li>时间、状态都离散的叫做马尔可夫链。</li>
<li>时间连续、状态离散的叫做时间连续马尔可夫链。</li>
<li>时间、状态都连续的叫做马尔可夫过程。</li>
</ol>

<h4 id="toc_1">转换概率</h4>

<p>马尔可夫链是通过对应的转移概率定义的，转移概率指的是随机变量从一个时刻到下一个时刻，从状态 \(s_i\) 转移到另一个状态 \(s_j\) 的概率，即：<br/>
\[<br/>
P(i\rightarrow j):=P_{i,j} = P(X_{t+1}=s_j|X_t = s_i)<br/>
\]</p>

<p>记 \(\pi_k^{(t)}\) 表示随机变量 \(X\) 在时刻 \(t\) 的取值为 \(s_k\) 的概率，则随机变量 \(X\) 在时刻 \(t+1\) 的取值为 \(s_i\) 的概率为：<br/>
\[<br/>
\begin{align*}<br/>
\pi_i^{(t+1)} &amp;= P(X_{t+1} = s_i)\\<br/>
&amp;= \sum_{k} P(X_{t+1}=s_i|X_t = s_k)\cdot P(X_t=s_k)\\<br/>
&amp;= \sum_k P_{k,i}\cdot \pi_{k}^{(t)}<br/>
\end{align*}<br/>
\]</p>

<p>假设状态的数目为 \(n\)，则有：<br/>
\[<br/>
(\pi_1^{(t+1)},\cdots,\pi_j^{(t+1)},\cdots,\pi_n^{(t+1)}) = (\pi_1^{(t)},\cdots,\pi_i^{(t)},\cdots,\pi_1^{(t)})\left [ \begin{array}{cccccc}<br/>
P_{1,1}&amp;P_{1,2}&amp;\cdots&amp;P_{1,j}&amp;\cdots&amp;P_{1,n}\\<br/>
P_{2,1}&amp;P_{2,2}&amp;\cdots&amp;P_{2,j}&amp;\cdots&amp;P_{2,n}\\<br/>
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\cdots&amp;\vdots\\<br/>
P_{i,1}&amp;P_{i,2}&amp;\cdots&amp;P_{i,j}&amp;\cdots&amp;P_{i,n}\\<br/>
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\cdots&amp;\vdots\\<br/>
P_{n,1}&amp;P_{n,2}&amp;\cdots&amp;P_{n,j}&amp;\cdots&amp;P_{n,n}\\<br/>
\end{array} \right]<br/>
\]</p>

<p>对于任意的 \(i\) 都有 \(\sum_{j=1}^n P_{i,j} = 1\)。若设 \(\Pi=[\pi_1^{(0)},\pi_2^{(0)},\cdots,\pi_n^{(0)}]\) 是系统的初始概率分布，\(\pi_i^{(0)}\) 是系统在初始时刻处于状态 \(i\) 的概率，满足 \(\sum_{i=1}^n \pi_i^{(0)}=1\) 。</p>

<h4 id="toc_2">平稳分布</h4>

<p>对于马尔可夫链，需要注意以下的两点：</p>

<ol>
<li>周期性：即经过有限次的状态转移，又回到了自身；</li>
<li>不可约：即两个状态之间相互转移；</li>
</ol>

<p><strong>马氏定理：</strong>如果一个非周期不可约马尔可夫链的转移矩阵为 \(P\)，无论初始值 \(\pi^{(0)}\) 的取值，都有 \(\lim_{t\rightarrow \infty} \pi^{(0)} P^t\) 存在且初始值无关，记 \(\lim_{t\rightarrow \infty} \pi^{(0)} P^t = \pi^*\)，我们有：<br/>
\[<br/>
\pi^* P = \pi^*<br/>
\]</p>

<p>\(pi\) 是方程唯一非负解。其中：<br/>
\[<br/>
\pi^* =[\pi(1),\pi(2),\cdots,\pi(j),\cdots],\quad \sum_{i=0}^n \pi(i)=1<br/>
\]</p>

<p>则称 \(\pi^*\) 为马尔可夫链的平稳分布。存在稳态分布要求马尔可夫链是连通的（没有孤立点），同时不存在一个连通子图是没有对外的出边的。</p>

<p><strong>细致平稳条件：</strong>如果非周期马尔可夫链的转移矩阵 \(P\) 和分布 \(\pi\) 满足 <br/>
\[<br/>
\pi(i) P_{i,j} = \pi(j) P_{j,i},\quad \forall i,j<br/>
\]</p>

<p>则 \(\pi^*=(\pi(1),\pi(2),\cdots,\pi(j),\cdots)\) 是马尔可夫链的平稳分布。</p>

<p>这个定理是显而易见的，因为细致平稳条件的物理含义就是对于任何两个状态 \(i,j\) ，从 \(i\) 转移出去到 \(j\) 而丢失的概率质量，恰好会被从 \(j\) 转移回来到 \(i\) 的概率质量补充，所以状态 \(i\) 上的概率质量 \(\pi(i)\) 是稳定的，从而 \(\pi^*\) 是马尔可夫链的平稳分布。数学上的证明也很简单，由细致平稳条件可得：<br/>
\[<br/>
\sum_{i=1}^n \pi(i)P_{i,j}=\sum_{i=1}^n \pi(j)P_{j,i}= \pi(j)\sum_{i=1}^n P_{j,i} =\pi(j)\\<br/>
\Rightarrow \pi P=\pi<br/>
\]</p>

<p>由于 \(\pi^*\) 是方程 \(\pi P=\pi\) 的解，所以 \(\pi^*\) 是平稳分布。</p>

<p>马氏定理和细致平稳条件非常重要，是MCMC(Markov Chain Monte Carlo) 方法的基础。</p>

<h3 id="toc_3">Metropolis 采样</h3>

<p>对于给定的概率分布 \(p(x)\)，我们希望能有便捷的方式生成它对应的样本。由于马氏链能收敛到平稳分布，于是一个很的漂亮想法是：如果我们能构造一个转移矩阵为 \(P\) 的马氏链，使得该马氏链的平稳分布恰好是 \(p(x)\)，那么我们从任何一个初始状态 \(x_0\) 出发沿着马氏链转移, 得到一个转移序列 \(x_0,x_1,x_2,\cdots,x_n,x_{n+1},\cdots\)， 如果马氏链在第 \(n\) 步已经收敛了，于是我们就得到了 \(\pi(x)\) 的样本 \(x_n,x_{n+1},\cdots\)。</p>

<p>这个绝妙的想法在 1953 年被 Metropolis 想到了，为了研究粒子系统的平稳性质， Metropolis 考虑了物理学中常见的波尔兹曼分布的采样问题，首次提出了基于马氏链的蒙特卡罗方法，即 Metropolis 算法，并在最早的计算机上编程实现。Metropolis 算法是首个普适的采样方法，并启发了一系列 MCMC 方法，所以人们把它视为随机模拟技术腾飞的起点。 Metropolis 的这篇论文被收录在《统计学中的重大突破》中， Metropolis 算法也被遴选为二十世纪的十个最重要的算法之一。</p>

<p>假设现在有个转移矩阵为 \(Q\) 的马氏链，其中 \(q(j|i)\)，表示马尔可夫链在第 \(t\) 代时的状态为 \(i\) ，下一时刻转移到状态为 \(j\) 的概率。此时不满足细致平稳性：<br/>
\[<br/>
\pi(i) q(j|i) \neq \pi(j) q(i|j),\quad \forall i,j<br/>
\]</p>

<p>为了满足细致平稳性，在左边乘上右边，在右边乘上左边，也就是：<br/>
\[<br/>
\pi(i) q(j|i)\pi(j) q(i|j) = \pi(j) q(i|j)\pi(i) q(j|i),\quad \forall i,j<br/>
\]</p>

<p>令 \(\alpha(j|i) = \pi(j) q(i|j)\)，则上式可以写成：<br/>
\[<br/>
\pi(i) q(j|i) \alpha(j|i) = \pi(j) q(i|j) \alpha(i|j),\quad \forall i,j<br/>
\]</p>

<p>假设 \(Q&#39;(j|i) = q_(j|i) \alpha(j|i)\) ，所以有：<br/>
\[<br/>
\begin{align}<br/>
\pi(i)\underbrace{q(j|i) \alpha(j|i)}_{Q&#39;(j|i)} = \pi(j) \underbrace{ q(i|j) \alpha(i|j)}_{Q&#39;(i|j)}\label{puaq}\\<br/>
\end{align}<br/>
\]</p>

<p>将 \(Q&#39;(j|i)\) 视为新的转移概率，这样便把原先具有转移矩阵 \(Q\) 的普通马氏链，改造为具有转移矩阵 \(Q&#39;\) 的马氏链，而 \(Q&#39;\) 是满足细致平稳条件的，平稳分布是 \(\pi^*\)，在改造过程中引入了接受概率 \(\alpha(i,j)\)，物理意义可以理解为在原来的马氏链上，从状态 \(i\) 以 \(q(j|i)\) 跳转到状态 \(j\) 的时候，我们以 \(\alpha(i|j)\) 的概率接受这个转移，于是得到新的马氏链 \(Q&#39;\) 的转移概率为 \(q(j|i) \alpha(j|i)\) 。</p>

<p>得到接受概率 \(\alpha\) 之后，就可以随机从均匀分布中得到 \(u\) 值，如果 \(u \le \alpha(j|i) = \pi(j) q(i|j)\) 则接受状态 \(i\) 转移 到 \(j\)，否则不接受转移。</p>

<p>具体的算法流程如下：</p>

<ol>
<li>初始化马氏链初始状态 \(X_0 = x_0\)</li>
<li><p>对 \(t=0,1,2,...\)，循环以下过程进行采样</p>

<ul>
<li>第 \(t\) 个时刻马氏链的状态 \(X_t = x_t\)，采样 \(y\sim q(x|x_t)\)</li>
<li>从均匀分布采样 \(u\sim U(0,1)\)</li>
<li>如果 \(u\le \alpha(y|x_t) =  \pi(y) q(x_t|y)\)，则接受转移 \(x_t\rightarrow y\)，即\(X_{t+1} = y\)</li>
<li>否则不接收转移，即 \(X_{t+1} = x_t\)</li>
</ul></li>
</ol>

<p>上面过程中 \(p(x)\)，\(q(x|y)\) 说的是离散的情形，事实上即便这两个分布是连续的，以上算法仍然是有效的，于是就得到更一般的连续概率分布 \(p(x)\) 的采样算法，而 \(q(x|y)\) 就是一个任意一个连续二元概率分布对应的条件分布。</p>

<h5 id="toc_4">Metropolis-Hastings 算法</h5>

<p>但是Metropolis算法构造出的接受概率可能会很小，这样造成算法要经过很多的迭代才能到达平稳分布。为了加快收敛效果，我们需要在 \ref{puaq} 两边同比例增加 \(\alpha(i|j)\) 和 \(\alpha(j|i)\) ,假设要将左边的 \(\alpha(i|j)\) 增加到 1 ，需要两边同乘上 \(\frac{1}{\alpha(i|j)}\) 倍，则右边接受概率变为 \(\frac{\alpha(j|i)}{\alpha(i|j)}\)：<br/>
\[<br/>
\pi(i) q(j|i) = \pi(j) q(i|j) \frac{\alpha(i|j)}{\alpha(j|i)} = \frac{\pi(i) q(j|i)}{\pi(j) q(i|j)},\quad \forall i,j<br/>
\]</p>

<p>这样接受概率就可以写成：<br/>
\[<br/>
\begin{align*}<br/>
\alpha(j|i) &amp;= 1\\<br/>
\alpha(i|j) &amp;= \frac{\pi(i) q(j|i)}{\pi(j) q(i|j)}\\<br/>
\end{align*}<br/>
\]</p>

<p>因为在 Metropolis 采样算法过程中，生成 \([0,1]\) 均匀分布随机值 \(u\) 必定不大于1，可以将 \(\alpha(i|j)\) 缩小范围：<br/>
\[<br/>
\alpha(i|j) = \frac{\pi(i) q(j|i)}{\pi(j) q(i|j)}\quad\Leftrightarrow\quad \alpha(i|j) = \min\bigg({1,\frac{\pi(i) q(j|i)}{\pi(j) q(i|j)}}\bigg)<br/>
\]</p>

<p>这样改造后接受概率对后续过程并没有影响。</p>

<p>具体的算法流程如下：</p>

<ol>
<li>初始化马氏链初始状态 \(X_0 = x_0\)</li>
<li><p>对 \(t=0,1,2,...\)，循环以下过程进行采样</p>

<ul>
<li>第 \(t\) 个时刻马氏链的状态 \(X_t = x_t\)，采样 \(y\sim q(x|x_t)\)</li>
<li>从均匀分布采样 \(u\sim U(0,1)\)</li>
<li>如果 \(u\le \alpha(y|x_t) =  \min\bigg({1,\frac{\pi(y) q(x_t|y)}{\pi(x_t) q(y|x_t)}}\bigg)\)，则接受转移 \(x_t\rightarrow y\)，即\(X_{t+1} = y\)</li>
<li>否则不接收转移，即 \(X_{t+1} = x_t\)</li>
</ul></li>
</ol>

<p>对于分布 \(\pi(x)\)，我们构造转移矩阵 \(Q&#39;\) 使其满足细致平稳条件<br/>
\[<br/>
p(x)Q&#39;(x\rightarrow y) = p(y)Q&#39;(y\rightarrow x)<br/>
\]</p>

<p>此处 \(x\) 并不要求是一维的，对于高维空间的 \(p(\mathbf x)\)，如果满足细致平稳条件：<br/>
\[<br/>
p(\mathbf x)Q&#39;(\mathbf x\rightarrow \mathbf y) = p(\mathbf y)Q&#39;(\mathbf y\rightarrow \mathbf x)<br/>
\]</p>

<p>那么以上的 Metropolis-Hastings 算法一样有效。</p>

<h3 id="toc_5">MCMC-Gibbs Sampling算法</h3>

<p>设想 \(p(x,y)\) 是 p.d.f. 或 p.m.f. ，如果直接对他们进行采样会比较困难。不过，我们假设我们可以很容易地从条件分布 \(p(x|y)\) 和 \(p(y|x)\) 中进行采样。假设有两个 \(x\) 轴坐标相同的点 \(A(x_1,y_1)\) 和 \(B(x_1,y_2)\)。<br/>
易得：<br/>
\[<br/>
p(x_1,y_1) p(y_2|x_1) = p(x_1)p(y_1|x_1)p(y_2|x_1)\\<br/>
p(x_1,y_2) p(y_1|x_1) = p(x_1)p(y_2|x_1)p(y_1|x_1)\\<br/>
\]</p>

<p>比较上述两个等式右边得：<br/>
\[<br/>
\begin{align}<br/>
p(x_1,y_1) p(y_2|x_1) = p(x_1,y_2) p(y_1|x_1)\label{pxyp}\\<br/>
\end{align}<br/>
\]</p>

<p>即<br/>
\[<br/>
\begin{align}<br/>
p(A) p(y_2|x_1) = p(B) p(y_1|x_1)\label{papy}\\<br/>
\end{align}<br/>
\]</p>

<p>同理，如果现在有个点 \(C(x_3,y_1)\)，和点 \(A\) 在同一个 \(y\) 轴上，有如下等式：<br/>
\[<br/>
\begin{align}<br/>
p(A) p(x_3,y_1) = p(C) p(x_1|y_1)\label{papx}\\<br/>
\end{align}<br/>
\]</p>

<p>令<br/>
\[<br/>
\begin{align*}<br/>
&amp;Q(A\rightarrow B) = p(y_B|x_1) &amp;\quad \text{if }x_A = x_B = x_1\\<br/>
&amp;Q(A\rightarrow C) = p(x_C|y_1) &amp;\quad \text{if }y_A = y_C = y_1\\<br/>
&amp;Q(A\rightarrow D) = 0 &amp;\quad \text{otherwise} \\<br/>
\end{align*}<br/>
\]</p>

<p>代入(\ref{papy})和(\ref{papx})得：<br/>
\[<br/>
p(A) Q(A\rightarrow B) = p(B) Q(B\rightarrow A)\\<br/>
p(A) Q(A\rightarrow C) = p(C) Q(C\rightarrow A)\\<br/>
\]</p>

<p>有了如上的转移矩阵 Q，我们很容易知道对平面上任意两点 \(X\)、\(Y\)，满足细致平稳条件<br/>
\[<br/>
\begin{align}<br/>
p(X)Q(X\rightarrow Y)=p(Y)Q(Y\rightarrow X)\label{pxqx}\\<br/>
\end{align}<br/>
\]</p>

<p>于是这个二维空间上的马氏链将收敛到平稳分布 \(p(x,y)p(x,y)\)。而这个算法就称为 Gibbs Sampling 算法。</p>

<h5 id="toc_6">算法步骤</h5>

<ol>
<li>随机初始化 \(x_0,y_0\)</li>
<li><p>对于 \(t=0,1,2,\cdots\)，循环采样</p>

<ul>
<li>从条件分布 \(p(Y|X=x_t)\) 中采样 \(y_{t+1}\) 得到点 \((x_t,y_{t+1})\)。</li>
<li>从条件分布 \(p(X|Y=y_{t+1})\) 中采样 \(x_{t+1}\) 得到点 \((x_{t+1},y_{t+1})\)。</li>
</ul></li>
</ol>

<h5 id="toc_7">Gibbs sampling 中的马氏转移链</h5>

<p>以上采样过程中，如图所示，马氏链的转移只是轮换的沿着坐标轴 \(x\) 轴和 \(y\) 轴做转移，于是得到样本 \((x_0,y_0),(x_0,y_1),(x_1,y_1),(x_1,y_2),(x_2,y_2),\cdots\) 马氏链收敛后，最终得到的样本就是 \(p(x,y)p(x,y)\) 的样本，而收敛之前的阶段称为 burn-in period。</p>

<p>Gibbs Sampling 算法大都是坐标轴轮换采样的，但是这其实是不强制要求的。最一般的情形可以是，在 \(t\) 时刻，可以在 \(x\) 轴和 \(y\) 轴之间随机的选一个坐标轴，然后按条件概率做转移，马氏链也是一样收敛的。轮换两个坐标轴只是一种方便的形式。</p>

<p>以上的过程我们很容易推广到高维的情形，对于(\ref{papx})式，如果 \(x_1\) 变为多维情形 \(\mathbf x_1\)，可以看出推导过程不变，所以细致平稳条件同样是成立的<br/>
\[<br/>
p(\mathbf x_1,y_1)p(y_2|\mathbf x_1)=p(\mathbf x_1,y_2)p(y_1|\mathbf x_1)<br/>
\]</p>

<p>此时转移矩阵 \(Q\) 由条件分布 \(p(y|\mathbf x_1)\) 定义。上式只是说明了一根坐标轴的情形，和二维情形类似，很容易验证对所有坐标轴都有类似的结论。所以 \(n\) 维空间中对于概率分布 \(p(x_1,x_2,\cdots,x_n)\) 可以如下定义转移矩阵：马氏链转移的过程中，只能沿着坐标轴做转移，每次只转移一根坐标轴，沿着 \(x_i\) 这根坐标轴做转移的时候，转移概率由条件概率 \(p(x_i|x_1,x_2,\cdots,x_{i-1},x_{i+1},\cdots,x_n)\) 定义；其他的轴转移概率都设置为 0。</p>

<p>于是我们可以把 Gibbs Smapling 算法从采样二维的 \(p(x,y)\) 推广到采样 \(n\) 维的 \(p(x_1,x_2,...,x_n)\)。</p>

<h5 id="toc_8">n 维 Gibbs Sampling 算法步骤</h5>

<ol>
<li>随机初始化 \(\{x_i:i=1,2,\cdots,n \}\)</li>
<li>对 \(t=0,1,\cdots\) 循环采样

<ul>
<li>\(x_1^{(t+1)} = p(x_1|x_2^{(t)},x_3^{(t)},\cdots,x_n^{(t)})\)</li>
<li>\(x_2^{(t+1)} = p(x_2|x_1^{(t)},x_3^{(t)},\cdots,x_n^{(t)})\)</li>
<li>\(\cdots\)</li>
<li>\(x_j^{(t+1)} = p(x_1|x_2^{(t)},x_3^{(t)},\cdots,x_{j-1}^{(t)},x_{j+1}^{(t)},\cdots,x_n^{(t)})\)</li>
<li>\(\cdots\)</li>
<li>\(x_n^{(t+1)} = p(x_n|x_2^{(t)},x_3^{(t)},\cdots,x_{n-1}^{(t)})\)</li>
</ul></li>
</ol>

<p>以上算法收敛后，得到的就是概率分布 \(p(x_1,x_2,\cdots,x_n)\) 的样本，当然这些样本并不独立，但是我们此处要求的是采样得到的样本符合给定的概率分布，并不要求独立。同样的，在以上算法中，坐标轴轮换采样不是必须的，可以在坐标轴轮换中引入随机性，这时候转移矩阵 \(Q\) 中任何两个点的转移概率中就会包含坐标轴选择的概率，而在通常的 Gibbs Sampling 算法中，坐标轴轮换是一个确定性的过程，也就是在给定时刻 \(t\)，在一根固定的坐标轴上转移的概率是 1。</p>

<h3 id="toc_9">总结</h3>

<p>无论 metropolis-hasting 算法还是 gibbs 算法，都需要一个 burn in 过程，只有在达到平衡状态时候得到的样本才能是平衡状态时候的目标分布的样本，因此，在 burn in 过程中产生的样本都需要被舍弃。如何判断一个过程是否达到了平衡状态还没有一个成熟的方法来解决，目前常见的方法是看是否状态已经平稳。</p>

<p>关于链的收敛有这样一些检验方法</p>

<ol>
<li><strong>图形方法</strong>：这是简单直观的方法。我们可以利用这样一些图形：

<ul>
<li>迹图（trace plot）：将所产生的样本对迭代次数作图，生成马氏链的一条样本路径。如果当 \(t\) 足够大时，路径表现出稳定性没有明显的周期和趋势，就可以认为是收敛了。</li>
<li>自相关图（Autocorrelation plot）：如果产生的样本序列自相关程度很高，用迹图检验的效果会比较差。一般自相关随迭代步长的增加而减小，如果没有表现出这种现象，说明链的收敛性有问题。</li>
<li>遍历均值图（ergodic mean plot）：MCMC的理论基础是马尔科夫链的遍历定理。因此可以用累积均值对迭代步骤作图，观察遍历均值是否收敛。</li>
</ul></li>
<li><strong>蒙特卡洛误差</strong></li>
<li><strong>Gelman-Rubin方法</strong></li>
</ol>

<hr/>

<p><a href="https://www.cnblogs.com/xbinworld/p/4266146.html">随机采样方法整理与讲解</a><br/>
<a href="https://www.jianshu.com/p/1511c94b2ac3">LDA漫游系列(四)-Gibbs Sampling</a><br/>
<a href="https://cosx.org/2013/01/lda-math-mcmc-and-gibbs-sampling/">靳志辉 LDA-math-MCMC 和 Gibbs Sampling</a><br/>
<a href="https://www.zybuluo.com/evilking/note/753058">自相关</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15189654050126.html">蒙特卡罗方法 Monte Carlo Simulation</a></h1>
			<p class="meta"><time datetime="2018-02-18T22:50:05+08:00" 
			pubdate data-updated="true">2018/2/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>蒙特卡罗方法（也常称之为 MC）也叫统计模拟方法，它使用随机数（或伪随机数）来解决问题，是一类重要的数值计算方法。该方法的名字来源于世界著名的赌城蒙特卡罗，而蒙特卡罗方法正是以概率为基础的方法。</p>

<p>由概率定义知，某事件的概率可以用大量试验中该事件发生的频率来估算，当样本容量足够大时，可以认为该事件的发生频率即为其概率。蒙特卡罗方法正是基于这个思想。一个简单的例子可以解释蒙特卡罗方法，假设我们需要计算一个不规则图形的面积，那么图形的不规则程度和分析性计算（比如积分）的复杂程度是成正比的。而采用蒙特卡罗方法是怎么计算的呢？首先你把图形放到一个已知面积的方框内，然后假想你有一些豆子，把豆子均匀地朝这个方框内撒，散好后数这个图形之中有多少颗豆子，再根据图形内外豆子的比例来计算面积。当你的豆子越小，撒的越多的时候，结果就越精确。</p>

<p>蒙特卡罗方法出现后很长一段时间都不太受到关注，直到计算机的出现，使大量模拟变得简单，这种方法才重新被关注起来。</p>

<p>下面我们使用模特卡罗方法解决几个有趣的问题：</p>

<h4 id="toc_0">圆周率 \(\pi\) 的计算</h4>

<p>圆周率的计算常用的方法是割圆法，这里我们使用蒙特卡罗方法很容易得出，这也是蒙特卡罗算法最经典的应用。假设我们有一个半径为 \(r\) 的圆形，很容找到它外切的边长为 \(2r\) 的正方形：</p>

<div align="center">
    <img src="media/15189654050126/15348520595458.jpg" width="250" />
</div>

<p>我们知道正方形的面积为 \(2r\times 2r=4r^2\) ，圆的面积为 \(\pi r^2\)，面积之比为：<br/>
\[<br/>
p = \frac{s(\text{circle})}{s(\text{square})} = \frac{\pi r^2}{4r^2} = \frac{\pi}{4}<br/>
\]</p>

<p>现在使用蒙特卡罗方法生成 \(n\) 对 \([-r,+r]\) 内的随机数（包含x、y两个坐标），计算是否在圆内（与圆心的距离与 \(r\) 比较），若有 \(m\) 个点落到圆内，我们可以认为落到圆内的概率与圆与正方形面积之比相等，即：<br/>
\[<br/>
\frac{m}{n} = \frac{\pi}{4} \quad\Rightarrow\quad \pi = \frac{4m}{n}<br/>
\]</p>

<p>通过这种方法，随着 \(n\) 的增大，\(\pi\) 会越来越精确。</p>

<h4 id="toc_1">自然对数 \(\mathbf e\) 的计算</h4>

<p>使用蒙特卡罗方法计算自然对数便不那么直观了，我们来考虑一下如下的定积分：<br/>
\[<br/>
S = \int_1^2 \frac 1 x dx<br/>
\]</p>

<p>我们将这个函数画出<br/>
<div align="center"><br/>
    <img src="media/15189654050126/15348619268478.jpg" width="250" /><br/>
</div></p>

<p>如上图所示上述定积分的值即是绿色曲线与正方形围成的面积。我们通过牛顿莱布尼兹公式求定积分为：<br/>
\[<br/>
S = \ln(x)\Big|_1^2 = \ln(2) - \ln(1) = \ln(2)<br/>
\]</p>

<p>使用蒙特卡罗方法求解这个面积，先在所标矩形内取 \(n\) 对随机点 \((x_1,y_1),(x_2,y_2),...,(x_n,y_n)\)，即 \(x_i\) 取值范围为 \([1,2]\)，\(y_i\) 取值范围为 \([0,1]\)。满足<br/>
\[<br/>
y_i &lt; \frac 1 {x_i}<br/>
\]</p>

<p>的点将在所要求的面积之内，所以正方形内曲线下面的面积与正方形面积之比为落在曲线下方区域与全部随机点个数之比。假设有 \(m\) 个点满足条件，即：<br/>
\[<br/>
\frac{m}{n} = \frac{\ln(2)}{1}\quad\Rightarrow\quad \log_e 2 = \frac m n \quad\Rightarrow\quad e = 2^{m/n}<br/>
\]</p>

<h4 id="toc_2">定积分的计算</h4>

<p>使用蒙特卡罗计算定积分有两种方法：一种就是上面的那种方法“面积法”，定积分的值便是阴影部分的面积，这里不再叙述。另一种方法是“期望法”现在来介绍这种方法：</p>

<p>看如下的积分：<br/>
\[<br/>
\theta = \int_a^b f(x)dx<br/>
\]</p>

<p>如果我们很难求出 \(f(x)\) 的原函数，那么这个积分比较难求解。当然我们可以通过蒙特卡罗方法来求解近似值。假设我们函数图像如下图：</p>

<div align="center">
    <img width="230" src="media/15189654050126/15348644591195.jpg" />
</div>

<p>原函数的积分是函数 \(f(x)\) 下方与绿色区域的面积。一个简单的近似求解方法是在 \([a,b]\) 之间随机采样一个点。比如 \(x_1\)，然后用 \(x_1\) 代表 \([a,b]\) 内所有的 \(f(x)\) 的值。那么上面的定积分的近似求解为：<br/>
\[<br/>
(b-a)f(x_1)<br/>
\]</p>

<div align="center">
    <img width="230" src="media/15189654050126/15348651594504.jpg" />
</div>

<p>也就是图中阴影的面积。显然，用一个值代表 \([a,b]\) 区间上所有的 \(f(x)\) 的值，这个假设太粗糙。那么我们可以采样 \([a,b]\) 区间的 \(n\) 个值：\(x_1,x_2,...x_{n}\) ,用它们的均值来代表 \([a,b]\) 区间上所有的 \(f(x)\) 的值：<br/>
\[<br/>
\overline f(x) = \frac 1 n \sum_{i=1}^{n} f(x_i)<br/>
\]</p>

<p>这样我们上面的定积分的近似求解为:<br/>
\[<br/>
(b-a)\overline f(x) = \frac{b-a}{n} \sum_{i=1}^{n} f(x_i)<br/>
\]</p>

<div align="center">
    <img width="250" src="media/15189654050126/15348661212745.jpg" />
</div>

<p>如图中矩形所示，这个假设比之前的稍好一些，但是它隐含了一个假定，即 \(x\) 在 \([a,b]\) 之间是均匀分布的，而绝大部分情况，\(x\) 在 \([a,b]\) 之间不是均匀分布的。如果我们用上面的方法，则模拟求出的结果很可能和真实值相差甚远。而如果我们找到一个分布，使得它能在值较大的地方采集到更多的样本，则能更好地逼近结果。所以我们要对采样进行加权，这个权重就是重要性权重。</p>

<h4 id="toc_3">重要性采样 Importance Sampling</h4>

<p>假设原函数 \(f(x)\) 也许本身就是定义在一个分布之上的，我们定义这个分布为 \(p(x)\)，我们无法直接从 \(p(x)\) 上进行采样，所以另辟蹊径重新找到一个更加简明的分布 \(q(x)\) ，从它进行取样，希望间接地求出 \(f(x)\) 在分布 \(p(x) \) 下的期望。</p>

<p>首先我们知道函数 \(f(x)\) 在概率分布 \(p(x)\) 下的期望为： <br/>
\[<br/>
\begin{align*}<br/>
\mathbb E_p[f(x)] &amp;= \int_{x}^{}f(x) p(x) dx = \int_{x}^{}f(x) \frac{p(x)}{q(x)}q(x)dx\\<br/>
&amp;= \int_{x}^{} f(x) w(x) q(x) dx\\<br/>
&amp;= \mathbb E_q[f(x) w(x)]<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(w(x) = \frac{p(x)}{q(x)}\) ，被称为重要性权重。</p>

<p><strong>重要性采样</strong>是通过引入重要性权重，将分布 \(p(x)\) 下 \(f(x)\) 的期望变为分布在 \(q(x)\)  下 \(f(x)w(x)\) 的期望，从而可以近似为<br/>
\[<br/>
\hat f(N) = \frac 1 N \Big( f(x^{(1)}) w(x^{(1)}) + ... + f(x^{(N)})w(x^{(N)}) \Big)<br/>
\]</p>

<p>其中 \(x^{(i)},i=1,2,...,N\) 是独立从 \(q(x)\) 中随机抽取的点。</p>

<p>重要性采样也可以在只知道为未归一化的分布 \(\hat p(x)\) 的情况下计算函数 \(f(x)\) 的期望。</p>

<p>\[<br/>
\begin{align*}<br/>
\mathbb E_p(f(x)) &amp;= \int_x f(x) \frac{\hat p(x)}{Z} dx\\<br/>
&amp;= \frac{\int_x f(x) p(x) dx}{\int_x \hat p(x) dx}\\<br/>
&amp;\approx \frac{\sum_{i=1}^N f(x^{(i)}) \hat w(x^{(i)})}{\sum_{i=1}^N \hat w(x^{(i)}) }\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(Z\) 为配分函数，\(p(x) = \frac{\hat p(x)}{Z}\)；\(\hat w(x) = \frac{\hat p(x)}{q(x)}\)，\(x^{(i)}\) 为独立从 \(q(x)\) 中随机抽取的点。</p>

<h3 id="toc_4">概率分布采样</h3>

<p>蒙特卡罗方法关键是获得 \(x\) 的概率分布，基于概率分布去采样 \(n\) 个 \(x\) 的样本集代入蒙特卡罗式子中求解。对于常见均匀分布 \(\mathbf U(0,1)\) 是最容易采样的，一般可以通过各种伪随机数发生器可以产生指定范围内的均匀分布。而其他常见的概率分布，无论是离散的分布还是连续的分布，它们的样本都可以通过均匀分布 \(\mathbf U(0,1)\) 的样本转换而得。比如二维正态分布的样本 \((Z_1,Z_2)\) 可以通过对独立采样 \(\mathbf U(0,1)\) 得到的样本 \((X_1,X_2)\) 通过如下的式子转换而得：<br/>
\[<br/>
Z_1=\sqrt{-2\ln(X_1)} \cos(2\pi X_2)\\<br/>
Z_2=\sqrt{-2\ln(X_1)} \sin(2\pi X_2)\\<br/>
\]</p>

<p>其他一些常见的连续分布，比如t分布，F分布，Beta分布，Gamma分布等，都可以通过类似的方式从 \(\mathbf U(0,1)\) 转化得到。</p>

<p>这里介绍几个将均匀分布 \(\mathbf U(0,1)\) 转换其他分布的常见方法，并运用于各种分布的采样：</p>

<h4 id="toc_5">连续型变量的逆变换法 Inverse Transform Method For Continuous Variable</h4>

<p>先来看看 CDF 和 PDF 的定义：对于随机变量 \(X\)，如下定义的函数 \(F_X(x)\)：<br/>
\[<br/>
F_X(x) = P\{X \le x\},\quad -\infty \lt x \lt \infty<br/>
\]</p>

<p>称为 \(X\) 的累积分布函数（CDF，Cumulative Distribution Function）。已知累积分布函数满足三个性质：</p>

<ol>
<li><p><strong>有界性</strong>：<br/>
\[<br/>
\begin{align*}<br/>
\lim_{x\rightarrow -\infty} F_X(x) &amp;= 0\\<br/>
\lim_{x\rightarrow \infty} F_X(x) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p></li>
<li><p><strong>单调性</strong>：<br/>
\[<br/>
F_X(x_1)\le F_X(x_2) \quad \text{if }x_1 \le x_2<br/>
\]</p></li>
<li><p><strong>右连续性</strong>：<br/>
\[<br/>
\lim_{x\rightarrow x_0^+} F_X(x) = F_X(x_0)<br/>
\]</p></li>
</ol>

<p>对于连续型随机变量 \(X\) 的累积分布函数 \(F_X(x)\)，如果存在一个定义在实数轴非负函数 \(f(x)\)，使得对于任意实数 \(x\)，有下式成立：<br/>
\[<br/>
F_X(x) = \int_{-\infty}^{x} f(t) dt<br/>
\]</p>

<p>则称 \(f(t)\) 为 \(X\) 的概率密度函数（PDF，Probability Density Function）。显然，当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。</p>

<p>由累积分布积分性质我们可以知道：<br/>
\[<br/>
\begin{equation}<br/>
\lim_{x\rightarrow \infty} F(x) = 1\quad\Rightarrow\quad \int_{-\infty}^{\infty} f(t) dt = 1\label{lxri}<br/>
\end{equation}<br/>
\]</p>

<p>假设我们想生成一个随机变量 \(X\) 具有累积分布函数（CDF）\(F_X(x)\)，我们希望找到一个映射能将均匀分布 \(\mathbf u\sim \text{Uniform}(0,1)\) 转换成服从 \(X\) 分布，即 \(X=T(u)\)，所以有：</p>

<p>\[<br/>
F_X(u) = P(X\le u) = P(T(u) \le u) = P(u \le T^{-1}(u)) = T^{-1}(u)<br/>
\]</p>

<p>通过这个现象，我们能很容易获得变换函数 \(T(u) = F_X^{-1}(u)\) ，这也就意味着 \(X=T(u) = F_X^{-1}(u)\) 都服从 \(F_X(x)\) 的 CDF 分布。</p>

<p>举例说明一下：假设我们有均匀分布随机函数 \(U(0,1)\) 和累积分布函数：<br/>
\[<br/>
F(x) = 1-\exp(-\sqrt{x})<br/>
\]</p>

<p>为了去求反函数，考虑到 \(F(F^{-1}(u)) = u\)，所以有：<br/>
\[<br/>
\begin{align*}<br/>
F(F^{-1}(u)) = 1-\exp(-\sqrt{F^{-1}(u)}) &amp;= u\\<br/>
\exp(-\sqrt{F^{-1}(u)}) &amp;= 1-u\\<br/>
\sqrt{F^{-1}(u)} &amp;=-\log(1-u)\\<br/>
F^{-1}(u) &amp;= (\log(1-u))^2<br/>
\end{align*}<br/>
\]</p>

<p>再给另一个例子，我们累积分布函数在 \(x\ge 0\) 时使用指数分布 \(F_X(x) = 1-\exp(-\lambda x)\) ，其他情况为0。我们可以得到反函数通过：<br/>
\[<br/>
1-\exp(-\lambda x) = y \quad\Rightarrow\quad x = F^{-1}(y) = -\frac{1}{\lambda} \ln(1-y)<br/>
\]</p>

<p>注意这里如果我们用 \(y\) 代替 \(1-y\) 并不会对分布产生影响。</p>

<h4 id="toc_6">离散型变量的逆变换法 Inverse Transform Method For Discrete Variable</h4>

<p>考虑到在区间 \([0,1]\) 间的均匀分布 \(U\) ，它的累积分布函数为<br/>
\[<br/>
F_U(x) = P(U\le x) = \left \{\begin{array}\\0 &amp;\text{if  }x\lt 0\\x&amp;\text{if  }x=0\\1&amp;\text{if }x\gt 1\\\end{array}\right .<br/>
\]</p>

<p>假设 \(X\) 是离散变量，\(p_i = P(X=x_i)，i=1,2,...,i\)。如果 \(U\) 是一个均匀分布的随机变量，若 \(0\le a \le b\)，有<br/>
\[<br/>
P(a\le U\le b) = P(U\le b) - P(U \le a) = F_U(b) - F_U(a) = b - a<br/>
\]</p>

<p>因此对每个 \(n\) 有<br/>
\[<br/>
P(p_1+p_2+...+p_{n-1} \le U \le p_1 + p_2 + ... + p_{n-1} + p_n) = p_n<br/>
\]</p>

<p>现在令 \(Y=\Phi(U)\) 是关于随机变量 \(U\) 的方程，定义为：<br/>
\[<br/>
Y = \Phi(U) = \left \{\begin{array}\\ x_1 &amp; \text{if }U\le p_1\\ x_2 &amp; \text{if }p_1 \le U\le p_2 \\\vdots&amp;\vdots\\x_n &amp; \text{if }p_1+p_2+...+p_{n-1}\le U\le p_1 + p_2 + ... + p_{n-1}+ p_n\\\end{array}\right .<br/>
\]</p>

<p>这样 \(Y\) 有和 \(X\) 同样的分布，因此，如果 \(u_1,...,u_k\) 是从均匀分布中取样而得，\(\Phi(u_1),...,\Phi(u_k)\) 就是从 \(X\) 的分布中取样。</p>

<h4 id="toc_7">逆变换法采样</h4>

<p>在计算机模拟时，我们所说的抽样，其实是指从一个概率分布中生成观察值（observations）的方法。而这个分布通常是由其概率密度函数（PDF）来表示的。而且，即使在已知PDF的情况下，让计算机自动生成观测值也不是一件容易的事情，我们可以用上面逆变换法的方式通过 PDF 进行积分来得到概率分布的 CDF，然后再得到 CDF 的反函数 \(F_X^{-1}(x)\)，如果你想得到 \(m\) 个观察值，则重复下面的步骤 \(m\) 次：</p>

<ol>
<li>从 \(\mathbf U(0,1)\) 中随机生成一个值（前面已经说过，计算机可以实现从均匀分布中采样），用 \(u\) 表示。</li>
<li>计算 \(F^{−1}(u)\) 的值 \(x\)，则 \(x\) 就是从 \(f(x)\) 中得出的一个采样点。</li>
</ol>

<p>假设我们希望在下面的 PDF 中抽样：<br/>
\[<br/>
f(x) = \left \{ \begin{array}\\<br/>
8x\quad &amp;\text{if }\quad 0\le x\lt 0.25\\<br/>
\frac 8 3 - \frac 8 3 x\quad &amp;\text{if }\quad 0.25\le x\le 1\\<br/>
0\quad &amp;\text{otherwise}\\<br/>
\end{array} \right .<br/>
\]</p>

<p>可以算得相应的 CDF 为：<br/>
\[<br/>
F(x) = \int^x_{-\infty} f(x) \mathbf dx=  \left \{ \begin{array}\\<br/>
0,\quad &amp; \text{if }\quad  x\lt 0\\<br/>
4x^2,\quad &amp;\text{if }\quad 0\le x\lt 0.25\\<br/>
\frac 8 3 x - \frac 4 3 x^2 - \frac 1 3\quad &amp;\text{if }\quad 0.25\le x\le 1\\<br/>
1\quad &amp;\text{if }\quad x\gt 1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>在通过 PDF 计算相应CDF 时，为了点的连续加入了常量值。对于 \(u\in [0,1]\)，它的反函数为：<br/>
\[<br/>
F^{-1}(u) = \left \{ \begin{array}\\<br/>
\frac{\sqrt{u}}{2}\quad &amp;\text{if }\quad 0\le u\lt 0.25\\<br/>
1 - \frac{\sqrt{3(1-u)}}{2}\quad &amp;\text{if }\quad 0.25\le u\le 1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>从下图中你可以发现 <font color="red"><strong>采样点</strong></font> 与 <font color="blue"><strong>原始分布</strong></font> 非常吻合：</p>

<div align="center">
    <img src="media/15189654050126/15351195909818.jpg" width="250" />
</div>

<h4 id="toc_8">接受拒绝法 Acceptance-Rejection Method</h4>

<p>一般来说逆转换法是第一选择，但是逆转换法有自身的局限性，必须能给出累积分布函数 \(F_X(x)\) 反函数的表达式，这限制了逆变换法的使用范围。当没法给出累积分布函数 \(F_X(x)\) 的逆函数的表达式时，接受拒绝法是另一种选择。它的适用范围比逆变换法要大，只要给出概率密度函数的解析表达式即可，而大多数常用分布的概率密度函数是可以查到的。</p>

<p>假设我们想对 PDF 为 \(p(x)\) 的函数进行采样，但是由于种种原因（例如这个函数很复杂），对其进行采样是相对困难的。另外有一个 PDF 为 \(q(x)\) 的函数则相对容易采样，例如采用 Inverse CDF 方法可以很容易对对它进行采样，甚至 \(q(x)\) 就是一个均匀分布，\(q(x)\) 称之为提议分布（Proposal distribution）。那么，当我们将 \(q(x)\) 与一个常数 \(M\) 相乘之后，可以实现下图所示之关系，即 \(q(x)\) 将 \(p(x)\) 完全“罩住”。</p>

<div align="center">
    <img src="media/15189654050126/15351230469930.jpg" width="250" />
</div>

<p>然后重复如下步骤，直到获得 \(m\) 个被接受的采样点：</p>

<ol>
<li>从 \(q(x)\) 中获得一个随机采样点 \(x_i\)</li>
<li><p>对于 \(x_i\) 计算接受概率（acceptance probability）：<br/>
\[<br/>
\alpha = \frac{p(x_i)}{Mq(x_i)}<br/>
\]</p></li>
<li><p>从 \(U(0,1)\) 中随机生成一个值，用 \(u\) 表示</p></li>
<li><p>如果 \(u \le \alpha\)，则接受 \(x_i\) 作为一个来自 \(p(x)\) 的采样值，否则就拒绝 \(x_i\) 并回到第一步。</p></li>
</ol>

<p>我们还是以之前的例子为例，使用接受决绝进行采样，使用 \(Mq(x)=3 - 2x\) 函数作为提议分布，即 \(q(x) = \frac 1 M (3-2x)\)，如下图：</p>

<div align="center">
    <img width="230" src="media/15189654050126/15351726022817.jpg" />
</div>

<p>对 \(q(x)\) 函数下面的面积进行归一化求一下 \(M\) 的大小，由 \ref{lxri} 式：<br/>
\[<br/>
\begin{align*}<br/>
\int_{-\infty}^{\infty} f(x) = 1\quad&amp;\Rightarrow\quad \int_{-\infty}^{\infty} \frac 1 M f(x) = 1\\<br/>
&amp;\Rightarrow\quad \int_{-\infty}^{0} f(x) + \int_{0}^{1} f(x) + \int_{1}^{\infty} f(x) = 1\\<br/>
&amp;\Rightarrow\quad \int_{-\infty}^{0} 0 \mathbf dx + \int_{0}^{1} \frac 1 M (3-2x) \mathbf dx + \int_{1}^{\infty} 1 \mathbf dx = 1\\<br/>
&amp;\Rightarrow\quad 0 + \int_{0}^{1} \frac 1 M (3-2x) \mathbf dx + 0 = 1\\<br/>
&amp;\Rightarrow\quad \frac 1 M (3x - x^2) \bigg |_0^1 = 1\\<br/>
&amp;\Rightarrow\quad \frac 2 M = 1\\<br/>
&amp;\Rightarrow\quad M = 2<br/>
\end{align*}<br/>
\]</p>

<p>所以 \(q(x) = \frac 3 2 - x^2\) ，现在来求 \(q(x)\) 的累积分布函数：<br/>
\[<br/>
F_X(x) = \left \{ \begin{array} \\<br/>
0\quad &amp; x \lt 0\\<br/>
-\frac 1 2 x^2 + \frac 3 2 x\quad &amp;\text{if }\quad 0\le x\le 1\\<br/>
1\quad &amp; x \gt 1\\<br/>
\end{array}\right .<br/>
\]</p>

<p>所以 \(q(x)\) 的分布函数可以由均匀分布通过反函数求得：<br/>
\[<br/>
F^{-1}_X(u) = \frac 3 2 - \sqrt{\frac{9}{4} - 2u}  \quad u\in[0,1]<br/>
\]</p>

<p>现在能通过 Inverse Transform 方法对 \(q(x)\) 进行取样，取样后计算 \(\alpha\)，再取随机数 \(u\) 与 \(\alpha\) 比较决定接受拒绝，代码如下：</p>

<pre><code class="language-python">import numpy as np
from matplotlib import pyplot as plt
import math
# 均匀取样 10000 个数据点
uniform_sample = np.random.rand(30000)
# 利用Inverse Transform 将 10000 个样本转换成满足 q 分布样本
q_sample = [3.0/2 - math.sqrt(9.0/4 - 2*x) for x in uniform_sample]
# 计算样本 p 的值
p = [8*x if x &gt;=0 and x &lt;0.25 else 8.0/3 - 8.0/3 * x for x in q_sample]
# 计算样本 q 的值
q = [3.0/2 - x for x in q_sample]
# 计算样本 a 的值
a = np.array(p)/(3*np.array(q))
# 接受拒绝样本
accept_sample = [x  for i,x in enumerate(q_sample) if np.random.rand() &lt;= a[i]]
# 画图，原始分布
x_d = np.linspace(0,1,5000)
plt.plot(x_d,[8*x if x &gt;=0 and x &lt;0.25 else 8.0/3 - 8.0/3 * x for x in x_d],color=&quot;r&quot;,linewidth=3)
# 画图，拒绝采样后的分布
cnts, bins = np.histogram(accept_sample,bins=np.linspace(0,1,21),density=True)
bins = (bins[:-1] + bins[1:]) / 2
plt.plot(bins, cnts,color=&quot;g&quot;,linewidth=3)
plt.show()
</code></pre>

<p>如下图，采样效果还是挺好的：</p>

<div align="center">
    <img src="media/15189654050126/15351958248333.jpg" width="250" />
</div>

<p>这里还有个更简单的做法，提议分布选最简单的均匀分布，如 \(q(x) = 1，M=3\) 。</p>

<h4 id="toc_9">自适应的拒绝采样 Adapter Reject Sample</h4>

<p>前面介绍的拒绝采样中，如果 \(p(x)\) 与 \(q(x)\) 不是很接近会使 \(\alpha\) 很小，大多数的采样都会被拒绝掉，会影响采样效率。我们需要找到一个与 \(p(x)\) 很接近的 \(q(x)\) ，如果函数是 log 式凹函数（log-concave，我们通常理解的凸函数，或下凹函数）的话，那么我们就可以采样自适应的拒绝采样方法。</p>

<p>有一个的漂亮的思路是用分段的直线将分布包络起来进行采样.用分段直线进行包络时,如果分布曲线是凹的（开口向下,concave）,那么该曲线上的点的切线都将在该曲线的上方.于是在该曲线上找若干个点,并用这些点的切线,就可以将该曲线包络住。</p>

<div align="center">
    <img src="media/15189654050126/15352107929781.jpg" width="250" />
</div>

<p>大多数分布都具有指数的形式,不一定是凹函数,取对数后分布形式会变的简洁易于找切线.此时对分布的要求就转为取对数后是凹函数即可。</p>

<p>总体步骤如下：</p>

<ol>
<li><p><strong>给出分布函数 PDF 的对数函数 \(f(x)=\log(p(x))\),及其对应的一阶导数函数 \(f’(x)\)；</strong></p>

<div align="center">
    <img src="media/15189654050126/15352593502795.jpg" width="300" />
</div></li>
<li><p><strong>给定几个初始点，求出这几个初始点的切线，并计算切线与切线的交点。如果有边界，边界一般为垂直于横轴的直线，要计算切线与边界的交点；</strong></p>

<div align="center">
    <img src="media/15189654050126/15352615796344.jpg" width="300" />
</div>

<p><font color="#666"><br/>
我们来看看交点的求法，假设初始点开始有 \(n\) 个为 \((x_0,x_1,...x_i,...,x_{n-1})\) ，我们知道曲线在 \(x_i\) 处的一阶导数值为该点切线的斜率，用 \(\text{fprima}_{x_i}\) 表示。假设现在需要计算曲线在初始点 \(x_i\) 与相邻初始点 \(x_{i+1}\) 的切线的交点，首先设过 \(x_i\) 和 \(x_{i+1}\) 点的切线方程为：<br/>
\[<br/>
\begin{align}<br/>
y &amp;= \text{fprima}_{x_i} x + b_i\label{yt1}\\<br/>
y &amp;= \text{fprima}_{x_{i+1}} x + b_{i+1} \label{yt2}\\<br/>
\end{align}<br/>
\]</p>

<p>将 \(x_i\) 代入 \(f(x)\) 得到该点纵坐标的值，设为 \(f_{x_i}\)。将点 \((x_i,\text{f}_{x_i})\) 和 \((x_{i+1},\text{f}_{x_{i+1}})\) 分别代入两条切线方程求出常数项 \(b_i\) 和 \(b_{i+1}\) ：<br/>
\[<br/>
\begin{align*}<br/>
\left \{ \begin{array}\\<br/>
\text{f}_{x_i} = \text{fprima}_{x_i} x_i + b_i\\<br/>
\text{f}_{x_{i+1}} = \text{fprima}_{x_{i+1}} x_{i+1} + b_{i+1} \\<br/>
\end{array} \right .&amp;\Rightarrow \left \{ \begin{array}\\<br/>
b_i = \text{f}_{x_i} - \text{fprima}_{x_i} x_i\\<br/>
b_{i+1} = \text{f}_{x_{i+1}} - \text{fprima}_{x_{i+1}} x_{i+1}<br/>
\end{array} \right.<br/>
\end{align*}<br/>
\]</p>

<p>已知 \ref{yt1} 与 \ref{yt2} 两条切线方程的解即为交点的坐标，所以：<br/>
\[<br/>
\begin{align}<br/>
\hat x_i &amp;= \frac{b_{i+1}-b_i}{\text{fprima}_{x_i} - \text{fprima}_{x_{i+1}}} = \frac{{\text{f}_{x_{i+1}} - \text{f}_{x_i}} + \text{fprima}_{x_i} x_i- {\text{fprima}_{x_{i+1}} x_{i+1}}}{\text{fprima}_{x_i} - \text{fprima}_{x_{i+1}}} \label{xf}\\<br/>
\hat y_i &amp;= \text{fprima}_{x_i} \hat x_i + b = \text{fprima}_{x_i} \hat x_i + \text{f}_{x_i} - \text{fprima}_{x_i} x_i = \text{fprima}_{x_i} (\hat x_i - x_i) + \text{f}_{x_i} \label{yf}\\<br/>
\end{align}<br/>
\]</p>

<p>通过式 \ref{xf} 我们可以求出相邻切线之间的切点的横坐标 \((\hat x_0,\hat x_1,...,\hat x_{n-2})\) （ \(n\) 个切线相邻切线直接交点最多为 \(n-1\) 个），再加上前后两个边界线的横坐标，便得到了所有交点的横坐标：x<br/>
\[<br/>
\hat x^*=(\hat x^*_0,\hat x^*_1,...,\hat x^*_{n})=(0,\hat x_0,\hat x_1,...,\hat x_{n-2},1)<br/>
\]</p>

<p>现在再来看所有交点的纵坐标，除与边界的交点外，相邻切线的交点可以由 \ref{yf} 式得到。切线与边界 \(x=0\) 的交点的纵坐标，也就是第一条切线方程与 \(x=0\) 的解：<br/>
\[<br/>
\begin{equation}<br/>
\hat y^*_0 = b_0 = \text{f}_{x_0} - \text{fprima}_{x_0} x_0 =  \text{fprima}_{x_0} (0- x_0) + \text{f}_{x_0} \label{yf_1}<br/>
\end{equation}<br/>
\]</p>

<p>切线与边界 \(x=1\) 的交点的纵坐标，也就是第 \(n-1\) 条（最后一条）切线方程与 \(x=1\) 的解：<br/>
\[<br/>
\begin{equation}<br/>
\hat y^*_{n} = \text{fprima}_{x_{n-1}} + b_{n-1} = \text{fprima}_{x_{n-1}} + \text{f}_{x_{n-1}} - \text{fprima}_{x_{n-1}} x_{n-1} = \text{fprima}_{x_{n-1}}(1-x_{n-1}) + \text{f} _{x_{n-1}} \label{yf_2}<br/>
\end{equation}<br/>
\]</p>

<p>结合 \ref{yf}、\ref{yf_1} 和 \ref{yf_2} 式：<br/>
\[<br/>
\hat y^*_j = \left \{ \begin{array}\\<br/>
\text{fprima}_{x_0} (0- x_0) + \text{f}_{x_0} \quad &amp;\text{if}\quad j=0\\<br/>
\text{fprima}_{x_i} (\hat x_i - x_i) + \text{f}_{x_i} \quad &amp;\text{if}\quad 1\le j \le n-1;i=j-1\\<br/>
\text{fprima}_{x_{n-1}}(1-x_{n-1}) + \text{f} _{x_{n-1}} \quad &amp;\text{if}\quad j = n<br/>
\end{array}\right .<br/>
\]</p>

<p>很容易统一纵坐标的求法 <br/>
\[<br/>
\hat y^*_j = \text{fprima}^* (\hat x^* - x^*) + \text{f}_{x^*}\\<br/>
\]</p>

<p>其中：<br/>
\[<br/>
\begin{align*}<br/>
\text{fprima}^* &amp;= (\text{fprima}_{x_{0}}，\text{fprima}_{x_{0}}，\text{fprima}_{x_{1}},...,\text{fprima}_{x_{n-1}})\\<br/>
x^* &amp;=(x_0,x_0,x_1,...,x_{n-1})<br/>
\end{align*}<br/>
\]</p>

<p></font></p></li>
<li><p><strong>将分段直线取指数转换为对应的指数曲线，分别计算各段指数曲线的定积分。也就是计算各段曲线下覆盖的面积。累积且归一化后得到一个分段 CDF</strong>；</p>

<div align="center">
    <img width="300" src="media/15189654050126/15352636080572.jpg" />
</div>

<p><font color="#666"><br/>
上面已经求出每一条切线方程，设初始点 \(x_i\) 对应的切线方程为：<br/>
\[<br/>
\begin{align}<br/>
y &amp;= \text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i} \label{ytx1}\\<br/>
\end{align}<br/>
\]</p>

<p>指数曲线为：<br/>
\[<br/>
\begin{align}<br/>
f_{x_i}(x) = \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\label{eye}\\<br/>
\end{align}<br/>
\]</p>

<p>计算指数曲线的定积分：     \[<br/>
\begin{align*}<br/>
S_i &amp;= \int_{x^*_i}^{x^*_{i+1}} f_{x_i}(x) = \int_{x^*_i}^{x^*_{i+1}} \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
&amp;= \frac 1 {\text{fprima}_{x_i}}\exp\Big[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}\Big]\bigg|_{x^*_i}^{x^*_{i+1}}\\<br/>
&amp;= \frac 1 {\text{fprima}_{x_i}}\bigg(\exp\Big[\text{fprima}_{x_i} (x^*_{i+1} - x_i)+ \text{f}_{x_i}\Big] - \exp\Big[\text{fprima}_{x_i} (x^*_i - x_i)+ \text{f}_{x_i}\Big] \bigg)<br/>
\end{align*}<br/>
\]</p>

<p>之后对所有曲线计算出的 \(S\) 进行归一化，得到归一化参数 \(M\)，即：<br/>
\[<br/>
M \sum_{i=0}^{n-1} S_i = 1 \quad \Rightarrow \quad M = \frac 1 {\sum_{i=0}^{n-1} S_i}<br/>
\]</p>

<p>那初始点 \(x_i\) 对应的曲线的 CDF 函数为：<br/>
\[<br/>
\begin{align*}<br/>
F_{x_i}(x) &amp;= M \int_{-\infty}^x f_{x_i}(x) \\<br/>
&amp;= M \int_{-\infty}^x \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
&amp;= M \int_{-\infty}^{x_i} \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}] + M \int_{x_i}^x \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
&amp;= M \sum_{j=0}^{i} S_j + M \int_{x_i}^x \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
\end{align*}<br/>
\]</p>

<p></font></p></li>
<li><p><strong>从均匀分布中得到一个样本，记为 \(a\)，找到属于分段 CDF 中的哪一段；</strong></p></li>
<li><p><strong>再用该段对应的指数函数的 CDF，再次使用 \(y\)，用 Inverse Transform 找到对应的 \(y\) 的值；</strong></p></li>
<li><p><strong>再次用均匀分布 \((0,1)\) 中产生一个随机值，若该随机值小于等于 \(p(x)/e(x)\) 则接受该样本 \(x\) ， \(e(x)\) 为该段对应的指数函数；</strong></p></li>
<li><p><strong>若第6步中样本 \(x\) 被拒，则将 \(x\) 点加入到初始点集合中，重复2、3步，也就是多加一段以形成更好的包络；</strong></p></li>
</ol>

<p>在采样过程中用到两次 Inverse Transform 和一个拒绝采样；</p>

<p>我们举个简单的例子说明这个过程，首先看一下 \(\text{Beta}(2,5)\) 分布：</p>

<div align="center">
    <img src="media/15189654050126/15352090709370.jpg" width="250" />
</div>

<p>第一步：Beta 分布函数对应的对数函数 \(f(x)=\log(p(x))\)，及其对应的对数函数一阶导数函数 \(f’(x)\)。<br/>
\[<br/>
\begin{align*}<br/>
f(x) &amp;= \log(\text{Beta}(\alpha,\beta)) = \log\bigg(\frac 1 {\text{B}(\alpha,\beta)} x^{\alpha-1}(1-x)^{\beta-1}\bigg)\\<br/>
&amp;= \frac 1 {\text{B}(\alpha,\beta)}\bigg[(\alpha-1)\log x + (\beta - 1)\log(1-x)\bigg]\\<br/>
f&#39;(x) &amp;= \frac 1 {\text{B}(\alpha,\beta)}\bigg[\frac{\alpha-1}{x} + \frac{\beta - 1}{1-x}\bigg]\\<br/>
\end{align*}<br/>
\]</p>

<p>将常数项 \(\frac 1{\text{B}(\alpha,\beta)}\) 用 \(B\) 表示，代码如下：</p>

<pre><code class="language-python">import numpy as np
from matplotlib import pyplot as plt

# beta原函数
def beta_pdf(x,a=2,b=5):
    return B*np.power(x,(a-1))*np.power((1-x),(b-1))

# beta对数函数
def f(x, a=2, b=5):
    return B*((a-1)*np.log(x)+(b-1)*np.log(1-x))

# beta对数函数的一阶导数函数
def fprima(x, a=2, b=5):
    return B*((a-1)/x-(b-1)/(1-x))
</code></pre>

<p>第二步：给定几个初始点，求出这几个初始点的切线，并计算切线与切线的交点。如果有边界，边界一般为垂直于横轴的直线，要计算切线与边界的交点；</p>

<p>Beta 分布有边界 \(x=0\) 和 \(x=1\) 。在示例中再给出3个初始点，那么一共有3个切线，两个边界，我们关心的交点就有4个（三条切线有两个交点，切线与两个边界有两个交点）。</p>

<pre><code class="language-python"># 初始点
x = np.array([0.1,0.4,0.8])

# 初始化交点的横轴对应的值
z = np.zeros(len(x)+1)
z[0] = 0.0  # 第一个边界
z[-1] = 1.0 # 第二个边界

# 计算切线交点对应的横轴的值
for j in range(len(x)-1):
  z[j+1] = (f(x[j+1])-f(x[j]) - x[j+1]*fprima(x[j+1]) + x[j]*fprima(x[j])) / (fprima(x[j]) - fprima(x[j+1]))

# 计算切线交点对应的纵轴的值
h = f(x)
hprime = fprima(x)
u = hprime[[0]+range(len(x))]*(z-x[[0]+range(len(x))]) + h[[0]+range(len(x))]

# 画出对应的 PDF 的对数曲线,切线,并标注交点
fig, ax = plt.subplots()
log_x = np.linspace(0.0,1.0,1000)
ax.plot(log_x,f(log_x),linewidth=3)

# 画切线
for i in range(len(x)):
    log_line_x = np.linspace(z[i],z[i+1],30)
    log_line_y = h[i] + hprime[i]*(log_line_x-x[i])
    ax.plot(log_line_x,log_line_y,color=&#39;green&#39;,linewidth=3)

# 绘制辅助线
xticks = []
xticklabels = []

# 初始点横坐标
for i in range(len(x)):    
    ax.plot([x[i]]*30,np.linspace(-35,0,30),ls=&#39;dotted&#39;,color=&#39;red&#39;,linewidth=2)
    xticks += [x[i]]
    xticklabels += [&quot;x[%d]&quot;%i]

# 交点横坐标
for i in range(len(z)):
    ax.plot([z[i]]*30,np.linspace(-35,0,30),ls=&#39;dotted&#39;,color=&#39;red&#39;,linewidth=2)
    xticks += [z[i]]
    xticklabels += [&quot;z[%d]&quot;%i]

ax.set_xticks(xticks)
ax.set_xticklabels(xticklabels)

# 绘制交点
ax.scatter(z,u,color=&#39;blue&#39;)
fig.show()
</code></pre>

<p>效果图：</p>

<div align="center">
    <img src="media/15189654050126/15352544615332.jpg" width="300" />
</div>

<p>第三步：将分段直线取指数转换为对应的指数曲线，分别计算各段指数曲线的定积分。也就是计算各段曲线下覆盖的面积。累积且归一化后得到一个分段 CDF。</p>

<h4 id="toc_10">组合法</h4>

<p>当目标分布可以用其它分布经过四则运算表示时，可以使用组合算法生成对应随机数。此部分仅以几个例子简要介绍。</p>

<ol>
<li><p><strong>正态分布（Box Muller方法）</strong></p>

<p>在上文中，我们直接给出了二维正态分布由均匀分布变换的方法：二维正态分布的样本 \((Z_1,Z_2)\) 可以通过对独立采样 \(\mathbf U(0,1)\) 得到的样本 \((X_1,X_2)\) 通过如下的式子转换而得：<br/>
\[<br/>
Z_1=\sqrt{-2\ln(X_1)} \cos(2\pi X_2)\\<br/>
Z_2=\sqrt{-2\ln(X_1)} \sin(2\pi X_2)\\<br/>
\]</p>

<p>证明：假设现在有两个独立的标准正态分布 \(X\sim \mathcal N(0,1)\) 和 \(Y\sim \mathcal N(0,1)\)，由于二者相互独立，则联合概率密度函数为<br/>
\[<br/>
\begin{align*}<br/>
p(x,y) = p(x)p(y) &amp;= \frac{1}{\sqrt{2\pi}}\exp(-\frac{x^2}{2})\cdot \frac{1}{\sqrt{2\pi}}\exp(-\frac{y^2}{2})\\<br/>
&amp;= \frac{1}{2\pi}\exp(-\frac{x^2+y^2}{2})<br/>
\end{align*}<br/>
\]</p>

<p>由逆转换法我们知道直接对 \(p(x,y)\) 求积分比较难，由此我们想到可以先将平面坐标转化为极坐标，令 <br/>
\[<br/>
\begin{align}<br/>
x=\rho\cos(\theta)\label{xrc}\\<br/>
y=\rho\sin(\theta)\label{xrs}\\<br/>
\end{align}<br/>
\]</p>

<p>我们知道二重积分转化为极坐标下二重积分如下<br/>
\[<br/>
\iint\limits_D p(x,y) \mathbf dx\mathbf dy = \int_{\alpha}^{\beta} \mathbf d\theta\int_{\rho_1(\theta)}^{\rho_2(\theta)} p(\rho\cos\theta,\rho\sin\theta)\rho \mathbf d\rho<br/>
\]</p>

<p>现在我们分别对 \(\theta\) 和 \(\rho\) 来求累计分布概率<br/>
\[<br/>
\begin{align*}<br/>
F_\theta(x) &amp;= \int_{0}^{x} \mathbf d\theta \int_{-\infty}^{\infty} \frac{1}{2\pi}\exp(-\frac{\rho^2}{2})\rho\mathbf d\rho\\<br/>
&amp;= \frac{x}{2\pi} \bigg[-\exp(-\frac{\rho^2}{2})\bigg]_{-\infty}^{\infty}\\<br/>
&amp;= \frac{x}{2\pi}\\<br/>
F_\rho(x) &amp; = \int_{0}^{2\pi}\mathbf d\theta \int_{0}^{x} \frac{1}{2\pi}\exp(-\frac{\rho^2}{2})\rho\mathbf d\rho\\<br/>
&amp;= \int_{0}^{x} \exp(-\frac{\rho^2}{2})\rho\mathbf d\rho\\<br/>
&amp;= \bigg[-\exp(-\frac{\rho^2}{2}) \bigg]_{0}^{x}\\<br/>
&amp;= 1 -\exp(-\frac{x^2}{2}) <br/>
\end{align*}<br/>
\]</p>

<p>对 CDF 求逆函数即可得 \(\theta\) 和 \(\rho\) 的分布，即<br/>
\[<br/>
\theta = {F_{\theta}}^{-1}(u) = 2\pi u\\<br/>
\rho = {F_{\rho}}^{-1}(u) = \sqrt{-2\ln(1-u)}\\<br/>
\]</p>

<p>而如果 \(u\) 是均匀分布的，那么 \(u = 1-u\) 也将是均匀分布的，于是可以用 \(u\) 替换 \(1-u\)，当我们得到均匀分布 \(U_1、U_2\) 后，可以通过下式得到二维正太分布采样：<br/>
\[<br/>
X = \rho\cos(\theta) = \cos(2\pi U_1)\sqrt{-2\ln U_2}\\<br/>
Y = \rho\sin(\theta) = \sin(2\pi U_1)\sqrt{-2\ln U_2}\\<br/>
\]</p></li>
<li><p><strong>泊松分布（Poisson distribution）</strong></p>

<p>泊松分布是一种统计与概率学里常见到的离散机率分布，概率函数为：<br/>
\[<br/>
p(N(t) = k) = \frac{\lambda^k}{k!} e^{-\lambda t},\quad k=1,2,...<br/>
\]</p>

<p>其中 \(N\) 表示某种函数关系，\(t\) 表示事件，\(n\) 表示发生的次数。如1小时内出生3个婴儿的概率，就表示为 \(P(N(1)= 3)\)，等号右边 \(\lambda\) 是单位时间(或单位面积)内随机事件的平均发生率。泊松分布适合于描述单位时间内随机事件发生的次数。通俗讲就是观察事物平均发生 \(\lambda\) 次的条件下，实际发生 \(k\) 次的概率。关于泊松分布<a href="https://www.face2ai.com/Math-Probability-5-4-The-Poisson-Distribution/">看这里</a></p>

<p>再来看指数分布，指数分布（也称为负指数分布）是描述泊松过程中的事件之间的时间的概率分布，即事件以恒定平均速率连续且独立地发生的过程。 这是伽马分布的一个特殊情况。关于指数分布的文章<a href="http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html">看这里</a></p>

<p>指数分布由泊松分布推出：设相邻两次事件间隔为 \(T\)，起始时刻为 \(T_{start}\)，则终止时间为 \(T_{start} + T\)，\(P\{T\ge t\}\) 表示 \([T_{start},T_{start} + t]\) 时间内没有事件发生，即：<br/>
\[<br/>
P\{T\ge t\} = P(N(t)=0) = e^{-\lambda t}<br/>
\]</p>

<p>从而可知事件发生的概率为：<br/>
\[<br/>
F_T(t) = 1 - P\{T\ge t\} = P\{T\lt t\} = 1 - e^{-\lambda t}<br/>
\]</p>

<p>也就是 CDF 函数为 \(F_T(t)\)，对应的概率质量函数 PMF 为：<br/>
\[<br/>
f_T(t) = \lambda e^{-\lambda t},\quad t\ge 0<br/>
\]</p>

<p>也就是有<br/>
\[<br/>
p(t=0) = \lambda<br/>
\]</p>

<p><strong>算法思想</strong>：根据分析可知，泊松分布对应的是一段时间内 （记为\(t_{max}\)）时间发生的次数，而指数分布对应的是事件发生时间间隔的概率分布；</p>

<p>反过来，<strong>已知两两相邻的时间变量，该变量服从指数分布且相互独立，所有时间变量相加，并让其不超过一段时间的总量 \(t_{max}\)，则累加数的分布对应泊松（Poisson）分布</strong>。</p>

<p><strong>算法步骤</strong>：</p>

<p>a. 生成一组均匀分布随机数：\(U\sim U(0,1)\)；<br/>
b. 利用逆变换法生成一系列独立的指数分布 \(X_i\)<br/>
c. 记<br/>
\[<br/>
Y = X_1 + X_2 + ... + X_k<br/>
\]</p>

<p>如果 \(Y&gt;t_{max}\)，则停止，并输出 \(k−1\);否则，继续生成 \(X_{k+1}\)，直到 \(Y&gt;t_{max}\) 为止；<br/>
d. 循环操作过程3；</p>

<p>输出的一系列整数（值为 \(k−1\)）服从参数为 \(\mu=\lambda t_{max}\) 的泊松分布。</p>

<p>这里我们不失一般性的令 \(t_max = 1\)，这样便需要找到最小的 \(t\) 使<br/>
\[<br/>
X_1 + X_2 + ... + X_k \gt 1 \quad\Rightarrow\quad \sum_{i=1}^k X_i \gt 1<br/>
\]</p>

<p>又因为 \(X_i\) 是指数分布，即<br/>
\[<br/>
X_i = F_T^{-1}(u_i) = \frac{\ln(1-u_i)}{-\lambda} \Leftrightarrow X_i = -\frac{\ln(u_i)}{\lambda}<br/>
\]</p>

<p>所以<br/>
\[<br/>
X_1 + X_2 + ... + X_k = \sum_{i=1}^k -\frac{\ln(u_i)}{\lambda} = -\frac{1}{\lambda} \ln \Big(\prod_{i=1}^k u_i\Big) \gt 1\\<br/>
\Rightarrow \prod_{i=1}^k u_i \lt e^{-\lambda}<br/>
\]</p>

<p>所以我们算法可以变成：生成一组均匀分布随机数 \(U_1,U_2,...,U_n\)，找到最小的 \(j\) 使<br/>
\[<br/>
\prod_{i=1}^k U_i \lt e^{-\lambda}<br/>
\]</p>

<p>输出一系列的 \(j-1\) 满足泊松分布。</p>

<p>代码如下：</p>

<pre><code class="language-python">import math
import random

def poisson(Lambda):
    j=0
    p = 1.0
    l = math.exp(-Lambda)
    while p &gt;= l:
        U = random.random()
        p = p * U
        j = j + 1
    return j-1

for i in range(100):
    x = poisson(5)
    print(x)
</code></pre>

<p>上面使用指数分布来生成泊松分布，其实泊松分布也可以通过离散型变换法得到，由于这过程中有阶乘的计算，为提升效率，这里使用一个方法简介计算，在 \(N(t)=K+1\) 时<br/>
\[<br/>
\begin{align}<br/>
P(N(t) = k+1) &amp;= \frac{\lambda^{k+1}}{(k+1)!} e^{-\lambda t}\\<br/>
&amp;= \frac{\lambda^k}{k!} e^{-\lambda t} \frac{\lambda}{k+1}\\<br/>
&amp;= \frac{\lambda}{k+1} P(N(t)=k)<br/>
\end{align}<br/>
\]</p>

<p>这样可以使用前一步的结果乘上 \(\frac{\lambda}{k+1}\) 得到下一个概率提升效率。</p>

<p>代码如下：</p>

<pre><code class="language-python">import math
import random

def poisson(Lambda):
    k=0
    p = math.exp(-Lambda)
    s = p
    U = random.random()
    if U &lt;= math.exp(-Lambda):
        return 0
    else:
        while U &gt; s:
            p = Lambda * p / (k+1)
            s = s + p
            k += 1
        return k-1

for i in range(100):
    x = poisson(5)
    print(x)
</code></pre></li>
</ol>

<hr/>

<p><a href="http://www.cnblogs.com/pinard/p/6625739.html">刘建平Pinard-蒙特卡罗方法</a><br/>
<a href="https://blog.csdn.net/ACdreamers/article/details/44978591">蒙特卡罗算法</a><br/>
<a href="https://www.cnblogs.com/xingshansi/p/6539319.html">信号处理-生成给定分布</a><br/>
<a href="https://blog.csdn.net/baimafujinji/article/details/51407703">蒙特卡罗采样-拒绝采样</a><br/>
<a href="https://blog.csdn.net/lin360580306/article/details/51240398">随机过程-Metropolis-Hastings算法</a><br/>
<a href="https://wenku.baidu.com/view/d2c27c0510661ed9ac51f325.html">极坐标计算二重积分</a><br/>
<a href="https://lucius-yu.github.io/docs/probability/BasicMCSamplingMethod/">基本的蒙特卡罗采样方法</a><br/>
<a href="http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html">泊松分布与指数分布</a><br/>
<a href="http://www3.eng.cam.ac.uk/%7Ess248/G12-M01/Week1/ITM.pdf">Inverse Transform Method</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15181958451732.html">随机森林 Random Forest</a></h1>
			<p class="meta"><time datetime="2018-02-10T01:04:05+08:00" 
			pubdate data-updated="true">2018/2/10</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>随机森林，英文名为 Random Forest，后面简称 RF，它是 Bagging 算法的进化版，它在 Bagging 的基础上改进了一些内容：</p>

<ol>
<li>随机森林就是由多棵 CART 树构成的。</li>
<li>对于普通的决策树，我们会在节点上所有的 \(n\) 个样本特征中选择一个最优的特征来做决策树的左右子树划分，但是 RF 通过随机选择节点上的一部分样本特征。假设特征总数目为 \(n\) ，每次随机选择 \(n_{sub}\) 个样本特征，在其中选择一个最优的特征来做决策树的左右子树划分。这样进一步增强了模型的泛化能力。如果 \(n_{sub}=n\) ，则此时 RF 的 CART 决策树和普通的 CART 决策树没有区别。\(n_{sub}\) 越小，则模型越健壮，当然此时对于训练集的拟合程度会变差。在实际案例中，一般会通过交叉验证调参获取一个合适的 \(n_{sub}\) 的值。</li>
</ol>

<h3 id="toc_0">随机森林算法步骤</h3>

<p><b>输入</b>：样本集 \(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)，弱分类器迭代次数 \(T\)<br/>
<b>输出</b>：最终的强分类器 \(f(x)\)<br/>
<b>算法过程</b>：</p>

<ul>
<li><p>对于\(t=1,2,...,T\)：</p>

<ul>
<li>对训练集进行第 \(t\) 次随机采样，共采集 \(m\) 次，得到包含 \(m\) 个样本的采样集 \(D_t\)；</li>
<li>用采样集 \(D_t\) 训练第 \(t\) 个决策树模型 \(G_t(x)\) ，在训练决策树模型的节点的时候，在节点上所有的样本特征中选择一部分样本特征， 在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分；</li>
</ul></li>
<li><p>如果是分类算法预测，则 \(T\) 个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，\(T\) 个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。</p></li>
</ul>

<h3 id="toc_1">随机森林扩展</h3>

<p>由于 RF 在实际应用中的良好特性，基于 RF ，有很多变种算法，应用也很广泛，不光可以用于分类回归，还可以用于特征转换，异常点检测等。下面对于这些RF家族的算法中有代表性的做一个总结。</p>

<h5 id="toc_2">Extra-Trees 极端随机树</h5>

<p>ET 或 Extra-Trees（Extremely randomized trees，极端随机树）是由PierreGeurts等人于2006年提出。该算法与随机森林算法十分相似，都是由许多决策树构成。但该算法与随机森林有两点主要的区别：</p>

<ol>
<li><p>随机森林应用的是 Bagging 模型，而 ET 是使用所有的训练样本得到每棵决策树，也就是每棵决策树应用的是相同的全部训练样本；</p></li>
<li><p>随机森林是在一个随机子集内得到最佳分叉属性，而 ET 是完全随机的得到分叉值，从而实现对决策树进行分叉的。</p></li>
</ol>

<p>从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于 RF 所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏倚相对于 RF 进一步增大。在某些时候，Extra-Trees 的泛化能力比 RF 更好。</p>

<h5 id="toc_3">Totally Random Trees Embedding</h5>

<p>Totally Random Trees Embedding(以下简称 TRTE)是一种非监督学习的数据转化方法。它将低维的数据集映射到高维，从而让映射到高维的数据更好的运用于分类回归模型。我们知道，在支持向量机中运用了核方法来将低维的数据集映射到高维，此处TRTE提供了另外一种方法。</p>

<p>TRTE 在数据转化的过程也使用了类似于 RF 的方法，建立 \(T\) 个决策树来拟合数据。当决策树建立完毕以后，数据集里的每个数据在T个决策树中叶子节点的位置也定下来了。比如我们有3颗决策树，每个决策树有5个叶子节点，某个数据特征 \(x\) 划分到第一个决策树的第2个叶子节点，第二个决策树的第3个叶子节点，第三个决策树的第5个叶子节点。则 \(x\) 映射后的特征编码为 \((0,1,0,0,0,\qquad 0,0,1,0,0,\qquad 0,0,0,0,1)\)，有15维的高维特征。这里特征维度之间加上空格是为了强调三颗决策树各自的子编码。</p>

<p>映射到高维特征后，可以继续使用监督学习的各种分类回归算法了。　　　　</p>

<h5 id="toc_4">Isolation Forest　　　　</h5>

<p>Isolation Forest（以下简称IForest）是一种异常点检测的方法。它也使用了类似于RF的方法来检测异常点。</p>

<p>对于在 \(T\) 个决策树的样本集，IForest 也会对训练集进行随机采样,但是采样个数不需要和 RF 一样，对于 RF，需要采样到采样集样本个数等于训练集个数。但是 IForest 不需要采样这么多，一般来说，采样个数要远远小于训练集个数？为什么呢？因为我们的目的是异常点检测，只需要部分的样本我们一般就可以将异常点区别出来了。</p>

<p>对于每一个决策树的建立， IForest 采用随机选择一个划分特征，对划分特征随机选择一个划分阈值。这点也和 RF 不同。</p>

<p>外，IForest 一般会选择一个比较小的最大决策树深度 max_depth ,原因同样本采集，用少量的异常点检测一般不需要这么大规模的决策树。</p>

<p>对于异常点的判断，则是将测试样本点 \(x\) 拟合到 \(T\) 颗决策树。计算在每颗决策树上该样本的叶子节点的深度 \(h_t(x)\) ，从而可以计算出平均高度 \(h(x)\)。此时我们用下面的公式计算样本点 \(x\) 的异常概率:<br/>
\[<br/>
s(x,m)=2^{−\frac{h(x)}{c(m)}}<br/>
\]</p>

<p>其中，\(m\) 为样本个数。\(c(m)\) 的表达式为：<br/>
\[<br/>
c(m)=2\ln(m−1)+\xi−2\frac{m−1}{m},\quad \xi\text{ 为欧拉常数}<br/>
\]</p>

<p>\(s(x,m)\) 的取值范围是 \([0,1]\) ,取值越接近于1，则是异常点的概率也越大。</p>

<h5 id="toc_5">优缺点</h5>

<p>RF的主要优点有：</p>

<ol>
<li>训练可以高度并行化，对于大数据时代的大样本训练速度有优势。个人觉得这是的最主要的优点。</li>
<li>由于可以随机选择决策树节点划分特征，这样在样本特征维度很高的时候，仍然能高效的训练模型。</li>
<li>在训练后，可以给出各个特征对于输出的重要性</li>
<li>由于采用了随机采样，训练出的模型的方差小，泛化能力强。</li>
<li>相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。</li>
<li>对部分特征缺失不敏感。</li>
</ol>

<p>RF的主要缺点有：</p>

<ol>
<li>在某些噪音比较大的样本集上，RF模型容易陷入过拟合。</li>
<li>取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果。</li>
</ol>

<hr/>

<p><a href="https://www.cnblogs.com/pinard/p/6156009.html">Bagging与随机森林算法原理小结</a><br/>
<a href="https://blog.csdn.net/xbmatrix/article/details/69488867?locationNum=10&amp;fps=1">Extra-Trees原理</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15176349609265.html">Numpy中random模块方法用法</a></h1>
			<p class="meta"><time datetime="2018-02-03T13:16:00+08:00" 
			pubdate data-updated="true">2018/2/3</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<h3 id="toc_0">rand方法</h3>

<p>生成0到1之间的数据，包含0，不包含1，可以指定生成后的维度，样本符合均匀分布</p>

<pre><code class="language-python">&gt;&gt;&gt; np.random.rand(4,2)
array([[0.59932964, 0.604558  ],
       [0.50929428, 0.27991478],
       [0.67848409, 0.90447861],
       [0.74733641, 0.93528965]])
</code></pre>

<h3 id="toc_1">randn方法</h3>

<p>生成一组样本，样本符合正态分布，使用方法如<code>rand</code>方法</p>

<pre><code class="language-python">&gt;&gt;&gt; np.random.rand(4,2)
array([[0.00355693, 0.88287118],
       [0.89048427, 0.38273187],
       [0.92432139, 0.76244856],
       [0.64154002, 0.61260094]])
</code></pre>

<h3 id="toc_2">randint方法</h3>

<p>生成指定返回的int随机数，可以指定生成的维度，包括下边界，不包含上边界</p>

<pre><code class="language-python">&gt;&gt;&gt; np.random.randint(2,5,(4,3))
array([[2, 3, 4],
       [2, 4, 2],
       [3, 2, 2],
       [2, 4, 2]])
# 如果hign没写则默认是[0,low)
&gt;&gt;&gt; np.random.randint(2,size=(3,2))
array([[0, 0],
       [0, 1],
       [0, 0]])
</code></pre>

<h3 id="toc_3">rand_sample方法</h3>

<p>生成一个随机的<code>[0,1)</code>之间浮点型数字，可以指定维度</p>

<pre><code class="language-python">&gt;&gt;&gt; np.random.random_sample((3,2))
array([[0.29125611, 0.76543326],
       [0.45151435, 0.37244176],
       [0.51016998, 0.12396989]])
</code></pre>

<h3 id="toc_4">choice方法</h3>

<p>从给定的数组中生成随机数，可以指定维度<br/>
这个函数有几个参数：</p>

<pre><code class="language-python">def choice(self, a, size=None, replace=True, p=None)
</code></pre>

<pre><code>a: 如果给定的是一个数字，比如5表示给定的数组为`range(5)`，必须是1维的
size: 维度
replace: 是否把取出的元素放回重新选择，如果为`True`那么生成的数组中可能含有相同的元素。默认为`True`。
p: 每一个元素出现的概率，输入应该是一个数组，数组长度与第一个参数长度相同。所有概率和加起来应该等于1。
</code></pre>

<pre><code class="language-python">&gt;&gt;&gt; np.random.choice(4,(2,2),replace=False)
array([[2, 1],
       [3, 0]])
#极端情况，只有一个概率为0 
&gt;&gt;&gt; np.random.choice(4,4,p=[0,0,0,1])
array([3, 3, 3, 3])
</code></pre>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15176287918503.html">Python中random模块各种方法的用法</a></h1>
			<p class="meta"><time datetime="2018-02-03T11:33:11+08:00" 
			pubdate data-updated="true">2018/2/3</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<h3 id="toc_0">random()生成随机浮点数，范围在0.0-1.0之间</h3>

<pre><code class="language-python">&gt;&gt;&gt; import random
&gt;&gt;&gt; random.random()
0.5197019223432617
</code></pre>

<h3 id="toc_1">uniform()生成随机浮点数，可以指定范围，包含两边边界</h3>

<pre><code class="language-python">&gt;&gt;&gt; random.uniform(1,2)
1.919524729278391
</code></pre>

<p>并且<code>uniform</code>中可以指定数组，假设我们需要生成一个随机数组<code>[x,y]</code>，并限定<code>x</code>在1到2之间，<code>y</code>在5到6之间，则可以使用</p>

<pre><code class="language-python">&gt;&gt;&gt; min = np.array([1,5])
&gt;&gt;&gt; max = np.array([2,6])
&gt;&gt;&gt; random.uniform(min,max)
array([1.41660269, 5.41660269])
</code></pre>

<p>如果需要生成指定个数的数组，需要使用<code>numpy</code>提供的<code>uniform</code>方法，<a href="15176349609265.html">见这里</a>。</p>

<h3 id="toc_2">randint()生成随机整数，可以指定范围，包含两边边界</h3>

<pre><code class="language-python">&gt;&gt;&gt; random.randint(1,2)
2
</code></pre>

<h3 id="toc_3">choice()从列表中随机返回一个元素</h3>

<pre><code class="language-python">&gt;&gt;&gt; random.choice(range(10))
9
</code></pre>

<h3 id="toc_4">sample()从列表里随机返回n个元素(不重复），可以用于数据集取样</h3>

<pre><code class="language-python">&gt;&gt;&gt; random.sample([1,2],2)
[1, 2]
</code></pre>

<h3 id="toc_5">shuffle()随机打乱一个数组，不返回，直接原数组操作，并且可以自定义random方法</h3>

<pre><code class="language-python">&gt;&gt;&gt; a = list(range(10))
&gt;&gt;&gt; a
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
&gt;&gt;&gt; random.shuffle(a)
&gt;&gt;&gt; a
[3, 5, 0, 9, 4, 2, 1, 7, 8, 6]
</code></pre>

<h3 id="toc_6">choices()方法类似于sample()方法，但是更强大，可以指定权重</h3>

<p><code>weights</code>:指定每一个数组权重，可以指定浮点数<br/>
<code>cum_weights</code>:指定累加权重，如果指定<code>cum_weights=[1,3,5]</code> 等价于指定<code>weights=[1,2,2]</code>，也就是每一个元素减去前一个元素就是当前位置权重，可以指定浮点数<br/>
<code>k</code>指定随机返回<code>k</code>个元素</p>

<pre><code class="language-python">&gt;&gt;&gt; count = {}
&gt;&gt;&gt; for i in range(500):
...     rand = random.choices(range(3),weights=[1,2,2],k=1)[0]
...     if count.get(rand) is None:
...             count[rand] = 0
...     count[rand]+=1
...
&gt;&gt;&gt; print(count)
{1: 188, 0: 109, 2: 203} #基本满足1:2:2
&gt;&gt;&gt;
&gt;&gt;&gt; count = {}
&gt;&gt;&gt; for i in range(500):
...     rand = random.choices(range(3),cum_weights=[1,3,5],k=1)[0]
...     if count.get(rand) is None:
...             count[rand] = 0
...     count[rand]+=1
...
&gt;&gt;&gt; print(count)
{0: 107, 2: 194, 1: 199} #基本满足1:2:2
</code></pre>

<h3 id="toc_7">sample()、choice()效率与choices比较</h3>

<p>在选择1个元素时</p>

<pre><code class="language-python">import random
import time
timeStart = time.time()
    # 创建10000个随机数，选择10000次
    list = range(1000)
    count = {}
    for i in range(500000):
        temp = random.choice(list)
    print(&quot;耗时:&quot;+str(time.time()-timeStart))
</code></pre>

<p>结果为：耗时:9.242528676986694</p>

<pre><code class="language-python">import random
import time
timeStart = time.time()
# 创建10000个随机数，选择10000次
list = range(1000)
count = {}
for i in range(500000):
    temp = random.sample(list)
print(&quot;耗时:&quot;+str(time.time()-timeStart))
</code></pre>

<p>结果为：耗时:26.432512044906616</p>

<pre><code class="language-python">import random
import time
timeStart = time.time()
# 创建10000个随机数，选择10000次
list = range(1000)
count = {}
for i in range(500000):
    temp = random.choices(list)
print(&quot;耗时:&quot;+str(time.time()-timeStart))
</code></pre>

<p>结果:耗时:10.003572225570679</p>

<p><strong>在都获取一个元素的时候，<code>choice</code>与<code>choices</code>的效率差不多，但是<code>sample</code>效率很慢</strong></p>

<p>获取多个元素</p>

<pre><code class="language-python">import random
import
timeStart = time.time()
# 创建10000个随机数，选择10000次
list = range(1000)
count = {}
for i in range(500000):
    temp = random.choices(list,k=100)
print(&quot;耗时:&quot;+str(time.time()-timeStart))
</code></pre>

<p>结果为：耗时:51.91596961021423</p>

<pre><code class="language-python">import random
import
timeStart = time.time()
# 创建10000个随机数，选择10000次
list = range(1000)
count = {}
for i in range(500000):
    temp = random.sample(list,k=100)
print(&quot;耗时:&quot;+str(time.time()-timeStart))
</code></pre>

<p>结果为：耗时:496.99442648887634</p>

<p><strong>在都获取多个元素的时候，<code>choices</code>的效率也明显优于<code>sample</code></strong></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15175826339606.html">Bagging 方法</a></h1>
			<p class="meta"><time datetime="2018-02-02T22:43:53+08:00" 
			pubdate data-updated="true">2018/2/2</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在集成学习中，除了 Boosting 方法，各个弱学习器中有依赖关系。另一个就是 Bagging 方法，各个弱学习器中间没有依赖关系，可以并行拟合。同一个学习算法在来自同一分布的多个不同的训练数据集上训练得到的模型偏差可能较大，即模型的方差（variance）较大，为了解决这个问题，可以综合多个模型的输出结果，对于回归问题可以取平均值，对于分类问题可以采取多数投票的方法。这就是Bagging的核心思想。</p>

<p>Bagging 需要同一分布的多个不同的训练集，关键之处在于“随机取样“。固定从训练集中采集固定个数的样本，但是这种采集是一种有放回的采集，对于每一次采集，我们都将这一次采集到的样本放回，也就是说我们可能采集到重复的样本，对于这个算法我们一般会随机采集与样本训练样本数目相同的样本，这样得到的采样集和训练集合样本数目相同，但是内容不同，对于数据集m个样本的进行T次随机采样，得到训练T个训练器的训练集。 </p>

<p>注意到这和GBDT的子采样是不同的。GBDT的子采样是无放回采样，而Bagging的子采样是放回采样。</p>

<p>对于一个样本，它在某一次含m个样本的训练集的随机采样中，每次被采集到的概率是 \(1/m\) 。不被采集到的概率为 \(1−1/m\) 。如果 \(m\) 次采样都没有被采集中的概率是 \((1−1/m)^m\) 。当m→∞时，\((1−1/m)^m \rightarrow \frac 1 e \approx 0.368\) 。也就是说，在 Bagging 的 \(m\) 轮随机采样中，训练集中大约有 36.8% 的数据没有被采样集采集中。</p>

<blockquote>
<p>高等数学中两个重要的极限性质：<br/>
\[<br/>
\lim_{x\rightarrow 0} \frac{\sin x}{x} = 1\\<br/>
\lim_{x\rightarrow +\infty} (1+\frac r x)^x = e^r\\<br/>
\]</p>
</blockquote>

<p>对于这部分大约36.8%的没有被采样到的数据，我们常常称之为袋外数据(Out Of Bag, 简称OOB)。这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。</p>

<p>与 Adaboost 算法一样，一般 Bagging 算法的基础学习器是神经网络或者决策树。</p>

<p>Bagging 的集合策略也比较简单，对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对T个弱学习器得到的回归结果进行算术平均得到最终的模型输出。</p>

<p>由于 Bagging 算法每次都进行采样来训练模型，因此泛化能力很强，对于降低模型的方差很有作用。当然对于训练集的拟合程度就会差一些，也就是模型的偏倚会大一些。</p>

<h3 id="toc_0">Bagging 算法步骤</h3>

<p><b>输入</b>：样本集 \(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)，弱学习器算法, 弱分类器迭代次数 \(T\) <br/>
<b>输出</b>：最终的强分类器 \(f(x)\)<br/>
<b>算法过程</b>：</p>

<ul>
<li><p>对于 \(t=1,2...,T\) :</p>

<ul>
<li>对训练集进行第 \(t\) 次随机采样，共采集 \(m\) 次，得到包含 \(m\) 个样本的采样集 \(D_t\)</li>
<li>用采样集 \(D_t\) 训练第 \(t\) 个弱学习器 \(G_t(x)\)</li>
</ul></li>
<li><p>如果是分类算法预测，则 \(T\) 个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，\( T\) 个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。</p></li>
</ul>

<hr/>

<p><a href="https://www.cnblogs.com/pinard/p/6156009.html">Bagging与随机森林算法原理小结</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15170125982743.html">XgBoost 算法</a></h1>
			<p class="meta"><time datetime="2018-01-27T08:23:18+08:00" 
			pubdate data-updated="true">2018/1/27</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	

		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15167212454767.html">提升树与GBDT</a></h1>
			<p class="meta"><time datetime="2018-01-23T23:27:25+08:00" 
			pubdate data-updated="true">2018/1/23</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>从提升方法学习中可以知道提升方法是采用加法模型和前向分布算法，提升树是以决策树为基函数的提升方法。对于分类问题决策树是二叉分类树，对于回归问题决策树是二叉回归树。提升树可以表示为决策树的加法模型：<br/>
\[<br/>
f_M(x) = \sum_{m=1}^M T(x;\Theta_m)<br/>
\]</p>

<p>其中 \(T(x;\Theta_m)\) 表示决策树；\(\Theta_m\) 表示决策树的参数；M 为树的个数。</p>

<h4 id="toc_0">前向分布算法</h4>

<p>由前向分布算法，可知第 \(m\) 轮模型 \(f_m(x)\) 为：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + T(x;\Theta_m)<br/>
\]</p>

<p>其中 \(f_{m-1}(x)\) 为当前模型，可以通过经验风险最小化来确定下一棵决策树参数 \(\Theta_m\) ，即：<br/>
\[<br/>
\hat \Theta_m = arg \min_{\Theta_m} \sum_{i=1}^N L(y_i, f_{m-1}(x_i) + T(x_i;\Theta_m))<br/>
\]</p>

<p>不同问题的提升树学习算法的主要区别是使用的损失函数不同，包括用平方误差损失函数的回归问题，用指数损失函数的分类问题，以及使用一般损失函数的一般决策问题。</p>

<p>对于二类分类问题，提升树算法可以算是 AdaBoost 算法的特殊情况，下面主要叙述回归问题的提升树：</p>

<p>已知一个训练数据集 \(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，\(x_i\in \mathcal X\subseteq R^n\)，\(\mathcal X\) 为输入空间，\(y_i\in \mathcal Y\subseteq R\)，\(\mathcal Y\) 为输出空间。如果将输入空间 \(\mathcal X\) 划分为 \(J\) 个互不相交的区域 \(R_1,R_2,...,R_J\)，并且在每一个区域上确定输出常量 \(c_j\) ，那么树可以表示为：<br/>
\[<br/>
T(x;\Theta) = \sum_{j=1}^J c_j I(x\in R_j)<br/>
\]</p>

<p>其中，参数 \(\Theta = \{(R_1,C_1),(R_2,c_2),...,(R_J,c_J)\}\) 表示树的区域划分和各区域上的常数。\(J\) 是回归树的复杂度即叶节点的个数。回归树使用以下的前向分步算法：<br/>
\[<br/>
\begin{align*}<br/>
&amp;f_0(x) = 0\\<br/>
&amp;f_m(x) = f_{m-1}(x) + T(x;\Theta_m), \quad m = 1,2,...,M\\<br/>
&amp;f_M(x) = \sum_{m=1}^M T(x;\Theta_m)<br/>
\end{align*}<br/>
\]</p>

<p>在前向分布算法的第 \(m\) 步，给定当前模型 \(f_{m-1}(x)\) ，需求解：<br/>
\[<br/>
\hat\Theta_m = arg \min_{\Theta_m} \sum_{i=1}^N L(y_i,f_{m-1}(x_i) + T(x_i;\Theta_m))<br/>
\]</p>

<p>得到 \(\hat\Theta_m\) ，即第 \(m\) 棵树的参数。</p>

<p>当采用平方误差损失函数时：<br/>
\[<br/>
L(y,f(x)) = (y-f(x))^2<br/>
\]</p>

<p>其损失变为：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f_{m-1}(x) + T(x;\Theta_m)) &amp;= [y-f_{m-1}(x) - T(x;\Theta_m)]^2\\<br/>
&amp;= [r-T(x;\Theta_m)]^2<br/>
\end{align*}<br/>
\]</p>

<p>这里：<br/>
\[<br/>
r = y - f_{m-1}(x)<br/>
\]</p>

<p>是当前模型拟合数据的残差（residual）。所以，对回归问题的提升树来说，只需简单的拟合当前模型的残差。这样，算法是相当简单的。</p>

<h4 id="toc_1">算法过程</h4>

<p><b>输入</b>：训练数据集 \(T=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}\)，其中 \(x_i\in \mathcal X\subseteq R^n\)，\(y_i \in\mathcal Y \subseteq R\)；<br/>
<b>输出</b>：提升树 \(f_M(x)\)<br/>
<b>算法过程</b>：</p>

<ul>
<li>初始化 \(f_0(x) = 0\)</li>
<li><p>对 \(m=1,2,...,M\)</p>

<ul>
<li><p>计算当前残差<br/>
\[<br/>
r_{mi} = y_i - f_{m-1}(x_i), \quad i=1,2,...,N<br/>
\]</p></li>
<li><p>拟合残差 \(r_{mi}\) 学习回归树，得到 \(T(x;\Theta_m)\) </p></li>
<li><p>更新 \(f_m(x) = f_{m-1}(x) + T(x, \Theta_m)\)</p></li>
</ul></li>
<li><p>得到回归问题提升树<br/>
\[<br/>
f_M(x) = \sum_{m=1}^M T(x,\Theta_m)<br/>
\]</p></li>
</ul>

<p>接下来先介绍一下决策树桩，然后举例说明提升树实例。</p>

<h4 id="toc_2">决策树桩 decision stump</h4>

<p>决策树桩，也可以称之为单层决策树，只对一列属性做一次判断决定最终的分类结果，比如只根据瓜的根蒂是否蜷缩来判断是否是好瓜，这提现的是单一特征起作用。显然 decision stump 仅可作为一个弱基本分类器，它的结果仅会比瞎猜 \(1/2\) 稍好一点点，在集成学习中，常可以作为基本分类器。</p>

<p>决策树桩仅可以对一个属性的一次判断获取结果，我们需要找到最低错误率的决策树桩，即优化目标函数：<br/>
\[<br/>
arg \min_{1\le c\le \text{d}} \frac 1 N \sum_{i=1}^N I(y_i \neq T_c(x_i))<br/>
\] </p>

<p>其中 \(c\) 表示属性值，\(d\) 表示属性列个数，\(N\) 表示样本数量。</p>

<h4 id="toc_3">提升树实例</h4>

<p>如下图的训练数据， \(x\) 的取值范围是区间 [0.5,10.5]，\(y\) 的取值范围是区间 [5.0,10.0]，学习这个回归问题的提升树模型，考虑只用决策树桩作为基函数<br/>
\[<br/>
\begin{array}{ccccccccccc}\\\hline<br/>
x_i &amp; 1 &amp;  2 &amp;  3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10\\\hline<br/>
y_i &amp; 5.56 &amp; 5.70 &amp; 5.91 &amp; 6.40 &amp; 6.80 &amp; 7.05 &amp; 8.90 &amp; 8.70 &amp; 9.00 &amp; 9.05 \\\hline<br/>
\end{array}<br/>
\]</p>

<p>按照算法，第一步要求 \(f_1(x)\) 即第一个树桩 \(T_1(x)\)：<br/>
在本例中只有一个属性 \(x\) ，我们只需要找到在属性 \(x\) 上找到为最佳切分点 \(s\) ，切分点将样本分成了 \(R_1\) 和 \(R_2\) 两部分，两部分的属性值为 \(c_1\) 和 \(c_2\) ：<br/>
\[<br/>
\min m(s) = \min_s\bigg[ \min_{c_1} \sum_{x_i \in R_1}(y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2}(y_i - c_2)^2 \bigg]<br/>
\]</p>

<p>求解最佳切分点 \(s\) ：<br/>
\[<br/>
R_1 = {x|x\le s} ,\quad R_2 = {x|x \gt s}<br/>
\]</p>

<p>容易求得在 \(R_1\) 和 \(R_2\) 两区域使平方误差最小的 \(c_1\) 和 \(c_2\) 为：<br/>
\[<br/>
c_1 = \frac 1 {|R_1|} \sum_{x_i \in R_1}y_i , \quad c_2 = \frac 1 {|R_2|} \sum_{x_i \in R_2} y_i<br/>
\]</p>

<p>当 \(s=1.5\) 时，\(R_1=\{1\}\)，\(R_2 = \{2,3,4,5,6,7,8,9,10\}\)，此时：<br/>
\[<br/>
c_1 = 5.56,\quad c_2 = 67.51/9 = 7.50\\<br/>
m(s) = \min_{c_1} \sum_{x_i \in R_1}(y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2}(y_i - c_2)^2 = 15.72<br/>
\]</p>

<p>当 \(s=2.5\)，\(s=3.5\)，...，\(s=9.5\)，会求出不同的 \(m(s)\) ，找到令 \(m(s)\) 最小的切分点 \(s\)，本例中 \(s=6.5\) 时，\(m(s)\) 达到最小值。此时 \(R_1(x) = \{1,2,3,4,5,6\}\)，\(R_2(x) = \{7,8,9,10\}\)，\(c_1=6.24\)，\(c_2=8.91\)。所以回归树为：<br/>
\[<br/>
T_1(x) = \left \{ \begin{array}\\<br/>
6.24&amp;\quad x \le 6.5\\<br/>
8.91&amp;\quad x \gt 6.5\\<br/>
\end{array} \right .\\<br/>
f_1(x) = T_1(x)<br/>
\]</p>

<p>计算残差 \(r_{2i} = y_i - f_1(x_i),\quad i=1,2,...,10\)，可得:<br/>
\[<br/>
\begin{array}{ccccccccccc}\\\hline<br/>
 x_i  &amp; 1 &amp;  2 &amp;  3 &amp;  4 &amp;  5 &amp;  6 &amp;  7 &amp;  8 &amp;  9 &amp;  10 \\\hline<br/>
 y_i &amp;  -0.68 &amp;  -0.54 &amp;  -0.33 &amp;  0.16 &amp;  0.56 &amp; 0.81 &amp;  -0.01 &amp;  -0.21 &amp;  0.09 &amp;  0.14 &amp; \\\hline<br/>
\end{array}<br/>
\]</p>

<p>用 \(f_1(x)\) 拟合训练集平方损失误差为：<br/>
\[<br/>
L(y,f_1(x)) = \sum_{i=1}^10 (y_i - f_1(x_i))^2 = \sum_{i=1}^10 r_{1i}^2 = 1.93<br/>
\]</p>

<p>建立第二棵树拟合残差，可以得到：<br/>
\[<br/>
T_2(x) = \left \{ \begin{array}\\<br/>
-0.52&amp;\quad x\le 3.5\\<br/>
0.22 &amp;\quad x \gt 3.5\\<br/>
\end{array} \right .<br/>
\]</p>

<p>所以回归树：<br/>
\[<br/>
f_2(x) = f_1(x) + T_2(x) = \left \{ \begin{array}\\<br/>
6.24-0.52=5.72 &amp; \quad x \le 3.5\\<br/>
6.24+0.22=6.46 &amp; \quad 3.5 \lt x \le 6.5\\<br/>
8.91+0.22=9.13 &amp; \quad x \gt 6.5\\<br/>
\end{array} \right .<br/>
\]</p>

<p>如果用 \(f_2(x)\) 拟合训练数据，平方损失误差为：<br/>
\[<br/>
L(y,f_2(x)) = \sum_{i=1}^10 (y_i - f_2(x_i))^2 = 0.79\\<br/>
\]</p>

<p>继续前向分步算法直到平方损失误差满足条件结束。</p>

<h3 id="toc_4">梯度提升树 GBDT</h3>

<p>提升树使用加法模型和前向分步算法，当损失函数是平方损失和指数损失函数时，很容易求解。但当损失函数是一般损失函数而言，往往每一步优化都不容易。针对这一问题，Freidman 提出了梯度提升技术，所以有了梯度提升树 GBDT。</p>

<p>GBDT (Gradient Boosting Decision Tree) 又叫 MART(Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力较强的算法。</p>

<p>GBDT 的树是回归树，不是分类树，GBDT用来做回归预测，调整后也可以用于分类。</p>

<p>它利用最速下降的近似方法，其关键是利用损失函数的负梯度在当前模型的值：<br/>
\[<br/>
-\bigg[\frac{\partial L(y,f(x_i))}{\partial f(x_i)} \bigg]_{f(x) = f_{m-1}(x)}<br/>
\]</p>

<p>作为回归问题提升树算法中的残差的近似值，拟合一个回归树。</p>

<h4 id="toc_5">梯度提升算法</h4>

<p><b>输入</b>：训练数据集 \(T = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，\(x_i \in \mathcal X \subseteq R^n\)，\(y_i\in \mathcal Y\subseteq R\)；损失函数 \(L(y,f(x))\)；<br/>
<b>输出</b>：回归树 \(\hat{f(x)}\)<br/>
<b>算法过程</b>：</p>

<ul>
<li>初始化
\[
f_0(x) = arg \min_c \sum_{i=1}^N L(y_i,c)
\]</li>
</ul>

<blockquote>
<p>当损失函数为平方损失函数时，平方损失函数是一个下凸函数，可以直接求导获得：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial L(y_i,c)}{\partial c} = \frac{\partial \sum_{i=1}^N \frac 1 2 (y_i-c)^2}{\partial c} = \sum_{i=1}^N -(y_i-c) = 0\\<br/>
&amp;c = \frac 1 N \sum_{i=1}^N y_i<br/>
\end{align*}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
f_0(x) = c = \frac 1 N \sum_{i=1}^N y_i<br/>
\]</p>
</blockquote>

<ul>
<li><p>对 \(m=1,2,...,M\) </p>

<ul>
<li><p>对 \(i=1,2,...,N\)，计算<br/>
\[<br/>
r_{mi} = -\bigg[ \frac{\partial L(y_i,f(x_i))}{\partial f(x_i)} \bigg ]_{f(x) = f_{m-1}(x)}<br/>
\]</p></li>
<li><p>对 \(r_{mi}\) 拟合一个回归树，得到第 \(m\) 棵树的叶节点区域 \(R_{mj}\)，\(j=1,2,...,J\)</p></li>
<li><p>对 \(j=1,2,...,J\) 计算<br/>
\[<br/>
c_{mj} = arg \min_c \sum_{x_i\in R_{mj}} L(y_i,f_{m-1}(x_i) + c)<br/>
\]</p></li>
</ul>

<blockquote>
<p>当损失函数为平方损失函数时，计算 \(r_{mj}\) ：<br/>
\[<br/>
\begin{align*}<br/>
r_{mi} = -\frac{\partial L(y_i,f_0(x_i))}{\partial f_{m-1}(x_i)} = -\frac{\partial \frac 1 2 (y_i - f_{m-1}(x_i))^2}{\partial f_{m-1}(x_i)} = y_i - f_{m-1}(x_i) <br/>
\end{align*}<br/>
\]</p>

<p>计算 \(c_{mj}\)：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \sum_{x_i\in R_{mj}} L(y_i,f_{m-1}(x_i) + c)}{\partial c} &amp;= \frac{\partial \sum_{x_i\in R_{mj}} \frac 1 2 (y_i - f_{m-1}(x_i) -c)^2}{\partial c}\\<br/>
&amp;= \sum_{x_i\in R_{mj}} (y_i - f_{m-1}(x_i) -c)\\<br/>
&amp;= \sum_{x_i\in R_{mj}} (y_i - f_{m-1}(x_i)) - |R_{mj}|c = 0\\<br/>
\therefore \quad c &amp;= \frac 1 {|R_{mj}|} \sum_{x_i\in R_{mj}} (y_i - f_{m-1}(x_i))\\<br/>
&amp;= \frac 1 {|R_{mj}|} \sum_{x_i \in R_{mj}} r_{mi}<br/>
\end{align*}<br/>
\]</p>
</blockquote>

<ul>
<li>更新 \(f_m(x) = f_{m-1}(x) + \sum_{j=1}^J c_{mj}I(x\in R_{mj})\)</li>
</ul></li>
<li><p>得到回归树<br/>
\[<br/>
\hat{f(x)} = f_M(x) = \sum_{m=1}^M \sum_{j=1}^J c_{mj} I(x\in R_{mj})<br/>
\]</p></li>
</ul>

<h4 id="toc_6">梯度提升树实例</h4>

<p>还是以前面的训练数据集为例，损失函数设为平方损失函数。</p>

<ol>
<li><p>首先初始学习器为：<br/>
\[<br/>
f_0(x) = c = \frac 1 N \sum_{i=1}^N y_i = 7.307<br/>
\]</p></li>
<li><p>当迭代轮数 \(m=1\) : <br/>
计算所有样本的残差：<br/>
\[<br/>
r_{1i} = -\frac{\partial L(y_i,f_0(x_i))}{\partial f_0(x_i)} = -\frac{\partial \frac 1 2 (y_i - f_0(x_i))^2}{\partial f_0(x_i)} = y_i - f_0(x_i)<br/>
\]</p>

<p>第一个样本的残差为 \(5.56 - 7.307 = -1.747\)<br/>
同理可以求得第 \(i=2,3,...,m\) 个样本的残差，然后使用残差作为样本的真实值训练 \(f_1(x)\)，残差如下：<br/>
\[<br/>
\begin{array}{ccccccccccc}\\\hline<br/>
x_i &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp;  6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 \\\hline<br/>
y_i &amp; -1.747 &amp; -1.607 &amp; -1.397 &amp; -0.907 &amp; -0.507 &amp; -0.257 &amp; 1.593 &amp; 1.393 &amp; 1.693 &amp; 1.743 \\\hline<br/>
\end{array}<br/>
\]</p>

<p>当切分点 \(s = -1.677\)，此时 \(R_1 = \{1\}\)，\(R_2 = \{2,3,4,5,6,7,8,9,10\}\)，此时：<br/>
\[<br/>
c_1 = -1.747,\quad c_2 = 0.194\\<br/>
m(s) = \min_{c_1} \sum_{x_i \in R_1}(y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2}(y_i - c_2)^2 = 15.72<br/>
\]</p>

<p>同理可以再算出其他切分点 \(s\) 对应的 \(m(s)\) ，找到令 \(m(s)\) 最小的切分点 \(s\)，此时划分的区域为 \(c_{1j}\)，\(j=1,2,...,J\)，回归树表示为：<br/>
\[<br/>
f_1(x) = f_0(x) + \sum_{j=1}^J c_{1j}I(x\in R_{1j})<br/>
\]</p></li>
<li><p>继续迭代 \(m=2,3,...,M\) 。</p></li>
</ol>

<h3 id="toc_7">GBDT 分类问题</h3>

<p>GBDT的分类算法从思想上和GBDT的回归算法没有区别，但是由于样本输出不是连续的值，而是离散的类别，导致我们无法直接从输出类别去拟合类别输出的误差。为了解决这个问题，主要有两个方法，一个是用指数损失函数，此时GBDT退化为Adaboost算法。另一种方法是用类似于逻辑回归的对数似然损失函数的方法。也就是说，我们用的是类别的预测概率值和真实概率值的差来拟合损失。</p>

<h4 id="toc_8">GBDT 二分类问题</h4>

<p>对于二分类，将真实值 \(y\) 和预测值 \(f(x)\) 的乘积，通过sigmoid处理成概率，再使用对数似然损失函数，损失函数为：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f(x)) = -\log P(y|x) = -\log[\text{sigmod}(yf(x))] = -\log(\frac{1}{1 + \exp(-yf(x))}) = \log(1+\exp(-yf(x)))<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(y\in \mathcal Y = \{-1,1\}\)</p>

<p>此时负梯度误差为：<br/>
\[<br/>
\begin{align*}<br/>
r_{mi} &amp;= -\bigg[\frac{\partial L(y,f(x_i))}{\partial f(x_i)} \bigg]_{f(x) = f_{m-1}(x)}\\<br/>
&amp;=-\frac{\partial L(y_i,f_{m-1}(x_i))}{\partial f_{m-1}(x_i)} \\<br/>
&amp;= -\frac{\partial \log(1+\exp(-yf_{m-1}(x_i)))}{\partial f_{m-1}(x_i)}\\<br/>
&amp;= \frac{y\exp(-yf_{m-1}(x_i))}{1+\exp(-yf_{m-1}(x_i))} \\<br/>
&amp;= \frac{y\exp(-yf_{m-1}(x_i)) \exp(yf_m(x_i))}{(1+\exp(-yf_{m-1}(x_i))) \exp(yf_{m-1}(x_i))} \\<br/>
&amp;= \frac{y}{\exp(yf_{m-1}(x_i))+1} \\<br/>
\end{align*}<br/>
\]</p>

<p>用 \(r_{mi}\) 拟合一个回归树，得到第 \(m\) 棵树的叶节点区域 \(R_{mj}\)，\(j=1,2,...,J\)，各个叶子节点的最佳残差拟合值为：<br/>
\[<br/>
\begin{align*}<br/>
c_{mj} &amp;= arg \min_c \sum_{x_i\in R_{mj}} L(y_i,f_{m-1}(x_i) + c) = arg \min_c \sum_{x_i \in R_{mj}} \log(1+\exp(-y_i(f(x_i) + c)))<br/>
\end{align*}<br/>
\]</p>

<p>由于上式比较难优化，我们一般使用近似值代替：<br/>
\[<br/>
c_{mj} = \sum_{x_i \in R_{mj}} r_{mi} / \sum_{x_i\in R_{mj}} |r_{mi}|(1−|r_{mi}|)<br/>
\]</p>

<p>除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，二元GBDT分类和GBDT回归算法过程相同。</p>

<h4 id="toc_9">GBDT 多分类问题</h4>

<p>多分类 GBDT 要比二分类更复杂一下，对应的是多元逻辑回归和二元逻辑回归的复杂度差别。假设类别数为 \(K\)，则此时我们的对数似然损失函数为：<br/>
\[<br/>
L(y,f(x)) = -\sum_{k=1}^K y_k \log p_k(x)<br/>
\]</p>

<p>如果输出样本为 \(k\) ，则 \(y_k=1\) ，第 \(k\) 类的概率 \(p_k(x)\) 的表达式为：<br/>
\[<br/>
p_k(x) = \frac{\exp(f_k(x))}{\sum_{l=1}^K \exp(f_l(x))} <br/>
\]</p>

<p>集合上面两式可以计算第 \(m\) 轮的第 \(i\) 个样本对应类别 \(k\) 的负梯度误差为：<br/>
\[<br/>
\begin{align*}<br/>
r_{mik} &amp;= -\bigg[\frac{\partial L(y_i,f(x_i))}{\partial f_k(x_i)}\bigg]_{f_l(x) = f_{l,m-1}(x)}\\<br/>
&amp;= -\bigg[\frac{\partial -\sum_{k=1}^K y_{ik} \log \big[{\exp(f_k(x_i))}/{\sum_{l=1}^K \exp(f_l(x_i))}\big]}{\partial f_k(x_i)} \bigg]_{f_l(x) = f_{l,m-1}(x)}\\<br/>
&amp;= -\bigg[\frac{\partial -\sum_{k=1}^K y_{ik} \log \big[{\exp(f_{k,m-1}(x_i))}/{\sum_{l=1}^K \exp(f_{l,m-1}(x_i))}\big]}{\partial f_{k,m-1}(x_i)} \bigg]\\<br/>
&amp;= \frac{y_{ik} \frac{\exp(f_{k,m-1}(x_i))}{{\sum_{l=1}^K \exp(f_{l,m-1}(x_i))}}- \frac{\exp(f_{k,m-1}(x_i))\exp(f_{k,m-1}(x_i))}{({\sum_{l=1}^K \exp(f_{l,m-1}(x_i))})^2}}{{\exp(f_{k,m-1}(x_i))}/{\sum_{l=1}^K \exp(f_{l,m-1}(x_i))}}\\<br/>
&amp;= \frac{y_{ik} p_{k,m-1}(x_i)- (p_{k,m-1})^2}{p_{k,m-1}(x_i)}\\<br/>
&amp;= y_{ik} - p_{k,m-1}(x_i)<br/>
\end{align*}<br/>
\]</p>

<p>观察上式可以看出，其实这里的误差就是样本 \(i\) 对应类别 \(k\) 的真实概率和 \(m−1\) 轮预测概率的差值。用 \(r_{mi}\) 拟合一个回归树，得到第 \(m\) 棵树的叶节点区域 \(R_{mj}\)，\(j=1,2,...,J\)，各个叶子节点的最佳残差拟合值为：<br/>
\[<br/>
\begin{align*}<br/>
c_{mjk} = arg \min_{c_{jk}} \sum_{x_i\in R_{mj}} \sum_{k=1}^K L(y_k,f_{m-1,k}(x_i)+\sum_{j=1}^J c_{jk}) \\<br/>
\end{align*}<br/>
\]</p>

<p>由于上式比较难优化，我们一般使用近似值代替：<br/>
\[<br/>
c_{mjk} = \frac{K-1}{K} \frac{\sum_{x_i \in R_{mj}} r_{mil}}{\sum_{x_i\in R_{mj}} |r_{mik}|(1-|r_{mik}|)}<br/>
\]</p>

<p>除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，多元GBDT分类和二元GBDT分类以及GBDT回归算法过程相同。</p>

<h3 id="toc_10">GBDT常见损失函数</h3>

<p>对于分类算法，其损失函数一般有对数损失函数和指数损失函数两种:</p>

<ol>
<li><p>如果是指数损失函数，则损失函数表达式为<br/>
\[<br/>
L(y,f(x))=\exp(−yf(x))<br/>
\]</p>

<p>其负梯度计算和叶子节点的最佳残差拟合可以参考Adaboost自适应提升方法。</p></li>
<li><p>如果是对数损失函数，分为二元分类和多元分类两种，参加上面的讲解。</p></li>
</ol>

<p>对于回归算法，常用损失函数有如下4种:</p>

<ol>
<li><p>均方差，这个是最常见的回归损失函数了<br/>
\[<br/>
L(y,f(x))=\frac 1 2 (y−f(x))^2<br/>
\]</p></li>
<li><p>绝对损失，这个损失函数也很常见：</p>

<p>\[<br/>
L(y,f(x) = |y-f(x)|<br/>
\]</p>

<p>对于负梯度误差为：<br/>
\[<br/>
\mathrm {sign}(y_i-f(x_i))<br/>
\]</p></li>
<li><p>Huber损失，它是均方差和绝对损失的折衷产物，对于远离中心的异常点，采用绝对损失，而中心附近的点采用均方差。这个界限一般用分位数点度量。损失函数如下：<br/>
\[<br/>
L(y,f(x))=\left \{\begin{array}\\<br/>
\frac 1 2 (y−f(x))^2\quad &amp;|y−f(x)|\le \delta\\<br/>
\delta (|y−f(x)|− \frac \delta 2)\quad &amp;|y−f(x)|&gt;\delta\\<br/>
\end{array} \right .<br/>
\]</p>

<p>对应的负梯度为：<br/>
\[<br/>
r(y_i,f(x_i))=\left \{\begin{array}\\<br/>
y_i−f(x_i)\quad &amp; |y_i−f(x_i)|\le\delta\\<br/>
\delta\text{ sign}(y_i−f(x_i))\quad &amp; |yi−f(xi)|&gt;\delta\\<br/>
\end{array} \right .<br/>
\]</p></li>
<li><p>分位数损失。它对应的是分位数回归的损失函数，表达式为<br/>
\[<br/>
L(y,f(x))= \sum_{y\ge f(x)}\theta|y−f(x)|+\sum_{y&lt;f(x)}(1−\theta)|y−f(x)|<br/>
\]</p>

<p>其中 \(\theta\) 为分位数，需要我们在回归前指定。对应的负梯度误差为：<br/>
\[<br/>
r(y_i,f(x_i))=\left \{\begin{array}\\<br/>
\theta\quad&amp; y_i\ge f(x_i)\\<br/>
\theta-1\quad &amp;y_i&lt;f(x_i)\\<br/>
\end{array}\right .<br/>
\]</p></li>
</ol>

<p>对于Huber损失和分位数损失，主要用于健壮回归，也就是减少异常点对损失函数的影响。</p>

<h3 id="toc_11">GBDT 的正则化</h3>

<p>和 Adaboost 一样，我们也需要对 GBDT 进行正则化，防止过拟合。GBDT的正则化主要有三种方式。</p>

<ol>
<li><p>和Adaboost类似的正则化项，即步长(learning rate)。定义为 \(v\)，对于前面的弱学习器的迭代<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + G_m(x)<br/>
\]</p>

<p>如果我们加上了正则化项，则有：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + v\text{ }G_m(x)<br/>
\]</p>

<p>\(v\) 的取值范围为 \(0&lt;v\le 1\)。对于同样的训练集学习效果，较小的 \(v\) 意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p></li>
<li><p>通过子采样比例（subsample）。取值为 \((0,1]\) 。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于 1 ，则只有一部分样本会去做GBDT的决策树拟合。选择小于 1 的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在 \([0.5, 0.8]\) 之间。</p>

<p>使用了子采样的GBDT有时也称作随机梯度提升树(Stochastic Gradient Boosting Tree, SGBT)。由于使用了子采样，程序可以通过采样分发到不同的任务去做boosting的迭代过程，最后形成新树，从而减少弱学习器难以并行学习的弱点。</p></li>
<li><p>对于弱学习器即CART回归树进行正则化剪枝。</p></li>
</ol>

<h3 id="toc_12">GBDT 优缺点</h3>

<p>GBDT主要的优点有：</p>

<ol>
<li>可以灵活处理各种类型的数据，包括连续值和离散值。</li>
<li>在相对少的调参时间情况下，预测的准备率也可以比较高。这个是相对SVM来说的。</li>
<li>使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。</li>
</ol>

<p>GBDT的主要缺点有：</p>

<ol>
<li>由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。</li>
</ol>

<hr/>

<p>李航【统计学习方法】<br/>
<a href="https://blog.csdn.net/lanchunhui/article/details/50980635">决策树桩</a><br/>
<a href="https://www.cnblogs.com/pinard/p/6140514.html">梯度提升树 GBDT</a><br/>
<a href="https://statweb.stanford.edu/%7Ejhf/ftp/trebst.pdf">Greedy Function Approximation:A Gradient Booting Machine</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15158019416874.html">自适应提升方法 Adaboost</a></h1>
			<p class="meta"><time datetime="2018-01-13T08:05:41+08:00" 
			pubdate data-updated="true">2018/1/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>Adaboost，英文全称是 Adapter Boosting（自适应增强）的缩写，由 Yoav Freund 和 Robert Schapire 在1995年提出。Adaboost 是属于 Boosting （提升）方法中具有代表性的一种。Boosting 方法是一种常见的统计学习方法，一种能提高任意给定学习算法准确率的方法。在分类问题上，它通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，来提高分类的性能。历史上，首先 Valiant 和 Kearns 提出了“弱可学习”和“强可学习”的概念：</p>

<blockquote>
<h5 id="toc_0">强可学习</h5>

<p>在概率近似正确（Probably approximate correct，PAC）学习的框架中，一个概念（一个类），如果存在一个多项式的学习算法可以学习它，并且正确率很高，那么就称这个概念是强可学习的。</p>

<h5 id="toc_1">弱可学习</h5>

<p>而一个概念存在一个多项式的学习算法可以学习它，但是正确率仅比随机猜测略好，那么称这个概念是弱可学习的。</p>
</blockquote>

<p>同时，Valiant 和 Kearns 首次提出了PAC学习模型中弱可学习和强可学习等价性的问题，即任意弱可学习问题都可以提升为强可学习问题。后来 Schapire 最先对这个问题作出了肯定的证明，也就是最初的 Boosting 方法，也就是如果已经学习了“弱可学习算法”，便可以通过这个方法将其提升为“强可学习算法”，而显然，学习一个“弱可学习算法”比“强可学习算法”要容易很多。</p>

<p>在1995年 Freund 对Schapire 提出的最初的 Boosting 算法做出了改进，提高了算法的效率，但是这两个算法都有一个天生的缺陷，都是需要知道“弱学习算法”学习正确率的下界，这在实际问题中难以做到；在1996年，Freund 和 Schapire 提出了 Adaboost 算法，效率与 Freund 之前的算法效率接近，却没有了事先知道“弱学习算法”正确率下界的限制条件，容易运用到实际问题中，因此该算法得到普遍应用。</p>

<h3 id="toc_2">Boosting 算法</h3>

<p>Boosting 算法是将”弱学习算法“提升到”强学习算法“的过程，主要是涉及两个部分：加法模型和前向分布算法。加法模型是指针对训练数据集学习一系列弱分类器，再将其线性相加的过程。</p>

<h4 id="toc_3">加法模型</h4>

<p>考虑加法模型(additive model)：<br/>
\[<br/>
f(x) = \sum_{m=1}^M \beta_m b(x;\gamma_m)<br/>
\]</p>

<p>其中 \(b(x;\gamma_m)\) 为基函数，\(\gamma_m\) 为基函数的参数，\(\beta_m\) 为基函数的系数。显然这是一个加法模型。</p>

<p>在给定训练数据及损失函数 \(L(y,f(x))\) 的条件下，学习加法模型 \(f(x)\) 成为经验风险极小化即损失函数极小化问题：<br/>
\[<br/>
\min_{\beta_m,\gamma_m} \sum_i^N L(y_i,\sum_{m=1}^M \beta_m b(x_i;\gamma_m))<br/>
\]</p>

<h4 id="toc_4">前向分布算法</h4>

<p>极小化上面的损失函数这是一个复杂的优化问题，前向分布算法（Forward stagewise Algorithm）解决这类问题的一个思路是：因为学习的是加法模型，如果能从前往后，每一步只学习一个基函数及其系数，逐步极小化损失函数，那么就可以简化优化的复杂度，每步只需优化如下损失函数：<br/>
\[<br/>
\min_{\beta,\gamma} \sum_{i=1}^N L(y_i,\beta b(x_i;\gamma))<br/>
\]</p>

<p>给定训练数据集 \(T = {(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}\)，\(x_i\in \mathcal X \subseteq R^n\) ，\(y_i \in mathcal Y = \{-1,1\}\)，损失函数为 \(L(y,f(x))\)，基函数的集合 \(\{b(x;\gamma)\}，学习加法模型 \)f(x)\( 的前向分布算法如下：<br/>
(1) 初始化 \)f_0(x)=0\(<br/>
(2) 对 \)m=1,2,...,M<br/>
　　(a) 极小化损失函数：<br/>
\[<br/>
(\beta_m,\gamma_m) = \arg \min_{\beta,\gamma} \sum_{i=1}^N L(y_i,f_{m-1}(x_i) + \beta f(x_i;\gamma))<br/>
\]</p>

<p>　　得到参数 \(\beta_m\)，\(\gamma_m\)<br/>
　　(b) 更新：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + \beta_m b(x;\gamma_m)<br/>
\]</p>

<p>(3) 得到加法模型：<br/>
\[<br/>
f(x) = f_M(x) = \sum_{m=1}^M \beta_m b(x;\gamma_m)<br/>
\]</p>

<p>这样前向分布算法将同时求解从 \(m=1\) 到 \(M\) 所有参数 \(\beta_m\)、\(\gamma_m\) 的问题化为逐次求解各个 \(\beta_m\) 、\(\gamma_m\) 的优化问题。</p>

<p>Boosting 算法采用不同的损失函数会得到不同的模型，AdaBoost 是损失函数为指数函数的 Boosting 算法。</p>

<h3 id="toc_5">AdaBoost算法</h3>

<p>AdaBoost是一种迭代算法，它通过提高前一轮被错误分类的样本的权值，降低被正确分类样本的权值，这样没有被正确分类的样本由于权值的增大，会得到下一轮弱分类器的更大关注。它能在学习的过程中不断减少训练误差，即在训练数据集上的分类误差率。假设给定一个二类分类的训练数据集：<br/>
\[<br/>
T = {(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}<br/>
\]</p>

<p>其中，每一个样本都是由实例和标签组成，实例 \(x_i\in \mathcal X \subseteq R^n\) ，标记 \(y_i \in \mathcal Y = \{-1,1\}\)，\(\mathcal X\) 是实例空间，\(\mathcal Y\) 是标记空间。</p>

<p>前面说到 AdaBoost 是损失函数为指数函数的 Boosting 算法，定义最终分类器的训练误差为指数形式：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f(x)) &amp;= \sum_{i=1}^N \exp(-y_i f(x_i))\\<br/>
\end{align*}<br/>
\]</p>

<p>假设前 \(m-1\) 轮迭代前向分步算法以及得到 \(f_{m-1}(x)\)，在第 \(m\) 轮迭代要得到 \(\alpha_m\)，\(G_m(x)\) 和 \(f_m(x)\)<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + \alpha_m G_m(x)<br/>
\]</p>

<p>目标是使前向分步算法得到的 \(\alpha_m\) 和 \(G_m(x)\) 使 \(f_m(x)\) 在训练数据上的误差最小，即：<br/>
\[<br/>
\begin{align*}<br/>
(\alpha_m,G_m(x)) &amp;= \arg \min_{\alpha,G} L(y,f_m(x))\\<br/>
&amp;= \arg\min_{\alpha,G} \sum_{i=1}^N \exp(-y_i f_m(x_i))\\<br/>
&amp;= \arg\min_{\alpha,G} \sum_{i=1}^N \exp[-y_i (f_{m-1}(x_i) + \alpha G(x_i))]\\<br/>
&amp;= \arg\min_{\alpha,G} \sum_{i=1}^N \exp[f_{m-1}(x_i)] \exp[-y_i \alpha G(x_i)]\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(w_{mi} = \exp[-y_i f_{m-1}(x_i)]\). 上式可以表示为：<br/>
\[<br/>
\begin{equation}<br/>
(\alpha_m,G_m(x)) = \arg \min_{\alpha,G} \sum_{i=1} w_{mi} \exp[-y_i \alpha G(x_i)] \\\label{ag}<br/>
\end{equation}<br/>
\]</p>

<p>容易看出 \(w_{mi}\) 与 \(\alpha\)，\(G(x)\) 无关，只依赖于 \(f_{m-1}(x)\)，随着每一轮的迭代而发生变化。\(w_{mi}\) 可以表示每一个样本的权值。初始时设样本的权值都设为 \(1/N\)，即：<br/>
\[<br/>
w_{1i} = \frac 1 N, \quad i=1,2,...,N<br/>
\]</p>

<p>定义第 \(m\) 轮基本分类器 \(G_m(x)\) 在训练数据集上加权分类误差率 \(e_m\) 等于样本权重乘上错误分类：<br/>
\[<br/>
e_m = \sum_{i=1}^N P(G_m(x_i) \neq y_i) = \sum_{i=1}^N w_{mi} I(G_m(x_i) \neq y_i)<br/>
\]</p>

<p>对于式 \ref{ag} ，我们来求解 \(G(x)\) 和 \(\alpha\) ，设最优解为 \(G(x)^*\)，\(\alpha^*\)。先求 \(G(x)^*\)，由前向分布算法可知，每一轮只需要求解令当前分类误差率最小的 \(G_(x)\) ：<br/>
\[<br/>
G(x)^* = \arg\min e_m = \arg\min \sum_{i=1}^N w_{mi} I(G_m(x_i) \neq y_i)<br/>
\]</p>

<p>再求 \(\alpha*\) ，先化简一下式 \ref{ag} ：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1} w_{mi} \exp[-y_i \alpha G(x)] &amp;= \sum_{y_i=G_m(x_i)} w_{mi} e^{-\alpha} + \sum_{y_i\neq G_m(x_i)} w_{mi} e^{\alpha} \\<br/>
&amp;= \sum_{y_i=G_m(x_i)} w_{mi} e^{-\alpha} + \sum_{y_i\neq G_m(x_i)} w_{mi} e^{-\alpha} + \sum_{y_i\neq G_m(x_i)} w_{mi} e^{\alpha} - \sum_{y_i\neq G_m(x_i)} w_{mi} e^{-\alpha}\\<br/>
&amp;= \sum_{i=1}^N w_{mi} e^{-\alpha} + (e^{\alpha} - e^{-\alpha}) \sum_{i=1}^N w_{mi} I(y_i\neq G_m(x_i))\\<br/>
&amp;= e^{-\alpha}\sum_{i=1}^N w_{mi} + (e^{\alpha} - e^{-\alpha}) e_m\\<br/>
&amp;= e^{-\alpha} + (e^{\alpha} - e^{-\alpha}) e_m\\<br/>
\end{align*}<br/>
\]</p>

<p>对 \(\alpha\) 求导可得：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial e^{-\alpha} + (e^{\alpha} - e^{-\alpha}) e_m}{\partial \alpha} &amp;= -e^{-\alpha} + (e^{\alpha} + e^{-\alpha}) e_m \\<br/>
&amp;= -e^{-\alpha} (1+e_m) + e^{\alpha} e_m \\<br/>
\end{align*}<br/>
\]</p>

<p>令求导结果为 0，得：<br/>
\[<br/>
\alpha^* = \frac 1 2 log \frac {1-e_m}{e_m}<br/>
\]</p>

<p>现在再来看看每一轮分类器的迭代：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + \alpha_m G_m(x)<br/>
\]</p>

<p>以及 \(w_{mi} = \exp[-y_i f_{m-1}(x_i)]\)，所以对于任何样本 \(x_i\) 都有：<br/>
\[<br/>
\begin{align*}<br/>
&amp;f_m(x_i) = f_{m-1}(x_i) + \alpha_m G_m(x_i)\\<br/>
\Rightarrow \quad &amp; -y_i f_m(x_i) = -y_i f_{m-1}(x_i) - y_i \alpha_m G_m(x_i)\\<br/>
\Rightarrow \quad &amp; \exp[-y_i f_m(x_i)] = \exp[-y_i f_{m-1}(x_i) - y_i \alpha_m G_m(x_i)]\\<br/>
\Rightarrow \quad &amp; \exp[-y_i f_m(x_i)] = \exp[-y_i f_{m-1}(x_i)] \exp[-y_i \alpha_m G_m(x_i)]\\<br/>
\Rightarrow \quad &amp; w_{m+1,i} = w_{mi} \exp[-y_i \alpha_m G_m(x_i)]\\<br/>
\end{align*}<br/>
\]</p>

<p>这样就得到了每一轮权值的更新，为了使权值和等于1，需要进行归一化处理。定义归一化因子 \(Z_m\)： <br/>
\[<br/>
Z_m = \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i))<br/>
\]</p>

<p>权值更新函数为：<br/>
\[<br/>
w_{m+1,i} = \frac{w_{mi}}{Z_m} \exp[-y_i \alpha_m G_m(x_i)]<br/>
\]</p>

<h3 id="toc_6">训练误差分析</h3>

<p>最终分类器在训练数据上的训练误差为：<br/>
\[<br/>
L(y,f_M(x)) = \sum_{i=1}^N \exp(-y_i f_M(x_i))\\<br/>
\]</p>

<p>样本在最终分类器上的样本分类误差定义为：<br/>
\[<br/>
err = \sum_{i=1}^N I(G_M(x_i) \neq y_i)<br/>
\]</p>

<p>现在证明可以通过减少训练误差的方式减小分类误差率。考虑到：<br/>
\[<br/>
I(G(x_i) \neq y_i) \le \exp(-y_i f(x_i)), \quad i = 1,2,...,N <br/>
\]</p>

<p>当 \(G(x_i) = y_i\) 时，\(I(G(x_i) \neq y_i) = 0\)，\(\exp(-y_i f(x_i)) &gt; 0\)，上式成立。<br/>
当 \(G(x_i) \neq y_i\) 时，\(I(G(x_i) \neq y_i) = 1\)，而 \(- y_i f(x_i) &gt; 0\)，所以 \(\exp(-y_i f(x_i)) &gt; e^0 = 1\) ，上式成立。</p>

<p>得证。</p>

<p>现在继续来化简一下最终分类器的训练误差：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f_M(x_i)) &amp;= \sum_{i=1}^N \exp(-y_i f_M(x_i)) \\<br/>
&amp;= \sum_{i=1}^N \exp(-y_i \sum_{m=1}^M \alpha_m G_m(x_i)) \\<br/>
&amp;= \sum_{i=1}^N \prod_{m=1}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N \frac 1 N \prod_{m=1}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N \frac 1 N \exp(-y_i \alpha_1 G_1(x_i)) \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N w_{1i} \exp(-y_i \alpha_1 G_1(x_i)) \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N Z_1 w_{2,i} \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N Z_1 \sum_{i=1}^N w_{2,i} \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N Z_1 Z_2 ... Z_{m-1} \sum_{i=1}^N w_{Mi} \exp(-y_i \alpha_M G_M(x_i)) \\<br/>
&amp;= N Z_1 Z_2 ... Z_{m-1} Z_M \sum_{i=1}^N w_{m+1,i}\\<br/>
&amp;= N \prod_{m=1}^M Z_m<br/>
\end{align*}<br/>
\]</p>

<p>这一定理说明，可以在每一轮选择适当的 \(G_m(x)\) 使 \(Z_m\) 最小，从而使训练误差减小最快。而实际 \(Z_m\) 还依赖 \(\alpha_m\) 的选择，实际并不可操作。</p>

<p>再来看一下 \(Z_m\) 的表达式：<br/>
\[<br/>
\begin{align}<br/>
Z_m &amp;= \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i)) \nonumber\\<br/>
&amp;= \sum_{G_m(x_i) = y_i} w_{mi} \exp(-\alpha_m) + \sum_{G_m(x_i) \neq y_i} w_{mi} \exp(\alpha_m)  \nonumber\\<br/>
&amp;= \sum_{G_m(x_i) = y_i} w_{mi} e^{-\alpha_m} + \sum_{G_m(x_i) \neq y_i} w_{mi} e^{-\alpha_m} + \sum_{G_m(x_i) \neq y_i} w_{mi}  e^{\alpha_m} - \sum_{G_m(x_i) \neq y_i} w_{mi} e^{-\alpha_m} \nonumber\\<br/>
&amp;= e^{-\alpha_m} \sum_{i=1} ^N w_{mi} + e^{\alpha_m} e_m - e^{-\alpha_m} e_m \nonumber\\<br/>
&amp;= e^{-\alpha_m} + e^{\alpha_m} e_m - e^{-\alpha_m}e_m  \nonumber\\<br/>
&amp;= (1-e_m) e^{-\alpha_m} + e_m e^{\alpha_m} \label{zm}<br/>
\end{align}<br/>
\]</p>

<p>由 \(\alpha=\frac 1 2 log \frac {1-e_m}{e_m}\) 可得 ：<br/>
\[<br/>
e^{\alpha} = \sqrt{\frac{1-e_m}{e_m}}\\<br/>
e^{-\alpha} = \sqrt{\frac{e_m}{1-e_m}}<br/>
\]</p>

<p>将上式代入 \ref{zm} 中得：<br/>
\[<br/>
\begin{align*}<br/>
Z_m &amp;= 2\sqrt{e_m(1-e_m)}<br/>
\end{align*}<br/>
\]</p>

<p>令 \(\gamma_m = \frac 1 2 - e_m\)：<br/>
\[<br/>
Z_m = \sqrt{1-4\gamma_m^2}<br/>
\]</p>

<p>比较 \(\sqrt{1-4\gamma_m^2}\) 与 \(\exp(-2\gamma_m^2)\) 的大小：<br/>
\(e^x\) 在 \(x_0=0\) 处泰勒展开：<br/>
\[<br/>
\begin{align*}<br/>
e^x &amp;= {e^{x_0}}+\frac{e^{x_0}}{1!}(x-x_0) + \frac{e^{x_0}}{2!}(x-x_0)^2\\<br/>
&amp;= 1 + x + \frac{x^2}{2}<br/>
\end{align*}<br/>
\]</p>

<p>令 \(x=-2\gamma_m^2\)，所以：\(\exp(-2\gamma_m^2) = 1 - 2\gamma^2 + 2\gamma_m^4\)</p>

<p>\(\sqrt{1-x}\) 在 \(x_0=0\) 处泰勒展开：<br/>
\[<br/>
\begin{align*}<br/>
\sqrt{1-x} &amp;= {(1-{x_0})^{1/2}} - \frac 1 2 \frac{(1-{x_0})^{-1/2}}{1!} (x-x_0) - \frac{1}{2*2} \frac{(1-{x_0})^{-3/2}}{2!}(x-x_0)^2\\<br/>
&amp;= 1 - \frac{x}{2} - \frac{x^2}{8}<br/>
\end{align*}<br/>
\]</p>

<p>令 \(x=4\gamma_m^2\)，所以：\(\sqrt{1-4\gamma_m^2} = 1 - 2\gamma^2 - 2\gamma^4\)</p>

<p>显然 \(\sqrt{1-4\gamma_m^2} \le \exp(-2\gamma_m^2)\)</p>

<p>所以最终分类其的训练误差：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f_M(x_i)) &amp;= \sum_{i=1}^N \exp(-y_i f_M(x_i) \\<br/>
&amp;= N\prod_{m=1}^M Z_m \\<br/>
&amp;= N\prod_{m=1}^M \sqrt{1-4\gamma_m^2} \\<br/>
&amp;\le \prod_{m=1}^M \exp(-2\gamma_m^2)\\<br/>
&amp;= \exp\big (-2\sum_{m=1}^M \gamma_m^2\big )\\<br/>
\end{align*}<br/>
\]</p>

<p>这表明当 \(\gamma_m &gt; 0\) 时， AdaBoost 的训练误差是以指数速率下降的。</p>

<h3 id="toc_7">算法步骤</h3>

<p><b>输入</b>：训练数据集 \(T = {(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}\)， \(x_i\in \mathcal X \subseteq R^n\)，\(y_i \in mathcal Y = \{-1,1\}\)。<br/>
<b>输出</b>：最终分类器 \(G(x)\)。<br/>
<b>算法过程</b>：<br/>
(1) 初始化训练数据的权值初始值：<br/>
\[<br/>
D_1 = (w_{11},...,w_{1i},...,w_{1N})<br/>
\]</p>

<p>(2) 对 \(m=1,2,...,M\)，迭代次数为 \(M\)：<br/>
(a) 在具有权值分布 \(D_m\) 的训练数据集上学习，得到基本分类器：<br/>
\[<br/>
G_m(x):\mathcal X \rightarrow \{-1,1\}<br/>
\]</p>

<p>(b) 计算 \(G_m(x)\) 在训练数据集上的分类误差率：<br/>
\[<br/>
e_m = P(G_m(x_i) \neq y_i) = \sum_{i=1}^N w_{mi} I(G_m(x_i)\neq y_i)<br/>
\]</p>

<p>(c) 计算 \(G_m(x)\) 的系数，也就是在最终分类器中的重要程度（对数为自然对数）：<br/>
\[<br/>
\alpha_m = \frac 1 2 \log \frac{1-e_m}{e_m}<br/>
\]</p>

<p>(d) 更新训练数据的权值分布：<br/>
\[<br/>
D_{m+1} = {w_{m+1,1},w_{m+1,2},...,w_{m+1,i},...,w_{m+1,N}}\\<br/>
w_{m+1,i} = \frac{w_{mi}}{Z_m} \exp(-\alpha_m y_i G_m(x_i)),\quad i=1,2,...,N<br/>
\]</p>

<p>这里的 \(Z_m\) 是规范因子，为了是样本概率分布和为1：<br/>
\[<br/>
Z_m = \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i))<br/>
\]</p>

<p>它使 \(D_{m+1}\) 成为一个概率分布。<br/>
(3) 构建基本分类器的线性组合<br/>
\[<br/>
F_M(x) = \sum_{m=1}^M \alpha_m G_m(x)<br/>
\]</p>

<p>得到最终分类器<br/>
\[<br/>
G(x) = sign(F_M(x)) = sign(\sum_{m=1}^M \alpha_m G_m(x))<br/>
\]</p>

<h3 id="toc_8">AdaBoost举例</h3>

<p>如下图的数据：<br/>
\[<br/>
\begin{array}{ccccccccccc}\hline<br/>
\text{No}&amp;1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 \\\hline<br/>
\text{x} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9  \\\hline<br/>
\text{y} &amp; 1 &amp; 1 &amp; 1 &amp; -1&amp; -1&amp; -1&amp; 1 &amp; 1 &amp; 1 &amp; -1 \\\hline<br/>
\end{array}<br/>
\]</p>

<p>首先初始化样本权重 \(D_1 = (w_{11},...,w_{1i},...,w_{1N})\)，其中<br/>
\[<br/>
w_{1i} = 0.1, \quad i=1,2,...,10<br/>
\]</p>

<p>在具有权值分布 \(D_1\) 的训练数据集上学习，当阈值取 2.5 时样本误差率最小：<br/>
\[<br/>
G_1(x) = \left \{ \begin{array}\\ 1 &amp;\quad x \le 2.5 \\ 0 &amp;\quad x \gt 2.5 \\\end{array}\right .<br/>
\]</p>

<p>计算 \(G_1(x)\) 在训练集上的分类误差率为：<br/>
\[<br/>
e_1 = \sum_{i=1}^N w_{1i} I(G_1(x_i) \neq y_i) = 0.3<br/>
\]</p>

<p>计算 \(G_1(x)\) 的系数为：<br/>
\[<br/>
\alpha_1 = \frac 1 2 \log \frac{1-e_1}{e_1} = 0.4236<br/>
\]</p>

<p>更新数据集的权值分布：<br/>
\[<br/>
D_2 = (w_{21},w_{22},...,w_{2i},...,w_{2N})\\<br/>
Z_1 = \sum_{i=1}^N w_{1i} \exp(-\alpha_1 y_i G_1(x_i))\\<br/>
w_{2i} = \frac{w_{1i}}{Z_1} \exp[-y_i \alpha_1 G_1(x_i)]\\<br/>
\]</p>

<p>得 \(D_2 = (0.0715,0.0715,0.0715,0.0715,0.0715,0.0715,0.1666,0.1666,0.166,0.0715)\)，\(f_1(x) = sign(0.4236 G_1(x))\)。分类器 \(sign(f_1(x))\) 在训练集上有三个误分点。</p>

<p>继续 \(m=2,...,M\) ，这里不再叙述。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15151569041850.html">概率近似正确学习 PAC Learning</a></h1>
			<p class="meta"><time datetime="2018-01-05T20:55:04+08:00" 
			pubdate data-updated="true">2018/1/5</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在计算机学习理论中，PAC 是英文 probably approximately correct 的缩写，是机器学习数学分析的框架，它由 Leslie Valiant 在 1994 年提出。</p>

<h3 id="toc_0">前置知识</h3>

<p>在学习 PAC 之前先看一下相关的概念：假设空间、版本空间、泛化误差和经验误差。</p>

<h5 id="toc_1">假设空间 hypothesis space</h5>

<p>所有属性可能取值组成的假设的集合称为假设空间，学习的过程可以看作是在假设空间中进行搜索的过程，搜索目标是找到与训练集“匹配”的假设，即能够将训练集中数据正确表示的假设。假设的表示一旦确定，假设空间规模大小就确定了。如以下的例子：<br/>
\[<br/>
\begin{array}{ccccc}\\\hline<br/>
\text{编号}\quad&amp;\quad\text{色泽}\quad&amp;\text{根蒂}\quad&amp;\quad\text{敲声}\quad&amp;\quad\text{好瓜}\quad\\\hline<br/>
\text{1}\quad&amp;\quad\text{青绿}\quad&amp;\text{蜷缩}\quad&amp;\quad\text{浊响}\quad&amp;\quad\text{是}\quad\\<br/>
\text{2}\quad&amp;\quad\text{乌黑}\quad&amp;\text{蜷缩}\quad&amp;\quad\text{浊响}\quad&amp;\quad\text{是}\quad\\<br/>
\text{3}\quad&amp;\quad\text{青绿}\quad&amp;\text{硬挺}\quad&amp;\quad\text{清脆}\quad&amp;\quad\text{否}\quad\\<br/>
\text{4}\quad&amp;\quad\text{乌黑}\quad&amp;\text{稍蜷}\quad&amp;\quad\text{沉闷}\quad&amp;\quad\text{否}\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>这里我们的假设空间由“色泽=？”、“根蒂=”、“敲声=？”三个属性的所有可能取值所形成的假设组成。例如，色泽的三个可能取值是“青绿”、“乌黑”、“浅白”，根蒂的三个可能取值是“蜷缩”、“稍蜷”、“硬挺”，敲声的三个取值是“浊响”，“清脆”，“沉闷”。还有可能不论色泽和根蒂是什么，只要是敲声是浊响的都是好瓜，即“色泽=* ” \(\land\) “根蒂=* ” \(\land\) “敲声=浊响” \(\leftrightarrow\) “好瓜”，所以每一种属性都要加上通配符 * ，所以每种属性都有4种可能，总共是 \(4^3=64\) 种可能。还有可能好瓜根本不存在，所以总共假设空间的规模大小是65。有了假设空间之后，要根据已获取的信息（数据集）来对假设空间进行剪枝。即要找到一个与训练集匹配的假设空间子集。</p>

<h5 id="toc_2">版本空间 version space</h5>

<p>在现实问题中我们常面临很大的假设空间，但学习的过程是给予有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与训练集一致的“假设集合”，我们称之为“版本空间”。如上面的例子中，假设空间的规模大小是65，删除与正例不一致的假设和与反例一致的假设即可得到版本空间。假设空间里如果有“色泽=青绿，根蒂=*，敲声=* ”的瓜是好瓜的假设，由编号3的训练集可知假设是不正确的，需要从假设空间里删除，最终留下来的就是版本空间。版本空间<font color=red><strong>不一定</strong></font>是正确的，也可能只是在训练集上是正确的，因此，要想判断的正确，就要全面、大量的训练，以排除更多假设空间中的错误假设。错误假设越少，剩下的假设越少，就越有可能是正确假设，我们判断的结果的正确概率越大。因为最终的假设会随着版本（数据集）变化而变化，所以叫做版本空间。</p>

<h5 id="toc_3">经验误差</h5>

<p>学习器在训练集上产生的误差叫做经验误差，由于这个误差是针对训练集的，因此又叫训练误差。训练数据也可以称之为经验，这就是经验误差的由来。</p>

<h5 id="toc_4">泛化误差</h5>

<p>机器学习的目标是使学得的模型能很好地适用于“新样本”，而不仅仅是在训练样本上工作很好，学得模型适用于新样本的能力我们称为“泛化（generalization）“能力，具有强泛化能力的模型能更好的适应于整个样本空间。这里泛化能力的度量便是泛化误差，泛化误差越小，也就是越能适用于新样本。一般来说，训练样本越多，经验误差可以越小，但是泛化误差不一定，可能会出现过拟合的情况。</p>

<h3 id="toc_5">PAC 学习理论 PAC learning theory</h3>

<p>计算学习理论中最基本的是概率近似正确学习理论，来研究什么时候一个问题是可以被学习的。</p>

<p>首先我们来考虑一下机器学习算法的目的，机器学习算法是通过希望学习一个模型能很好地完成从样本空间 \(\mathcal X\) 到标记空间 \(\mathcal Y\) 的映射。这样的每一个映射，我们称之为概念 concept ，用 \(c\) 表示。若对于样例 \((x,y)\) 有 \(c(x)=y\) 成立，则称 \(c\) 为目标概念。所有我们希望学得的目标概念所构成的集合称为“概念类（concept class）”，用符号 \(\mathcal C\) 表示。</p>

<p>对于给定的算法 \(\Phi\) ，它所考虑的所有可能概念的集合被称为“假设空间”，用符号 \(\mathcal H\) 表示，其中单个的概念称之为假设。</p>

<p>若目标概念 \(c \in \mathcal H\)，则 \(\mathcal H\) 中存在假设能将所有示例按与真实标记一致的方式完全分开，我们称该问题对学习算法 \(\mathcal L\) 是“可分的（separable）”，亦称“一致的（consistent）”。 反之，若算法的假设空间中不包含目标概念，则称该数据集对算法是“不可分的”或称“不一致的”。</p>

<p>举个简单的例子：对于非线性分布的数据集，若使用一个线性分类器，则该线性分类器对应的假设空间就是空间中所有可能的超平面，显然假设空间不包含该数据集的目标概念，所以称数据集对该学习器是不可分的。给定一个数据集D，我们希望模型学得的假设 \(h\) 尽可能地与目标概念一致，这便是概率近似正确 (Probably Approximately Correct，简称PAC)的来源，即以较大的概率学得误差满足预设上限的模型。这就是“概率”“近似正确”的含义，形式化地说，令 \(\delta\) 表示置信度，可定义：</p>

<p><b>PAC辨识（PAC Identify）</b>：对 \(\epsilon &gt; 0\)，\(\delta &lt; 1\)，所有 \(c\in \mathcal C\) 和分布 \(\mathcal D\)，若存在学习算法 \(\mathcal L\) ，其输出假设 \(h \in \mathcal H\) 满足：<br/>
\[<br/>
P(\mathrm{E}(h) \le \epsilon) \ge 1 - \delta<br/>
\]</p>

<p>其中\(\mathrm{E}(h)\) 表示泛化误差，则称学习算法 \(\mathcal L\) 能从假设空间 \(\mathcal H\) 中PAC辨识出概念类 \(\mathcal C\)，这样的学习算法 \(\mathcal L\) 能以较大的概率（至少 \(1-\delta\)）学得学习目标概念 \(c\) 的近似（误差最多为 \(\epsilon\)）。</p>

<p>PAC 辨识也可以写成如下形式：<br/>
\[<br/>
\begin{align*}<br/>
P(\mathrm{E}(h) \gt \epsilon) &amp;= 1 - P(\mathrm{E}(h) \le \epsilon) \\<br/>
&amp;\le 1 - (1-\delta) \\<br/>
&amp;= \delta\\<br/>
\end{align*}<br/>
\]</p>

<p>表示泛化误差大于 \(\epsilon\) 的概率不大于 \(\delta\)。在此基础上可以定义：</p>

<p><b>PAC可学习性（PAC Learnable）</b>：令 \(m\) 表示从分布 \(\mathcal D\) 中独立同分布采样得到的样本数目，\(\epsilon &gt; 0\)，\(\delta &lt; 1\)，对所有分布 \(\mathcal D\)，若存在学习算法 \(\mathcal L\) 和多项式函数 \(\text{poly}(\cdot,\cdot,\cdot,\cdot)\) ，使得对于任何 \(m\ge \text{poly}(1/\epsilon,1/\delta,\text{size(}\mathbf x\text{),size(c)})\)，\(\mathcal L\) 能从假设空间 \(\mathcal H\) 中PAC 辨识概念类 \(\mathcal C\)，则称概念类 \(\mathcal C\) 对假设空间 \(\mathcal H\) 而言是 PAC 可学习的，有时候也称概念类 \(\mathcal C\) 是 PAC 可学习的。其中 \(\text{size(}x)\) 数据本身的复杂度，\(\text{size}(c)\) 为目标概念的复杂度。</p>

<p>对于计算机而言，必然要考虑时间复杂性，于是：</p>

<p><b>PAC学习算法（PAC Learning Algorithm）</b>：若学习算法 \(\mathcal L\) 使概念类 \(\mathcal C\) 可学习的，且 \(\mathcal L\) 的运行时间也是多项式函数 \(\text{poly(}1/\epsilon,1/\delta,\text{size(}\mathbf x\text{),size(c)})\)，则称概念类 \(\mathcal C\) 是高效PAC可学习的（efficiently PAC learnable）的，称 \(\mathcal L\) 为概念类 \(\mathcal C\) 的 PAC 学习算法。</p>

<p>假设学习算法 \(\mathcal L\) 处理每一个样本的时间为常数，则 \(\mathcal L\) 的时间复杂度等价于样本的时间复杂度。于是，我们对算法时间复杂度的关心就转变为对样本复杂度的关系：</p>

<p><b>样本复杂度（Sample Complexity）</b>：满足 PAC 学习算法 \(\mathcal L\) 所需要的 \(m \ge \text{poly(}1/\epsilon,1/\delta,\text{size(}\mathbf x),\text{size(c))}\) 中的最小的 \(m\)，称之为学习算法 \(\mathcal L\) 的样本复杂度。</p>

<p>PAC 学习中一个关键因素是假设空间 \(\mathcal H\) 的复杂度。\(\mathcal H\) 包含了学习算法 \(\mathcal L\) 所有可能输出的假设，若在 PAC 学习中假设空间与概念类完全相同，即 \(\mathcal H=\mathcal C\)，这称为 “恰 PAC 可学习”；直观上看，这意味着学习算法的能力与学习任务 ”恰好匹配“ 。然而，通常我们目标概念 \(\mathcal C\) 一无所知，显然，更重要的是研究假设空间和目标概念不一样的情况，即 \(\mathcal H \ne C\) 。一般而言，\(\mathcal H\) 越大，其包含任意目标概念的可能性越大，但从中找到某个具体目标概念的难度也越大。 \(\mathcal H\) 有限时，我们称 \(\mathcal  H\) 为“有限假设空间”，否则称为“无限假设空间”。</p>

<h3 id="toc_6">有限假设空间</h3>

<h5 id="toc_7">可分情形</h5>

<p>可分情形意味着目标概念 \(c\) 属于假设空间 \(\mathcal H\)，即 \(c\in \mathcal H\)，若给定包含 \(m\) 个数据集的训练样本 \(D\)，如何找出满足误差参数的假设呢？既然 \(D\) 中样例标记都是有目标概念 \(c\) 赋予的，并且 \(c\) 存在于假设空间 \(\mathcal H\) 中，那么，任何在训练集 \(D\) 上出现的标记错误的假设肯定不是目标概念 \(c\) 。于是，我们只需要保留与 \(D\) 一致的假设，剔除与 \(D\) 不一致的假设即可，若训练集 \(D\) 足够大，则可不断借助 \(D\) 中样例剔除不一致的假设，直到 \(\mathcal H\) 中仅剩下一个假设为止，这个假设就是目标概念 \(c\) 。通常情况下，由于训练集规模有限，假设空间 \(\mathcal H\) 中可能存在不止一个与 \(D\) 一致的“等效”假设，对于这些等效假设，无法根据 \(D\) 来对它们做进一步的区分。</p>

<p>到底需要多少样例才能学得目标概念 \(c\) 得有效近似呢？对 PAC 学习而言，只要训练集 \(D\) 的规模能使学习算法 \(\mathcal L\) 以概率 \(1-\delta\) 找到目标假设的 \(\epsilon\) 近似即可。</p>

<p>我们先估计泛化误差大于 \(\epsilon\) 但在训练集上仍表现完美的假设出现的概率。假定 \(h\) 的泛化误差大于 \(\epsilon\) ，即\(\mathrm{E}(h) \gt \epsilon\)，对分布 \(D\) 上随机采样而得的任何样例 \((x,y)\)，有：<br/>
\[<br/>
\begin{align*}<br/>
P(h(x) = y) &amp;= 1-P(h(x) \neq y)\\<br/>
&amp;= 1- \mathrm{E}(h)\\<br/>
&amp;\lt 1 - \epsilon<br/>
\end{align*}<br/>
\] </p>

<p>由于 \(D\) 包含 \(m\) 个从 \(\mathcal D\) 中独立同分布采样而得的样例，因此，\(h\) 与 \(D\) 表现一致的概率为：<br/>
\[<br/>
P(h(x_1) = y_1) \land P(h(x_2) = y_2) \land ... \land P(h(x_m) = y_m) = (1-P(h(x)\neq y)^m \lt (1-\epsilon)^m<br/>
\]</p>

<p>我们事先并不知道学习算法 \(\mathcal L\) 会输出 \(\mathcal H\) 中的那个假设，但仅需保证泛化误差大于 \(\epsilon\) ，且在训练集上表现完美的所有假设出现概率之和不大于 \(\delta\) 即可：<br/>
\[<br/>
\begin{equation}<br/>
P(h\in \mathcal H:\mathrm{E}(h) &gt; \epsilon \land \hat {\mathrm{E}}(h) = 0) \lt \sum_{i=1}^{|\mathcal H|}  (1-\epsilon)^m \lt |\mathcal H|(1-\epsilon)^m\\\label{hiH}<br/>
\end{equation}<br/>
\]</p>

<p>考虑到 \(1-x &lt; e^{-x}\) ，证明：<br/>
令 \(F(x) = e^{-x} - 1 + x\)，当 \(x \ge 0\) 时有： <br/>
\[<br/>
F&#39;(x) = -e^{-x} + 1 \ge 0<br/>
\]</p>

<p>所以 \(F(x)\) 在 \(x \ge 0\) 时单调递增，\(F(x) \ge F(0) = 0 \)，所以得证。</p>

<p>所以式(\ref{hiH})可以写为：<br/>
\[<br/>
P(h\in \mathcal H:\mathrm{E}(h) &gt; \epsilon \land \hat {\mathrm{E}}(h) = 0) \lt |\mathcal H|(1-\epsilon)^m\lt |\mathcal H|e^{-m\epsilon}<br/>
\]</p>

<p>令上式不大于 \(\delta\) ，即：<br/>
\[<br/>
|\mathcal H|e^{-m\epsilon} \le \delta<br/>
\]</p>

<p>可得：<br/>
\[<br/>
\begin{equation}<br/>
m \ge \frac 1 \epsilon (\ln{|\mathcal H| + \ln{\frac 1 \delta}}) \label{yxm}<br/>
\end{equation}<br/>
\]</p>

<p>由此可知，有限假设空间 \(\mathcal H\) 都是 PAC 可学习的，所需的样例数目如(\ref{yxm})所示，输出假设 \(h\) 的泛化误差随样本数目的增多而收敛到 0，收敛速度为 \(O(\frac 1 m)\) 。</p>

<h5 id="toc_8">不可分情形</h5>

<p>对于目标概念不存在于假设空间中 \(\mathcal H\) 中，假定对于任何的 \(h\in\mathcal H\)，\(\mathrm{\hat E(h)}\ne 0\)，也就是 \(\mathcal H\) 中的任意一个假设都会在训练集上产生或多或少的错误。由泛化误差 \(\mathrm{E}(h)\) 与经验误差 \(\mathrm{\hat E(h)}\) 的定义易知 \(\mathbb E(\mathrm{\hat E(h)})=\mathrm{E(h)}\) ，因此由霍夫丁不等式理论一可得出定义。</p>

<p><b>若训练集 \(D\) 中包含 \(m\) 个从分布 \(\mathcal D\) 上独立同分布采样而得的样例，\(0\lt \epsilon\lt 1\)，则对任意 \(h\in\mathcal H\)，有：</b></p>

<p>\[<br/>
\begin{align}<br/>
&amp;P\big(\mathrm{\hat E(h)- E(h)}\ge \epsilon\big)\leq e^{-2m\epsilon^{2}}\label{dbo1}\\<br/>
&amp;P\big(\mathrm{E(h)-\hat E(h)}\ge \epsilon\big)\leq e^{-2m\epsilon^{2}}\label{dbo2}\\<br/>
&amp;P\big(\big|\mathrm{\hat E(h)- E(h)}\big|\ge \epsilon\big)\leq 2e^{-2m\epsilon^{2}}\label{dbo3}\\<br/>
\end{align}<br/>
\]</p>

<p>上面各式可以用霍夫丁不等式定理一得到，等式中 \(\mathrm{E}(h)\) 可以看成 \(\mathbb E\big[\mathrm{\hat E}(h)\big]\)，所以 \(\mathrm{\hat E}(h) - \mathrm{E}(h)\) 可以写成 \(\mathrm{\hat E}(h) - \mathbb E\big[\mathrm{\hat E}(h)\big]\)，再运用霍夫丁不等式即可。</p>

<p><strong>推论：若训练集 \(D\) 包含 \(m\) 个从 \(\mathcal D\) 中 i.i.d 采样而得的样本，\(0\lt \epsilon \lt 1\)，则对 \(h\in \mathcal H\) ，式(\ref{tl})以至少 \(1-\delta\) 的概率成立：</strong><br/>
\[<br/>
\begin{equation}<br/>
\mathrm{\hat E}(h) - \sqrt{\frac{\ln(2/\delta)}{2m}} \lt \mathrm{E}(h) \lt \mathrm{\hat E}(h) + \sqrt{\frac{\ln(2/\delta)}{2m}} \label{tl}\\<br/>
\end{equation}<br/>
\]</p>

<blockquote>
<p>下面简单证明一下这个推论：由(\ref{dbo3})式可知 \(P\big(\big|\mathrm{\hat E(h)- E(h)}\big|\gt \epsilon\big)\leq 2e^{-2m\epsilon^{2}}\)，该式子可以写成：<br/>
\[<br/>
\begin{align}<br/>
P \big(\big|\mathrm{\hat E(h)- E(h)}\big|\le \epsilon\big)\ge 1-2e^{-2m\epsilon^{2}}\label{dbo4}\\<br/>
\end{align}<br/>
\]</p>

<p>令 \(\delta = 2\exp({-2m\epsilon^2})\)，所以：<br/>
\[<br/>
\epsilon = \sqrt{\frac{\ln(2/\delta)}{2m}}<br/>
\]</p>

<p>所以由(\ref{dbo4})式可知 \(\big|\mathrm{\hat E(h)- E(h)}\big|\le\sqrt{\frac{\ln(2/\delta)}{2m}}\) 的概率不小于 \(1-\delta\)，整理可得推论。</p>
</blockquote>

<p>推论说明样本数目 \(m\) 较大时，\(h\) 的经验误差是其泛化误差很好的近似。对于有限假设空间我们有：<br/>
\[<br/>
P\Bigg( \Big| \mathrm{E}(h) - \mathrm{\hat E}(h)\Big| \le \sqrt{\frac{\ln|\mathcal H| + \ln(2/\delta)}{2m}}  \Bigg) \ge 1 - \delta<br/>
\]</p>

<blockquote>
<p>证明：令 \(h_1,h_2,...,h_{|\mathcal H}\) 是假设空间 \(\mathcal H\) 中的假设，有：<br/>
\[<br/>
\begin{align}<br/>
P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big) &amp;= P \big(\exists h \in \mathcal H:\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big)\nonumber\\<br/>
&amp;= P\Big(\big(\big| \mathrm{E(h_1)- \hat E(h_1)} \big| \gt \epsilon \big) \vee \cdots \vee \big(\big| \mathrm{E(h_{|\mathcal H|}) -\hat E(h_{|\mathcal H|})} \big| \gt \epsilon \big) \Big )\nonumber\\<br/>
&amp;\le \sum_{i=1}^{|\mathcal H|} \sup_{h\in \mathcal H}P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big)\nonumber\\<br/>
&amp;= |\mathcal H| \sup_{h\in \mathcal H}P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big)\label{mshp}\\<br/>
\end{align}<br/>
\]</p>

<p>由式(\ref{dbo3})可得：<br/>
\[<br/>
\sup_{h\in \mathcal H}P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big) = 2e^{-2m\epsilon^{2}}<br/>
\]</p>

<p>上式代入(\ref{mshp})可得：<br/>
\[<br/>
P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big) \le 2|\mathcal H|e^{-2m\epsilon^{2}}<br/>
\]</p>

<p>令 \(\delta = 2|\mathcal H|e^{-2m\epsilon^{2}} \) 求出 \(\epsilon\) 得表达式，便能很容易证明。</p>
</blockquote>

<p>而显然当 \(c\notin \mathcal H\) 时学习算法 \(\mathcal L\) 无法学得目标概率的 \(\mathcal c\) 的 \(\epsilon\) 近似。当时当假设空间 \(\mathcal H\) 给定时，必定存在一个泛化误差最好的假设，找到此假设的 \(\epsilon\) 近似也不失为一个较好的目标。\(\mathcal H\) 中训泛化差最好的假设是 \(\min_{h\in\mathcal H} \mathrm{E}(h)\)，于是以此目标可以将 PAC 学习推广到 \(\mathcal c \notin \mathcal H\) 的情况，这称为不可知学习（agnostic learning）。相应的，我们有：</p>

<p><strong>不可知 PAC 可学习（agnostic PAC learnable）</strong>：令 \(m\) 表示从 \(\mathcal H\) 中独立同分布（i.i.d.） 采样的样本个数，\(0\lt \epsilon\)，\(\delta \lt 1\)，对于所有分布 \(\mathcal H\) ，若存在学习算法 \(\mathcal L\) 和多项式 \(poly(\cdot,\cdot,\cdot,\cdot)\)，使得对于任意的 \(m\ge poly(1/\epsilon,1/\delta,\text{size}(\mathbf x),\text{size}(c))\)，\(\mathcal L\) 能从假设空间 \(\mathcal H\) 输出满足下式的假设 \(h\)：<br/>
\[<br/>
P\Big(\mathrm{E(h) - \min_{h&#39;\in\mathcal H}\hat E(h&#39;)} \le \epsilon\Big) \ge 1 - \delta<br/>
\]</p>

<p>则称假设空间 \(\mathcal H\) 是不可知 PAC 可学习的。</p>

<blockquote>
<p>对 \(\mathcal c \in \mathcal H\) 的情况称为<strong>可实现学习 realization learning</strong></p>
</blockquote>

<p>与 PAC 可学习类似，若学习算法的 \(\mathcal L\) 的运行时间也是多项式函数 \(poly(1/\epsilon,1/\delta,\text{size}(\mathbf x),\text{size}(c))\)，则称 \(\mathcal H\) 是高效不可知 PAC 可学习的，学习算法 \(\mathcal L\) 则称假设空间 \(\mathcal H\) 的不可知 PAC 学习算法，满足上述条件的最小的 \(m\) 称为学习算法 \(\mathcal L\) 的样本复杂度。</p>

<h3 id="toc_9">VC 维 Vapnik-Chervonenkis dimension</h3>

<p>现实学习任务所面临的通常是无限假设空间，例如实数域中的所有区间、\(\mathcal R^d\) 空间中的所有线性超平面。欲对此种情形的可学习性进行研究，需度量假设空间的复杂度。最常见的办法是考虑假设空间的“VC维”。</p>

<p>介绍 VC 维之前，我们先引入几个概念：增长函数（growth function）、对分（dichotomy）和打散（shattering）。</p>

<h4 id="toc_10">增长函数 growth function</h4>

<p>有些文献中将增长函数称为打散系数（shatter coefficient），其实是一样的。给定假设空间 \(\mathcal H\) 和示例集 \(D=\{x_1,x_2,...,x_m\}\)，\(\mathcal H\) 中每个假设 \(h\) 都能对 \(D\) 中示例赋予标记，标记结果可表示为：<br/>
\[<br/>
h|_D = \{(h(x_1),h(x_2),...,h(x_m))\}<br/>
\]</p>

<p>随着 \(m\) 的增大，\(\mathcal H\) 中所有假设对 \(D\) 中的示例所能赋予标记的可能结果数也会增大。</p>

<p><b>所有的 \(m \in \mathbf N\)，假设空间 \(\mathcal H\) 的增长函数 \(\Pi_{\mathcal H}(m)\) 为：<br/>
\[<br/>
\Pi_{\mathcal H}(m) = \max_{\{x_1,...,x_m\}\subseteq \mathcal X}\big|\{(h(x_1),...,h(x_m))\}|h\in \mathcal H\big|<br/>
\]<br/>
</b></p>

<p>增长函数 \(\Pi_{\mathcal H}(m)\) 表示假设空间 \(\mathcal H\) 对 \(m\) 个示例所能赋予标记的最大可能结果数。例如一个二分类问题，当 \(D\) 中只有两个示例 \(\{a,b\}\) ，\(h\) 对 \(D\) 中的示例所能赋予标记的可能为 \(\{(a=0,b=0),(a=0,b=1),(a=1,b=0),(a=1,b=1)\}\) ，当有三个示例时，赋予的标记有 8 种可能，对于 \(m\) 个示例最多有 \(2^m\) 种可能，即：<br/>
\[<br/>
\Pi_{\mathcal H}(m) \le 2^m<br/>
\]</p>

<p>显然，\(\mathcal H\) 对示例所能赋予标记的可能结果数越大，\(\mathcal H\) 的表示能力越强，对学习任务的适应能力也越强。因此，增长函数描述了假设空间 \(\mathcal H\) 的表示能力，由此反应出假设空间的复杂度。</p>

<h5 id="toc_11">对分 dichotomy</h5>

<p>假设空间 \(\mathcal H\) 中不同的假设对于 \(D\) 中示例赋予标记的结果可能相同，也可能不同；尽管 \(\mathcal H\) 中可能包含无穷多个假设，单其对 \(D\) 中示例赋予标记的可能结果数是有限的。对于二分类问题来说，\(\mathcal H\) 中假设对 \(D\) 中示例赋予标记的每种可能称为对 \(D\) 的一次“对分”。</p>

<h5 id="toc_12">打散 shatter</h5>

<p>对于二分类而言，若假设空间 \(\mathcal H\) 能实现示例集 \(D\) 的所有对分，即存在：<br/>
\[<br/>
\Pi_{\mathcal H}(m) = 2^m<br/>
\]</p>

<p>称示例集 \(D\) 能被假设空间“打散”，这也就是“打散系数”的由来。</p>

<h3 id="toc_13">VC 维</h3>

<p><b><br/>
假设空间 \(\mathcal H\) 的 VC 维定义为：<br/>
\[<br/>
V_{\mathcal H} = \max\{m|\Pi_{\mathcal H}(m) = 2^m\}<br/>
\]</p>

<p></b></p>

<p>\(V_{\mathcal H} = d\) 表明存在大小为 \(d\) 的示例集能被假设空间 \(\mathcal H\) 打散，这并不意味着所有大小为 \(d\) 的示例都能被假设空间 \(\mathcal H\) 打散。VC 维的定义与数据分布 \(D\) 无关，这意味着在数据分布未知的情况下仍能计算假设空间 \(\mathcal H\) 的VC维。</p>

<p>若存在大小为 \(d\) 的示例集能被 \(\mathcal H\) 打散，但是不存在 \(d+1\) 的示例集能被 \(\mathcal H\) 打散，则 \(\mathcal H\) 的 VC 维是 \(d\) 。如果对于所有的 \(m\) 有 \(\Pi_{\mathcal H} = 2^m\) ，那么有 \(V_{\mathcal H} = \infty\)。</p>

<p>我们可利用增长函数来估计经验误差与泛化误差之间的关系：</p>

<p><b>VC 不等式：对假设空间 \(\mathcal H\)，\(m\in \mathcal N\)，\(0\lt \epsilon \lt 1\) 和任意 \(h\in \mathcal H\) 有：<br/>
\[<br/>
P\bigg(\sup_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg) \le 4\Pi_{\mathcal H}(2m)\exp(-\frac{m\epsilon^2}{8})<br/>
\]</p>

<p></b></p>

<p>我们现在来尝试证明这个公式，为了证明这个定理，我们需要引入一个 “ghost sample” ，它是一个和训练数据 \(D\) 相同的数据，它只是为了帮我们证明结论，并不会在最后的结果中出现。设 \(D&#39; = \{(X&#39;_1,Y&#39;_1),..., (X&#39;_n , Y&#39;_n )\}\)，是独立于 \(D\) 外的以 i.i.d 形式从 \(\mathcal D\) 中采样出来的随机变量。定义这个样本上的经验损失为：<br/>
\[<br/>
\mathrm {\hat E&#39;(h)} = \frac 1 m \sum_{i=1}^m \mathbf{I}(h(x&#39;_i) \neq y&#39;_i)<br/>
\]</p>

<p>其中 \(\mathbf{I}\)是指示函数。</p>

<p>在下面的证明中，我们不失一般性地假设 \(m\epsilon^2\ge 2\)，否则定理中的边界会小。首先我们看 <b>Symmetrization 引理</b>：</p>

<p>对于任意的 \(\epsilon\)，且 \(m\epsilon^2 \ge 2\)，有：<br/>
\[<br/>
\begin{equation}<br/>
P\bigg(\sup_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg) \le 2P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}|\gt \frac \epsilon 2 \bigg) \label{psmm}<br/>
\end{equation}<br/>
\]</p>

<p>注意右边涉及两个不同的经验误差（empirical risk）的绝对值项是对称的，且这两个经验误差都是建立在有限的数据集合上，这样我们就避开了无限集的问题。现在我们假设不等式左边的上确界可以达到，并在 \(\widetilde{h}(D)\equiv \widetilde{h} \in \mathcal H\) 时达到。尽管因为 \(\mathcal H\) 是无限空间，不太容易定义出 \(\mathcal H\) 中达到最大值的元素，我们还是可以定义 \(\widetilde{h}\) 为：<br/>
\[<br/>
\widetilde{h} \approx \arg \max_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|<br/>
\]</p>

<p>现在我们来看一下(\ref{psmm})式的右边：<br/>
\[<br/>
\begin{align}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;\ge P\bigg( |\mathrm{\hat E(\widetilde h) - \hat E&#39;(\widetilde h)} | \gt \frac \epsilon 2\bigg)\label{pbs1}\\<br/>
&amp;\ge P\bigg( \Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) \Big| &gt; \epsilon \text{ and } \Big|\hat E&#39;(\widetilde h) - E(\widetilde h)} \Big| \lt \frac \epsilon 2\bigg)\label{pbs2}\\<br/>
&amp;= \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) \Big| &gt; \epsilon\Big\} \mathbf{I}\Big\{\Big|\hat E&#39;(\widetilde h) - E(\widetilde h)} \Big| \lt \frac \epsilon 2\Big\} \bigg]\label{pbs3}\\<br/>
&amp;= \mathbb E\bigg\{\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\} \mathbb E\Big[\mathbf{I}\Big\{\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)} \Big| \lt \frac \epsilon 2\Big\}\Big| D&#39;\Big] \bigg\}\label{pbs4}\\<br/>
&amp;= \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\} P\Big[\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2 \Big | D&#39;\Big]\bigg]\label{pbs5}\\<br/>
\end{align}<br/>
\]</p>

<p>式子从(\ref{pbs1})到式子(\ref{pbs2})是因为对于任意实数 \(x\)，\(y\) 和 \(z\)，有：<br/>
\[<br/>
|x-z|\gt \epsilon\text{ and }|y-z| \gt \frac \epsilon 2 \Rightarrow |x-y| \gt \frac \epsilon 2<br/>
\]</p>

<p>在 \(D&#39;\) 的条件下：<br/>
\[<br/>
\mathrm{\hat E&#39;(\widetilde h)} - \mathrm{E(\widetilde h)} = \frac 1 m \sum_{i=1}^m U_i(\widetilde h)<br/>
\]</p>

<p>其中 \(U_i(\widetilde h) = \mathbf{I}(\widetilde h(x&#39;_i) \neq y&#39;_i) - \mathbb E\big[\mathbf{I}(\widetilde h(x&#39;_i) \neq y&#39;_i)|D&#39;\big]\)，它是一个平均值为 0 的独立同分布的随机变量。使用切比雪夫不等式：<br/>
\[<br/>
\begin{align*}<br/>
P\Big[\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big] &amp;= P\Big[\Big|\frac 1 m \sum_{i=1}^m U_i(\widetilde h)\Big| \lt \frac \epsilon 2 \bigg| D&#39;\Big]\\<br/>
&amp;= P\Big[\Big|\sum_{i=1}^m U_i(\widetilde h)\Big| \lt \frac{m\epsilon}{2} \bigg| D&#39;\Big]\\<br/>
&amp;\ge 1 - \frac {\text{var}\Big[|\sum_{i=1}^m U_i(\widetilde h)|\Big|D&#39;\Big]}{(m\epsilon/2)^2}\\<br/>
&amp;= 1 - \frac{4}{m^2\epsilon^2} \text{var}\Big[|\sum_{i=1}^m U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
&amp;= 1 - \frac{4m}{m^2\epsilon^2}\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
&amp;= 1 - \frac{4}{m\epsilon^2}\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>若随机变量 \(X\) 的范围为 \([a,b]\)，则：<br/>
\[<br/>
\mathbb{D}(X) \le \frac{(b-a)^2}{4}<br/>
\]</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb{D}(X) &amp;= \mathbb{E}\{[X-\mathbb{E}(X)]^2\} \\<br/>
&amp;= \mathbb E\{X^2 - 2X\mathbb{E}(X) + [\mathbb{E}(X)]^2\} \\<br/>
&amp;= \mathbb{E}(X^2) - 2[\mathbb{E}(X)]^2 + [\mathbb{E}(X)]^2 \\<br/>
&amp;= \mathbb{E}(X^2) - [\mathbb{E}(X)]^2<br/>
\end{align*}<br/>
\]</p>

<p>考虑到 \(a \le X \le b\)，即 \(\mathbb{E}(a) \le \mathbb{E}(X) \le \mathbb{E}(b)\)，也就是 \(a\le \mathbb{E}(X) \le b\)，令 \(Y=\frac{X-a}{b-a}\)，可知 \(0\le Y \le 1\)，<br/>
\[<br/>
\begin{align*}<br/>
&amp;\mathbb{D}(Y) = \mathbb{D}(\frac{X-a}{b-a}) = \frac{\mathbb{D}(X)}{b-a}\\<br/>
&amp;\Rightarrow \quad \mathbb{D}(X) = \mathbb{D}(Y)\cdot (b-a) = \{\mathbb{E}(Y^2) - [\mathbb{E}(Y)]^2\}\cdot (b-a)\\<br/>
&amp;\because \quad Y \le 1 \\<br/>
&amp;\therefore \quad Y^2 \le Y \\<br/>
&amp;\therefore \quad \mathbb{D}(Y^2) &lt; \mathbb{D}(Y)\\<br/>
&amp;\Rightarrow \quad \mathbb{D}(X) = \{\mathbb{E}(Y^2) - [\mathbb{E}(Y)]^2\}\cdot (b-a) \le \{\mathbb{E}(Y) - [\mathbb{E}(Y)]^2\}\cdot (b-a)\\<br/>
\end{align*}<br/>
\]</p>

<p>由均值不等式可知：<br/>
\[<br/>
\mathbb{E}(Y) - [\mathbb{E}(Y)]^2 = \mathbb{E}(Y)[1-\mathbb{E}(Y)] \le \frac{\big\{\mathbb{E}(Y)+[1-\mathbb{E}(Y)] \big\}^2}{4}= \frac 1 4<br/>
\]</p>

<p>所以：\(\mathbb{D}(X) \le {(b-a)^2}/{4}\)，得证</p>
</blockquote>

<p>由 \(U_i(\widetilde h)\) 的定义知 \(|U_i(\widetilde h)|\) 的区间为 \([0,1]\)，所以 \(\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big] \le \frac 1 4\)，所以：<br/>
\[<br/>
\begin{align*}<br/>
P\Big(\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big) &amp;\ge 1 - \frac{4}{m\epsilon^2}\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
&amp;\ge 1- \frac{4}{m\epsilon^2}\cdot \frac 1 4 = 1- \frac{1}{m\epsilon^2}\\<br/>
\because\quad &amp; m\epsilon^2 &gt; 2\\<br/>
\therefore \quad &amp; -\frac{1}{m\epsilon^2} &gt; -\frac 1 2\\<br/>
\Rightarrow \quad P\Big(\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big) &amp;\ge 1- \frac{1}{m\epsilon^2} \ge \frac 1 2<br/>
\end{align*}<br/>
\]</p>

<p>现在再看式(\ref{pbs5})，可以知道：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;\ge \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\} P\Big[\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big]\bigg]\\<br/>
&amp;\ge \frac 1 2 \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\}\bigg]\\<br/>
&amp;= \frac 1 2 P\Big[\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big]\\<br/>
&amp;= \frac 1 2 P\Big[\sup_{h\in \mathcal H}\Big|\mathrm{\hat E(h) - E(h) }\Big| &gt; \epsilon \Big]\\<br/>
\end{align*}<br/>
\]</p>

<p>上面推导过程中最后一个不等式，是由于 \(\widetilde h\) 的定义是此时 \(\mathrm{\hat E(\widetilde h) - E(\widetilde h)}\) 能得到最大值，此时也就等价于 \(\mathrm{\hat E(h) - E(h) }\) 达到上确界。所以引理得证。</p>

<p>Symmetrization 引理一个很大的好处是我们将无限假设空间的问题边界问题转换成有限假设空间边界问题，现在我们来考虑有限假设空间上的<br/>
\[<br/>
\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)} = \frac 1 m \sum_{i=1}^m \mathbf{I}[h(x_i) \neq y_i]-\frac 1 m \sum_{i=1}^m \mathbf{I}[h(x&#39;_i) \neq y&#39;_i] = \frac 1 m \sum_{i=1}^m \{\mathbf{I}[h(x_i) \neq y_i]-\mathbf{I}[h(x&#39;_i) \neq y&#39;_i]\}<br/>
\]</p>

<p>注意上面的等式，令 \(\mathbf h=(h_1,h_2,...,h_m,h&#39;_1,h&#39;_2,...,h&#39;_m)\)，这里 \(h_1\) 表示 \(h(x_1)\) ，\(h&#39;_1\) 表示 \(h(x&#39;_1)\) ，\(\mathbf h\) 只取决于训练样本和 “ghost sample”，因此考虑 \(\mathcal H\) 在两个样本 \(DD&#39;\) 的投影 \(\mathcal H_{D\cup D&#39;}\)，便有：<br/>
\[<br/>
\begin{eqnarray}<br/>
\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| = \sup_{\mathbf h \in \mathcal H_{D\cup D&#39;}}\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\label{hmc}\\<br/>
\end{eqnarray}<br/>
\]</p>

<blockquote>
<p>现在我们仅考虑经验损失边界 ，如果很多假设有着相同的经验损失（也就是在各数据点上都产生相同的 labels/values 对），我们可以取出一个作为代表，称之为“有效假设”，将其他的都去除。在数据集 \(D\) 上仅选择那些不同的有效假设，我们可以将假设空间限制到一个更小的子集 \(\mathcal H_D\)。 同理，如果考虑 \(\mathcal H\) 在训练样本和 ”ghost sample“ 的限制，即 \(\mathcal H_{D\cup D&#39;}\)。</p>
</blockquote>

<p>因为上限值很大，所以至少存在一个 \(\mathbf h\) 能使  \(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\) 很大：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;= P\bigg(\sup_{\mathbf h \in \mathcal H_{D\cup D&#39;}}\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;= P\bigg(\exists \mathbf h \in \mathcal H_{D\cup D&#39;}:\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>由于 \(\mathcal H_{DD&#39;}\) 是可数的，我们可以对这个特殊 \(\mathbf h\) 的概率用联合概率的一致性：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\exists \mathbf h \in \mathcal H_{D\cup D&#39;}:\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)&amp;\le \sum_{ \mathbf h \in \mathcal H_{D\cup D&#39;}}P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;\le |\mathcal H_{D\cup D&#39;}| P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>一致限（union bound）：若 \(A_1,A_2,...,A_k\) 为k个不同的事件（不一定相互独立），那么有：<br/>
\[<br/>
P(A_1\cup A_2 \cup ... \cup A_k) = P(A_1) + P(A_2) + ... + P(A_n)<br/>
\]</p>

<p>一致限说明：k个事件中任一个事件发生的概率小于等于这k个事件发生的概率和（等号成立的条件为这k个事件相两两互斥）</p>
</blockquote>

<p>用增长函数的定义我们知道 \(|\mathcal H_{D\cup D&#39;}| \le \Pi_\mathcal H(2m)\)，代入得：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\exists \mathbf h \in \mathcal H_{D\cup D&#39;}:\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg) &amp;\le |\mathcal H_{D\cup D&#39;}| P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;\le \Pi_\mathcal H(2m) P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>这里我们令 \(L_i = \mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\)，它的期望值为：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E(L_i) &amp;= \mathbb E\big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i) \big]\\<br/>
&amp;= \mathbb E\big[\mathbf{I}(h_i \neq y_i)\big]-\mathbb E\big[\mathbf{I}(h&#39;_i \neq y&#39;_i) \big]\\<br/>
&amp;= \mathrm{E}(h) - \mathrm{E}(h) = 0<br/>
\end{align*}<br/>
\]</p>

<p>我们允许我们表示 \(\hat {\mathrm{E}}(h) - \mathrm{E&#39;}(h)\)：<br/>
\[<br/>
\begin{align*}<br/>
\hat {\mathrm{E}}(h) - \mathrm{E&#39;}(h) &amp;= \frac 1 m \sum_{i=1}^m \big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\big]\\<br/>
&amp;= \frac 1 m \sum_{i=1}^m L_i\\<br/>
&amp;= \frac 1 m \sum_{i=1}^m \big [L_i-\mathbb{E}(L_i)\big]\\<br/>
\end{align*}<br/>
\]</p>

<p>除此之外我们注意到 \(L_i\) 的取值范围是 \([-1,1]\) ，我们可以运用霍夫丁不等式理论二：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \big [L_i - \mathbb{E}(L_i)\big ]\bigg|\gt t\bigg) \le 2\exp(-\frac{2t^2m^2}{\sum_{i=1}^{m}(1+1)^2}) = 2\exp(-\frac{2t^2m^2}{4m}) = 2\exp(-\frac{mt^2}{2})<br/>
\end{align*}<br/>
\]</p>

<p>令 \(t=\frac \epsilon 2\) ，得：<br/>
\[<br/>
P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg) \le 2\exp(-\frac{m\epsilon^2}{8})<br/>
\]</p>

<p>最终结果可得：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;\le \Pi_\mathcal H(2m) \sup_{\mathbf h \in \mathcal H_{D,D&#39;}} P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;= 2\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})\\<br/>
\end{align*}<br/>
\]</p>

<p>结合 Symmetrization 引理可以得到：<br/>
\[<br/>
P\bigg(\sup_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg) \le 2P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}|\gt \frac \epsilon 2 \bigg) \le 4\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})<br/>
\]</p>

<p>所以 VC 不等式可证。</p>

<h4 id="toc_14">VC 维举例</h4>

<p><b>实数域举例</b>：实数域的区间 \([a,b]\) ，令 \(\mathcal H\) 表示实数域中的所有闭区间构成的集合 \(\{h_{[a,b]}:a,b\in \mathbb R,a\le b\}\)，\(\mathcal X = \mathbb R\)，对 \(x \in \mathcal X\)，若 \(x \in [a,b]\)，则 \(h_{[a,b]}(x) = +1\)，否则 \(h_{[a,b]}(x) = -1\)。若 \(D=\{x_1,x_2\} = \{0.5,1.5\}\)，则假设空间中 \(\mathcal H\) 中存在假设 \(\{h_{[0,1]},h_{[0,2]},h_{[1,2]},h_{[2,3]}\}\) 将 \(\{x_1,x_2\}\) 打散，所以假设空间 \(\mathcal H\) 的 VC 维至少为2；对任意大小为 3 的示例集 \(\{x_3,x_4,x_5\}\)，不妨设 \(x_3\lt x_4 \lt x_5\)，则 \(\mathcal H\) 中不存在任意假设 \(h_{[a,b]}\) 能实现对分结果 \(\{(x_3,+1),(x_4,-1),(x_5,+1)\}\) ，于是 VC 维为2.</p>

<p><b>二维平面举例</b>：令 \(\mathcal H\) 表示二维实平面上所有线性划分构成的集合，\(\mathcal X=\mathbb R^2\)。</p>

<div align="center">
    <img width="600" src="media/15151569041850/15338602041302.jpg" />
</div>

<p>如上图所示，存在大小为 3 的示例集可被 \(\mathcal H\) 打散，但不存在大小为 4 的示例集可被 \(\mathcal H\) 打散。于是，二维平面上所有线性划分构成的假设空间 \(\mathcal H\) 的 VC 维为 3 。</p>

<h4 id="toc_15">Sauer 引理</h4>

<p>Sauer 引理基于 VC 维提供一类二分类增长函数的多项式约束。若假设空间 \(\mathcal H\) 的 VC 维为 \(d\)，则对任意的 \(m\in \mathbb N\) 有：<br/>
\[<br/>
\Pi_\mathcal H(m) \le \sum_{i=0}^d\bigg(\begin{array}{c}m\\i\\\end{array}\bigg) <br/>
\]</p>

<blockquote>
<p>其中<br/>
\[<br/>
\bigg( \begin{array}{c}m\\n\\\end{array} \bigg) = \frac{m!}{n!(n-m)!} <br/>
\]</p>

<p>表示组合数，又可以简写为 \(C_n^m\) ，物理意义表示为从 \(m\) 个不同元素中取出 \(n\) 个元素的组合数。规定 \(C_0^m = 1\)、\(C_m^m = 1\) 和 \(C_0^0 = 1\)。</p>
</blockquote>

<p>证明：由数学归纳法证明。当 \(m=1\)，\(d=0\) 或 \(d=1\) 时：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\Pi_\mathcal H(m) = \left \{ \begin{array}{c}<br/>
2^0 = 1\quad&amp;m=1,d=0\\<br/>
2^1 = 2\quad&amp;m=1,d=1\\<br/>
\end{array} \right .\\<br/>
&amp;\sum_{i=0}^d \left(\begin{array}{c}m\\i\\\end{array}\right ) = \left \{ \begin{array}\\ \left (\begin{array}{c}1\\0\\\end{array}\right ) = 1;\quad &amp;m=1,d=0\\<br/>
\left (\begin{array}{c}1\\0\\\end{array}\right ) + \left ( \begin{array}{c}1\\1\\\end{array}\right ) = 2;\quad &amp;m=1,d=1\\<br/>
\end{array}\right .<br/>
\end{align*}<br/>
\]</p>

<p>定理成立。</p>

<p>假设定理对 \((m-1,d-1)\) 和 \((m-1,d)\) 成立。令 \(D=\{x_1,x_2,...,x_m\}\)，\(D&#39;=\{x_1,x_2,...,x_{m-1}\}\)，<br/>
\[<br/>
\begin{align*}<br/>
\mathcal H_{|D}  &amp;= \{(h(x_1),h(x_2),...,h(x_m))|h\in\mathcal H\},\\<br/>
\mathcal H_{|D&#39;} &amp;= \{(h(x_1),h(x_2),...,h(x_{m-1}))|h\in\mathcal H\}.\\<br/>
\end{align*}<br/>
\]</p>

<p>任何假设 \(h\in \mathcal H\) 对 \(x_m\) 的分类结果或为 \(+1\) 或为 \(-1\)，因此任何出现 \(\mathcal H_{|D&#39;}\) 中的串都会在 \(\mathcal H_{|D}\) 中出现一次或两次，令 \(\mathcal H_{D&#39;|D}\) 表示在 \(\mathcal H_{|D}\) 中出现两次的 \(\mathcal H_{|D&#39;}\) 中串组成的集合，即：<br/>
\[<br/>
\mathcal H_{D&#39;|D} = \{(y_1,y_2,...,y_{m-1})\in \mathcal H_{|D&#39;} | \exists h,h&#39;\in \mathcal H,(h(x_i)=h&#39;(x_i) = y_i)\land(h(x_m)\neq h&#39;(x_m)),1\le i\le m-1\}<br/>
\]</p>

<p>考虑到 \(\mathcal H_{D&#39;|D}\) 中的串在 \(\mathcal H_{|D}\) 中出现了两次，但在 \(\mathcal H_{|D&#39;}\) 中仅出现了一次，有：<br/>
\[<br/>
\begin{align}<br/>
|\mathcal H_{|D}| = |\mathcal H_{|D&#39;}| + |\mathcal H_{D&#39;|D}|\label{mmm}<br/>
\end{align}<br/>
\]</p>

<p>\(D&#39;\) 的大小为 \(m-1\) ，由假设可得：<br/>
\[<br/>
\begin{align}<br/>
|\mathcal H_{|D&#39;}| \le \Pi_{\mathcal H}(m-1) \le \sum_{i=0}^d \bigg( \begin{array}{c}m-1\\i\\\end{array}\bigg )\label{mlp}\\<br/>
\end{align}<br/>
\]</p>

<p>令 \(Q\) 表示能被 \(\mathcal H_{D|D&#39;}\) 打散的集合，由 \(\mathcal H_{D&#39;|D}\) 定义可知 \(Q\cup\{x_m\}\) 必能被 \(\mathcal H_{|D}\) 打散。由于 \(\mathcal H\) 的 VC 维为 \(d\)，因此 \(\mathcal H_{D&#39;|D}\) 的 VC 维最小为 \(d-1\)，于是有：<br/>
\[<br/>
\begin{align}<br/>
|H_{D&#39;|D}| \le \Pi(m-1) \le \sum_{i=0}^{d-1}\bigg(\begin{array}{c}m-1\\i\\\end{array}\bigg )\label{hll}<br/>
\end{align}<br/>
\]</p>

<p>由式(\ref{mmm})、(\ref{mlp})和(\ref{hll})可得：<br/>
\[<br/>
\begin{align*}<br/>
|\mathcal H_{|D}| &amp;\le \sum_{i=0}^d \left(\begin{array}{c}m-1\\i\\\end{array}\right ) + \sum_{i=0}^{d-1} \left(\begin{array}{c} m-1\\i\\\end{array}\right)\\<br/>
&amp;= \sum_{i=0}^d \left(\begin{array}{c}m-1\\i\\\end{array}\right ) + \sum_{i=0}^{d} \left(\begin{array}{c} m-1\\i-1\\\end{array}\right)\\<br/>
&amp;= \sum_{i=0}^d \bigg(\left(\begin{array}{c}m-1\\i\\\end{array}\right)+\left(\begin{array}{c}m-1\\i-1\\\end{array}\right )\bigg)\\<br/>
&amp;= \sum_{i=0}^d \left (\begin{array}{c}m\\i\\\end{array} \right )<br/>
\end{align*}<br/>
\]</p>

<p>由集合 \(D\) 的任意性，引理得证。</p>

<p><strong>Sauer推论1：如果 \(d &lt; \infty\) ，对于所有的 \(m \ge 1\) ：<br/>
\[<br/>
\Pi_\mathcal H(m) \le \sum_{i=0}^d\bigg(\begin{array}{c}m\\i\\\end{array}\bigg)  \le (m+1)^d<br/>
\]</strong></p>

<p>推论证明：通过二项式定理：<br/>
\[<br/>
\begin{align*}<br/>
(m+1)^d &amp;= \sum_{i=0}^d m^i \left( \begin{array}\\d\\i\\\end{array}\right ) = \sum_{i=0}^d m^i \frac{d!}{(d-i)!i!}\\<br/>
&amp;\ge \sum_{i=1}^d \frac{m!}{i!} \ge \sum_{i=1}^d \frac{m!}{(m-i)!i!} = \sum_{i=1}^d \left (\begin{array}{cc}m\\i\\\end{array}\right )<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>二项式定理：可以将 \(x+y\) 的任意次幂展开成和的形式<br/>
\[<br/>
(x+y)^n = \left(\begin{array}\\ n\\0\\\end{array} \right)x^n y^0 + \left(\begin{array}\\ {n}\\1\\\end{array}\right) x^{n-1} y^1 + \cdots + \left(\begin{array}{cc} n\\{n-1}\\\end{array} \right )x^1 y^{n-1} + \left(\begin{array}\\ n\\n\\\end{array} \right )x^0 y^n\\<br/>
\]</p>
</blockquote>

<p><strong>Sauer推论2：对于所有的 \(m\le d\) ，有：<br/>
\[<br/>
\Pi_\mathcal H(m) \le \sum_{i=0}^d\bigg(\begin{array}{c}m\\i\\\end{array}\bigg) \le\bigg(\frac{me}{d}\bigg)^d<br/>
\]</strong></p>

<p>推论证明：如果 \(\frac d m \le 1\) 然后<br/>
\[<br/>
\begin{align*}<br/>
\bigg(\frac d m \bigg)^d \sum_{i=0}^d \left (\begin{array}{cc}m\\i\\\end{array}\right ) &amp;\le \sum_{i=0}^d \bigg(\frac d m \bigg)^i \left (\begin{array}{cc}m\\i\\\end{array}\right ) \le \sum_{i=0}^m \bigg(\frac d m \bigg)^i \left (\begin{array}{cc}m\\i\\\end{array}\right ) \\<br/>
&amp;= \bigg(1+\frac d m\bigg)^m \le (e^{d/m})^m \le e^d<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>上面的推理使用了\[<br/>
(1+x)&lt;e^x<br/>
\]</p>

<p>这个不等式在上面已经有证明。</p>
</blockquote>

<p>因此<br/>
\[<br/>
\sum_{i=0}^d \left (\begin{array}{cc}m\\i\\\end{array}\right )  \le e^d \bigg(\frac m d \bigg )^d = \bigg (\frac {me}{d}\bigg)^d<br/>
\]</p>

<p><strong>Sauer推论3：如果 \(d\gt 2\) ，那么对于所有 \(m \ge d\)：<br/>
\[<br/>
\Pi_\mathcal H(m) \le m^d<br/>
\]</strong></p>

<p>推论证明：如果 \(d \gt 2\)，且 \(d\in \mathcal N\) ，则\(\frac e d \lt 1\)，由上个推论自然可证。</p>

<p>我们现在来根据<strong>VC不等式定理</strong>和推论可得基于 VC 维的泛化误差界</p>

<p><strong>定理1</strong>：若假设空间 \(\mathcal H\) 的VC维为 \(d\)，则对任意 \(m\gt d\)，\(0\lt \delta\lt 1\) 和 \(h\in \mathcal H\) 有<br/>
\[<br/>
\begin{align}<br/>
P\bigg(\Big|\mathrm E(h) - \mathrm{\hat E}(h)\Big|\le \sqrt{\frac{8d\ln\frac{2em}{d} + 8\ln\frac{4}{\delta}}{m}}\bigg) \ge 1 - \delta\label{pbhb}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：由VC不等式可知：<br/>
\[<br/>
P\bigg(|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg)\le 4\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})\\<br/>
\Rightarrow P\bigg(|\mathrm E(h) - \mathrm{\hat E(h)}|\le \epsilon\bigg)\ge 1 - 4\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})\ge 1 - 4\bigg(\frac{2me}{d}\bigg)^d \exp(-\frac{m\epsilon^2}{8})\\<br/>
\]</p>

<p>令 \(\delta = 4\Big(\frac{2me}{d}\Big)^d \exp\Big(-\frac{m\epsilon^2}{8}\Big)\) 得<br/>
\[<br/>
\epsilon = \sqrt{\frac{8\ln(4/\delta) + 8d\ln(2em/d)}{m}}<br/>
\]</p>

<p>得证。</p>

<p>由该定理可知(\ref{pbhb})得泛化误差界只与样例数目 \(m\) 有关，收敛速率为 \(\mathbb O(1/m\) ，与数据分布 \(\mathcal D\) 和样例集 \(D\) 无关。因此基于 VC 维的泛化误差界是分布无关（distribution-free）、数据独立（data-independent）的。</p>

<p>令 \(h\) 表示学习算法 \(\mathcal L\) 输出的假设，若 \(h\) 满足：<br/>
\[<br/>
h = \min_{h&#39;\in\mathcal H} \mathrm{\hat E}(h&#39;)<br/>
\]</p>

<p>则称学习算法 \(\mathcal L\) 满足经验风险最小化（ERM，Empirical Risk Minimization）原则的算法，有下面的定理：</p>

<p><strong>定理2</strong>：任何VC维有限的假设空间 \(\mathcal H\) 都是（不可知）PAC可学习的。</p>

<p>证明：假设 \(\mathcal L\) 是满足经验风险最小化的算法，\(h\) 是算法输出的假设。令 \(g\) 表示 \(\mathcal H\) 中最小泛化误差的假设，即：<br/>
\[<br/>
\mathrm{E}(g) = \min_{h\in\mathcal H}\mathrm{E}(h)<br/>
\]</p>

<p>令 <br/>
\[<br/>
\begin{align}<br/>
\delta&#39;/2 = \delta，\nonumber\\<br/>
\sqrt{\frac{\ln(\delta&#39;/2)}{2m}} = \frac \epsilon 2\label{sfl}<br/>
\end{align}<br/>
\]</p>

<p>由<strong>推论</strong>公式(\ref{tl})可知<br/>
\[<br/>
\begin{align}<br/>
\mathrm{\hat E}(g) - \frac \epsilon 2 \le \mathrm{E}(g) \le \mathrm{\hat E}(g) + \frac \epsilon 2\label{mheg}<br/>
\end{align}<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。令<br/>
\[<br/>
\begin{align}<br/>
\sqrt{\frac{8\ln(4/\delta&#39;) + 8d\ln(2em/d)}{m}} = \frac \epsilon 2\label{sf8}\\<br/>
\end{align}<br/>
\]</p>

<p>由<strong>定理1</strong>公式(\ref{pbhb}) 可知<br/>
\[<br/>
\begin{align}<br/>
P\bigg(\Big|\mathrm E(h) - \mathrm{\hat E}(h)\Big|\le \frac \epsilon 2\bigg) \ge 1 - \delta\label{pbbme}<br/>
\end{align}<br/>
\]</p>

<p>由(\ref{mheg})知<br/>
\[<br/>
\mathrm{E}(g) - \mathrm{\hat E}(g) + \frac \epsilon 2 \ge 0<br/>
\]</p>

<p>结合(\ref{pbbme})知<br/>
\[<br/>
\mathrm E(h) - \mathrm{\hat E}(h) \le \frac \epsilon 2 + \mathrm{E}(g) - \mathrm{\hat E}(g) + \frac \epsilon 2<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。</p>

<p>所以<br/>
\[<br/>
\mathrm{E}(h) - \mathrm{E}(g) \le \mathrm{\hat E}(h) - \mathrm{\hat E}(g) + \epsilon \le \epsilon<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。由(\ref{sfl})和(\ref{sf8})可以解出 \(m\)，再由 \(\mathcal H\) 的任意性可知定理成立，得证。</p>

<hr/>

<p>周志华 机器学习<br/>
<a href="https://web.eecs.umich.edu/%7Ecscott/past_courses/eecs598w14/notes/05_vc_theory.pdf">VC Theory</a><br/>
<a href="http://freemind.pluskid.org/pdf/slt/vc-theory-symmetrization.pdf">VC Symmetrization</a><br/>
<a href="https://mostafa-samir.github.io/ml-theory-pt2/">ml-theory-pt2</a><br/>
<a href="https://blog.csdn.net/wangjianguobj/article/details/57413819">30分钟了解PAC学习理论</a><br/>
<a href="https://blog.csdn.net/icefire_tyh/article/details/52064910">机器学习(周志华西瓜书)参考答案总目录</a><br/>
<a href="http://mlweb.loria.fr/book/en/SauerShelah.html">Sauer&#39;s Lemma</a><br/>
<a href="http://mlweb.loria.fr/book/en/VCbound.html">My first VC bound</a><br/>
<a href="http://mlweb.loria.fr/book/en/symmetrization.html">Symmetrization (where we start seeing ghost samples)</a><br/>
<a href="https://people.cs.umass.edu/%7Eakshay/courses/cs690m/files/lec4.pdf">Lecture 4: The Vapnik-Chervonenkis Dimension</a><br/>
<a href="http://nowak.ece.wisc.edu/SLT09/lecture19.pdf">The Proof of the Vapnik-Chervonenkis (VC) Inequality</a><br/>
<a href="http://www.cs.cmu.edu/%7Ehanxiaol/slides/rademacher_vc_hanxiaol.pdf">Rademacher Complexity and VC Dimension</a><br/>
<a href="https://web.eecs.umich.edu/%7Ecscott/past_courses/eecs598w14/notes/05_vc_theory.pdf">Vapnik-Chevronenkis Theory</a><br/>
<a href="https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec14.pdf">Introduction to Statistical Learning Theory</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15145527362267.html">回归分类树-CART算法</a></h1>
			<p class="meta"><time datetime="2017-12-29T21:05:36+08:00" 
			pubdate data-updated="true">2017/12/29</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>CART算法的英文名称是 Classfication And Regression Tree，即可以用来创建分类树也可以用来创建回归树。通过 ID3 和 C4.5 算法得到的决策树不一定是二叉树，但是通过 CART 得到的决策树肯定是二叉树。CART 算法的生成也是分为三个部分：特征选择、决策树生成、决策树剪枝：</p>

<ol>
<li>特征选择：当 CART 是分类树的时候，以基尼指数选择最优特征，同时决定该特征的最优二值切分点。</li>
<li>决策树生成：基于训练数据生成决策树，生成的树要求尽可能大</li>
<li>决策树剪枝：用合适的方法对已经生成的树进行剪枝选择最优子树。</li>
</ol>

<p>首先我们来分别了解一下 CART 的分类树和回归树。</p>

<h3 id="toc_0">特征选择</h3>

<p>首先来了解一下特征选择所需要的基尼指数知识。</p>

<h5 id="toc_1">基尼指数 Gini</h5>

<p>基尼指数（基尼不纯度）表示在样本集合中一个随机选中的样本被分错的概率。Gini指数越小表示集合中被选中的样本被分错的概率越小，也就是说集合的纯度越高，反之，集合越不纯。所以基尼指数（基尼不纯度）= 样本被选中的概率 * 样本被分错的概率，定义 \(p_k\) 表示选中的样本属于k类别的概率，则这个样本被分错的概率是 \((1-p_k)\)：<br/>
\[<br/>
Gini(k) = \sum_{k=1}^K p_k (1-p_k) = \sum_{k=1}^K p_k - \sum_{k=1}^K p_k^2 = 1 - \sum_{k=1}^K p_k^2<br/>
\]</p>

<p>当二分类时，\(Gini(k) = 2p(1-p)\)。</p>

<p>假设样本集合 D 有 K 个类别，类别 \(C_k\) 包含 \(|C_k|\) 个样本，他们被正确选中为类别 \(C_k\) 的概率为：<br/>
\[<br/>
p(k) = \frac{|C_k|}{|D|}<br/>
\]</p>

<p>所以基尼指数：<br/>
\[<br/>
Gini(k) = 1 - \sum_{k=1}^K p_k^2 = 1 - \sum_{k=1}^K (\frac{|C_k|}{|D|})^2<br/>
\]</p>

<p>基于特征 A 划分样本集合 D 后，集合被分为 \(D_1,D_2,...D_n\)，在 CART 算法中 \(n=2\)，此时基尼指数：<br/>
\[<br/>
Gini(D,A) = \sum_{D_i} \frac{|D_i|}{|D|} Gini(D_i)<br/>
\]</p>

<p>当拥有多个特征时，需要计算以每一个取值作为划分点，对样本D划分之后子集的纯度 \(Gini(D,Ai)\)，(其中Ai 表示特征A的可能取值)。然后从所有的可能划分的 \(Gini(D,Ai)\) 中找出Gini指数最小的划分，这个划分的划分点，便是使用特征 A 对样本集合 D 进行划分的最佳划分点。</p>

<h3 id="toc_2">CART生成树</h3>

<p>决策树的生成是递归生成二叉决策树的过程，对分类树用基尼指数最小化准则，对回归树采用平方误差最小化准则进行特征选择，生成二叉树。</p>

<h4 id="toc_3">分类树生成算法</h4>

<p><b>输入</b>：训练数据集离散数据集 D，停止计算的条件；<br/>
<b>输出</b>：CART 决策树<br/>
<b>算法过程</b>：<br/>
（1）设结点的训练数据集为 D ，计算现有特征对该数据基的基尼指数。此时，对每一个特征 A，对其可能取的每个值 a，根据样本点对 A=a 的测试为“是”或“否” 将 D 分割成 \(D_1\) 和 \(D_2\) 两部分，利用 \(A=a\) 的基尼指数；<br/>
（2）在所有可能的特征 A 以及它们所有可能的切分点 a 中，选择基尼指数最小的特征及其对应的切分点作为最优特征和最优切分点，依最优特征与最优切分点，从现结点生成两个子结点，将训练数据集依特征分配到两个子结点中去。<br/>
（3）对两个子结点递归地调用（1）、（2），直至满足停止条件；<br/>
（4）生成 CART 决策树；</p>

<p>算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于阈值阈值（样本基本属于同一类），活着没有更多特征。</p>

<h5 id="toc_4">举例说明</h5>

<p>比如在之前决策树的14天数据中，当 \(A_1\) = 天气特征时，有三种取值，分别是晴天、阴天、下雨，可能的划分情况有{{晴天}{阴天、下雨}}、{{晴天、阴天}{下雨}}、{{阴天}{晴天、下雨}}，分别计算每一种情况的基尼指数。<br/>
\[<br/>
Gini(D,A_1=阴天) = \frac 4 {14}* 2*1*0 + \frac{10}{14} *2 * \frac 5 {10} * \frac 5 {10} = 0.3571 \\<br/>
Gini(D,A_1=下雨) = \frac 5 {14}* 2*\frac 3 5 * \frac 2 5 + \frac {9}{14} * 2* \frac{6}{9} *\frac{3}{9} = 0.4571 \\<br/>
Gini(D,A_1=晴天) = \frac 5 {14}* 2*\frac 2 5 * \frac 3 5 + \frac 9 {14} * 2 * \frac 7 9  *\frac 2 9 = 0.3937<br/>
\]</p>

<p>再计算 \(A_2\) = 湿度特征时，有三种取值，求得每一种取值的基尼指数。。。依次类推，选择所有可能特征及其所有可能的切分点种，基尼指数最小的特征和切分点。将训练数据分到两个子结点中，再对子结点按照同样的方式选择最优特征和最优切分点。CART算法每次都是生成二叉树，在这个例子中某属性特征值为3个时，有3个可能的切分点。当特征值为4个时，如a、b、c、d，可能有{{a}{b,c,d}}、{{b}{a,c,d}}、{{c}{a,b,d}}、{{d}{a,b,c}}、{{a,b}{c,d}}、{{a,c}{b,d}}、{{a,d}{b,c}}这7种。同时，如果没有把特征 \(A\) 的取值完全分开，后面我们还有机会在子节点继续选择到特征 \(A\) 来划分子结点。这和ID3或者C4.5不同，在ID3或者C4.5的一棵子树中，离散特征只会参与一次节点的建立。</p>

<h4 id="toc_5">回归树的生成</h4>

<p><b>输入</b>：数据集 \(D={(x_1,y_1),(x_2,y_2),...(x_n,y_n)}\)<br/>
<b>输出</b>：CART决策树<br/>
<b>算法过程</b>：<br/>
一个回归树对应着输入空间的（特征空间）一个划分以及在划分的单元的输出值。假设已将输入空间划分为M个单元 \(R_1,R_2,...,R_M\)，并且在每一个单元 \(R_M\) 上有一个固定的输出值 \(c_m\)，于是回归树模型可表示为：<br/>
\[<br/>
f(x) = \sum_{i=1}^M c_m I(x\in R_m)<br/>
\]</p>

<p>当输入空间的划分确定时，可以用平方误差 \(\sum_{x_i\in R_m}(y_i-f(x_i))^2\) 来表示回归树对于训练数据的预测误差，用平方误差最小的准则求解每一个单元上的最优输出值。易知，单元 \(R_m\) 上的 \(c_m\) 的最优值 \(\hat c_m\) 是 \(R_m\) 上所有的输入实例 \(x_i\) 对应的输出 \(y_i\) 的均值，即：<br/>
\[<br/>
\hat c_m = ave(y_i|x_i \in R_m)<br/>
\]</p>

<p>特征选择时选择第 \(j\) 个变量 \(x^{j}\) 和它的取值 \(s\) ，作为切分变量和切分点，并定义两个区域：<br/>
\[<br/>
R_1(j,s) = \{x|x^j \le s\} \quad\quad R_2(j,s) = \{x|x^j \gt s\}<br/>
\]</p>

<p>其中定义两个区域的 \(y_i\) 均值：<br/>
\[<br/>
c_1 = ave(y_i|x\in R_1(j,s) \qquad c_2 = ave(y_i|x\in R_2(j,s))<br/>
\]</p>

<p>然后在所有可能特征的最优切分点上寻找最优切分变量和最优切分点，具体地，求解：<br/>
\[<br/>
\min_{j,s} [\min_{c_1} \sum_{x_i\in R_1(j,s)} (y_i-c_1)^2 + \min_{c_2}\sum_{x_i \in R_2(j,s)}(y_i-c2)^2]<br/>
\]</p>

<p>遍历所有输入变量，找到最优的切分变量 \(j\)，构成一个对\((j,s)\)，依次将输入空间划分为两个区域，接着对每一个区域重复上述过程生成一棵回归树，这样的回归树通常被称为最小二乘回归树。</p>

<h5 id="toc_6">举例说明</h5>

<p>假设考虑如下只有一个属性 \(x\) 的数据集 D：</p>

<table>
<thead>
<tr>
<th>x</th>
<th>1</th>
<th style="text-align: left">2</th>
<th style="text-align: left">3</th>
<th style="text-align: left">4</th>
<th style="text-align: left">5</th>
<th style="text-align: left">6</th>
<th style="text-align: left">7</th>
<th style="text-align: left">8</th>
<th style="text-align: left">9</th>
<th style="text-align: left">10</th>
</tr>
</thead>

<tbody>
<tr>
<td>y</td>
<td>5.56</td>
<td style="text-align: left">5.75</td>
<td style="text-align: left">5.91</td>
<td style="text-align: left">6.4</td>
<td style="text-align: left">6.8</td>
<td style="text-align: left">7.05</td>
<td style="text-align: left">8.9</td>
<td style="text-align: left">8.7</td>
<td style="text-align: left">9</td>
<td style="text-align: left">9.05</td>
</tr>
</tbody>
</table>

<p>这里我们不失一般性的考虑9个切分点：1.5 , 2.5 , 3.5 , 4.5 , 5.5 , 6.5 , 7.5 , 8.5 , 9.5 。因为数据集中只有一个属性 \(x\) ，选择属性 \(x\) 所有可能的切分点将数据集分成两部份。当 \(s=1.5\) 时：<br/>
\[<br/>
\begin{align*}<br/>
R_1(j=x,s=1.5) &amp;= \{x|x \le 1.5\} = \{1\}\\<br/>
R_2(j=x,s=1.5) &amp;= \{x|x \gt 1.5\} = \{2,3,4,5,6,7,8,9,10\} <br/>
\end{align*}<br/>
\]</p>

<p>这个区域的输出值为对应区域所有对象 \(y\) 的均值：<br/>
\[<br/>
\begin{align*}<br/>
c_1 &amp;= 5.56\\<br/>
c_2 &amp;= ave(y_i|x \in R_2(j=x,s=1.5) = \frac 1 9(5.75 + 5.91 + 6.4 + 6.8 + 7.05 + 8.9 + 8.7 + 9 + 9.05 ) = 7.50<br/>
\end{align*}<br/>
\]</p>

<p>在两个区域上分别用  \(\sum_{x_i\in R_m}(y_i-f(x_i))^2\) 计算平方误差：<br/>
\[<br/>
\begin{align*}<br/>
\text{Loss}(R_1) &amp;= 0\\<br/>
\text{Loss}(R_2) &amp;= \sum_{x_i\in R_2}(y_i-f(x_i)) = (5.75-7.5)^2+(5.91-7.5)^2+(6.4-7.5)^2+(6.8-7.5)^2+(7.05-7.5)^2\\<br/>
&amp;+(8.9-7.5)^2+(8.7-7.5)^2+(9-7.5)^2+(9.05-7.5)^2 = 15.545\\<br/>
\text{Loss}(s=1.5) &amp;= \text{Loss}(R_1) + \text{Loss}(R_2) = 15.545<br/>
\end{align*}<br/>
\]</p>

<p>同理可以计算出 \(x\) 的其他分割点 \(s\) 的均方误差：\(\text{Loss}(s=2.5)=12.07\)...，如果有多个属性值，用同样的方式再求出其他属性值不同切分点的均方误差。从中选出最小的均方误差对应的属性值和切分点就是最优切分变量和最优切分点。</p>

<h3 id="toc_7">CART剪枝</h3>

<p>CART剪枝算法就是在完整的决策树上，剪掉一些子树，使决策树变小。对CART的剪枝可以通过代价复杂度算法（Cost-Complexity Pruning，CCP）来进行：</p>

<p>在剪枝过程中，计算子树的损失函数：<br/>
\[<br/>
C_\alpha (T) = C(T) + \alpha|T|<br/>
\]</p>

<p>其中，\(T\) 为任意子树，\(C(T)\) 为训练数据的预测误差（后面讲具体计算过程），\(|T|\) 为子树的叶节点个数，\(\alpha \ge 0\) 为参数，正则化项。\(C_\alpha (T)\) 为参数是 \(\alpha\) 是子树 T 的整体损失，参数 \(\alpha\) 用来平衡训练数据的拟合程度和模型的复杂度。</p>

<p>对于固定的 \(\alpha\) ，一定存在使损失函数 \(C_\alpha(T)\) 最小的子树，将其表示为 \(T_\alpha\)，当 \(|T|\) 越大时，模型复杂度越高，对训练数据的拟合越好，反之 \(|T|\) 越小时，模型复杂度越小，但是对训练数据的拟合也不好。当 \(\alpha\) 越大，越倾向于一个复杂度较小的树。当 \(\alpha=0\) 时，不考虑模型复杂度，未剪枝的决策树对训练数据效果最好。</p>

<p>Breiman 等人证明：可以用递归的方法对树进行剪枝，将 \(\alpha\) 从小增大，\(0=\alpha_0&lt;\alpha_1&lt;\alpha_2&lt;...&lt;\alpha_n&lt;+\infty\)，产生一系列的区间 \([\alpha_i,\alpha_{i+1}]，i=0,1,...,n\)；剪枝得到的子树序列对应着区间 \(\alpha\in[\alpha_i,\alpha_{i+1}]，i=0,1,...,n\) 的最优子树序列 \(\{T_0,T_1,...,T_n]\)，序列中的子树是嵌套的。</p>

<p>从整体树 \(T_0\) 开始剪枝，对 \(T_0\) 的任意内部结点 \(t\)，以 \(t\) 为单结点树的损失函数是：<br/>
\[<br/>
C_\alpha(t) = C(t) + \alpha<br/>
\]</p>

<blockquote>
<p>其中：<br/>
\[<br/>
C(t) = p(t) r(t)<br/>
\]</p>

<p>这里 \(p(t)\) 表示结点在总样本中所占的比例，\(r(t)\) 表示该结点的误差代价（分错的结点的比例，结点中类比较多的实例为正确实例）。</p>
</blockquote>

<p>以 \(t\) 为根结点的子树 \(T_t\) 的损失函数为：<br/>
\[<br/>
C_\alpha(T_t) = C(T_t) + \alpha|T_t|<br/>
\]</p>

<blockquote>
<p>其中：<br/>
\[<br/>
C(T_t) = \sum_i^m p(t_i)r(t_i) <br/>
\]</p>

<p>这里 \(p(t_i)\) 表示每一个叶结点在总样本中所占的比例，\(r(t)\) 表示该叶结点的误差代价。</p>
</blockquote>

<p>当 \(\alpha=0\) 及 \(\alpha\) 足够小时，有不等式<br/>
\[<br/>
\begin{equation}<br/>
C_\alpha(T_t) &lt; C_\alpha(t) \label{ca}<br/>
\end{equation}<br/>
\]</p>

<p>当 \(\alpha\) 增大时，在某一 \(\alpha\) 有：<br/>
\[<br/>
\begin{align*}<br/>
&amp;C_\alpha(T_t) = C_\alpha(t)\\<br/>
&amp;\Rightarrow C(T_t) + \alpha|T_t| = C_\alpha(t)\\<br/>
&amp;\Rightarrow \alpha = \frac{C_\alpha(t) - C_\alpha(T_t)}{|T_t|-1}<br/>
\end{align*}<br/>
\]</p>

<p>当 \(\alpha\) 再增大时，不等式 \ref{ca} 反向。只要 \(\alpha=\frac{C(t)-C(T_t)}{|T_t|-1}\) ，\(T_t\) 与 \(t\) 有相同的损失函数值，而 \(t\) 的结点少，因此 \(t\) 比 \(T_t\) 更可取，对 \(T_t\) 进行剪枝。</p>

<p>为此，对 \(T_0\) 中每一内部结点 \(t\)，计算：<br/>
\[<br/>
g(t) = \frac{C(t) - C(T_t)}{|T_t|-1}<br/>
\]</p>

<p>它表示剪枝后整体损失函数减少的程度。在 \(T_0\) 中剪去 \(g(t)\) 最小的 \(T_t\)，将得到的子树称为 \(T_1\)，同时将最小的 \(g(t)\) 设为 \(\alpha_i\)，\(T_i\) 为区间\([\alpha_i,\alpha_2)\) 的最优子树。</p>

<p>如此剪枝下去，自下而上直至得到根结点。在这一过程中，不断地增加 \(\alpha\) 的值，产生新的区间。在剪枝得到的子树序列 \(T_0\),\(T_1\),...,\(T_n\) 中通过交叉验证选取最优子树 \(T_\alpha\)。在子树序列中，每棵子树 \(T_1\),\(T_2\),...,\(T_n\) 都对应于一个参数 \(\alpha_1\),\(\alpha_2\),...,\(\alpha_n\)。所以当最优子树 \(T_k\) 确定时，对应的 \(\alpha_k\) 也确定了，即得到最优决策树 \(T_\alpha\)。</p>

<h5 id="toc_8">举例说明</h5>

<p>如下这棵树：</p>

<div align="center">
    <img width="400" src="media/15145527362267/15325307805907.jpg" />
</div>

<p>一开始时 \(\alpha_0=0\) ，以结点 Node1 的损失函数为：<br/>
\[<br/>
C(t) = p(t)r(t) = \frac{18}{40}*\frac{8}{18} = \frac 1 5\\<br/>
C(T_t) = \frac 3 {40} *\frac 1 3 +\frac 9 {40}*\frac 4 9  + \frac 6 {40} *\frac 1 6= \frac{6}{40}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
g(t)=\frac{C(t)-C(T_t)}{|T_t|-1} = \frac{1}{2}*(\frac 1 5-\frac 6 {40}) = \frac{1}{40}<br/>
\]</p>

<p>以结点 Node2 的损失函数为：<br/>
\[<br/>
C(t) = p(t)r(t) = \frac{15}{40}*\frac{6}{15} = \frac 6 {40}\\<br/>
C(T_t) = \frac 9 {40}*\frac 4 9  + \frac 6 {40} *\frac 1 6= \frac{5}{40}<br/>
\]</p>

<p>计算：<br/>
\[<br/>
g(t) =\frac{C(t)-C(T_t)}{|T_t|-1} = \frac 6 {40}-\frac 5 {40} = \frac{1}{40}<br/>
\]</p>

<p>所以这个g(t)相同，选择 \(|T_t|\) 最大的进行剪枝（在和训练集误差相等的情况下选择模型复杂度较低的决策树，所以剪掉 \(|T_t|\) 较大的枝。这里也就是选择 Node1 进行剪枝得到子树 \(T_1\)，同时将最小的 g(t) 设为 \(\alpha_1\) ，\(T_1\)  为区间 \([\alpha_1,\alpha_2)\) 的最优子树。</p>

<p>继续剪枝，直到得到根结点为止，这个过程中不断增加 \(\alpha\) 的值产生新的区间。 </p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15139484052551.html">基于层次的聚类算法-凝聚法-BIRCH算法</a></h1>
			<p class="meta"><time datetime="2017-12-22T21:13:25+08:00" 
			pubdate data-updated="true">2017/12/22</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>BIRCH算法是一种凝聚层次聚类算法，它的全称是Balanced Iterative Reducing And Clustering Using Hierarchies，中文名也就是利用层次方法的平衡迭代规约和聚类。在大多数情况下，BIRCH可以只扫描一次数据集就可以完成聚类，这也使它可以在数据挖掘算法中处理大数据。BIRCH的作者声明BIRCH算法是数据领域第一个可以有效处理噪音的聚类算法。</p>

<p>BIRCH算法通过构建一个CF（Clustering Feature）树来实现，首先来介绍一下CF和CF树</p>

<h3 id="toc_0">CF（聚类特征）</h3>

<p>CF(Clustering Feature 聚类特征)，当给定一个N个d维的数据 \(X_1,X_2,...X_N\)，CF可以被定义成一个元组，即 \(\overrightarrow {CF}=(N,\overrightarrow{LS},\overrightarrow{SS})\) ，其中N表示元素的个数，\(\overrightarrow{LS}=\sum_{i=1}^N \overrightarrow X_{i}\)，它是所有元素各维度上的线性和，\(\overrightarrow{SS}=\sum_{i=1}^N (\overrightarrow X_{i})^2\)是所有数据点各维度上的平方和。</p>

<p>通过一个简单例子来说明：例设一个数据集有3个数据点 (2,5) 、 (3,2) 和 (4,1) ，那么此时<br/>
\[<br/>
N=3\\<br/>
\overrightarrow{LS}=(2+3+4,5+2+1)=(9,8)\\<br/>
\overrightarrow{SS}=(2^2+3^2+4^2,5^2+2^2+1^2)=(29,30)<br/>
\]</p>

<p>使用CF元组的好处在于，很多性质都可以通过这三个特征来表示，比如：<br/>
簇中心：<br/>
\[<br/>
\begin{align*}<br/>
    \overrightarrow C&amp;=\frac{\sum_{i=1}^N \overrightarrow X_i}{N}\\<br/>
    &amp;=\frac {\overrightarrow{LS}}{N}<br/>
\end{align*}<br/>
\]</p>

<p>簇半径：<br/>
\[<br/>
\begin{align*}<br/>
R&amp;=\sqrt{\frac{\sum_{i=1}^{N} (\overrightarrow C-\overrightarrow X_i)^2}{N}}\\<br/>
&amp;=\sqrt{\frac{\sum_{i=1}^N (\overrightarrow C^2+\overrightarrow X_i^2-2\overrightarrow X_0\overrightarrow X_i)}{N}}\\<br/>
&amp;=\sqrt{\frac{N\overrightarrow C^2+\overrightarrow{SS}+2\overrightarrow C\overrightarrow{LS}}{N}}<br/>
\end{align*}<br/>
\]<br/>
簇直径：<br/>
\[<br/>
\begin{align*}<br/>
D&amp;=\sqrt{\frac{\sum_{i}^N \sum_{j}^N (\overrightarrow{X_i}-\overrightarrow{X_j})^2}{N(N-1)}} \\<br/>
&amp;=\sqrt{\frac{\sum_{i}^N \sum_i^N(\overrightarrow{X_i}^2+\overrightarrow{X_j}^2-2\overrightarrow X_i \overrightarrow X_j)}{N(N-1)}} \\<br/>
&amp;=\sqrt{\frac{\sum_i^N(N\overrightarrow X_i^2+\overrightarrow{SS}-2\overrightarrow X_i \overrightarrow{LS})}{N(N-1)}}\\<br/>
&amp;=\sqrt{\frac{N\sum_i^N(\overrightarrow X_i^2)+N\overrightarrow{SS}-2\overrightarrow{LS}\sum_i{\overrightarrow X_i})}{N(N-1)}}\\<br/>
&amp;=\sqrt{\frac{N\overrightarrow{SS}+N\overrightarrow{SS}-2\overrightarrow{LS}\overrightarrow{LS}}{N(N-1)}}\\<br/>
&amp;=\sqrt{\frac{2N\overrightarrow{SS}-2\overrightarrow{LS}^2}{N(N-1)}}<br/>
\end{align*}<br/>
\]<br/>
假设\(CF_1=(N_1,LS_1,SS_1)\)，\(CF_2=(N_2,LS_2,SS_2)\)，它们的欧几里得距离为</p>

<p>\[<br/>
\begin{align*}<br/>
D&amp;=\sqrt{\frac{\sum_i^{N_1}\sum_j^{N_2}(\overrightarrow{X_i}-\overrightarrow{X_j})^2}{N_1N_2}}\\<br/>
&amp;=\sqrt{\frac{\sum_i^{N_1}\sum_j^{N_2}(\overrightarrow X_i^2+\overrightarrow X_j^2-2\overrightarrow X_i\overrightarrow X_j)}{N_1N_2}}\\<br/>
&amp;=\sqrt{\frac{\sum_i^{N_1}(N_2\overrightarrow X_i^2+\overrightarrow{SS_2}-2\overrightarrow{LS_2}X_i)}{N_1N_2}}\\<br/>
&amp;=\sqrt{\frac{N_2\overrightarrow{SS_1}+N_1\overrightarrow{SS_2}-2\overrightarrow{LS_2}\overrightarrow{LS_1}}{N_1N_2}}<br/>
\end{align*}<br/>
\]</p>

<p>由上面公式可以看出，如果集群用CF元组来表示，则集群间的很多性质都可以用这个对应的CF元组来进行计算。</p>

<h3 id="toc_1">CF树</h3>

<p>CF树类似于B树，是由CF元组成的树形结构，如下图：</p>

<div align=center>
<img width="350px" src="media/15139484052551/15255635948989.jpg" />
</div>

<p>易知：<br/>
\[<br/>
\begin{align*}<br/>
N_1 &amp;= N_2+N_3\\<br/>
LS_1 &amp;= LS_2+LS_3\\<br/>
SS_1 &amp;= SS_2+SS_3<br/>
\end{align*}<br/>
\]</p>

<p>CF树的内存结构如下图所示，CF树的顶层节点称为根节点（Root Node），最下面一层节点称为叶结点（Leaf Node），中间层为枝结点（Branch Node），其中根节点和枝结点都是由CF元组和child组成，child指向枝结点的位置。而叶结点还有两个特殊的空间prev和next，用来指向前一个叶结点和后一个叶结点。<br/>
<div align=center><br/>
    <img width="550px" src="media/15139484052551/15255835588796.jpg" /><br/>
</div><br/>
在CF树中有几个比较重要的参数需要注意：枝平衡因子\(\beta\)（Branch factor）、叶平衡因子\(\gamma\)（Leaf factor）和空间阈值\(\tau\)（threshold），\(\beta\)表示非叶节点的存储的<CF,Child>元组（entry）的个数不能超过的数量，也就是限制非叶节点的子节点数目，同理\(\gamma\)表示叶节点存储的CF元组的最大个数，也就是限制叶节点的子节点数目。\(\tau\)限制的是簇直径的阈值，既限制簇的紧密程度。上图是在\(\beta=2\)，\(\gamma=3\)的情况下绘制的。</p>

<h3 id="toc_2">CF树的构造</h3>

<p><b>输入</b>：数据集 D，值枝平衡因子\(\beta\)，叶平衡因子\(\gamma\)和空间阈值\(\tau\)<br/>
<b>输出</b>：CF 树<br/>
<b>算法过程</b>：</p>

<ol>
<li><b>初始化</b>：定义一个空的叶节点 leafNode；定义一个叶节点头节点 leafNodeHead，leafNodeHead的 next 指向 leafNode， leafNode 的 prev 指向 leafNodeHead。定义一个根节点 root 指向 leafNode；</li>
<li>循环所有数据集，当循环到样本点 X 时，建立CF元组，再定义包含该CF元组的 minCluster ；</li>
<li>向根节点插入 minCluster，如果根节点是叶节点，执行步骤4；否则执行步骤6；</li>
<li><b>叶节点的插入minCluster</b>：如果被插入的叶节点的 children 为空，直接向 children 中添加一个mincluster；否则找到该叶节点的 children 中距离 minCluster 最近的节点，如上图假设找到的是节点4，判断节点4插入minCluster的CF元组后的直径，如果该直径小于空间阈值 \(\tau\)，向节点4中插入minCluster的CF元组；如果该直径大于空间阈值 \(\tau\)，则向叶结点的children 中插入一个新的节点。插入后判断叶节点的children长度是否大于叶平衡因子 \(\gamma\)，如果大于 \(\gamma\)，需要进行步骤5叶节点的分裂；插入minCluster 之后要一层层更新父结点的CF元组；</li>
<li><b>叶节点的分裂</b>：假设要分裂的叶节点为 leaf，先找到 leaf 的children 中距离最远的两个孩子 cf1 和 cf2，定义一个新的叶节点 newLeaf ，将cf1 放入newLeaf 的children 中，定义一个枝节点 nonLeaf，nonLeaf 的父结点指向 leaf 的父结点，将 leaf 和 newLeaf 都放入 nonLeaf 的children 中，且 leaf 与 newLeaf 的父结点都指向 nonLeaf ，然后循环 leaf 的所有children，将其中与 cf1 的距离小于与 cf2 的距离的CF元组从 leaf 的children中删除，加入 newLeaf 的children中。分裂完成后，将 nonLeaf 插入nonLeaf 父节点的 children 中，并判断nonLeaf的父结点的 children 在插入了 nonLeaf 后是否超出枝平衡因子 \(\beta\)，如果超过执行步骤7进行枝节点分裂；</li>
<li><b>枝节点的插入</b>：循环枝节点的所有children，找到与minCluster 最近的孩纸，如果该孩子是枝节点，则向该枝节点孩子继续执行步骤6；如果该孩子是叶节点，执行步骤4；</li>
<li><b>枝节点的分裂</b>：假设要分裂的枝节点为nonLeaf，先找到 nonLeaf 的children中相距最近的两个孩子 leaf1 和 leaf2，定义一个新的枝节点newNonLeaf，向 newNonLeaf 的children 中加入leaf1，定义一个新的枝节点 parentNonLeaf，parentNonLeaf 的父节点指向nonLeaf的父结点，将 newNonLeaf 和 nonLeaf 都加入parnetNonLeaf 中，且 newNonLeaf 和 nonLeaf 的父结点都指向 parentNonLeaf；循环 nonLeaf 的所有children，将与 leaf1 的距离小于与 leaf2 的距离的孩子从 nonLeaf 的 children 中删除，加入newNonLef 的children中；分裂完成后，将 parentNonLeaf 插入它父节点的 children 中，并判断插入后是否超过枝平衡因子 \(\beta\)，如果超过执行步骤7进行枝节点分裂；</li>
<li><b>根节点更新</b>步骤3执行完成后，此时root已经不在是根节点，要递归找到父结点，令root等于parent等于空的节点，此时完成root的更新。</li>
</ol>

<h3 id="toc_3">代码实例</h3>

<pre><code>#coding=utf-8
import os
import sys
import numpy as np
import math

class MinCluster(object):
    def __init__(self):
        self.cf = None
        self.inst_marks = []

    @staticmethod
    def getDiameter(cluster1, cluster2):
        cf = CF.clone(cluster1.cf)
        cf.addCF(cluster2.cf,True)
        diameter = 0.0
        for i in range(len(cf.LS)):
            diameter += 2*cf.N*cf.SS[i]-2*cf.LS[i]
        diameter = diameter/(cf.N*cf.N-cf.N)
        return math.sqrt(diameter)

class CF(object):
    def __init__(self,data=None):
        if data is not None:
            self.N = 1
            self.LS = data
            self.SS = np.zeros_like(data)
            for i in range(self.LS.size):
                self.SS[i] = math.pow(self.LS[i],2)
        else:
            self.N = 0
            self.LS = np.zeros(BIRCH.dimen)
            self.SS = np.zeros(BIRCH.dimen)

    #UPGMA的变体
    def getDistanceTo(self, cf):
        dis = 0.0
        for i in range(len(cf.LS)):
            dis += self.SS[i] / self.N + cf.SS[i] / cf.N - 2 * self.LS[i] * cf.LS[i] / (cf.N * self.N)
        return math.sqrt(dis)

    def addCF(self,cf, add):
        if add:
            self.N += cf.N
            for i in range(len(self.LS)):
                self.LS[i] += cf.LS[i]
                self.SS[i] += cf.SS[i]
        else:
            self.N -= cf.N
            for i in range(len(self.LS)):
                self.LS[i] -= cf.LS[i]
                self.SS[i] -= cf.SS[i]

    @staticmethod
    def clone(cf):
        new_cf = CF()
        new_cf.N = cf.N
        for i in range(len(cf.LS)):
            new_cf.LS[i] = cf.LS[i]
            new_cf.SS[i] = cf.SS[i]
        return new_cf

class TreeNode(CF):
    def __init__(self):
        CF.__init__(self)
        self.parent = None
        self.children = []

    def addChild(self, cluster):
        self.children.append(cluster)

    def split(self):
        pass

    def absorbSubCluster(self, cluster):
        pass

# 定义一个叶节点
class LeafNode(TreeNode):

    def __init__(self):
        TreeNode.__init__(self)
        self.L = 10
        self.T = 2.8
        self.prev = None
        self.next = None

    def absorbSubCluster(self, cluster):
        # 找到叶节点的孩子中与cluster最近的簇
        cf = cluster.cf
        nearIndex = 0
        minDist = sys.maxsize
        child_len = len(self.children)
        if child_len &gt; 0:
            for i in range(child_len):
                dist = cf.getDistanceTo(self.children[i].cf)
                if dist &lt; minDist:
                    nearIndex = i
            # 计算两个簇合并之后的直径
            mergeDiameter = MinCluster.getDiameter(self.children[i],cluster)
            if mergeDiameter &gt; self.T:
                # 那么将cluster作为一个单路的子结点插入叶结点下
                self.addChild(cluster)
                if len(self.children) &gt; self.L:
                    self.split()
            else:
                self.children[nearIndex].mergeCluster(cluster)
        else:
            self.addChild(cluster)
        self.addCFUpToRoot(cluster.cf)

    def split(self):
        # 找到距离最远的两个结点
        c1 = -1
        c2 = -1
        maxDist = 0
        for i in range(len(self.children) - 1):
            for j in range(i + 1, len(self.children)):
                dist = self.children[i].cf.getDistanceTo(self.children[j].cf)
                if dist &gt; maxDist:
                    maxDist = dist
                    c1 = i
                    c2 = j
        # 以这两个孩子为中心，分成两个簇
        newLeafNode = LeafNode()  # 新建一个簇存放领养新结点
        newLeafNode.children.append(self.children[c2])
        # 如果本结点已经是根结点，创建一个结点领养新结点
        if self.parent is None:
            nonLeafNode = NonLeafNode()
            nonLeafNode.N = self.N
            nonLeafNode.LS = self.LS.copy()
            nonLeafNode.SS = self.SS.copy()
            self.parent = nonLeafNode
            nonLeafNode.addChild(self)
        # 根结点领养新结点
        newLeafNode.parent = self.parent
        self.parent.addChild(newLeafNode)

        for i in range(len(self.children)):
            if i != c1 and i != c2:
                dist1 = self.children[i].cf.getDistanceTo(self.children[c1].cf)
                dist2 = self.children[i].cf.getDistanceTo(self.children[c2].cf)
                if dist1 &gt; dist2:
                    newLeafNode.addChild(self.children[i])
        for child in newLeafNode.children:
            newLeafNode.addCF(child.cf, True)
            self.children.remove(child)
            self.addCF(child.cf, False)
        # 把新增加的leafNode加入双向列表
        if self.next is not None:
            newLeafNode.next = self.next
            newLeafNode.next.prev = newLeafNode
        self.next = newLeafNode
        newLeafNode.prev = self
        # 结点分裂是否导致枝结点也需要分裂

        nonLeafNode = self.parent
        if len(nonLeafNode.children) &gt; nonLeafNode.B:
            nonLeafNode.split()

    def addCFUpToRoot(self, cf):
        leaf = self
        while leaf is not None:
            leaf.addCF(cf,True)
            leaf = leaf.parent


class NonLeafNode(TreeNode):
    def __init__(self):
        TreeNode.__init__(self)
        self.B = 5

    def absorbSubCluster(self, cluster):
        cf = cluster.cf
        nearIndex = 0
        minDist = sys.maxsize
        child_len = len(self.children)
        for i in range(child_len):
            dist = cf.getDistanceTo(self.children[i])
            if dist &lt; minDist:
                nearIndex = i
        self.children[nearIndex].absorbSubCluster(cluster)

    def split(self):
        # 找到距离最远的两个结点
        c1 = -1
        c2 = -1
        maxDist = 0
        for i in range(len(self.children) - 1):
            for j in range(i + 1, len(self.children)):
                dist = self.children[i].getDistanceTo(self.children[j])
                if dist &gt; maxDist:
                    maxDist = dist
                    c1 = i
                    c2 = j
        # 以这两个孩子为中心，分成两个簇
        newLeafNode = NonLeafNode()  # 新建一个簇存放领养新结点
        newLeafNode.children.append(self.children[c2])
        # 如果本结点已经是根结点，创建一个结点领养新结点
        if self.parent is None:
            nonLeafNode = NonLeafNode()
            nonLeafNode.N = self.N
            nonLeafNode.LS = self.LS.copy()
            nonLeafNode.SS = self.SS.copy()
            self.parent = nonLeafNode
            nonLeafNode.addChild(self)
        # 根结点领养新结点
        newLeafNode.parent = self.parent
        self.parent.addChild(newLeafNode)

        for i in range(len(self.children)):
            if i != c1 and i != c2:
                dist1 = self.children[i].getDistanceTo(self.children[c1])
                dist2 = self.children[i].getDistanceTo(self.children[c2])
                if dist1 &gt; dist2:
                    newLeafNode.addChild(self.children[i])
        for child in newLeafNode.children:
            newLeafNode.addCF(child, True)
            self.children.remove(child)
            self.addCF(child, False)
        # 结点分裂是否导致枝结点也需要分裂
        nonLeafNode = self.parent
        if len(nonLeafNode.children) &gt; nonLeafNode.B:
            nonLeafNode.split()

class BIRCH(object):
    dimen = 4
    def __init__(self):
        self.dimen = BIRCH.dimen # 数据点的维度
        self.leafNodeHead = LeafNode() # 叶节点的头
        self.point_num = 0 # 数据点个数

    def buildTree(self, fileName):
        leaf = LeafNode()
        root = leaf
        self.leafNodeHead.next = leaf
        leaf.prev = self.leafNodeHead
        # 判断是否存在
        if not os.path.exists(fileName):
            print(&quot;Data File Not Exists&quot;)
            return
        # 读取文件
        with open(fileName) as fr:
            for line in fr.readlines():
                self.point_num +=1
                data = np.zeros([self.dimen],np.float64)
                lineAttr = line.strip().split(&quot;\t&quot;)
                for i in range(data.size):
                    data[i] = lineAttr[i]
                # 处理数据
                mark = str(self.point_num) + lineAttr[data.size]
                # 根据一个point创建一个minCluster
                cf = CF(data)
                subCluster = MinCluster()
                subCluster.cf = cf
                subCluster.inst_marks.append(mark)
                # 把新的point插到树中
                root.absorbSubCluster(subCluster)
                while root.parent is not None:
                    root = root.parent
        return root

if __name__ == &#39;__main__&#39;:
    birch = BIRCH()
    root = birch.buildTree(&quot;iris.txt&quot;)
    print(root)
</code></pre>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15134035483527.html">基于层次的聚类算法-分裂法-BiKMeans算法与DIANA算法</a></h1>
			<p class="meta"><time datetime="2017-12-16T13:52:28+08:00" 
			pubdate data-updated="true">2017/12/16</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>BiKMeans算法与DIANA算法是两种典型的分裂式基于层次的聚类算法，在介绍算法之前，先了解一下基于层次聚类算法。</p>

<h3 id="toc_0">基于层次聚类算法</h3>

<p>在数据挖掘（data mining）和统计学（statistics）中，层次聚类（Hierarchical clustering)是聚类分析的一种方法。层次化聚类的策略通常分为两种：<br/>
    <strong>凝聚法（Agglomerative)</strong>：这是一种自下向上的方式，开始时把每一个元素当作一个单个的簇，在沿着层次结构向上移动过程中，合并成对的簇。<br/>
    <strong>分裂法（Divisive)</strong>：这是一种自上向下的方式，开始时将所有所有元素当成一个簇，在沿着层次结构向下移动过程中，递归的进行分裂操作。<br/>
    通常，合并和分裂在决定过程中都是用贪心的方式。层次化聚类的结果通常表现为系统树状图（<em>dendrogram</em>）的形式。</p>

<p>在大多数的层次聚类方法中，为了决定哪些簇应该被合并（凝聚法）或者两个簇应该被分裂（分裂法），我们需要来度量观察集合之间的不相似度，这可以通过选择一个合适的度量标准和链接标准来实现。</p>

<h4 id="toc_1">度量标准（Metric）</h4>

<p>选择一个合适的度量标准将会影响集群的形状。一些元素可能会在某个度量标准下距离很近，在另一个度量标准下距离会很远，例如在二维空间里，(1,0)和(0,0)两个点在通常标准下它们的距离总是1，但是(1,1)和(0,0)两个点它们的曼哈顿距离（Manhattan distance）是2，但是欧几里得距离（Euclidean distance）是\(\sqrt {2}\)，最大距离（Maximum distance）是1。</p>

<p>下面是一些在层次聚类中通常使用的度量标准：</p>

<table>
<thead>
<tr>
<th>名称</th>
<th>公式</th>
</tr>
</thead>

<tbody>
<tr>
<td>欧几里得距离（Euclidean distance）</td>
<td>\(\|a-b\|_{2}=\sqrt{\sum_{i}(a_{i}-b_{i})^{2}}\)</td>
</tr>
<tr>
<td>平方欧几里得距离（Squared Euclidean distance）</td>
<td>\(\|a-b\|_{2}=\sum_{i}(a-b)^{2}\)</td>
</tr>
<tr>
<td>曼哈顿距离（Manhattan distance）</td>
<td>\(\|a-b\|_{1}=\sum_{i}\left\vert a_{i}-b_{i}\right\vert\)</td>
</tr>
<tr>
<td>最大距离（Maximum distance）</td>
<td>\(\|a-b\|_{\infty}=\max_{i}\left\vert a_{i}-b_{i}\right\vert\)</td>
</tr>
</tbody>
</table>

<p>对于一些文本或非数字类型的数据，通常使用海明距离（Hamming distance）或者编辑距离（Edit distance or Levenshtein distance）</p>

<h4 id="toc_2">连接标准（Linkage criteria)</h4>

<p>连接标准根据观察对象间成对的距离确定观察组之间的距离。两个观察对象A和B之间的常用的连接标准如下：</p>

<table>
<thead>
<tr>
<th>名称</th>
<th>英文名称</th>
<th>公式</th>
</tr>
</thead>

<tbody>
<tr>
<td>全连接聚类(最大连接)</td>
<td>Maximum or complete-linkage clustering</td>
<td>\(\max\,\{\,d(a,b):a \in A,\,b \in B\,\}\)</td>
</tr>
<tr>
<td>单连接聚类(最小连接)</td>
<td>Minimum or single-linkage clustering</td>
<td>\(\min\,\{\,d(a,b):a\in A,\,b\in B\,\}\)</td>
</tr>
<tr>
<td>平均连接聚类</td>
<td>Mean or average-linkage clustering or UPGMA</td>
<td>\(\frac{1}{\vert A \vert\vert B \vert}\sum_{a \in A}\sum_{b \in B}d(a,b)\)</td>
</tr>
<tr>
<td>质心连接聚类</td>
<td>Centroid-linkage clustering or UPGMC</td>
<td>\(\|c_{t}-c_{s}\|\) 这里\(c_{t}\)和\(c_{s}\)是各自集合的质心</td>
</tr>
</tbody>
</table>

<p>上面公式里的d函数就是前面介绍的度量标准（Metric），采用哪种距离计算函数。</p>

<h4 id="toc_3">凝聚聚类（自下而上）</h4>

<p>假设需要聚类一些数据，采用欧几里得距离（Euclidean distance）作为距离计算函数。<strong>用给定的高度来切割树将会得到给定精度的分区聚类</strong>。假设聚类产生的系统树状图如下：</p>

<div align=center>
    <img width=250 src="media/15134035483527/15253679953629.jpg" />
</div>

<p>如图若在系统树状图的第二行后面切割将会产生四个集群{a},{b,c},{d,e},{f}。</p>

<div align=center>
    <img width=250 src="media/15134035483527/15253682104508.jpg" />
</div>

<p>同理，如果在系统树状图的第三行后面切割则会产生三个集群 {a} , {b,c} , {d,e,f} 。这是一个更粗糙的聚类，但是集群的数量会更少，同时集群的大小会变大。</p>

<p>凝聚聚类是采用逐步合并集群的方式从单个的元素生成层次结构，在上面的例子中，有六个元素 {a} , {b} , {c} , {d}, {e} , {f} ，第一步是决定哪两个元素将被合并到一个集群。通常，我们依据距离选择两个距离最近的元素来合并。假设我们已经合并了两个最近的集群 {b} 和 {c} 得到一个新的集群 {b,c}，现在集群为 {a} , {b,c} , {e} , {f}，如果要进一步合并他们，我们需要计算 {a} 和 {b,c} 的距离，因此这里需要定义两个集群间的距离，距离计算时 {b,c} 中心点位置的选择就需要连接标准的制定。</p>

<p>当集群的数量足够的少的时候，可以决定来停止聚类。另外一些连接标准可以保证凝聚之后的集群间的距离比凝聚之前更远，当集群分离太远而不能进行合并时可以选择停止聚类。</p>

<h4 id="toc_4">分裂聚类（自上而下）</h4>

<p>分裂聚类算法开始时将所有元素当做一个簇。一个大的簇会被逐步分裂直到簇个数达到自定的大小，因为分裂一个大小为n的集群会存在 \(2^n\) 种方式，因此这里需要启发式分裂方法。关于分裂聚类的典型算法有Bisecting KMeans算法、DIANA算法，这里直接通过BiKMeans算法和DIANA算法来了解分裂聚类算法。</p>

<h3 id="toc_5">BiKMeans 算法</h3>

<p>BiKMeans（Bisecting KMeans、二分KMeans）是一种常见的分裂聚类算法，通过它名字便知道它与基于划分的聚类算法KMeans算法肯定关系很大，其实它是KMeans算法的改进版本。由于传统的KMeans算法的聚类结果易受到初始聚类中心点选择的影响，因此在传统的KMeans算法的基础上进行算法改进，一定程度上克服了算法陷入局部最优状态。</p>

<p>二分KMeans在分裂过程中以降低SSE（误差平方和）为目标。开始时将所有的对象作为一个簇，然后用KMeans方式（K=2）将簇一分为二；如果簇的大小小于指定给定大小，再在两个簇中选择能最大限度降低SSE的簇进行一分为二；以此进行下去，直到簇的数目等于用户给定的数目k为止。</p>

<h5 id="toc_6">算法步骤</h5>

<p><b>输入</b>：数据集 D ，簇个数 K<br/>
<b>输出</b>：聚类后的簇 \(C_1\),\(C_2\),...,\(C_K\)<br/>
<b>算法过程</b>：</p>

<pre><code>将所有数据点看成一个簇；
h=1；
当前簇的数目 h 小于 K 时：  
    对于每一个簇：  
        在该簇上进行KMeans聚类（k=2），分裂成两个簇 
        计算划分后的误差平方和 SSE
    比较 h 种划分的SSE值，选择SSE值最小的那种簇划分进行划分
    更新簇的分配结果
    添加新的“簇中心”
    簇的数目 h 加1
</code></pre>

<h3 id="toc_7">DIANA算法</h3>

<p>DIANA算法（DIvisive ANAlysis)算法是一种分裂式层次聚类算法，首先将所有的对象初始化到一个簇中，然后根据一些原则将该簇分裂，直到到达用户指定的簇数目或者两个簇之间的距离超过了某个阈值。</p>

<h5 id="toc_8">算法步骤</h5>

<p><b>输入</b>：数据集 D ，簇个数 K<br/>
<b>输出</b>：聚类后的簇 \(C_1\),\(C_2\),...,\(C_K\)<br/>
<b>算法过程</b>：</p>

<pre><code>将所有数据点看成一个簇；
h=1；
当前簇的数目 h 小于 K 时：
    在所有簇中找出具有最大直径的簇，在该簇上操作：
        找到簇中每一个点与其他点的平均距离；
        将平均距离最大的点放入splinter group 中，其他点放入old party中；
        循环 old party 中所有点：
            找到与 splinter group 中最近的点的距离不大于到old party中最近点的距离的点；
            将该点加入splinter group；
        spilnter group和old party为被选中的簇分裂成的2个簇与其它簇一起组成新的簇集合；
        簇的数目 h 加1
</code></pre>

<p>下面举例说明，假设二维空间八个元素，分布位置如下：</p>

<p>\[<br/>
\begin{array}{|c|c|c|}<br/>
\hline<br/>
\text{坐标点} &amp; \text{属性1} &amp; \text{属性2} \\<br/>
\hline<br/>
P_1 &amp; 1 &amp; 1 \\<br/>
P_2 &amp; 1 &amp; 2 \\<br/>
P_3 &amp; 2 &amp; 1 \\<br/>
P_4 &amp; 2 &amp; 2 \\<br/>
P_5 &amp; 3 &amp; 4 \\<br/>
P_6 &amp; 3 &amp; 5 \\<br/>
P_7 &amp; 4 &amp; 4 \\<br/>
P_8 &amp; 4 &amp; 5 \\<br/>
\hline<br/>
\end{array}<br/>
\]</p>

<ol>
<li><p>找出具有最大直径的集群，开始时指的就是所有集群。</p></li>
<li><p>在最大直径集群中，找到每个点与其他点的平均距离：<br/>
\(P_1\)与其他点平均距离为：<br/>
    \(\begin{align*}<br/>
    d(P_1)&amp;=(\sqrt{(1-1)^2+(2-1)^2}+\sqrt{(2-1)^2+(1-1)^2}+\dots+\sqrt{(4-1)^2+(5-1)^2})/7\\<br/>
    &amp;=(1+1+1.1414+3.6+4.24+4.47+5)/7\\<br/>
    &amp;=2.96<br/>
    \end{align*}\)<br/>
    同理：<br/>
\(d(P_2)=(1+1.414+1+2.828+3.6+3.6+4.24)/7=2.526\)<br/>
\(d(P_3)=(1+1.414+1+3.16+4.12+3.6+4.27)/7=2.68\)<br/>
\(d(P_4)=(1.414+1+1+2.24+3.16+2.828+3.6)/7=2.18\)<br/>
\(d(P_5)=2.18\)<br/>
\(d(P_6)=2.68\)<br/>
\(d(P_7)=2.526\)<br/>
\(d(P_8)=2.96\)   </p>

<p>在上面所有的距离中，\(P_1\) 与其他点的平均距离最远，放入 splinter group，其他点放入 old party 中，那么 splinter group={\(P_1\)}，old party={\(P_2\),\(P_3\),\(P_4\),\(P_5\),\(P_6\),\(P_7\),\(P_8\)}</p></li>
<li><p>找出 old party 中到 splinter group 最近的点的距离不大于到 old party 其他点最小距离的点，加入到 splinter group 中。</p>

<p>对于old party中的每一个点依次计算，首先计算点 \(P_2\) 到 splinter group 最近点的距离：\(P_2\) 到 splinter group 中点 \(P_1\) 的距离为1，因为 splinter group 中只有 \(P_1\) 一个点，所以 \(P_2\) 到 splinter group 中最近的点的距离为1；</p>

<p>计算\(P_2\) 到 old parter 中最近点的距离：\(P_2\) 到 old party 中点 \(P_3\) 的距离为1.1414；\(P_2\) 到 old party 中点 \(P_4\) 的距离为1; \(P_2\) 到 old party 中点 \(P_5\) 的距离为2.828；\(P_2\) 到 old party 中点 \(P_6\) 的距离为3.6；\(P_2\) 到 old party 中点 \(P_7\) 的距离为3.6；\(P_2\) 到 old party 中点 \(P_8\) 的距离为4.24；因此 \(P_2\) 到 old party 中最近的点 \(P_4\) 的距离是1；</p>

<p>满足<strong>到splinter group最近的点距离不大于到old party其他点最小距离</strong>的条件，因此将\(P_2\)加入splinter group中。此时splinter group={ \(P_1\) , \(P_2\) }，old party={ \(P_3\) , \(P_4\) , \(P_5\) , \(P_6\) , \(P_7\) , \(P_8\) }</p></li>
<li><p>重复步骤3，直到不存在这样的点结束，此时已经将最大的集群分成两个。如果此时集群的数量未达到终止条件，则继续重复步骤2，选择一个最大直径的集群进行分裂。</p></li>
</ol>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15129060526675.html">基于密度的聚类算法-Optics算法</a></h1>
			<p class="meta"><time datetime="2017-12-10T19:40:52+08:00" 
			pubdate data-updated="true">2017/12/10</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>前面我们介绍了一种基于密度的聚类算法DBSCAN，在缺点里提到 DBSCAN 算法对参数敏感，不同的 \(\epsilon\) 和 MinPts 会有不同结果，而这个参数是需要我们手动设置的。而 Optics算法在这一点上做出了改进，它对输入参数的设置不敏感。</p>

<h3 id="toc_0">算法介绍</h3>

<p>Optics算法的英文名称是Order Point To Identify the Clustering Structure。由于该算法是DBSCAN算法的改进，它们在很多概念上是公用的，比如直接密度可达、核心对象、密度相连等，除此之外Optics算法引入了独有的一些概念：</p>

<ul>
<li><p><b>核心距离(core-distance)</b><br/>
&emsp;&emsp;假设 p 是核心对象，那么使 p 满足阈值 MinPts 最小的半径 R，称之为核心距离。即核心对象 p 的 R-邻域内至少有 MinPts 个对象，而对于任意小于 R 的 R&#39;，核心对象 p 的 R&#39;-邻域内对象的数量都小于 MinPts。对于任意核心对象 p，有核心距离 \(\text{cd}(p) \le \epsilon\)。</p></li>
<li><p><b>可达距离(reachability-distance)</b><br/>
&emsp;&emsp;假设 p 是核心对象， q 对 p 的可达距离 \(\text{rd}(q|p)\) 为对象 p 到 q 的距离与 p 核心距离的较大值称为可达距离，即：<br/>
\[<br/>
rd(q|p) = \left \{\begin{array}\\<br/>
undifined &amp;\quad\quad \text{if}\quad |D_\epsilon(p)| \gt MinPts\\<br/>
max\{cd(p),\text{dist}(p,q)\} &amp;\quad\quad <br/>
\text{if}\quad |D_\epsilon(p)| \le MinPts<br/>
\end{array} \right .<br/>
\]</p>

<p>&emsp;&emsp;注意：一个点会有很多的可达距离，选取最小的可达距离，。</p></li>
</ul>

<h3 id="toc_1">算法步骤</h3>

<p><b>输入</b>：数据集合 D，参数\(\epsilon\) 和 MinPts<br/>
<b>输出</b>：数据集合 D 各元素的一个有序排列，包括核心距离和可达距离<br/>
<b>算法过程</b>：</p>

<pre><code>创建两个队列，有序队列 dpQue 和结果队列 dpList。
循环不在dpList中的对象：
    如果当前对象 dp 是核心对象；
        将 dp 加入有序队列 dpQue；
    如果有序队列 dpQue 非空：
        从 dpQue 中取出第一个元素 newDp，加入结果队列，并从 dpQue 中删除；
        如果该元素 newDp 是核心对象：
            循环 newDp 所有的直接密度可达对象：
                设该直接密度可达对象为 tempDp，可达距离为 tempDist;
                如果对象 tempDp 不在结果队列中：
                    如果对象 tempDp 不在有序队列 dpQue 中：
                        将对象 tempDp 加入 dpQue 中；
                    如果对象 tempDp 在有序队列 dpQue 中：
                        如果 dpQue 中已经存在的对象 tempDp 的可达距离大于tempDist:
                            更新 dpQue 中对象 tempDp 的可达距离为 tempDist；
            对 dpQue 队列按照可达距离重新排序；
</code></pre>

<p>该算法主要逻辑就是找出每一个对象最小的可达距离。关键点在于如果对象 p 是核心对象，对象 p 所有直接密度可达对象关于对象 p 的可达距离都与 p 的核心距离有关。所以循环对象 p 的所有直接密度可达对象，如果不在 dpQue 中需要插入，已经在 dpQue 中，要更新可达距离。</p>

<h5 id="toc_2">数据结构</h5>

<pre><code class="language-python">class DataPoint:
    def __init__(self,point,name):
        self.point = point
        self.name  = name

    # 获取数据点维度
    def getDimension(self):
        return len(self.point)

    # 定义深拷贝
    def copy(self):
        temp = DataPoint(self.point, self.name)
        temp.setReachableDistance(self.reachableDistance)
        return temp
        
    # 设置可达距离 
    def setReachableDistance(self,reachableDistance):
        self.reachableDistance = reachableDistance

    # 获取可达距离
    def getReachableDistance(self):
        return self.reachableDistance
    
    # 获取数据点名称
    def getName(self):
        return self.name
</code></pre>

<h5 id="toc_3">返回两个点的欧几里得距离</h5>

<pre><code class="language-python">def getDistance(dp1, dp2):
    distance = 0.0
    dim1 = dp1.getDimension()
    dim2 = dp2.getDimension()
    if dim1 == dim2:
        for i in range(dim1):
            temp = math.pow((dp1.point[i]-dp2.point[i]), 2)
            distance += temp
        distance = math.pow(distance, 0.5)
        return distance
    return distance
</code></pre>

<h5 id="toc_4">判断是否是核心对象，并返回所有直接密度对象</h5>

<pre><code class="language-python">def isKeyAndReturnObjects(dataPoint, dataPoints, radius, ObjectNum):
    arrivableObjects = [] #用来存储所有直接密度可达对象
    distances = [] #对应直接可达对象的欧几里得距离

    for i in range(len(dataPoints)):
        dp = dataPoints[i]
        distance = getDistance(dataPoint, dp)
        if distance &lt;= radius: #在radius-邻域内
            distances.append(distance)
            arrivableObjects.append(dp)

    if len(arrivableObjects)&gt;=ObjectNum : #是核心对象
        newDistances = distances[:]
        newDistances.sort()
        coreDistance=distances[ObjectNum-1] #核心距离
        dataPoint.setReachableDistance(coreDistance)
        for j in range(len(arrivableObjects)):
            if coreDistance &gt; newDistances[j]: #可达距离的计算
                arrivableObjects[j].setReachableDistance(coreDistance)
            else:
                arrivableObjects[j].setReachableDistance(newDistances[j])
        return arrivableObjects
    return None
</code></pre>

<h5 id="toc_5">核心代码，可以对比上面的算法过程</h5>

<pre><code class="language-python">def startAnalysis(dataPoints, radius, ObjectNum):
    dpList = []
    dpQue = []
    total = 0
    while total &lt; len(dataPoints):
        if isContainedInList(dataPoints[total], dpList) == -1 :# 不在结果队列里面
            tmpDpList = isKeyAndReturnObjects(dataPoints[total],dataPoints, radius, ObjectNum) # 如果对象是核心对象，返回直接密度可达对象
            if tmpDpList and len(tmpDpList) &gt; 0 :
                newDataPoint = dataPoints[total].copy()
                dpQue.append(newDataPoint)
        while dpQue:
            tempDpfromQ = dpQue.pop(0)
            newDataPoint = tempDpfromQ.copy()
            dpList.append(newDataPoint)
            tempDpList = isKeyAndReturnObjects(tempDpfromQ,dataPoints, radius, ObjectNum)
            print(newDataPoint.getName() + &quot;:&quot; + str(newDataPoint.getReachableDistance()))
            if tempDpList != None and len(tempDpList) &gt; 0:
                for i in range(len(tempDpList)):
                    tempDpfromList = tempDpList[i]
                    indexInList = isContainedInList(tempDpfromList,dpList)
                    indexInQ = isContainedInList(tempDpfromList, dpQue)
                    if indexInList == -1: #当前密度可达对象不在结果集中
                        if indexInQ &gt; -1: #当前密度可达对象在dpQue中，看是否能更新可达距离
                            index = -1
                            for dataPoint in dpQue: #这里的循环就是为了找到dpQue中的该直接密度可达对象
                                index += 1
                                if index == indexInQ:
                                    if dataPoint.getReachableDistance() &gt; tempDpfromList.getReachableDistance():
                                        dataPoint.setReachableDistance(tempDpfromList.getReachableDistance())
                        else:
                            dpQue.append(tempDpfromList.copy())
            # 对Q进行重新排序
            dpQue.sort(key = lambda dp:dp.getReachableDistance())
        total+=1
        print(&quot;------&quot;)
    return dpList
</code></pre>

<h5 id="toc_6">主函数</h5>

<pre><code class="language-python">dpoints = []

    dpoints.append(DataPoint([2,3],&quot;a&quot;))
    dpoints.append(DataPoint([2,4],&quot;b&quot;))
    dpoints.append(DataPoint([1,4],&quot;c&quot;))
    dpoints.append(DataPoint([1,3],&quot;d&quot;))
    dpoints.append(DataPoint([2,2],&quot;e&quot;))
    dpoints.append(DataPoint([3,2],&quot;f&quot;))

    dpoints.append(DataPoint([8,7],&quot;g&quot;))
    dpoints.append(DataPoint([8,6],&quot;h&quot;))
    dpoints.append(DataPoint([7,7],&quot;i&quot;))
    dpoints.append(DataPoint([7,6],&quot;j&quot;))
    dpoints.append(DataPoint([8,5],&quot;k&quot;))

    dpoints.append(DataPoint([100,2],&quot;l&quot;))## 噪音点

    dpoints.append(DataPoint([8,20],&quot;m&quot;))
    dpoints.append(DataPoint([8,19],&quot;n&quot;))
    dpoints.append(DataPoint([7,18],&quot;o&quot;))
    dpoints.append(DataPoint([7,17],&quot;p&quot;))
    dpoints.append(DataPoint([8,21],&quot;q&quot;))

    startAnalysis(dpoints, 2, 4)
</code></pre>

<h5 id="toc_7">输出结果</h5>

<p><img src="media/15129060526675/15322365491439.jpg" alt="" style="width:250px;"/></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15127423559946.html">霍夫丁不等式 Hoeffding's inequality</a></h1>
			<p class="meta"><time datetime="2017-12-08T22:12:35+08:00" 
			pubdate data-updated="true">2017/12/8</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在概率论中，Hoeffding不等式提供了有界独立随机变量之和偏离其预期值超过一定数量的概率的上界。 1963年Wassily Hoeffding证明了Hoeffding不等式。</p>

<h4 id="toc_0">霍夫丁不等式的定义</h4>

<p>设有两两独立的一系列随机变量 \(X_1,X_2,...,X_i,...,X_n\) 。假设对所有的 \(X_{i}\) 都是几乎有界的变量，即满足：<br/>
\[<br/>
P(X_i \in [a_i,b_i]) = 1<br/>
\]</p>

<p>那么这n个随机变量的经验平均数：<br/>
\[<br/>
\overline X = \frac{X_1+X_2+...+X_n}{n}<br/>
\]</p>

<p>霍夫丁不等式定义如下，对于任意的 \(t&gt;0\)，霍夫丁不等式理论一：<br/>
\[<br/>
{{\displaystyle {\begin{aligned}\operatorname {P} ({\overline {X}}-\mathbb E [{\overline {X}}]\geq t)\leq e^{-2nt^{2}}\end{aligned}}}}\\<br/>
\]</p>

<p>霍夫丁不等式理论二：<br/>
\[<br/>
{P ({\overline {X}}-\mathbb E [{\overline {X}}]\geq t)\leq \exp \left(-{\frac {2t^{2}n^{2}}{\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\right),\!}\\<br/>
{P (|{\overline {X}}-\mathbb E [{\overline {X}}]|\geq t)\leq 2\exp \left(-{\frac {2t^{2}n^{2}}{\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\right),\!}<br/>
\]</p>

<p>在证明霍夫丁不等式之前，先来看一看霍夫丁引理：</p>

<h4 id="toc_1">霍夫丁引理 Hoeffding&#39;s Lemma</h4>

<p>如果 \(X\) 是一个期望为 0 的实数随机变量，即 \(\mathbb E(X)=0\) ，当 \(a \le X \le b\) ，对于任意一个 \(\lambda \in R\) ，都有：<br/>
\[<br/>
\mathbb E(e^{\lambda X}) \le \exp(\frac{\lambda^2(b-a)^2}{8})<br/>
\]</p>

<p>注意因为假设随机变量 \(X\) 有一个 0 的期望值，在定理中 \(a\) 和 \(b\) 必满足 \(a \le 0 \le b\)。</p>

<h5 id="toc_2">引理证明</h5>

<p>因为 \(e^{\lambda x}\) 是一个关于 \(x\) 的下凸函数，由琴生不等式知，对于 \(a\le x \le b\)：<br/>
\[<br/>
e^{\lambda X} = \exp(\frac{\lambda ab-\lambda aX - \lambda ba + \lambda bX}{b-a}) =  \exp(\frac{\lambda a(b-X)}{b-a} + \frac{\lambda b(X-a)}{b-a}) \le \frac{b-X}{b-a}e^{\lambda a} + \frac{X-a}{b-a} e^{\lambda b}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E[e^{\lambda X}] &amp;\le \mathbb E[\frac{b-X}{b-a} e^{\lambda a} + \frac{X-a}{b-a} e^{\lambda b}]\\<br/>
&amp;= \frac{b-\mathbb E[X]}{b-a} e^{\lambda a} + \frac{\mathbb E[X]-a}{b-a} e^{\lambda b}\\<br/>
&amp;= \frac{b}{b-a} e^{\lambda a} + \frac{-a}{b-a} e^{\lambda b}\\<br/>
&amp;= -\frac{a}{b-a} e^{\lambda a} [-\frac b a + e^{\lambda (b - a)}]\\<br/>
&amp;= -\frac{a}{b-a} e^{\lambda a} [-\frac{b-a+a}{a} + e^{\lambda (b - a)}]\\<br/>
&amp;= -\frac{a}{b-a} e^{\lambda a} [-\frac{b-a}{a} -1 + e^{\lambda (b - a)}]\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(\theta = - \frac a {b-a} &gt; 0\)：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E[e^{\lambda X}] &amp;\le -\frac{a}{b-a} e^{\lambda a} [-\frac{b-a}{a} -1 + e^{\lambda (b - a)}]\\<br/>
&amp;= \theta e^{-\lambda (b-a)\theta}[\frac 1 \theta - 1 + e^{\lambda(b-a)}]\\<br/>
&amp;= e^{-\lambda (b-a)\theta}(1 - \theta + \theta e^{\lambda(b-a)})<br/>
\end{align*}<br/>
\]</p>

<p>令 \(u = \lambda (b-a)\) ，则<br/>
 \[<br/>
 \begin{equation}<br/>
 \mathbb E[e^{\lambda X}] \le e^{-\theta u}(1-\theta + \theta e^u)\label{elx}\\<br/>
 \end{equation}<br/>
 \]</p>

<p>考虑到：<br/>
\[<br/>
\begin{align*}<br/>
1-\theta + \theta e^u &amp;= \theta(\frac 1 \theta + 1 + e^u)\\<br/>
&amp;= \theta(-\frac b a + e^{u})\\<br/>
&amp; &gt; 0\quad \because \theta &gt; 0\text{ and } a \lt 0\text{ and } b \ge 0\\<br/>
\end{align*}<br/>
\] </p>

<p>所以式 \ref{elx} 可以写成：<br/>
\[<br/>
\mathbb E[e^{\lambda X}] \le e^{-\theta u}(1-\theta + \theta e^u) = \exp[-\theta u + \log (1-\theta + \theta e^u)]<br/>
\]</p>

<p>定义：<br/>
\[<br/>
\left \{ \begin{array} \\<br/>
\phi:\mathbb R \rightarrow \mathbb R\\<br/>
\phi(u) = -\theta u + \log(1-\theta + \theta e^u)<br/>
\end{array} \right .<br/>
\]</p>

<p>即得：<br/>
\[<br/>
\begin{equation}<br/>
\mathbb E[e^{\lambda X}] \le e^{\phi(u)} \label{eep}<br/>
\end{equation}<br/>
\]</p>

<p>运用泰勒中值定理（同济大学高数上p139），对于每一个实数 \(u\) 都存在一个 \(v\) 在 0 到 \(\mu\) 之间，有：<br/>
\[<br/>
\phi(u) = \phi(0) + \phi&#39;(0)u + \frac{\phi&#39;&#39;(v)}{2!}u^2<br/>
\]</p>

<p>注意到<br/>
\[<br/>
\begin{align*}<br/>
\phi(0) &amp;= 0 + \log(1-\theta + \theta) = 0\\<br/>
\phi&#39;(0) &amp;= -\theta + \frac{\theta e^u}{1-\theta+\theta e^u}\bigg |_{u=0} = 0\\<br/>
\phi&#39;&#39;(v) &amp;= \frac{\theta e^u(1-\theta+\theta e^u) - (\theta e^u)^2}{(1-\theta+\theta e^u)^2}\bigg|_{u=v}\\<br/>
&amp;= \frac{\theta e^u(1-\theta)}{(1-\theta+\theta e^u)^2}\bigg|_{u=v}\\<br/>
&amp;= \frac{\theta e^v(1-\theta)}{(1-\theta+\theta e^v)^2}\\<br/>
&amp;= \frac{\theta e^v}{1-\theta+\theta e^v} \quad \frac{1-\theta}{1-\theta+\theta e^v}\\<br/>
&amp;= t(1-t)<br/>
\end{align*}<br/>
\]</p>

<p>其中<br/>
\[<br/>
\begin{align*}<br/>
t &amp;= \frac{\theta e^v}{1-\theta+\theta e^v}\\<br/>
&amp;= \frac{\theta e^v}{1 + \theta(e^v-1)}\\<br/>
&amp;&gt; 0<br/>
\end{align*}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\phi&#39;&#39;(v) = t(1-t) = -t^2 + t = -(t^2 - t + \frac 1 4)+\frac 1 4 = -(t-\frac 1 2)^2+\frac 1 4 \le \frac 1 4<br/>
\]</p>

<p>因此：<br/>
\[<br/>
\phi(x) \le \phi(0) + \phi&#39;(0)u + \frac{\phi&#39;&#39;(v)}{2!}u^2 = 0 + 0 + \frac 1 2 u^2 \cdot \frac 1 4 = \frac{u^2}{8} = \frac{\lambda^2(b-a)^2}{8}<br/>
\]</p>

<p>代入式 \ref{eep} 得：<br/>
\[<br/>
\mathbb E[e^{\lambda X}] \le \exp(\frac{\lambda^2(b-a)^2}{8})<br/>
\]</p>

<p>得证。</p>

<h4 id="toc_3">霍夫丁不等式证明</h4>

<p>令 \(S_n = X_1 + X_2 + ... + X_n\)，即 \(\overline X = \frac{S_n}{n}\) ，则霍夫丁不等式可以写成：<br/>
\[<br/>
\begin{align*}<br/>
&amp; {P ({\overline {X}}-{\mathbb E} [{\overline {X}}]\geq o)\leq \exp \left(-{\frac {2o^{2}n^{2}}{\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\right),\!}\\<br/>
\Rightarrow &amp; {P (\frac{S_n}{n}-{\mathbb E} [\frac{S_n}{n}]\geq o)\leq \exp \left(-{\frac {2o^{2}n^{2}}{\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\right),\!}\\<br/>
\Rightarrow &amp; {P (\frac{S_n}{n}- \frac{\mathbb E[S_n]}{n}\geq o)\leq \exp \left(-{\frac {2o^{2}n^{2}}{\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\right),\!}\\<br/>
\Rightarrow &amp; {P ({S_n}- {\mathbb E[S_n]}\geq no)\leq \exp \left(-{\frac {2o^{2}n^{2}}{\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\right),\!}\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(t = no\) 便可以得到：<br/>
\[<br/>
{P ({S_n}- {\mathbb E[S_n]}\geq t)\leq \exp \left(-{\frac {2t^{2}}{\sum _{i=1}^{n}(b_{i}-a_{i})^{2}}}\right),\!}\\<br/>
\]</p>

<p>对于 \(s,t &gt; 0\)<br/>
\[<br/>
\begin{align*}<br/>
P ({S_n}- {\mathbb E[S_n]}\geq t) = P(e^{s(S_n-\mathbb E[S_n])} \ge e^{st})<br/>
\end{align*}<br/>
\]</p>

<p>令 \(X = e^{s(S_n-\mathbb E[S_n])} \)，\(\alpha = e^{st}\)，应用马尔可夫不等式：<br/>
\[<br/>
\begin{align}<br/>
P ({S_n}- {\mathbb E[S_n]}\geq t) &amp;= P(e^{s(S_n-\mathbb E[S_n])} \ge e^{st})\nonumber\\<br/>
&amp;\le \frac{\mathbb E[e^{s(S_n-\mathbb E[S_n])}]}{e^{st}}\nonumber\\<br/>
&amp;= e^{-st} \mathbb E[\exp(s(S_n-\mathbb E[S_n]))]\nonumber\\<br/>
&amp;= e^{-st} \mathbb E[\exp[s(\sum_{i=1}^n X_i -\mathbb E[\sum_{i=1}^n X_i])]]\nonumber\\<br/>
&amp;= e^{-st} \mathbb E[\exp[s(\sum_{i=1}^n(X_i -\mathbb E[X_i]))]]\nonumber\\<br/>
&amp;= e^{-st} \mathbb E[\prod_{i=1}^n \exp[s(X_i -\mathbb E[X_i])]]\nonumber\\<br/>
&amp;= e^{-st} \prod_{i=1}^n \mathbb E[\exp[s(X_i -\mathbb E[X_i])]]\label{spe}<br/>
\end{align}<br/>
\]</p>

<p>当 \(\lambda = s\) ，\(x = X_i -\mathbb E[X_i]\) 代入霍夫丁引理，可得：<br/>
\[<br/>
\mathbb E[\exp[s(X_i -\mathbb E[X_i])]] \le \exp(\frac{s^2(b_i-a_i)^2}{8})<br/>
\]</p>

<p>将上式代入式 \ref{spe} 得：<br/>
\[<br/>
\begin{align*}<br/>
P({S_n}- {\mathbb E[S_n]}\geq t) &amp;= e^{-st} \prod_{i=1}^n \mathbb E[\exp[s(X_i -\mathbb E[X_i])]]\\<br/>
&amp;\le e^{-st} \prod_{i=1}^n \exp({\frac{s^2(b_i-a_i)^2}{8}})\\<br/>
&amp;= \exp(-st + \frac 1 8 s^2 \sum_{i=1}^n (b_i-a_i)^2)<br/>
\end{align*}<br/>
\]</p>

<p>为了得到上界，我们要找到右边关于 \(s\) 的不等式的最小值，定义：<br/>
\[<br/>
\left \{ \begin{array}\\<br/>
&amp;g:\mathbb R+ \rightarrow \mathbb R\\<br/>
&amp;g(s):-st + \frac 1 8 s^2 \sum_{i=1}^n (b_i-a_i)^2\\<br/>
\end{array}\right .<br/>
\]</p>

<p>对 \(g(s)\) 求导，并令其等于0，即 \(g&#39;(s) = 0\)：<br/>
\[<br/>
g&#39;(s) = -t + \frac 1 4 s \sum_{i=1}^n (b_i-a_i)^2 = 0 \\<br/>
\Rightarrow s = \frac{4t}{\sum_{i=1}^n (b_i-a_i)^2}<br/>
\]</p>

<p>因此：<br/>
\[<br/>
\begin{align*}<br/>
P({S_n}- {\mathbb E[S_n]}\geq t) &amp;\le \exp[-st + \frac 1 8 s^2 \sum_{i=1}^n (b_i-a_i)^2]\\<br/>
&amp;= \exp[\frac{-4t^2}{\sum_{i=1}^n (b_i-a_i)^2} + \frac 1 8 (\frac{4t}{\sum_{i=1}^n (b_i-a_i)^2})^2 \sum_{i=1}^n (b_i-a_i)^2]\\<br/>
&amp;= \exp[\frac{-4t^2}{\sum_{i=1}^n (b_i-a_i)^2} + \frac{2t^2}{\sum_{i=1}^n (b_i-a_i)^2}]\\<br/>
&amp;= \exp[\frac{-2t^2}{\sum_{i=1}^n (b_i-a_i)^2}]\\<br/>
\end{align*}<br/>
\]</p>

<p>得证。</p>

<hr/>

<p><a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality">Hoeffiding inequality</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15124873066800.html">切比雪夫不等式 chebyshev's inequality</a></h1>
			<p class="meta"><time datetime="2017-12-05T23:21:46+08:00" 
			pubdate data-updated="true">2017/12/5</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>切比雪夫不等式是以俄罗斯数学家 Pafnuty Chebyshev 命名的，它的数学形式如下：<br/>
\[<br/>
P(|X-\mu|\ge \epsilon) \le \frac{\sigma^2}{\epsilon^2}<br/>
\]</p>

<p>其中 \(\mu\) 是期望，\(\sigma\) 是标准差。切比雪夫不等式的一个扩展形式：<br/>
\[<br/>
P(|X-\mu| \lt \epsilon ) \le 1 - \frac{\sigma^2}{\epsilon^2}<br/>
\]</p>

<h4 id="toc_0">切比雪夫不等式证明</h4>

<p>这里提供两种方式证明切比雪夫不等式</p>

<h5 id="toc_1">直接证明</h5>

<p>对于每一个事件 \(A\) ，假设 \(I_A\) 为 \(A\) 的指示函数，定义为：<br/>
\[<br/>
I_A = \left \{ \begin{array}\\ 1 \quad &amp; x \in A\\ 0 \quad &amp; x \notin A\\\end{array}\right .<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
P(|X-\mu| \ge \epsilon) &amp;= \mathbb E(I_{|X-\mu| \ge \epsilon})\\<br/>
&amp;= \mathbb E\Big(I_{[({X-\mu})/{\epsilon}]^2 \ge 1}\Big)\\<br/>
&amp;\le \mathbb E\Big[(\frac{X-\mu}{\epsilon})^2\Big]\\<br/>
&amp;= \frac{\mathbb E[(X-\mu)^2]}{\epsilon^2}\\<br/>
&amp;= \frac {\sigma^2}{\epsilon^2}<br/>
\end{align*}<br/>
\]</p>

<h5 id="toc_2">通过马尔可夫不等式证明</h5>

<p>由马尔可夫不等式可知：<br/>
\[<br/>
P(|Y|\ge \alpha) \le \frac{\mathbb E(|Y|)}{\alpha}<br/>
\]</p>

<p>令 \(Y=(X-\mu)^2\) ，得：<br/>
\[<br/>
P((X-\mu)^2\ge \alpha) \le \frac{((X-\mu)^2)}{\alpha} = \frac {\sigma^2}{\alpha}<br/>
\]</p>

<p>令 \(\alpha = \epsilon^2\)：<br/>
\[<br/>
P((X-\mu)^2\ge \epsilon^2) \le \frac{\sigma^2}{\epsilon^2}<br/>
\]</p>

<p>在 \(\epsilon&gt;0\) 的情况下，也就等价于：<br/>
\[<br/>
P(|X-\mu| \ge \epsilon) \le \frac{\sigma^2}{\epsilon^2}<br/>
\]</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15121851089277.html">基于密度的聚类算法-Meanshift算法</a></h1>
			<p class="meta"><time datetime="2017-12-02T11:25:08+08:00" 
			pubdate data-updated="true">2017/12/2</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	

		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15121456213558.html">马尔可夫不等式 Markov's inequality</a></h1>
			<p class="meta"><time datetime="2017-12-02T00:27:01+08:00" 
			pubdate data-updated="true">2017/12/2</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在概率论中，马尔可夫不等式给定了一个随机变量的非负函数大于等于一个正常数的概率的上界，它是以俄罗斯数学家 Andrey Markov命名的，尽管它最早出现在 Chebyshev(马尔可夫的老师) 的工作中，有时候它也被称为第一切比雪夫不等式。</p>

<h3 id="toc_0">马尔可夫不等式定义</h3>

<p>如果 \(X\) 是一个非负的随机变量，\(\alpha &gt; 0\)，\(X\) 不小于 \(\alpha\) 的概率不大于 \(X\) 的期望除以 \(\alpha\)：<br/>
\[<br/>
P(X\ge \alpha) \le \frac{\mathbb E(X)}{\alpha}<br/>
\]</p>

<p>令 \(\tilde\alpha=\frac{\alpha}{\mathbb E(X)}\)，所以前面的不等式可以写成：<br/>
\[<br/>
P(X\ge \tilde\alpha \mathbb E(X)) \le \frac 1 {\tilde\alpha}<br/>
\]</p>

<p>在测度理论中，马尔可夫不等式表明如果 \((X,\Sigma,\mu)\) 是一个测度空间，\(f\) 是一个可测量的扩展的实数函数，\(\epsilon \ge 0\)，那么：<br/>
\[<br/>
\mu(\{x\in X:|f(x)|\ge \epsilon\}) \le \frac 1 \epsilon \int_X |f|d\mu<br/>
\]</p>

<p>如果 \(\phi\) 是关于非负实数的单调递增非负函数，\(X\) 是一个随机变量，\(\alpha \ge 0\)，\(\phi(\alpha)&gt;0\)，有：<br/>
\[<br/>
P(|X| \ge \alpha) \le \frac{\mathbb E(\phi(|X|))}{\phi(\alpha)}<br/>
\]</p>

<p>一个直接的推论，若 \(X\) 是一个非负实数：<br/>
\[<br/>
P(X \ge \alpha) \le \frac{\mathbb E(X^n)}{\alpha^n}<br/>
\]</p>

<h3 id="toc_1">马尔可夫不等式证明</h3>

<h4 id="toc_2">概率论</h4>

<p>从期望的定义可以知道：<br/>
\[<br/>
\mathbb E(X) = \int_{-\infty}^{\infty} x f(x) dx<br/>
\]</p>

<p>因为 \(X\) 是一个非负的随机变量，因此：<br/>
\[<br/>
\mathbb E(X) = \int_{-\infty}^{\infty} x f(x) dx = \int_{0}^{\infty} x f(x) dx<br/>
\]</p>

<p>所以我们可以推导出：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E(X) &amp;= \int_{0}^{\infty} x f(x) dx = \int_0^\alpha x f(x) dx + \int_\alpha^{\infty} x f(x)\\<br/>
&amp;\ge \int_\alpha^{\infty} x f(x) dx \\<br/>
&amp;\ge \int_\alpha^{\infty} \alpha f(x) dx \\<br/>
&amp;= \alpha \int_\alpha^{\infty} f(x) dx \\<br/>
&amp;= \alpha P(x \ge \alpha)<br/>
\end{align*}<br/>
\]</p>

<p>所以可得到：<br/>
\[<br/>
P(X \ge \alpha) \le \frac{\mathbb E(X)}{\alpha}<br/>
\]</p>

<h4 id="toc_3">测度理论</h4>

<p>我们可以假设函数 \(f\) 是非负的，因为只有它的绝对值进入等式。现在考虑 \(X\) 上的实数函数：<br/>
\[<br/>
s(x) = \left \{ \begin{array}\\<br/>
\epsilon \quad &amp; \text{if }f(x)\text{ }\ge \epsilon\\<br/>
0 \quad &amp; \text{if }f(x)\text{ }\lt \epsilon\\<br/>
\end{array} \right.<br/>
\]</p>

<p>然后有 \(0\le s(x) \le f(x)\)，通过勒贝格积分可得：<br/>
\[<br/>
\int_X f(x) d\mu \ge \int_X s(x) d\mu = \epsilon \mu(\{x \in X:f(x) \ge \epsilon \})<br/>
\]</p>

<p>因为 \(\epsilon \gt 0\) ，两边除以 \(\epsilon\) ，可得：<br/>
\[<br/>
\mu(\{x \in X:f(x) \ge \epsilon \}) \le \frac 1 \epsilon \int_X f(x) d\mu<br/>
\]</p>

<hr/>

<p><a href="https://en.wikipedia.org/wiki/Markov%27s_inequality">Markov&#39; inequality In Wikipad</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15117059954234.html">基于密度的聚类算法-DBSCAN算法</a></h1>
			<p class="meta"><time datetime="2017-11-26T22:19:55+08:00" 
			pubdate data-updated="true">2017/11/26</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>DBSCAN算法的英文名称是 Density-Based Spatial Clustering of Applications with Noise，中文名称是含有噪声的基于密度的空间聚类算法。与KMeans算法基于只能基于凸分布样本不同的是，基于密度的DBSCAN算法适用于任何形状的样本集。</p>

<h3 id="toc_0">基于密度聚类算法</h3>

<p>基于密度的算法是根据样本集之间的紧密程度，基于密度的算法可以在具有噪音的样本中发现任意形状和大小的簇。DBSCAN算法是其中的代表算法。为了更好的说明基于密度的聚类算法，先来看幅图：</p>

<div align=center>
    <img width=300 src="media/15117059954234/15320142792578.jpg" />
</div>

<p>基于密度聚类算法核心思想就是先发现密度较高的点，然后把相近的高密度点逐步都连成一片，进而生成各种簇。如果该样本集使用基于密度的聚类方法，能很好的进行聚类。由图中可以知道同类中的点相聚很近，不同类的点相聚较远。</p>

<h3 id="toc_1">DBSCAN算法</h3>

<p>DBSCAN算法既然是通过密度来进行聚类，我们知道密度的定义是单位面积内样本点的个数，这里有两个重要的参数，面积的大小和样本点的数量。所以这里我们引入两个参数（<b>\(\epsilon\)</b>,<b>MinPts</b>）来描述样本点的紧密程度，其中，\(\epsilon\) 描述了某一样本的半径阈值，<b>MinPts</b> 描述了某一样本的半径为 \(\epsilon\) 的邻域中样本个数的阈值。</p>

<p>定义几个概念：</p>

<ul>
<li><p><b>\(\epsilon\)-邻域</b>：对于给定对象 \(x_j\in D\)，半径为 \(\epsilon\) 内的邻域叫做该对象的 \(\epsilon\)-邻域。定义对象 \(x_j\) 的 \(\epsilon\)-邻域内样本组成的样本集 \(D_{\epsilon}(x_j)\)，有：<br/>
\[<br/>
D_{\epsilon}(x_j) = \{x\in D|\text{dist}(x-x_j)\le \epsilon\}<br/>
\]</p></li>
<li><p><b>核心对象</b>：如果对象 \(x_j\) 的 \(\epsilon\)-领域内的对象数量 \(|D_{\epsilon}(x_j)| \) 大于等于 MinPts ，则认为样本点 \(x_j\) 是核心对象。</p></li>
<li><p><b>直接密度可达</b>：如果对象 \(x_j\) 属于核心对象，对象 \(x_i\) 在 \(x_j\) 的\(\epsilon\)-邻域内，即\(x_i\in D_{\epsilon}(x_j)\) ，则称对象 \(x_i\) 从对象 \(x_j\) 直接密度可达。直接密度可达不具有对称性。</p></li>
<li><p><b>密度可达</b>：如果对象 \(x_j\) 从对象 \(x_i\) 直接密度可达，对象 \(x_k\) 从对象 \(x_j\) 直接密度可达，此时认为 \(x_k\) 从对象 \(x_i\) 密度可达。密度可达不具有对称性。</p></li>
<li><p><b>密度相连</b>：如果对象 \(x_p\) 到对象 \(x_q\) 和 对象 \(x_o\) 都密度可达，此时认为对象 \(x_q\) 和对象 \(x_o\) 密度相连，具有对称性。</p></li>
</ul>

<p>如下图，设 MinPts=6，圆的半径为 \(\epsilon\)，易看出对象 \(a\) 的 \(\epsilon\)-邻域内的样本点数量为6，对象 \(b\) 的 \(\epsilon\)-邻域内的样本点数量为7，均大于 MinPts，所以对象 \(a\) 和对象 \(b\) 都是核心对象。对象 \(c\) 在核心对象 \(a\) 的 \(\epsilon\)-邻域内，称对象 \(c\) 从对象 \(a\) 直接密度可达。同理对象 \(a\) 在核心对象 \(b\) 的\(\epsilon\)-邻域内，称对象 \(a\) 从对象 \(b\) 直接密度可达，所以 \(c\) 从 \(b\) 密度可达。对象 \(d\)在核心对象 \(b\) 的\(\epsilon\)-邻域内，即 \(b\) 到 \(d\) 直接密度可达，并且可知 \(d\) 到 \(c\) 密度相连。</p>

<div align=center>
    <img width=300 src="media/15117059954234/15320184035358.jpg" />
</div>

<p>DBSCAN算法的目标是寻找到最大密度的相连的样本集合作为一个簇。在这个簇里有一个或多个核心对象，如果只有一个核心对象，那么其他点都在这个对象的 \(\epsilon\)-邻域内；如果有多个核心对象，那么必定任何一个核心对象 \(\epsilon\)-邻域内都有其他的核心对象，否则这两个核心对象无法密度可达。在算法中，我们将不是核心对象但在核心对象的 \(\epsilon\)-邻域内的对象称为边界点，将不在任何一个核心对象的 \(\epsilon\)-邻域的样本点称为噪音点。</p>

<h3 id="toc_2">DBSCAN算法步骤</h3>

<p><b>输入</b>：</p>

<ul>
<li>D：包含 n 个对象的数据集</li>
<li>\(\epsilon\)：邻域半径参数</li>
<li>MinPts：样本个数阈值</li>
</ul>

<p><b>输出</b>：基于密度的簇集合<br/>
<b>算法过程</b>：</p>

<pre><code>标记所有对象为未访问
执行以下步骤，直到没有对象被标记为未访问：
    随机选取一个标记为未访问的对象p；
    标记p为已访问；
    如果对象p的ϵ-邻域内对象至少有MinPts个(即对象p为核心对象)：
        创建一个新的簇C，将对象p加入C；
        定义一个集合N，将对象p的ϵ-邻域的所有对象加入N；
        循环N中的每一个对象p‘：
            如果对象p’被标记为未访问：
                标记p’为已访问；
                如果对象p‘的ϵ-邻域内对象至少有MinPts个：
                    将对象p’的ϵ-邻域内所有对象加入N；
            如果p‘不属于任何一个簇，将p‘加入C中
        输出簇C；
    否则标记为噪音点或边界点；
</code></pre>

<h3 id="toc_3">DBSCAN算法优缺点</h3>

<h6 id="toc_4">优点：</h6>

<p>1）不需要事先输入簇的个数，会自动发现簇的个数<br/>
2）可以发现任意形状的簇<br/>
3）可以在聚类的同时发现噪音点</p>

<h6 id="toc_5">缺点：</h6>

<p>1）对参数敏感，需要手动输入参数 \(\epsilon\) 和MinPts<br/>
2）样本较多时，计算量大，可以通过建立KD树来搜索近邻改进算法<br/>
3）样本密度不均匀时，聚类间距差相差很大时，聚类质量较差</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15109749394756.html">基于层次的聚类算法-自下向上-Chameleon算法</a></h1>
			<p class="meta"><time datetime="2017-11-18T11:15:39+08:00" 
			pubdate data-updated="true">2017/11/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	

		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15109408623126.html">GMM与最大期望算法</a></h1>
			<p class="meta"><time datetime="2017-11-18T01:47:42+08:00" 
			pubdate data-updated="true">2017/11/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>EM算法的一个重要应用时高斯混合模型的参数估计，高斯混合模型应用广泛，在许多情况下，EM算法时学习高斯混合分布的有效方法。先来介绍一下高斯混合分布 GMM 和相关的几个概念：</p>

<h4 id="toc_0">高斯分布</h4>

<p>高斯分布（Gaussian Distribution），有时也被称为正太分布，在自然界中最常见的存在。假设对我国成年男人的身高作出统计，如下图：</p>

<div align="center">
    <img width='300' src='media/15109408623126/15326117493088.jpg'/>
</div>

<p>这个图形非常直观的展现了高斯分布的形状，高斯函数的数学定位为 \(N(\mu,\sigma^2)\)，其中 \(\mu\) 为分布的平均值，\(\sigma\) 为分布的标准差：<br/>
\[<br/>
\mathcal N(y|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})<br/>
\]</p>

<p>上面身高的高斯分布便是在 \(N(172,36)\) 下绘制的分布图。期望值决定了分布的位置，标准差决定分布的振幅。</p>

<h4 id="toc_1">混合高斯分布</h4>

<p>高斯混合分布（Gaussian Mixture Model）是指多个高斯分布的线性分布，理论上高斯混合分布能模拟出任何分布形状。高斯混合模型的数学定义如下：<br/>
\[<br/>
\begin{align*}<br/>
P(y|\theta) &amp;=\sum_{k=1}^K P(\text{第}k\text{个高斯分布}|\theta)  P(y|\text{第}k\text{个高斯分布},\theta)\\<br/>
&amp;= \sum_{k=1}^K \alpha_k \mathcal N(y|\theta_k)\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\alpha_k\) 是系数，\(\alpha_k \ge 0\)，\(\sum_{k=1}^K \alpha_k = 1\)，\(\mathcal N(y|\theta_k)\) 是高斯分布密度，\(\theta_k=(\mu_k,\sigma_k^2)\)：<br/>
\[<br/>
\mathcal N(y|\theta_k) = \frac{1}{\sqrt{2\pi}\sigma_k} exp(-\frac{(y-\mu_k)^2}{2\sigma_k^2})<br/>
\]</p>

<p>称为第 \(k\) 个分模型。</p>

<p>如下图是分别是我国成年男女的身高分布：</p>

<div align="center">
    <img width='360' src="media/15109408623126/15326156226146.jpg" />
</div>

<p>假设成年男人的身高满足高斯分布 \(N(\mu_1,\sigma_1)\)，成年女人身高满足高斯分布 \(N(\mu_2,\sigma_2)\)，我国男女的比例分别是 \(\alpha_1\) 和 \(\alpha_2\) ，混合高斯分布模型如下：<br/>
\[<br/>
P(y|\theta) = \alpha_1 \mathcal N(y|\mu_1,\sigma_1) + \alpha_2 \mathcal N(y|\mu_2,\sigma_2)<br/>
\]</p>

<p>上式中未知的参数有六个，\(\theta=(\alpha_1,\mu_1,\sigma_2,\alpha_2,\mu_2,\sigma_2)\)。如果要从 GMM 的分布中随机地取一个点的话，实际上可以分为两步：首先随机地在这 \(K\) 个分布之中选一个，每个分布被选中的概率实际上就是它的系数 \(\alpha_k\) ，选中单个分布之后，比如上图蓝色的分布，这里已经回到了普通的 Gaussian 分布，转化为已知的问题。</p>

<h5 id="toc_2">高斯混合模型参数估计的 EM 算法</h5>

<p>假设观察数据 \(y_1,y_2,...y_n\) 由高斯混合模型生成：<br/>
\[<br/>
P(y|\theta) =  \sum_{k=1}^K \alpha_k \mathcal N(y|\theta_k)<br/>
\]</p>

<p>其中 \(\theta=(\alpha_1,\alpha_2,...,\alpha_k;\theta_1,\theta_2,...,\theta_k)\) 。显然我们已经知道观察数据 \(y_1,y_2,...,y_n\) 的生成步骤：首先根据概率 \(\alpha_k\) 选择第 \(k\) 个高斯分布模型 \(\mathcal N(y,\theta_k)\) ，然后根据模型生成观察数据 \(y_j\) 。使用 \(\gamma_j\) 表示第 \(j\) 个观察数据来自的高斯分布 ，\(\gamma_{jk}\) 表示第 \(j\) 个观察数据来源于第 \(k\) 个高斯分布的概率，其定义如下：<br/>
\[<br/>
\begin{align*}<br/>
\gamma_{jk} = \left \{ \begin{array}\\<br/>
1\qquad &amp;\gamma_j = k\\<br/>
0\qquad &amp;\gamma_j \neq k\\<br/>
\end{array}\right .<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(j=1,2,...,N\)，\(k=1,2,...,K\)，\(\gamma_{jk}\) 是 \(0-1\) 随机变量，容易看出：<br/>
\[<br/>
\sum_{k=1}^K \hat\gamma_{jk} = 1<br/>
\]</p>

<p>有了观察数据 \(y_j\) 以及未观察数据 \(\gamma_{jk}\)，那么完全数据是：<br/>
\[<br/>
(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}),\quad j=1,2,...,N<br/>
\]</p>

<p>先来看对于单样本 \(y_j\) 的概率：<br/>
\[<br/>
\begin{align*}<br/>
p(y_j|\gamma_{j1},\gamma_{j2},...,\gamma_{jK},\theta) &amp;= \prod_{k=1}^K [p(y_j|\gamma_{jk} ,\theta)]^{\gamma_{jk}}=\prod_{k=1}^K [\mathcal N(y_j|\theta_k)]^{\gamma_{jk}}\\<br/>
\end{align*}<br/>
\]</p>

<p>隐变量的先验概率为：<br/>
\[<br/>
p(\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta) = \prod_{k=1}^K \alpha_k^{\gamma_{jk}}<br/>
\]</p>

<p>所以单样本 \(y_j\) 的似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
p(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta) &amp;= p(y_j|\gamma_{j1},\gamma_{j2},...,\gamma_{jK},\theta) p(\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta)\\<br/>
&amp;= \prod_{k=1}^K [\mathcal N(y_j|\theta_k)]^{\gamma_{jk}} \prod_{k=1}^K \alpha_k^{\gamma_{jk}}\\<br/>
&amp;= \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}<br/>
\end{align*} <br/>
\]</p>

<p>于是，可以写出完整数据的似然函数：<br/>
\[<br/>
\begin{align*}<br/>
P(y,\gamma|\theta) &amp;= \prod_{j=1}^N p(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta)\\<br/>
&amp;= \prod_{j=1}^N \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>所以完整数据的对数似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta) &amp;= \log p(y,\gamma|\theta) = \log \prod_{j=1}^N \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K [\gamma_{jk} \log\alpha_k+\gamma_{jk}\log\mathcal N(y_j|\theta_k)]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K [\gamma_{jk} \log\alpha_k+\gamma_{jk}\log \frac 1 {\sqrt{2\pi}\sigma_k} \exp(-\frac{(y_j-\mu_k)^2}{2\sigma_k^2})]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
\end{align*}<br/>
\]</p>

<p>EM算法的E步骤，确定Q函数：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_\gamma[\log p(y,\gamma|\theta)|y,\theta^{i}] \\<br/>
&amp;= \sum_\gamma p(\gamma|y,\theta^{(i)}) \log p(y,\gamma|\theta)\\<br/>
&amp;= \sum_\gamma p(\gamma|y,\theta^{(i)}) \sum_{j=1}^N \sum_{k=1}^K \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} \\<br/>
\end{align*}<br/>
\]</p>

<p>现在计算 \(\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk}\)，因为只有当 \(\gamma_{j}=k\) 时 \(\gamma_{jk} = 1\) ，否则 \(\gamma_{jk}=0\)。所以：<br/>
\[<br/>
\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} = \sum_\gamma \gamma_{jk} \sum_{j=1}^N \sum_{k=1}^K p(\gamma_{jk}|y_j,\theta^{(i)}_k) = p(\gamma_{jk}=1|y_j,\theta^{(i)}_k)<br/>
\]</p>

<p>令\(\hat\gamma_{jk} = \sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk}\)：</p>

<p>\[<br/>
\begin{align*}<br/>
\hat\gamma_{jk} &amp;= P(\gamma_{jk}=1|y_j,\theta_k^{(i)})\\<br/>
&amp;= \frac{P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}{P(y_j|\theta^{(i)}_k)}\\<br/>
&amp;= \frac{P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}{\sum_{k=1}^K P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}\\<br/>
&amp;= \frac{P(y_j|\gamma_{jk}=1,\theta_k^{(i)})P(\gamma_{jk}=1|\theta_k^{(i)})}{\sum_{k=1}^K P(y_j|\gamma_{jk}=1,\theta_k^{(i)})P(\gamma_{jk}=1|\theta_k^{(i)})}\\<br/>
&amp;= \frac{\alpha^{(i)}_k \mathcal N(y_j|\theta_k^{(i)})}{\sum_{k=1}^K \alpha^{(i)}_k \mathcal N(y_j|\theta_k^{(i)}) },\quad j=1,2,...,N;k=1,2,...,K<br/>
\end{align*}<br/>
\]</p>

<p>代入 Q 函数中：<br/>
\[<br/>
Q(\theta,\theta^{(i)}) = \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} \\<br/>
\]</p>

<p>EM 算法的M步骤，求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \mu_k} &amp;= \frac{\partial \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \mu_k} \\<br/>
&amp;= \sum_{j=1}^N \frac{[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \mu_k}\\<br/>
&amp;= \sum_{j=1}^N \frac{(y_j-\mu_k)}{\sigma_k^2}\hat\gamma_{jk}\\<br/>
\because &amp;\sum_{j=1}^N \frac{(y_j-\mu_k)}{\sigma_k^2}\hat\gamma_{jk} = 0\\<br/>
\therefore &amp; \sum_{j=1}^N y_j \hat\gamma_{jk}-\sum_{j=1}^N \gamma_{jk}\mu_k = 0\quad \Rightarrow\quad \mu_k = \frac{\sum_{j=1}^N y_j \hat\gamma_{jk}}{\sum_{j=1}^N\hat\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \sigma_k^2} <br/>
&amp;= \frac{\partial \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \sigma_k^2} \\<br/>
&amp;= \sum_{j=1}^N \frac{[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \frac 1 2\log\sigma_k^2  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \sigma_k^2}\\<br/>
&amp;= \sum_{j=1}^N[\frac{1}{2\sigma_k^2} + (\mu_j-y_j)^2 \frac 1 {2\sigma_k^4}]\hat\gamma_{jk}\\<br/>
&amp;= \sum_{j=1}^N \frac{\sigma_k^2+(\mu_j-y_j)^2}{2\sigma_k^4}\hat\gamma_{jk}\\<br/>
\because &amp;\sum_{j=1}^N \frac{\sigma_k^2+(\mu_j-y_j)^2}{2\sigma_k^4}\hat\gamma_{jk} = 0\\<br/>
\therefore &amp; \sum_{j=1}^N [\sigma_k^2+(\mu_j-y_j)^2]\hat\gamma_{jk} = 0\\<br/>
\Rightarrow &amp; \sigma_k^2 = \frac{\sum_{j=1}^N (\mu_j-y_j)^2\hat\gamma_{jk}}{\sum_{j=1}^N \hat\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>现在还剩下一个 \(\alpha_k\) 没有求出，这里用拉格朗日乘子法求解，原问题为：<br/>
\[<br/>
\begin{align*}<br/>
\min \quad&amp;-Q(\theta,\theta^{(i)})\\<br/>
e.t. \quad&amp;\sum_{k=1}^K \alpha_k = 1<br/>
\end{align*}<br/>
\]</p>

<p>定义拉格朗日函数：<br/>
\[<br/>
L(\alpha,\beta) = -\sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \alpha_k -1)\\<br/>
\]</p>

<p>原问题的极小问题可以表示为拉格朗日方程的极大极小问题，先求 \(L(\alpha,\beta)\) 对 \(\alpha\) 的极小值：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial L(\alpha,\beta)}{\partial \alpha_k} &amp;= \frac{\partial \{-\sum_{j=1}^N [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \alpha_k -1)\}}{\partial \alpha_k}\\<br/>
&amp;= -\sum_{j=1}^N \frac 1 \alpha_k \hat\gamma_{jk} + \beta<br/>
\end{align*}<br/>
\]</p>

<p>令导数为0，可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta}<br/>
\]</p>

<p>将 \(\alpha_k\) 代入 \(L(\alpha,\beta)\) 中，得到关于 \(\beta\) 的函数 \(\min_{\alpha_k}L(\alpha,\beta)\)：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\alpha_k} L(\alpha,\beta) &amp;= -\sum_{j=1}^N \sum_{k=1}^K[\log (\frac{\sum_{i=1}^N \hat\gamma_{ik}}{\beta})+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \frac{\sum_{i=1}^N \hat\gamma_{ik}}{\beta} -1)\\<br/>
&amp;=  -\sum_{j=1}^N \sum_{k=1}^K[\log \sum_{i=1}^N \hat\gamma_{ik} - \log\beta+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} +\sum_{i=1}^N \sum_{k=1}^K\hat\gamma_{ik}-\beta\\<br/>
\end{align*}<br/>
\]</p>

<p>拉格朗日乘子法可知需对 \(\min_{\alpha_k} L(\alpha,\beta)\) 求 \(\beta\) 的最大值，对 \(\beta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\min_{\alpha_k} L(\alpha,\beta)}{\partial \beta} = \frac{\sum_{j=1}^N\sum_{k=1}^K \hat\gamma_{jk}}{\beta} - 1 = \frac{N}{\beta} -1 <br/>
\end{align*}<br/>
\]</p>

<p>令导数为0，可得 \(\beta=N\)，代入可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{N}<br/>
\]</p>

<blockquote>
<p>其实不用拉格朗日求出 \(\beta\) 也可以，在求出 \(\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta}\) 后，直接考虑到：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{k=1}^K \alpha_k = 1 \quad &amp;\Rightarrow \quad \sum_{k=1}^K \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta} = 1\\<br/>
&amp;\Rightarrow \quad \frac{\sum_{j=1}^N \sum_{k=1}^K \hat\gamma_{jk}}{\beta} = 1\\<br/>
&amp;\Rightarrow \quad \frac{N}{\beta} = 1 \\<br/>
&amp;\Rightarrow \quad \beta = N<br/>
\end{align*}<br/>
\]</p>

<p>代入可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{N}<br/>
\]</p>
</blockquote>

<p>至此，我们在隐变量已知的情况下得到了GMM的三种类型参数的求解公式。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15103700734723.html">基于层次的聚类算法-自下向上-Rock算法</a></h1>
			<p class="meta"><time datetime="2017-11-11T11:14:33+08:00" 
			pubdate data-updated="true">2017/11/11</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	

		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15103338404339.html">基于划分的聚类算法-KMean算法与KMean++及优化</a></h1>
			<p class="meta"><time datetime="2017-11-11T01:10:40+08:00" 
			pubdate data-updated="true">2017/11/11</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<blockquote>
<p>聚类就是按照某个特定标准(如距离准则)把一个数据集分割成不同的类或簇，使得同一个簇内的数据对象的相似性尽可能大，同时不在同一个簇中的数据对象的差异性也尽可能地大。即聚类后同一类的数据尽可能聚集到一起，不同数据尽量分离。</p>
</blockquote>

<p>聚类算法还算比较常用的算法之一，我们在实际开发中，也经常需要用到。聚类算法的种类有很多，在后续遇到的时候再好好学习，这里来学习一种比较简单的聚类算法，<code>k-means</code>算法（<code>k-means</code>算法是距离准则的一种），以及它的几个变种算法。</p>

<h3 id="toc_0">k-means 算法</h3>

<p><code>k-means</code>是聚类方法中最常用的之一，该算法是以<code>k</code>为参数，将对象分成<code>k</code>个簇，使同一个簇中的元素尽可能的相似，不同簇的元素有很大的差异性。<code>k-means</code>的算法过程如下：</p>

<ol>
<li>随机在数据集中选出<code>k</code>个元素，假定为簇中心</li>
<li>对数据集中的每一个元素，找出离自己最近的那个簇中心，比如<code>k1</code>，那么这个元素便属于<code>k1</code>簇</li>
<li>遍历完所有的簇后，此时，每一个簇<code>k1,k2,k3...k</code>都包含若干元素，分别计算这些簇的平均值，作为新的簇中心</li>
<li>重复<code>2</code>,<code>3</code>直到所有数据点所属的簇不再发生变化，停止。至此，数据集划分成了<code>k</code>个簇。</li>
</ol>

<p>这个过程看起来十分简单，下面用代码实现，首先加载数据集：</p>

<pre><code class="language-python">import numpy as np
from matplotlib import pyplot as plt


# 加载数据集
def load_data_set():
    fr = open(file)
    data = []
    for line in fr.readlines():
        data.append(list(map(float, line.strip().split(&quot;\t&quot;))))
    return data

# 聚类
def split_group(data, center, k):
    group = {}
    cluster_change = False
    if isinstance(data, list):  # 如果是一个list，也就是第一次传入，默认假设分类为-1的
        data = {-1: data}
    for index, arr in data.items():
        for ele in arr:
            ele_arr = np.tile(ele, k).reshape(-1, 2)
            distance = np.sum((ele_arr - center) ** 2, axis=1)
            min_p = np.argmin(distance)
            if group.get(min_p) is None:
                group[min_p] = []
            group[min_p].append(ele)
            if cluster_change is False and min_p != index:
                cluster_change = True
    return group, cluster_change


def random_select(data,k):
    column_num = np.shape(data)[1]
    min_n = np.min(data, axis=0)
    max_n = np.max(data, axis=0)
    return np.random.uniform(min_n, max_n, (k,column_num))


if __name__ == &#39;__main__&#39;:
    file = &quot;/Users/Fei/Desktop/testSet.txt&quot;
    k = 4
    data = load_data_set()
    # 画出所有的点
    plt.subplot(111)
    # 从数据集中随机获取四个点，作为簇中心
    center = random_select(data,k)
    # center = np.random.uniform(random.choices(data, k=k))
    cluster = data.copy()
    cluster_change = True
    while cluster_change:
        # 循环每一个数据集找出离自己最近的簇中心，加入这个簇
        cluster, cluster_change = split_group(cluster, center, k)
        # 获取新的簇中心点
        center = np.array([np.sum(np.array(y), axis=0) / 20 for (x, y) in cluster.items()])
    # 绘制最终位置
    plt.scatter(np.array(cluster[0])[:, 0], np.array(cluster[0])[:, 1], c=&quot;black&quot;)
    plt.scatter(np.array(cluster[1])[:, 0], np.array(cluster[1])[:, 1], c=&quot;green&quot;)
    plt.scatter(np.array(cluster[2])[:, 0], np.array(cluster[2])[:, 1], c=&quot;blue&quot;)
    plt.scatter(np.array(cluster[3])[:, 0], np.array(cluster[3])[:, 1], c=&quot;yellow&quot;)
    plt.scatter(center[:, 0], center[:, 1], c=&quot;red&quot;)
    plt.show()

</code></pre>

<p>效果如下：</p>

<div align=center>
    <img width=450 src="media/15103338404339/15176316411276.jpg" />
</div>

<p>可以看到整个聚类还是比较成功的，当然其实这种方式还是有些缺点的</p>

<p>不足：<br/>
1、很多数据集我们事先并不知道到底分成多少个类比较合适，也就是<code>k</code>的值难以确定。<br/>
2、聚类的效果很大程度是需要依靠第一次随机<code>k</code>个簇中心的选择。如果第一次选择的<code>k</code>个簇中心的位置不好，比如两个簇中心相距很近，后面聚类效果可能并不理想。</p>

<h3 id="toc_1">k-means++ 算法</h3>

<p>为了上述解决第二个问题，我们直观上也应该觉得两个簇中心的距离应该越远越好，于是<code>k-means++</code>算法就出现了。<code>k-means++</code>算法首先会随机选出一个数据中的一个点做为簇中心，然后后面的几个簇中心的选择方法是：首先计算所有点和距离最近的簇中心的距离，距离越大的点作为簇中心的概率越大，重复执行多次，选出<code>k</code>个簇中心，然后使用<code>k-means</code>方法聚类。</p>

<p>该算法中关键点在于怎么选出<code>k</code>个簇中心。</p>

<pre><code class="language-python">data = load_data_set()
    # 随机选择一个点作为簇中心点
    centroids = random.choices(data,k=1)
    dists = {}
    # 遍历所有的点，找出与这个点最近的簇中心之间的距离
    data_len = len(data)
    for i in range(k-1):
        cent = centroids[i]
        # 绝对的最大最小
        dists[i] = np.sum(np.power(np.tile(cent, data_len).reshape((-1, 2)) - data,2),axis=1)
        centroids.append(random.choices(data, np.min([y for x,y in dists.items()],axis=0))[0])
</code></pre>

<p>上面代码虽然很少但是做的事情很多。关键点在于</p>

<pre><code class="language-python">random.choices(data, np.min([y for x,y in dists.items()],axis=0))[0]
</code></pre>

<p>这里先使用<code>np.min([y for x,y in dists.items()],axis=0)</code>方法求出每个点距离它最近的簇中心的距离，因为<code>[y for x,y in dists.items()]</code>第一行的元素表示每一个点距离第一个簇中心的距离，第二行的元素表示每个点距离第二个簇中心的距离......以此类推，以此对每一列求最小值既可得到每一个点距离最近的簇中心的距离。<br/>
然后我们将这个距离作为选择每一个点的概率，通过<code>random.choices()</code>方法即可实现。</p>

<p>完整代码如下：</p>

<pre><code class="language-python">import numpy as np
import random
from matplotlib import pyplot as plt

def load_data_set():
    data = []
    with open(file) as fr:
        for line in fr.readlines():
            data.append(list(map(float,line.strip().split(&#39;\t&#39;))))
    return data

def split_group(data, center, k):
    group = {}
    cluster_change = False
    if isinstance(data, list):  # 如果是一个list，也就是第一次传入，默认假设分类为-1的
        data = {-1: data}
    for index, arr in data.items():
        for ele in arr:
            ele_arr = np.tile(ele, k).reshape(-1, 2)
            distance = np.sum((ele_arr - center) ** 2, axis=1)
            min_p = np.argmin(distance)
            if group.get(min_p) is None:
                group[min_p] = []
            group[min_p].append(ele)
            if cluster_change is False and min_p != index:
                cluster_change = True
    return group, cluster_change

if __name__ == &#39;__main__&#39;:
    file = u&quot;/Users/Fei/Desktop/testSet.txt&quot;
    k = 4
    data = load_data_set()
    # 随机选择一个点作为簇中心点
    centroids = random.sample(data,1)
    dists = {}
    # 遍历所有的点，找出与这个点最近的簇中心之间的距离
    data_len = len(data)
    for i in range(k-1):
        cent = centroids[i]
        # 绝对的最大最小
        dists[i] = np.sum(np.power(np.tile(cent, data_len).reshape((-1, 2)) - data,2),axis=1)
        centroids.append(random.choices(data, weights=np.min([y for x,y in dists.items()],axis=0))[0])
    # 用得到的四个簇中心点来计算划分簇
    cluster = data.copy()
    cluster_change = True
    while cluster_change:
        # 循环每一个数据集找出离自己最近的簇中心，加入这个簇
        cluster, cluster_change = split_group(cluster, centroids, k)
        # 获取新的簇中心点
        centroids = np.array([np.sum(np.array(y), axis=0) / 20 for (x, y) in cluster.items()])
    # 绘制最终位置
    plt.scatter(np.array(cluster[0])[:, 0], np.array(cluster[0])[:, 1], c=&quot;black&quot;)
    plt.scatter(np.array(cluster[1])[:, 0], np.array(cluster[1])[:, 1], c=&quot;green&quot;)
    plt.scatter(np.array(cluster[2])[:, 0], np.array(cluster[2])[:, 1], c=&quot;blue&quot;)
    plt.scatter(np.array(cluster[3])[:, 0], np.array(cluster[3])[:, 1], c=&quot;yellow&quot;)
    plt.scatter(np.array(centroids)[:, 0], np.array(centroids)[:, 1], c=&quot;red&quot;)
    plt.show()
</code></pre>

<p>效果如下：</p>

<div align=center>
    <img width=450 src="media/15103338404339/15176479650413.jpg" />
</div>

<p>效果看上去和<code>k-means</code>一致，而在某些时候虽然只是改变了簇中心的选择，但是这十分有效。</p>

<h3 id="toc_2">KMean算法优化——elkan KMeans</h3>

<p>在传统的KMean算法中，每一次迭代需要求出所有样本点到所有质心间的距离，这样做会比较耗时。elkan KMeans利用了两边之和大于等于第三边,以及两边之差小于第三边的三角形性质，来减少距离的计算。</p>

<div align=center>
    <img width=450 src="media/15103338404339/15319350436275.jpg" />
</div>

<p>如上图，由三角形性质（两边之差小于第三边）可知：</p>

<p>\[<br/>
AB - AC \le BC<br/>
\]</p>

<p>当我们计算出质心A和质心B之间的距离AB后，当需要判断C与A和B哪个更近时，只需要再计算C与A之间的距离AC，如果<br/>
\[<br/>
2AC \le AB \quad \Rightarrow \quad AC \le AB - AC \le BC \quad \Rightarrow \quad AC \le BC<br/>
\]</p>

<p>那么便省去了计算B与C的距离BC。</p>

<h3 id="toc_3">KMeans算法优化——Mini Batch KMeans</h3>

<p>在统的K-Means算法中，要计算所有的样本点到所有的质心的距离。如果样本量非常大，比如达到10万以上，特征有100以上，此时用传统的K-Means算法非常的耗时，就算加上elkan KMeans优化也依旧。在大数据时代，这样的场景越来越多。此时Mini Batch K-Means应运而生。</p>

<p>顾名思义，Mini Batch，也就是用样本集中的一部分的样本来做传统的K-Means，这样可以避免样本量太大时的计算难题，算法收敛速度大大加快。当然此时的代价就是我们的聚类的精确度也会有一些降低。一般来说这个降低的幅度在可以接受的范围之内。</p>

<p>在Mini Batch K-Means中，我们会选择一个合适的批样本大小batch size，我们仅仅用batch size个样本来做K-Means聚类。那么这batch size个样本怎么来的？一般是通过无放回的随机采样得到的。</p>

<p>为了增加算法的准确性，我们一般会多跑几次Mini Batch K-Means算法，用得到不同的随机采样集来得到聚类簇，选择其中最优的聚类簇。</p>

<hr/>

<p><a href="http://www.cnblogs.com/pinard/p/6164214.html">K-means聚类算法原理</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15097627425135.html">KNN 算法 与 KD树</a></h1>
			<p class="meta"><time datetime="2017-11-04T10:32:22+08:00" 
			pubdate data-updated="true">2017/11/4</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<h3 id="toc_0">KNN 算法</h3>

<p>KNN 算法全称是 K-Nearest Neighbors，中文名称 K 近邻算法，作为一种基本的分类算法。KNN采用一种投票表决的方式，首先在样本空间里选出目标对象最相似的 K 个近邻，用这 K 个近邻大多数归属的类别作为目标对象的类别，其中 K 通常是不大于20的整数。KNN算法中，所选择的近邻都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。</p>

<p>如下图是两个部落居民居住分布图：</p>

<div align=center>
    <img width="300" src="media/15097627425135/15316253197416.jpg" />
</div>

<p>如果要用 KNN 方法裁决金矿所有权，采用 \(K=1\) 时，会认为金矿属于B部落，因为离金矿最近的居民（对象）属于B部落（类别），所以金矿（目标对象）属于B部落：</p>

<div align=center>
    <img width="300" src="media/15097627425135/15316252573368.jpg" />
</div>

<p>如果采用 \(K=3\) 时，情况就会不同，认为金矿属于A部落，离金矿最近的3个居民（对象）中，有2个（大多数）属于A部落，所以金矿（目标对象）属于A部落：</p>

<div align="center">
    <img width="300" src="media/15097627425135/15316253946661.jpg" />
</div>

<p>在这个例子中，<strong>最相近</strong>用的是欧几里得距离：</p>

<p>\(D = \sqrt{{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}}\)</p>

<p>在实际项目中，可能还会采用其他距离，如曼哈顿距离：<br/>
\(D = \|x_{1}-x_{2}\|+\|y_{1}-y_{2}\|\)</p>

<p>在KNN算法中，由于k选择的不同，得到的分类也可能是不同的，如当 \(K=1\) 时，金矿属于B部落，而当 \(K=3\) 时，金矿属于A部落。</p>

<h5 id="toc_1">算法步骤：</h5>

<ol>
<li>计算目标对象与各训练数据之间的距离；</li>
<li>按照距离的递增关系进行排序；</li>
<li>选取与目标对象距离最小的K个点；</li>
<li>确定目标对象最近的 K 个点所在类别的出现频率；</li>
<li>返回前K个点中出现频率最高的类别作为目标对象的预测分类。</li>
</ol>

<h5 id="toc_2">算法缺点</h5>

<p>从算法上来看，KNN 算法有一些缺点：<br/>
1）只计算了最近 K 个邻居的类别，而未考虑 K 个邻居远近程度，也就是距离近的邻居和距离远的邻居具有相同的投票权。因此，我们可以采用权值的方法来改进，和该样本距离小的邻居权值大，和该样本距离大的邻居权值则相对较小，由此，将距离远近的因素也考虑在内，避免因一个样本过大导致误判的情况；</p>

<p>2）在计算时，需要计算所有待分类对象与所有训练对象的距离，再进行排序选择出最近的 K 个邻居。因此我们需要一种快速搜索近邻的算法，一种比较常见的算法就是KD树。</p>

<h3 id="toc_3">BST树</h3>

<p>在介绍KD树之前，先介绍一种一维形式二叉查找树 BST（Binary Search Tree），可以快速定位一维数据，如下图：</p>

<div align="center">
    <img width="250px" src="media/15097627425135/15316274460262.jpg" />
</div>

<p>BST 具有以下性质：</p>

<ol>
<li>若它的左子树不为空，则它的左子树节点上的值皆小于它的根节点。</li>
<li>若它的右子树不为空，则它的右子树节点上的值皆大于它的根节点。</li>
<li>它的左右子树也分别是二叉查找树。</li>
</ol>

<p>当上图中，要搜索结点64便很简单，将64与根结点56比较，64比56大，在它的的右子树上；将64与子结点78比较，64比78小，在结点78的左子树上；如此递归下去，很容易搜索到结果。</p>

<p>构造BST树也非常简单，在集合中选择一个点作为根结点（尽可能选择一个使左右子树深度差不多的点，如中位点），然后按照上面方法找到一个叶结点作为父结点，按照左小右大开辟新结点。假设上例中，我们需要插入一个72的结点，比较根结点56与72，56小于72，在根结点56的右子树上；发现结点78，比较72与78，72小于78，在结点78的左子树上；发现结点64，因为64是叶结点，需要开辟新结点，72比64大，所以将结点72作为64的右结点：</p>

<div align="center">
    <img width="250" src="media/15097627425135/15316291384018.jpg" />
</div>

<p>如果再插入点60，发现结点64后，60比64小，且64不含左子树，开辟新结点60作为64的左子结点，如下：</p>

<div align="center">
    <img width="250" src="media/15097627425135/15316290927517.jpg" />
</div>

<p>下面叙述在BST上搜索最近邻的方法：</p>

<ol>
<li>在BST树上找到包含目标点 x 的叶结点：从根结点出发，递归向下访问BST树，如目标结点小于切分点的值，则移动到左子结点，否则移动到右子结点，直到子结点为叶结点为止，记录当前搜索路径 search_path。</li>
<li>从 search_path 中取出最后一个点作为”当前最近点“，计算距离=该叶结点与目标结点距离，并设为“当前最近距离”。</li>
<li>回溯搜索路径 search_path，对每个结点计算该结点和目标结点的距离，如果该距离小于当前最小距离，则更新该结点为“当前最近点”，并更新“当前最近距离”为该距离。</li>
</ol>

<p>在一维数据上，可以通过BST树来实现。拓展到k维数据上，便可以通过构建KD树来迅速搜索最近邻。</p>

<h3 id="toc_4">KD树</h3>

<p>假设输入为k维空间的数据集 \(D=(x_1,x_2,...,x_N)\)，其中 \(x_i = (x_i^{(1)},x_i^{(2)},...,x_i^{(k)})\)，输出为KD树。</p>

<ol>
<li>开始：构造根结点，根结点对于包含 \(D\) 的k维空间的超矩形区域。</li>
<li>选择 \(x^{(1)}\) 为坐标轴，以 \(D\) 中所有实例的 \(x^{(i)}\) 坐标的中位数（偶数个数，其中任何一个都可以）为切分点，将根结点分为两个区域，切分由通过切分点并与坐标轴垂直的超平面实现。由根结点生成深度为1的左、右子结点；左子结点对应坐标 \(x^{(i)}\) 小于切分点的子区域，右子结点对应坐标 \(x^{(i)}\) 大于切分点的子区域。落在超平面的实例点保存在根结点。</li>
<li>重复：对深度为 j 的结点，选择 \(x^{(l)}\) 为切分的坐标轴，其中 \(l=j\%k+1\) ，以该结点的区域中所有实例的 \(x^{(l)}\) 坐标的中位数为切分点，将该结点对应的区域分成两个子区域，切分由通过切分点并与坐标轴 \(x^{(l)}\) 垂直的超平面实现。由该结点生成深度 j+1 的左右子结点。左子结点对应坐标 \(x^{(l)}\) 小于切分点的子区域，右子结点对应坐标 \(x^{(l)}\) 大于切分点的子区域。</li>
<li>直到两个子区域没有实例存在时则结束，此时形成了KD树的特征空间划分。</li>
</ol>

<p>举个2维空间的例子，数据集 \(D=((2,3)^T,(5,4)^T,(9,6)^T,(4,7)^T,(8,1)^T,(7,2)^T)\)构造平衡KD树。</p>

<p>1）构造根结点为包含 \(D\) 的k维空间的超矩形区域。</p>

<div align="center">
    <img width="300" src="media/15097627425135/15316691655134.jpg" />
</div>

<p>2）选择 \(x^{(1)}\) 轴，所有实例的 \(x^{(1)}\) 轴值为（2，5，9，4，8，7），中位数为7，切分为过7且与 \(x^{(i)}\) 轴垂直的超平面：</p>

<div align="center">
    <img width="300" src="media/15097627425135/15316729790397.jpg" />
</div>

<p>3）分割超平面将根结点分成两部分，其中 \(x^{(1)} \lt 7\) 的分为左子结点，分别为 \(((2,3)^T,(4,7)^T,(5,4)^T)\)，\(x^{(1)} \gt 7\) 的分为右子结点，分别为 \(((8,1)^T,(9,6)^T)\)。左子结点 \(x^{(2)}\) 轴的中位数为4，右子结点 \(x^{(2)}\) 轴的中位数为6，分别过中位数且垂直 \(x^{(2)}\) 轴作分割超平面：</p>

<div align="center">
    <img width="300" src="media/15097627425135/15316732569554.jpg" />
</div>

<p>4）对上面过程形成的左右结点，深度为2，选择 \(x^{(1)}\) 轴进行分割：</p>

<div align="center">
    <img width="300" src="media/15097627425135/15316735112236.jpg" />
</div>

<p>特征空间划分完成，对分割线上的结点，可以建立KD树：</p>

<div align="center">
    <img width="300" src="media/15097627425135/15316743917066.jpg" />
</div>

<h3 id="toc_5">KD树最近邻搜索</h3>

<p>KD树的最近邻搜索同BST大同小异：</p>

<ol>
<li>在KD树上找到包含目标点 x 的叶结点：从根结点出发，递归向下访问KD树，如目标结点小于切分点的值，则移动到左子结点，否则移动到右子结点，直到子结点为叶结点为止，记录沿途经过点为search_path。</li>
<li>从 search_path 中取出最后一个点为”当前最近点“，计算距离=该结点与目标结点距离，并设为“当前最近距离”。</li>
<li><p>回溯搜索路径 search_path，对每个结点执行以下操作：</p>

<p>（a）如果该结点保存的实例点比当前最近点距目标点更近，则以该实例点为“当前最近点”；<br/>
（b）当前节点为根节点，结束。否则检查该子结点的父结点的另一个子结点对应的区域是否有更近的点。具体的，检查另一个子结点对应的区域是否与以目标点为球心、以目标点与“当前最近点”间的距离为半径的超球体相交。如果相交，可能在另一个子结点对应的区域内存在距离目标更近的点，移动到另一个子结点，<font color=red>将其当做根节点，重复步骤1，2，3进行目标节点最近邻搜索</font>。如果不相交，向上回退。</p></li>
</ol>

<p>举个一个例子来阐述这个算法：假设数据集 \(D = ((4,1)^T,(3,4)^T,(5,4)^T,(2,3)^T,(3,5)^T,(5,3)^T,(4.1,9)^T)\)，需要搜索最近邻的对象为 \((4.1,5)\) ，这里生成KD树的步骤直接省略，生成的KD树如下：</p>

<div align="center">
    <img width="320" src="media/15097627425135/15319189036938.jpg" />
</div>

<p>生成的特征空间如下：</p>

<div align="center">
    <img width="250" src="media/15097627425135/15319274240539.jpg" />
</div>

<p>从根节点 \((4,1)\) 开始，递归向下搜索KD树，第一个切分点值为 \(4\) ，小于目标节点对应值 \(4.1\)，移动到右子节点 \((5,4)\) ；第二个切分点值为 \(4\) ，小于目标节点对应值 \(9\) ，移动到右子节点 \((4.1,9)\) ，该节点为叶节点，记录沿途经过点为 search_path 为 \(((4,1)^T,(5,4)^T，(4.1,9)^T)\) 。</p>

<p>从 search_path 中取出最后一个点 \((4.1,9)^T\) ，步骤（a）：计算该节点与目标节点 \((4.1,5)^T\) 的距离为4，设该节点为“当前最近点”，当前距离为“当前最近距离”；步骤（b）：以 \((4.1,5)^T\) 为圆心，4为半径作圆，与超平面 \(y=4\) 相交，最近点可能在父节点的另一个节点 \((5,3)^T\) 上，将 \((5,3)^T\) 当做根节点，进行最近邻搜索。</p>

<ul>
<li>因为 \((5,3)^T\) 是叶节点，直接计算它与目标节点的距离为2.19，小于“当前最近距离”，更新“当前最近点”为 \((5,3)^T\) 和更新“当前最近距离”为2.19。</li>
</ul>

<div align="center">
    <img width="270" src="media/15097627425135/15366780863386.jpg" />
</div>

<p>从 search_path 中取出最后一个点 \((5,4)^T\) ，步骤（a）：计算该节点与目标节点 \((4.1,5)^T\) 的距离为1.35，小于“当前最近距离”，更新&quot;当前最近点&quot;为 \((5,4)^T\) 和更新”当前最近距离“为1.35；步骤（b）：以 \((4.1,5)^T\) 为圆心，1.35为半径作圆，与超平面 \(x=4\) 相交，最近点可能在父节点的另外一个节点 \((3,4)^T\) 上，将 \((3,4)^T\) 当做根节点，搜索最近邻。</p>

<div align="center">
    <img width="270" src="media/15097627425135/15366782535217.jpg" />
</div>

<ul>
<li>从根节点 \((3,4)^T\) 开始搜索目标节点 \((4.1,5)^T\) 的最近邻，\((3,4)^T\) 切分点的值是4，目标节点 \((4.1,5)^T\) 对应位置值 5 大于切分点，在 \((3,4)^T\) 的右子节点 \((3,5)^T\) 上，因为\((3,5)^T\)是叶节点搜索结束，此时 \(\text{search_path}^{*}\) 为 \(((3,4)^T,(3,5)^T)\) 。</li>
<li>从 \(\text{search_path}^{*}\) 中取出最后一个点 \((3,5)^T\)，步骤（a）：计算该节点与目标节点的距离为1.10，小于“当前最近距离”，更新“当前最近点“为 \((3,5)^T\) 和”更新当前最近距离“为1.10；步骤（b）：以 \((4.1,5)^T\) 为圆心，1.10为半径作圆，与超平面 \(y=4\) 相交，最近点可能在父节点的另外一个节点 \((2,3)^T\) 上，将 \((2,3)^T\) 当做根节点，搜索最近邻，由于\((2,3)^T\) 是叶节点，直接计算与目标节点的距离为2.9，大于“当前最近距离”，不更新。</li>
<li>从 \(\text{search_path}^{*}\) 中取出最后一个点 \((3,4)^T\)，步骤（a）：计算该节点与目标节点的距离为1.49，大于“当前最近距离”，不更新。步骤（b）：当前节点为根节点，结束。</li>
</ul>

<p>从 search_path 中取出最后一个点 \((4,1)^T\) ，步骤（a）：计算该节点与目标节点的距离为4.001，大于“当前最近距离”，不更新；步骤（b）：当前节点为根节点，结束。</p>

<p>所以“最近点”为 \((3,5)^T\) ，当前最近距离为1.10。</p>

<h3 id="toc_6">KD树相关代码</h3>

<p>节点定义</p>

<pre><code class="language-python">class KD_node:
    def __init__(self, point=None, split=None, LL = None, RR = None, parent = None):
        &quot;&quot;&quot; 
        point:数据点 
        split:划分域 
        LL, RR:节点的左子节点跟右子节点
        parent:父节点
        &quot;&quot;&quot;
        self.point = point
        self.split = split
        self.left = LL
        self.right = RR
        self.parent = parent
</code></pre>

<p>创建KD树：</p>

<pre><code class="language-python">def createKDTree(root,data_list,split=0,parent=None):
    &quot;&quot;&quot; 
    root:当前树的根节点 
    data_list:数据点的集合(无序) 
    return:构造的KDTree的树根 
    &quot;&quot;&quot;
    LEN = len(data_list)
    if LEN == 0:
        return
    # 数据点的维度
    dimension = len(data_list[0])
    # 根据划分域的数据对数据点进行排序
    data_list.sort(key=lambda x: x[split])
    # 选择下标为len / 2的点作为分割点
    point = data_list[LEN // 2]
    root = KD_node(point, split, parent=parent)
    root.left = createKDTree(root.left, data_list[0:(LEN // 2)],(split+1)%dimension,root)
    root.right = createKDTree(root.right, data_list[(LEN // 2 + 1):LEN],(split+1)%dimension,root)
</code></pre>

<p>搜索最近邻步骤1：搜索KD树代码</p>

<pre><code class="language-python">def findKD(root, query):
    &quot;&quot;&quot;
    root: KDTree的树根
    query: 查询点
    return: 返回KD树查找到的叶节点
    &quot;&quot;&quot;
    temp_root = root
    next = None
    ##二分查找建立路径
    while temp_root.left and temp_root.right:
        # 当前节点的划分域
        ss = temp_root.split
        if query[ss] &lt;= temp_root.point[ss]:
            next = temp_root.left
        else:
            next = temp_root.right
        if next is None:
            break
        else:
            temp_root = next
    return temp_root
</code></pre>

<p>步骤2：搜索最近邻代码</p>

<pre><code class="language-python">    def findNN(root, query, NN = None, min_dist = None):
    &quot;&quot;&quot; 
    root:KDTree的树根 
    query:查询点 
    return:返回距离data最近的点NN，同时返回最短距离min_dist 
    &quot;&quot;&quot;
    # 初始化为root的节点
    temp_root = findKD(root,query)
    dist = computeDist(query, temp_root.point)
    if min_dist is None or dist &lt; min_dist:
        min_dist = dist
        NN = temp_root.point
    while root != temp_root:
        if temp_root.parent:
            ss = temp_root.parent.split
            if abs(query[ss] - temp_root.parent.point[ss]) &lt; min_dist:
                if query[ss] &lt;= temp_root.parent.point[ss]:
                    brother = temp_root.parent.right
                else:
                    brother = temp_root.parent.left
                NN,min_dist = findNN(brother, query, NN, min_dist)
        temp_root = temp_root.parent
        dist = computeDist(query,temp_root.point)
        if dist &lt; min_dist:
            min_dist = dist
            NN = temp_root.point

    return NN, min_dist
</code></pre>

<h3 id="toc_7">KD树搜索K邻域</h3>

<p>搜索最近邻了解后，搜索K邻域便很简单，维护一个存放节点和对应距离的堆，将搜索最近邻过程中计算的节点和相应的距离加入其中，如果堆的大小小于K，直接加入；如果堆的大小等于K，则替换最大距离的节点。搜索结束后，输出K邻域即可。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15092133657181.html">决策树 Decision Tree</a></h1>
			<p class="meta"><time datetime="2017-10-29T01:56:05+08:00" 
			pubdate data-updated="true">2017/10/29</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>决策树，英文名称是Decision Tree（简称DT）。DT是一种树形结构，它的每一个内部节点表示属性上的一次判断，每一个分支代表一种结果的输出，最后的每一个叶节点代表一种结果。决策树的决策过程需要从决策树的根节点开始，待测数据与决策树中的特征节点进行比较，并按照比较结果选择选择下一比较分支，直到叶子节点作为最终的决策结果。决策树在分类问题上可以看做if-then的集合，主要优点是模型具有很高的可读性和执行速度快。</p>

<h3 id="toc_0">决策树学习</h3>

<p>决策树学习是指利用训练数据通过最小化损失函数找到最佳分类特性和阈值，进而建立决策树。决策树的生成包括特征选择、决策树生成和决策树修剪这三个流程，后面会重点介绍这三个流程。决策树通常使用的损失函数是正则化的极大似然函数，当损失函数确定后，学习问题就变成在损失函数意义下选择最优决策树的问题。决策树的算法通常是一个递归选择最优特征，然后根据特征对数据集进行分类，得到子集，使各个子集在当前特征条件下是最好的分类。如果这个子集已经被正确分类，则停止。否则继续对这个子集选择新的最优特征，继续对其进行分割，如此递归下去直到所有的子集都被正确分类。决策树的剪枝是为了使树更加简单，减少对训练数据的拟合，使决策树能够适应更多未知问题。决策树可以认为是一种贪心算法，得到的解可能并不是最优解。</p>

<h4 id="toc_1">特征选择</h4>

<p>特征选择是决策树学习中最重要的步骤，直接决定着决策树的好坏。当一个特征进行分类的结果与随机分类的结果没有较大差别，那么我们认为这个特征是没有分类能力的，经验上来说可以扔掉这样的特征。特征选择是用来确定通过哪个特征来划分特征空间，特征选择的目的：使用某特征对数据集划分之后，各数据子集的纯度要比划分前的数据集的纯度高，这里划分后的纯度表示为各子集的纯度的带权和。通常有几个常见的评判标准：</p>

<h5 id="toc_2">信息熵 Entropy</h5>

<p>首先看一下信息熵的定义，信息熵表示一个信息所含有的信息量的大小，同时也说明一个信息的不确定度的大小。如果我们有一个六面都是1的骰子，不论怎么掷它，我们知道结果肯定是1，没有任何不确定度，所以信息熵为0。</p>

<p>接下来从数学的角度，描述熵的定义：假设随机变量X的可能取值有\(x_1\)，\(x_2\)， ... , \(x_n\)，对于每一个可能的取值 \(x_i\)，其概率 \(P(X=x_i) = p_i , ( i = 1,2, ... , n)\)。随机变量X的信息熵：<br/>
\[<br/>
H(X) = -\sum_{i=1}^N p_i \log p_i<br/>
\]</p>

<p>这里的信息熵通常是以2为底数，具体计算中以什么为底数并没有什么影响，当以2为底数时，信息熵的单位为比特。底数不同时，单位不同，意义相同。在以下计算中，以e为底数来方便计算。而信息熵前面的负号是因为概率通常小于等于1，取对数后小于等于0，为使结果为非负数，所以加上负号。</p>

<p>而对于一个数据集D，有 k 个类别，每一个类别用 \(\text{C}_k\) 表示，数量为 \(|\text{C}_k|\) ，则每一个类别的概率为 \(\frac{|\text{C}_k|}{|\text{D}|}\) ，样本集合D的经验熵：<br/>
\[<br/>
H(D) = -\sum_{k=1}^N \frac{|\text{C}_K|}{|D|} \log \frac{|\text{C}_K|}{|D|}<br/>
\]</p>

<p>这里举个例子：假设训练样本记录了一个人14天的天气、温度、湿度、风四个特征和是否出去玩的情况：<br/>
\[<br/>
\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
日期&amp;天气&amp;温度&amp;湿度&amp;风&amp;是否出去玩\\\hline<br/>
01  &amp;晴天&amp;高温&amp;高  &amp;弱&amp;否\\\hline<br/>
02  &amp;晴天&amp;高温&amp;高  &amp;强&amp;否\\\hline<br/>
03  &amp;阴天&amp;高温&amp;高  &amp;弱&amp;是\\\hline<br/>
04  &amp;下雨&amp;中温&amp;高  &amp;弱&amp;是\\\hline<br/>
05  &amp;下雨&amp;凉爽&amp;中  &amp;弱&amp;是\\\hline<br/>
06  &amp;下雨&amp;凉爽&amp;中  &amp;强&amp;否\\\hline<br/>
07  &amp;阴天&amp;凉爽&amp;中  &amp;强&amp;是\\\hline<br/>
08  &amp;晴天&amp;中温&amp;高  &amp;弱&amp;否\\\hline<br/>
09  &amp;晴天&amp;凉爽&amp;中  &amp;弱&amp;是\\\hline<br/>
10  &amp;下雨&amp;中温&amp;中  &amp;弱&amp;是\\\hline<br/>
11  &amp;晴天&amp;中温&amp;中  &amp;强&amp;是\\\hline<br/>
12  &amp;阴天&amp;中温&amp;高  &amp;强&amp;是\\\hline<br/>
13  &amp;阴天&amp;高温&amp;中  &amp;弱&amp;是\\\hline<br/>
14  &amp;下雨&amp;中温&amp;高  &amp;强&amp;否\\<br/>
\end{array}<br/>
\]</p>

<p>设是否出去玩为随机变量Y，则：<br/>
\[<br/>
P(Y=\text{是}) = \frac{9}{14}\\<br/>
P(Y=\text{否}) = \frac{5}{14}\\<br/>
\]</p>

<p>所以：<br/>
\[<br/>
H(Y) = - P(Y=\text{是})\log P(Y=\text{是}) - P(Y=\text{否})\log P(Y=\text{否}) = -\frac{9}{14}\log \frac{9}{14} - \frac{5}{14}\log\frac{5}{14} = 0.6518<br/>
\]</p>

<h5 id="toc_3">代码示例</h5>

<pre><code class="language-python">## 最后一行是标签
def calculateEntropy(data):
    count = len(data)
    labelCounts = np.unique(data[:,-1],return_counts=True)[1]
    entropy = 0
    for labelCount in labelCounts:
        entropy -= labelCount/count * math.log(labelCount/count)
    return entropy
</code></pre>

<h5 id="toc_4">条件熵 Condition Entropy</h5>

<p>条件熵表示在某个条件下的信息熵， \(P(Y|X)\) 则表示在 \(X\) 的条件下 \(Y\) 的信息熵：<br/>
\[<br/>
H(Y|X) = \sum_{x\in X} P(x) H(Y|X=x)<br/>
\]</p>

<p>在上个例子中若 \(X\) 表示湿度，使用 \(Y\) 表示是否出去玩，则：<br/>
\[<br/>
P(x=\text{高}) = \frac{7}{14} = \frac 1 2\\<br/>
P(\text{Y=是}|x=\text{高}) = \frac{3}{7}\\<br/>
P(\text{Y=否}|x=\text{高}) = \frac{4}{7}\\<br/>
P(x=\text{中}) = \frac{7}{14} = \frac 1 2\\<br/>
P(\text{Y=是}|x=\text{中}) = \frac 6 7\\<br/>
P(\text{Y=否}|x=\text{中}) = \frac 1 7<br/>
\]</p>

<p>所以信息熵：<br/>
\[<br/>
\begin{align*}<br/>
H(Y|x=\text{高}) &amp;= -P(\text{是}|x=\text{高}) \log P(\text{是}|x=\text{高}) - P(\text{否}|x=\text{高})\log P(\text{否}|x=\text{高}) \\<br/>
&amp;= -\frac 3 7 \log(\frac 3 7) - \frac 4 7 \log(\frac 4 7) = 0.6829\\<br/>
H(Y|x=\text{中}) &amp;= -P(\text{是}|x=\text{中}) \log P(\text{是}|x=\text{中}) - P(\text{否}|x=\text{中})\log P(\text{否}|x=\text{中}) \\<br/>
&amp;= -\frac 6 7 \log(\frac 6 7) - \frac 1 7 \log(\frac 1 7) = 0.41<br/>
\end{align*}<br/>
\]</p>

<p>条件熵为：<br/>
\[<br/>
\begin{align*}<br/>
H(Y|X) &amp;= P(x=\text{高})H(Y|x=\text{高})+P(x=\text{中})H(Y|x=\text{中})\\<br/>
&amp;= \frac 1 2 \times 0.6829 + \frac 1 2 \times 0.41 = 0.5465<br/>
\end{align*}<br/>
\]</p>

<h5 id="toc_5">代码示例</h5>

<pre><code class="language-python"># 以data的第i行为条件，data的最后一行为标签
def calculateConditionEntropy(data,k):
    entropy = 0
    count = len(data)
    labelLabels, labelCounts = np.unique(data[:,k],return_counts=True)
    for i in range(len(labelLabels)):
        entropy += labelCounts[i]/count * calculateEntropy(data[data[:,k] == labelLabels[i]])
    return entropy
</code></pre>

<h5 id="toc_6">信息增益 Information Gain</h5>

<p>信息增益是指以某特征划分数据集前后熵的差值，我们认为在数据集划分前熵的值已经是确定的，而划分后，如果得到的熵越小，也就是各子集的混乱度越小，纯度越高。因此在选择特征的时候，选择使划分后熵最小的特征，这一点有点类似于梯度下降法，通常会选择梯度最大的方向。定义信息增益为Y的信息熵减去在特征X下的条件熵，即：<br/>
\[<br/>
IG(X) = H(Y) - H(Y|X)<br/>
\]</p>

<p>所以上例子中，\(IG(X) = 0.6518-0.5465 = 0.1053\) ，用相同的方式我们可以求出其他特征的信息增益。</p>

<p>优点：容易理解，计算简单。<br/>
缺点： <br/>
1.信息增益考察的是特征对整个系统的贡献（所有类别使用相同的特征集合），没有到具体的类别上，所以一般只能用来做全局的特征选择，而没法针对单个类别做特征选择（每一个类别有自己的特征集合）。 <br/>
2.只能处理连续型的属性值，没法处理连续值的特征。 <br/>
3.算法天生偏向选择分支多的属性，容易导致overfitting。</p>

<h5 id="toc_7">信息增益比 Infomation Gain Ratio</h5>

<p>在上面提到信息增益天生偏向选择分支多的属性，举个极端的例子：刚才的例子中，如果选择的特征是第一列日期，那么每一天都会被分到一个单独的类中，此时一个类也只有一条记录，此时子集信息熵会变成0，但是这并不是我们希望得到的。为了解决这个问题，自然想到的就是给分支多的特征加以惩罚，定义惩罚系数 \(\text{pub}\) 。于是便有了信息增益比：<br/>
\[<br/>
IGR(X) = \text{pub}\cdot IG(X)<br/>
\]</p>

<p>其中惩罚系数定义为 \(\text{pub}\)：<br/>
\[<br/>
\text{pub} = \frac{1}{\text{IntI}(X)}<br/>
\]</p>

<p>这里的 \(\text{IntI}(X)\) 定义为属性 X 的固有信息（Intrinsic Information of an Attribute），还记得我们在前面信息熵小节里说过数据集D有k个类别 \(C_1,C_2,...,C_k\)，样本集合D的经验熵的计算，这个固有信息便可以理解为这里的经验熵：<br/>
\[<br/>
H(D) = -\sum_{k=1}^N \frac{|\text{C}_K|}{|D|} \log \frac{|\text{C}_K|}{|D|}<br/>
\]</p>

<p>所以代入这里，便是：<br/>
\[<br/>
\text{pub} = \frac{1}{H(X)} = \frac{1}{-\sum_{k=1}^N \frac{|\text{C}_K|}{|X|} \log \frac{|\text{C}_K|}{|X|}}\\<br/>
\] </p>

<p>当我们使用信息增益比时会更加偏向于选择分支较少的特征，为了解决这个问题，一个做法是先通过信息增益过滤掉小于平均增益的特征，然后对剩余特征比较信息增益比，使用信息增益比最大的特征进行分类。</p>

<h4 id="toc_8">决策树的生成</h4>

<p>以下就 ID3算法、C4.5算法、CART算法了解决策树的生成：</p>

<h5 id="toc_9">ID3 算法</h5>

<p>ID3决策树的英文名称是 Iterative Dichotomiser 3，即迭代二叉树3代，它在决策树各节点特征选择上使用信息增益准则，递归选择决策树。从根结点开始，对结点计算所有可能特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征划分形成子结点；再对子结点递归地调用以上方法，构建决策树；直到所有特征的信息增益均很小或没有可以选择的特征为止，最后得到一个决策树。</p>

<p><b>输入</b>：训练数据集D，特征集A，阈值 \(\epsilon\)<br/>
<b>输出</b>：决策树T<br/>
<b>算法过程</b>：<br/>
（1）若 D 中所有实例都属于同一类别 \(C_k\)，则 T 为单结点树，并将 \(C_k\) 做为该结点的类标记，返回 T；<br/>
（2）若 A=\(\varnothing\)，则T为单结点树，将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记；<br/>
（3）计算 A 中的各特征对数据 D 的信息增益，选择信息增益最大的特征 \(A_z\)；<br/>
（4）如果 \(A_z\) 的信息增益小于阈值 \(\epsilon\) ，则置 T 为单结点树，并将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记，返回 T；<br/>
（5）否则，对 \(A_z\) 的每一个可能去值 \(a_i\) ，将 D 分给成若干个非空子集 \(D_i\)，将 \(D_i\) 中实例树最大的类作为标记，构建子节点，由结点及其子结点构成树 T，返回 T；<br/>
（6）对第 i 个子结点，以 \(D_i\) 为训练集，以 \(A-A_z\) 为特征集，递归地调用（1）～（5）步，得到子树 \(T_i\)，返回 \(T_i\)。</p>

<h5 id="toc_10">代码示例</h5>

<p>代码每次创建子树都会删除已经划分的特征，可以优化一下。</p>

<pre><code class="language-python">import os
import numpy as np
import math

class Cluster():
    def __init__(self, label=&quot;&quot;, feature=&quot;&quot;):
        self.label = label
        self.feature= feature
        self.children = []
        self.data = []

    def addData(self, data):
        self.data.extend(data)

def loadData():
    fileName = &quot;14day.txt&quot;
    if not os.path.exists(fileName):
        print(&quot;Data File Not Exists&quot;)
        return
    feature = []
    data  = []
    with open(fileName) as fOpen:
        for index,line in enumerate(fOpen.readlines()):
            if index == 0:
                feature = line.strip().split(&quot; &quot;)
            else:
                data.append(line.strip().split(&quot; &quot;))
    return feature,data

def calculateEntropy(data):
    count = len(data)
    labelCounts = np.unique(data[:,-1],return_counts=True)[1]
    entropy = 0
    for labelCount in labelCounts:
        entropy -= labelCount/count * math.log(labelCount/count)
    return entropy

def calculateConditionEntropy(data,k):
    entropy = 0
    count = len(data)
    labelLabels, labelCounts = np.unique(data[:,k],return_counts=True)
    for i in range(len(labelLabels)):
        entropy += labelCounts[i]/count * calculateEntropy(data[data[:,k] == labelLabels[i]])
    return entropy

def createTree(feature, data):
    data = np.array(data)
    if len(set(data[:,-1])) == 1:
        cluster = Cluster(data[-1,-1])
        cluster.addData(data)
        return cluster
    if len(feature) == 0:
        tempLabel,tempCount = np.unique(data[:,-1],return_counts=True)
        maxLabel = tempLabel[np.argmax(tempCount)]
        cluster = Cluster(maxLabel)
        cluster.addData(data)
        return cluster

    # 计算当前信息熵
    # entropyBefore = calculateEntropy(data)
    minEntropy = math.inf
    minIdex = -1
    for i in range(len(feature)-1):
        entropy = calculateConditionEntropy(data,i)
        if entropy &lt; minEntropy:
            minEntropy = entropy
            minIdex = i
    print(&quot;划分:&quot;+feature[minIdex])
    cluster = Cluster(feature=feature[minIdex])
    newFeature = list(np.delete(feature,minIdex))
    newLabel = set(data[:,minIdex])
    for label in newLabel:
        newData = np.delete(data[data[:,minIdex]==label],minIdex,axis=1)
        newCluster = createTree(newFeature,newData)
        cluster.children.append(newCluster)
    return cluster

if __name__ == &quot;__main__&quot;:
    feature, data = loadData()
    root = createTree(feature, data)
    print(feature)
</code></pre>

<h4 id="toc_11">C4.5算法</h4>

<p>C4.5算法与ID3算法类似，不同的是在树的生成过程中，使用信息增益率来进行选择特征。</p>

<p><b>输入</b>：训练数据集 D，特征集 A ，阈值 \(\epsilon\)<br/>
<b>输出</b>：决策树 T<br/>
<b>算法过程</b>：<br/>
（1）若 D 中所有实例都属于同一类别 \(C_k\)，则 T 为单结点树，并将 \(C_k\) 做为该结点的类标记，返回T；<br/>
（2）若 A=\(\varnothing\) ，则 T 为单结点树，将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记；<br/>
（3）计算 A 中的各特征对数据D的信息增益率，选择信息增益率最大的特征 \(A_z\)；<br/>
（4）如果 \(A_z\) 的信息增益率小于阈值 \(\epsilon\) ，则置T为单结点树，并将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记，返回 T；<br/>
（5）否则，对 \(A_z\) 的每一个可能去值 \(a_i\) ，将 D 分给成若干个非空子集 \(D_i\)，将 \(D_i\) 中实例树最大的类作为标记，构建子节点，由结点及其子结点构成树 T，返回 T；<br/>
（6）对第 i 个子结点，以 \(D_i\)为训练集，以 \(A-A_z\) 为特征集，递归地调用（1）～（5）步，得到子树 \(T_i\)，返回 \(T_i\)。</p>

<h4 id="toc_12">决策树剪枝</h4>

<p>在决策树的学习中，我们知道层数越多，叶结点越复杂，分类效果越好，越容易产生过拟合，对测试集的效果也会受影响。在决策树学习中将已生成的树进行简化的过程称为剪枝，具体地，剪枝从已生成的树上裁掉一些子树或叶节点，并将其根结点和父结点作为新的叶结点，从而简化分类树模型。</p>

<p>通常有两个剪枝方法，预剪枝和后剪枝：</p>

<h5 id="toc_13">预剪枝</h5>

<p>在决策树的生成过程中进行剪枝，常见的有以下几种方式：</p>

<ol>
<li>设置树的高度阈值，当树的高度超过阈值时停止生长。</li>
<li>设置叶结点的最小实例个数，当叶节点的实例树小于阈值时停止生长，不足之处是不能处理那些数据量比较小的特殊情况。</li>
<li>设置经验熵阈值，当叶节点的经验熵小于阈值时停止生长。</li>
<li>设置性能增益阈值，当每次扩展对系统性能的增益小于阈值就可以让它停止生长。</li>
</ol>

<h5 id="toc_14">后剪枝</h5>

<p>设树的叶节点的数量为 \(|T|\)，叶节点 \(t\) 有 \(N_t\) 个样本点，其中 k 类样本点有 \(N_{tk}\) 个，\(k=1,2,...,K\)，定义 \(H(t)\) 为叶节点 \(t\) 的经验熵：<br/>
\[<br/>
H_t(T) = \sum_k^K \frac{N_{tk}}{N_t} \log \frac{N_{tk}}{N_t}<br/>
\]</p>

<p>经验熵反应一个叶结点的分类的混乱程度，经验熵越大，说明该叶结点所对应的分类结果越混乱，也就是说分类结果中包含了较多的类别，表明该分支的分类效果较差。</p>

<p>定义该决策树的损失函数 \(C_\alpha(T)\)为：<br/>
\[<br/>
C_\alpha(T) = \sum_t^{|T|} N_t H_t(T)<br/>
\]</p>

<p>损失函数实际熵是求经验熵的权重，给每一个经验熵一个权重 \(N_t\)。</p>

<p>为了防止过拟合添加 L1 正则化项，修正后的损失函数为：<br/>
\[<br/>
C_\alpha(T) = \sum_t^{|T|} N_t H_t(T) + \alpha |T|<br/>
\]</p>

<p>添加L1正则化项是为了防止过度拟合，在决策树中要追求损失函数和模型复杂度的平衡。当 \(|T|\) 越大时，模型复杂度越高，对训练数据的拟合越好，反之 \(|T|\) 越小时，模型复杂度越小，但是对训练数据的拟合也不好。当 \(\alpha\) 越大，越倾向于一个复杂度较小的树。当 \(\alpha=0\) 时，不考虑模型复杂度，未剪枝的决策树对训练数据效果最好。</p>

<ol>
<li>计算每一个结点的经验熵</li>
<li>递归地从树的叶节点向子结点收缩，设一组叶节点回缩到其父结点之前和之后的整体树为 \(T_{b}\) 和 \(T_{a}\) ，计算损失函数得 \(C_\alpha(T_{b})\) 和 \(C_\alpha(T_{a})\)，当 \(C_\alpha(T_a) \le C_\alpha(T_b)\) 时则进行剪枝，将父结点变成新的叶结点。</li>
<li>重复2，直到不能剪枝为止。</li>
</ol>

<p>决策树的剪枝算法可以由一种动态规划的算法实现。</p>

<hr/>

<p><a href="https://blog.csdn.net/bird_fly_i/article/details/72824639">决策树剪枝算法原理</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15089443346795.html">期望最大化算法 EM</a></h1>
			<p class="meta"><time datetime="2017-10-25T23:12:14+08:00" 
			pubdate data-updated="true">2017/10/25</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>期望最大化算法的英文名称是 Expectation Maximization Algorithm，被称为机器学习十大算法之一。它是一种启发式迭代算法，是一种从不完全数据中求极大似然的算法。算法的每次迭代由两部组成：E步，求期望（Expectation）；M步，求最大值。</p>

<p>看到某篇文章中有个生动的例子阐述EM算法的核心思想：食堂大师傅炒了一盘菜，要等分给俩个人吃，显然没有必要拿天平去称分量，而是可以先随意的将菜倒入两个碗中，然后对比两个碗，从多的里面拿出少量放入少的碗里，再进行比较，再从多的里面拿出少量放入少的碗中，这个过程一直迭代下去，直到看不出哪个多一点少一点为止。</p>

<p>而EM算法便是这样，假设我们不知道A和B两个参数的值，并且如果知道了A的值，就能很容易求出B的值，知道B的值，也能很容易求出A的值。可以考虑先赋予A一个初值，通过这个值求出B的值，再反过来通过B的值求得A的值，反复迭代直到A、B收敛。</p>

<h3 id="toc_0">二硬币问题</h3>

<p>考虑一个掷硬币的例子：假设有A和B两个密度不相等硬币，它们掷出来的正面和反面的概率不相等，我们将 A 和 B 投掷出来的正面的概率设为 \(\theta_A\) 和 \(\theta_B\) ，现在独立的进行5次实验，每次实验选取 A 或 B 中一枚硬币投掷10次，统计出正面的概率。</p>

<p>在这个实验中，我们记录两组向量 \(x=(x_1,x_2,x_3,x_4,x_5)\) 和 \(z=(z_1,z_2,z_3,z_4,z_5)\) ，其中 \(x_i\in(0,1,2,3,4,5,6,7,8,9,10)\) 代表第 \(i\) 次实验中出现正面朝上的次数，\(z_i\in(A,B)\) 表示第 \(i\) 次实验投掷的是硬币A还是硬币B。这次设置的参数估计是完整数据情况，因为我们模型里关联的随机变量（每次实验的结果和投掷硬币的类型）的值都是已知的。</p>

<p>这里一个简单的估计 \(\theta_A\) 和 \(\theta_B\) 的方法是返回每一个硬币观察到的正面的比例。<br/>
\[<br/>
\begin{equation}<br/>
\hat\theta_A = \frac{\text{用 A 硬币投掷出来的正面的次数}}{\text{用 A 硬币投掷的总的次数}} \label{ybzm}\\<br/>
\hat\theta_B = \frac{\text{用 B 硬币投掷出来的正面的次数}}{\text{用 B 硬币投掷的总的次数}} \\<br/>
\end{equation}<br/>
\]</p>

<p>实际上，在统计学上这种直观的猜测被称为极大似然估计。如果用 \(\log P(x;z;\theta)\)表示得到的观察到的正面次数 \(x\) 和 使用硬币的类型 \(z\) 的联合概率的对数形式（对数似然），那么\ref{ybzm}中的公式就是求解使 \(\log P(x;z;\theta)\) 最大的 \(\hat\theta=(\theta_A,\theta_B)\) 。</p>

<div align=center>
    <img width=500 src="media/15089443346795/15308145217430.jpg">
</div>

<p>现在考虑挑战一个参数估计问题中更大的变体，我们给出正面次数的记录但不给出每一组投掷的硬币的类型。我们将 z 称为隐藏变量或潜在因子。这种新设置中的参数估计被称为不完整数据情况。这次对每一种硬币计算正面出现的比例将不再可行，因为我们将不知道每一次实验中所使用的硬币类型。然而，我们有一些方法来使数据完整（在我们的例子中，正确猜测5次实验中使用的是哪个金币），然后我们就能将不完整数据的参数估计简化到完整数据的极大似然估计。</p>

<p>可以通过一个迭代的方法得到完整数据通过下列步骤：开始时给定一个初始值 \(\hat \theta^{(t)}=(\hat\theta^{(t)}_A,\hat\theta^{(t)}_B)\)，我们通过这个初始值来估计5次实验中每一次最有可能使用的硬币是 A 还是 B。然后我们假设这些结论（即猜测指定的硬币）是正确的，然后再使用常规的最大似然估计处理来获得 \(\hat\theta^{(t+1)}\)。最后，重复这两个过程直到收敛。随着参数模型的改进，最终完成的质量也会提高。</p>

<p>如下图所示：先初始化 \(\hat\theta_A^{(0)}=0.6\) 和 \(\hat\theta_B^{(0)}=0.5\) ，我们第一轮实验掷的 5H 和 5T ，正面出现的概率是0.5，更有可能是用硬币 B 投掷，同理第二轮实验正面的概率为0.9，更有可能是硬币 A 投掷......全部猜测完之后，便可以根据我们猜测计算出投掷硬币 A 正面出现的次数是24，反面出现的次数是6，那么可以计算出硬币 A 正面出现的概率 \(\hat\theta_A^{(1)}=0.8\)，同理计算出硬币 B 正面出现的概率 \(\hat\theta_B^{(1)}=0.45\)。重复这个过程，得出最终过程。</p>

<div align=center>
    <img width=520 src="media/15089443346795/15308182178307.jpg">
</div>

<p>期望最大化算法就是对这个基本思想的改进。期望最大化算法并不需要在每一次迭代中选出一个最有可能的硬币（ A 还是 B ），而是用当前参数 \(\hat\theta^{(t)}\) 计算出投掷硬币是 A 或 B 的概率，在此基础上建立一个所有可能完成数据的加权训练数据集。最后，通过改进版本的极大似然估计处理这些加权训练数据集得出一个新的估计参数 \(\hat\theta^{(t+1)}\) 。通过使用加权训练集而不是单个的最有可能的完整数据的好处是EM算法考虑了模型在每一个完整数据的置信度。</p>

<p>如下图所示：先初始化 \(\hat\theta_A^{(0)}=0.6\) 和 \(\hat\theta_B^{(0)}=0.5\) ，我们第一轮实验掷的 5H 和 5T ，所以是用硬币 A 投掷的，正面出现的概率为 \(P_A=\text{C}_{10}^5 (\hat\theta_A^{(0)})^5 (1-\theta_A^{(0)})^5\)，如果是硬币 B 投掷的，正面出现的概率为 \(P_B=\text{C}_{10}^5 (\hat\theta_B^{(0)})^5 (1-\theta_B^{(0)})^5\)，所以投掷的是硬币 A 的概率为：\(\frac{P_A}{P_A+P_B}\thickapprox 0.45\)，同理可求的投掷的是硬币 B 的概率为：\(\frac{P_B}{P_A+P_B}\thickapprox 0.55\)。实际发生正面向上的次数是5，所以这次硬币 A 正面向上的期望为 \(5\times 0.45=2.2\)，硬币 B 正面向上的期望是 \(5\times 0.55\thickapprox 2.8\)，同理求出其他实验结果，这时候再按照完整数据求的硬币 A 正面向上的概率：<br/>
\[<br/>
\hat\theta_A^{(1)} = \frac{21.3}{21.3+8.6} = 0.71<br/>
\]<br/>
同理可求得硬币 B 正面向上的概率。重复这两个流程，便可得最终结果。</p>

<div align=center>
    <img width=520 src="media/15089443346795/15308183981554.jpg">
</div>

<p>总的来说，通过这个EM算法例子，可知EM算法包括两个步骤：E步骤求期望的过程；M步骤，求极大的过程。</p>

<h3 id="toc_1">琴生不等式 Jensen inequality</h3>

<p>1）若 \(f(x)\) 是区间 \((a,b)\) 上的凸函数，有：<br/>
\[<br/>
f[E(x)] \ge E[f(x)]<br/>
\]</p>

<p>2) 若 \(f(x)\) 是区间 \((a,b)\) 上的凹函数（下凸函数），有：<br/>
\[<br/>
f[E(x)] \le E[f(x)]<br/>
\]</p>

<p>3）加权形式凸函数，有：<br/>
\[<br/>
f(a_1x_1+a_2x_2+...+a_nx_n) \ge a_1f(x_1) + a_2f(x_2) + ... + a_nf(x_n),\sum_{i=1} a_i = 1<br/>
\]</p>

<p>4）加权形式凹函数（下凸函数），有：<br/>
\[<br/>
f(a_1x_1+a_2x_2+...+a_nx_n) \le a_1f(x_1) + a_2f(x_2) + ... + a_nf(x_n),\sum_{i=1} a_i = 1<br/>
\]</p>

<p>在本文中，使用加权形式凸函数，令 \(f(x) = \log(x)\) ，\(f(x)&#39;&#39; = (1/x)&#39; = -x^{-2} &lt; 0\)，所以 \(f(x)\) 是凸函数，则：<br/>
\[<br/>
\begin{equation}<br/>
\log[\sum_{i=1} a_i x_i] \ge \sum_{i=1} a_i f(x_i) \label{jensen0}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_2">EM算法推导</h3>

<p>现在通过一个经典的三硬币模型，来看一下EM算法的算法步骤以及推导过程。</p>

<h5 id="toc_3">三硬币模型</h5>

<p>假设有三枚硬币，记为 A，B，C。这些硬币都是密度不均匀的，投掷正面向上的概率分别为 \(\pi\)，\(p\)，\(q\)。现在进行实验：每轮实验先投掷 A 硬币，如果正面朝上，则投掷 B 硬币，如果反面朝上，则投掷 C 硬币；然后投掷选出的硬币，记录正面向上为1，反面向上为0。独立重复进行 n 次实验，假设只能观察到最终记录的结果，不能观察到掷硬币的过程，现在要估计 \(\theta=(\pi,p,q)\) 的概率参数。</p>

<p>将问题抽象出来：</p>

<ul>
<li><strong>输入</strong>：观察数据 \(Y\)</li>
<li><p><strong>输出</strong>：模型参数 \(\theta\)</p></li>
<li><p><strong>方法</strong>：定义隐变量为 \(Z\) ，则观察数据的对数似然函数 <br/>
\[<br/>
L(\theta|Y) = \log P(Y|\theta) = \log \sum_Z P(Y,Z|\theta) = \log \sum_Z P(Y|Z,\theta) P(Z|\theta)<br/>
\]</p>

<p>最大化观测数据的对数似然函数<br/>
\[<br/>
\theta^* = arg \max_\theta L(\theta|Y)<br/>
\]</p></li>
</ul>

<p>对于这个问题不能直接求解，只能通过迭代的方式求解。EM算法便是用来求解此类问题的一种迭代算法。EM算法首先选取参数的初值 \(\theta^{(0)} = (\pi^{(0)},p^{(0)},q^{(0)})\)，然后通过迭代，第 \(i\) 次迭代参数的估计值记为 \(\theta^{(i)} = (\pi^{(i)},p^{(i)},q^{(i)})\)，在第 \(i+1\) 次迭代的E步迭代参数的估计值记为 \(\theta\)。</p>

<h5 id="toc_4">E 步骤：</h5>

<p>定义完全数据 \(Y\), \(Z\) 的对数似然函数 \(\log P(Y,Z|\theta)\)，关于未观测数据 \(Z\) 在给定观测数据 \(Y\) 和当前参数估计 \(\theta_i\) 的情况下的后验概率分布 \(P(Z|Y,\theta_i)\) 的条件期望称为 \(Q\)函数：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
&amp;= \sum_Z \log P(Y,Z|\theta) P(Z|Y,\theta^{(i)}) <br/>
\end{align*}<br/>
\]</p>

<p>\(Q\) 函数中的两个概率分布：</p>

<ul>
<li><p>完全数据 \(Y\), \(Z\) 的对数似然函数 \(\log P(Y,Z|\theta)\)：<br/>
\[<br/>
\log P(Y,Z|\theta) = \log P(Y|Z,\theta)P(Z|\theta)<br/>
\]</p></li>
<li><p>未观测数据 \(Z\) 的后验概率分布 \(P(Z|Y,\theta^{(i)})\)：<br/>
\[ <br/>
\begin{equation}<br/>
P(Z|Y,\theta^{(i)})=\frac{P(Y,Z|\theta^{(i)})}{P(Y|\theta^{(i)})}=\frac{P(Y,Z|\theta^{(i)})}{\sum_{Z′}P(Y,Z′|\theta^{(i)})}=\frac{P(Y|Z,\theta^{(i)})P(Z|\theta^{(i)})}{\sum_{Z′}P(Y|Z′,\theta^{(i)})P(Z′|\theta^{(i)})}\label{zhy}<br/>
\end{equation}<br/>
\]</p></li>
</ul>

<h5 id="toc_5">M步骤：</h5>

<p>求解使 \(Q(\theta,\theta^{(i)})\) 最大的 \(\theta\) ，确定第 \(i+1\) 次迭代的参数估计值 \(\theta^{(i+1)}\) ：<br/>
\[<br/>
\theta^{(i+1)} = arg \max_\theta Q(\theta,\theta^{(i)})<br/>
\]</p>

<h5 id="toc_6">证明：</h5>

<p>在迭代过程中，我们希望新估计值 \(\theta\) 能使 \(L(\theta)\) 增加，即 \(L(\theta) &gt; L(\theta^{(i)})\)，并逐步成为最大值，所以：<br/>
\[<br/>
\begin{align}<br/>
L(\theta) - L(\theta^{(i)}) &amp;= \log P(Y|\theta) - \log P(Y|\theta^{(i)}) \nonumber\\<br/>
&amp;= \log [\sum_Z P(Z,\theta) P(Y|Z,\theta)] - \log P(Y|\theta^{(i)}) \nonumber\\<br/>
&amp;= \log [\sum_Z P(Y|Z,\theta^{(i)}) \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}] - \log P(Y|\theta^{(i)}) \label{ptl}<br/>
\end{align}<br/>
\]</p>

<p>使用式 \ref{jensen0} 得：<br/>
\[<br/>
\log [\sum_Z P(Y|Z,\theta^{(i)}) \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}] \ge \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}<br/>
\]</p>

<p>将上式带入式 \ref{ptl} 得：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta) - L(\theta^{(i)}) &amp;\ge  \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})} - \log P(Y|\theta^{(i)})\\<br/>
&amp;= \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})}\\<br/>
\end{align*}<br/>
\] </p>

<p>令 <br/>
\[<br/>
\begin{equation}<br/>
B(\theta,\theta^{(i)}) = L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})} \label{BTT}\\<br/>
\end{equation}<br/>
\]</p>

<p>则：<br/>
\[<br/>
L(\theta) \ge B(\theta,\theta^{(i)})<br/>
\]</p>

<p>那么，\(B(\theta,\theta^{(i)})\) 是 \(L(\theta)\) 的下限。并从式 \ref{BTT} 可知：<br/>
\[<br/>
 L(\theta^{(i)}) = B(\theta^{(i)},\theta^{(i)})<br/>
\] </p>

<p>任何能使 \(B(\theta,\theta^{(i)})\) 变大的 \(\theta\) 都能使 \(L(\theta)\) 增大，选择 \(\theta^{(i+1)}\) 使 \(B(\theta,\theta^{(i)})\) 达到极大。即：<br/>
\[<br/>
\theta^{(i+1)} = arg \max_\theta B(\theta,\theta^{(i)})<br/>
\]</p>

<p>现在对 \(B(\theta,\theta^{(i)})\) 求 \(\theta^{(i+1)}\) ：<br/>
\[<br/>
\begin{align*}<br/>
\theta^{(i+1)} &amp;= arg \max_\theta B(\theta,\theta^{(i)}) = arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})} ] \\<br/>
&amp;= arg \max_\theta \{L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) [\log P(Z,\theta) P(Y|Z,\theta) - \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})]\} \\<br/>
&amp;= arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta) - \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})] \\<br/>
\end{align*}<br/>
\]</p>

<p>省去其中含有 \(\theta^{(i)}\) 的常数项：<br/>
\[<br/>
\begin{align*}<br/>
\theta^{(i+1)} &amp;= arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta) - \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})] \\<br/>
&amp;= arg \max_\theta [\sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta)]\\<br/>
&amp;= arg \max_\theta [\sum_Z P(Y|Z,\theta^{(i)}) \log P(Y,Z|\theta)]\\<br/>
\end{align*}<br/>
\]</p>

<p>令<br/>
\[<br/>
Q(\theta,\theta^{(i)}) = \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y,Z|\theta)<br/>
\]</p>

<p>所以这就像相当于 EM 算法的一次迭代，即求 \(Q\)函数及求其极大化的过程。</p>

<h5 id="toc_7">EM算法的收敛性</h5>

<p>要证明EM 算法的收敛性，也就是每一次迭代都比以前的结果更优，也就是证明：<br/>
\[<br/>
\begin{equation}<br/>
L(\theta^{(i+1)}) \ge  L(\theta^{(i)}) \quad\Leftrightarrow\quad \log P(Y|\theta^{(i+1)}) \ge \log P(Y|\theta^{(i)})\label{LTLL}<br/>
\end{equation}<br/>
\]</p>

<p>也就是证明 \(\log P(Y|\theta)\) 单调递增，考虑到：</p>

<p>\[<br/>
\begin{align}<br/>
\because \quad &amp; \sum_Z P(Z|Y,\theta^{(i)})=1\nonumber\\<br/>
\therefore \quad &amp; \log P(Y|\theta)= [\log P(Y|\theta)]\sum_Z P(Z|Y,\theta^{(i)})\nonumber\\<br/>
&amp;\qquad\qquad = \sum_Z P(Z|Y,\theta^{(i)})\log P(Y|\theta)\nonumber\\<br/>
\because \quad &amp;P(Y|\theta) = \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)}\nonumber\\<br/>
\therefore \quad &amp; \log P(Y|\theta) = \sum_Z P(Z|Y,\theta^{(i)})\log \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)}\nonumber\\<br/>
&amp;\qquad\qquad = \sum_Z P(Z|Y,\theta^{(i)}) \log P(Y,Z|\theta) - \sum_Z P(Z|Y,\theta^{(i)}) \log P(Z|Y,\theta) \nonumber\\<br/>
&amp;\qquad\qquad = E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] - E_Z[\log P(Z|Y,\theta)|Y,\theta^{(i)}]\label{slxzm}<br/>
\end{align}<br/>
\]</p>

<p>令</p>

<p>\[<br/>
\begin{align*}<br/>
H(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Z|Y,\theta)|Y,\theta^{(i)}]= \sum_Z P(Z|Y,\theta^{(i)}) \log(Z|Y,\theta)<br/>
\end{align*}<br/>
\]</p>

<p>所以式 \ref{slxzm} 可以写成 \(\log P(Y|\theta) = Q(\theta,\theta^{(i)}) - H(\theta,\theta^{(i)})\)，则：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta^{(i+1)}) - L(\theta^{(i)}) &amp;= \log P(Y|\theta^{(i+1)}) - \log P(Y|\theta^{(i)}) \\<br/>
&amp;= [Q(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i+1)},\theta^{(i)})] - [Q(\theta^{(i)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)})] \\<br/>
&amp;= [Q(\theta^{(i+1)},\theta^{(i)})- Q(\theta^{(i)},\theta^{(i)})] - [H(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)})] \\<br/>
\end{align*}<br/>
\]</p>

<p>因为EM算法是求 \(\theta^{(i+1)}\) 使 \(Q(\theta,\theta^{(i)})\) 增大，所以第一项不用证明，必大于0，现证明第二项：<br/>
\[<br/>
\begin{align*}<br/>
H(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)}) &amp;= \sum_Z  P(Z|Y,\theta^{(i)}) \log P(Z|Y,\theta^{(i+1)})  - \sum_Z P(Z|Y,\theta^{(i)})\log(Z|Y,\theta^{(i)}) \\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \log \frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})} \\<br/>
&amp;\le \log [\sum_Z \log P(Z|Y,\theta^{(i)}) \frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})} ]\\<br/>
&amp;= \log [\sum_Z P(Z|Y,\theta^{(i+1)})]\\<br/>
&amp;= 0<br/>
\end{align*}<br/>
\]  </p>

<p>所以\(L(\theta^{(i+1)}) - L(\theta^{(i)}) \ge 0\)，得证。从上面的推导可以看出，EM算法可以保证收敛到一个稳定点，但是却不能保证收敛到全局的极大值点，因此它是局部最优的算法，当然，如果我们的优化目标 \(Q(θ,θ^{(i)})\) 是凸的，则EM算法可以保证收敛到全局最大值，这点和梯度下降法这样的迭代算法相同。</p>

<h4 id="toc_8">三硬币求解</h4>

<p>我们用 \(y\) 表示观察变量，表示一次实验观察的结果是 1（正面） 或 0（反面）；使用 \(z\) 表示隐变量，表示未观察到的投掷 A 硬币的结果。一次实验观察数据 \(Y_i\) 的概率：<br/>
\[<br/>
\begin{align*}<br/>
P(Y_i=y|\theta) &amp;= \sum_z P(y,z|\theta) = \sum_z P(z|\theta)P(y|z,\theta) \\<br/>
&amp;= \pi p^y (1-p)^{1-y} + (1-\pi) q^y (1-q)^{1-y}<br/>
\end{align*}<br/>
\]</p>

<p>将观察数据表示为 \(Y=(Y_1,Y_2,...,Y_n)^T\)，不可观察数据表示为 \(Z=(Z_1,Z_2,...,Z_n)^T\)，观察数据的似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
P(Y|\theta) &amp;= P(Y_1,Y_2,...,Y_n|\theta) = \prod_{i=1}^n P(Y_i|\theta) \\<br/>
&amp;= \prod_{i=1}^n [\pi p^{y_i} (1-p)^{1-{y_i}} + (1-\pi) q^{y_i} (1-q)^{1-y_{i}}]<br/>
\end{align*}<br/>
\]</p>

<h6 id="toc_9">E步骤：</h6>

<p>先定义Q函数为：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
\end{align*}<br/>
\]</p>

<p>现在来化简 Q函数，先看：<br/>
\[<br/>
P(Y,Z|\theta) = \prod_j P(Y_j,Z_j|\theta) = \prod_j \prod_k P(Y_j,Z_j=k|\theta)^{Z_{jk}}<br/>
\]</p>

<p>这里使用 \(Z_{jk}\) 表示观察数据 \(Y_j\) 对应的隐藏数据，也就是硬币 A 的结果，在这个例子中 \(k=\{0,1\}\)：<br/>
\[<br/>
Z_{jk} = \left \{ \begin{array}\\ 1 \quad &amp; Z_j = k\\ 0 \quad &amp; Z_j \neq k\\\end{array}\right .<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\log P(Y,Z|\theta) &amp;= \log \prod_j \sum_k P(Y_j,Z_j=k|\theta)^{Z_{jk}} = \sum_j \sum_k Z_{jk} \log P(Y_j,Z_j=k|\theta) <br/>
\end{align*}<br/>
\]</p>

<p>上式代入 Q函数得：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \log P(Y,Z|\theta)\\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \sum_j \sum_k Z_{jk} \log P(Y_j,Z_j=k|\theta)\\<br/>
&amp;= \sum_j \sum_k \sum_Z P(Z|Y,\theta^{(i)}) (Z_{jk})\log P(Y_j,Z_j=k|\theta)\\<br/>
&amp;= \sum_j \sum_k \log P(Y_j,Z_j=k|\theta) \sum_Z P(Z|Y,\theta^{(i)}) Z_{jk}\\<br/>
\end{align*}<br/>
\]</p>

<p>现在来计算 \(\sum_Z P(Z|Y,\theta^{(i)}) Z_{jk}\)，因为只有 \(Z_j=k\) 时 \(Z_{jk}=1\) ，其他都等于0，所以：<br/>
\[<br/>
\sum_Z P(Z|Y,\theta^{(i)}) Z_{jk} = \sum_Z Z_{jk} \sum_j\sum_k P(Z_j=k|Y_j,\theta^{(i)}) = P(Z_j=k|Y_j,\theta^{(i)})<br/>
\]</p>

<p>分别代入 \(k=0\) 或 \(k=1\)，得：<br/>
\[<br/>
\begin{align*}<br/>
P(Z_j=0|Y_j,\theta^{(i)}) &amp;= \frac{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}} \\<br/>
P(Z_j=1|Y_j,\theta^{(i)}) &amp;= \frac{(1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}} \\<br/>
\end{align*}<br/>
\]</p>

<p>令：</p>

<p>\[<br/>
\begin{equation}<br/>
\mu_{i,j} = \frac{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}}\label{muij}<br/>
\end{equation}<br/>
\]</p>

<p>则：</p>

<p>\[<br/>
\sum_Z P(Z_j=k|Y_j,\theta^{(i)}) Z_{jk} = \left \{ \begin{array}\\<br/>
\mu_{i,j} &amp; \quad if\quad k=0\\<br/>
1-\mu_{i,j} &amp; \quad if\quad k=1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>再求 \(\sum_j \sum_k \log P(Y_j,Z_j=k|\theta)\)，分别代入 \(k=0\) 或 \(k=1\) 得：</p>

<p>\[<br/>
P(Y_j,Z_j|\theta) = \left \{ \begin{array}\\<br/>
\pi p^{y_j}(1-p)^{1-y_j}&amp; \quad if \quad k = 0\\<br/>
(1-\pi) q^{y_j}(1-q)^{1-y_j}&amp;\quad if \quad k = 1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>所以Q函数可以改写为：</p>

<p>\[<br/>
Q(\theta,\theta^{(i)}) = \sum_j \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}<br/>
\]</p>

<h6 id="toc_10">M步骤</h6>

<p>Q函数对参数 \(\pi\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \pi} &amp;= \sum_j \frac{\partial \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}}{\partial \pi}\\<br/>
&amp;= \sum_j [\mu^{i,j} \frac{p^{y_j}(1-p)^{1-y_j}}{\pi p^{y_j}(1-p)^(1-y_j)} - (1-\mu_{i,j})\frac{q^{y_j}(1-q)^{1-y_j}}{(1-\pi)q^{y_j}(1-q){1-y_j}}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}}{\pi} - \frac{1-\mu_{i,j}}{1-\pi}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}(1-\pi) - (1-\mu_{i,j})\pi}{\pi(1-\pi)}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j} - \pi}{\pi(1-\pi)}]\\<br/>
&amp;= \frac{\sum_j \mu_{i,j} - n\pi}{\pi(1-\pi)}] = 0\\<br/>
\Rightarrow \quad &amp; \pi = \frac 1 n \sum_j \mu_{i,j}<br/>
\end{align*}<br/>
\]</p>

<p>Q函数对参数 \(p\) 求导：</p>

<p>\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial p} &amp;= \sum_j \frac{\partial \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}}{\partial p}\\<br/>
&amp;= \sum_j [\mu_{i,j}\frac{\pi y_j p^{y_j-1}(1-p)^{1-y_j}-\pi p^{y_j}(1-y_j)(1-p)^{-y_j}}{\pi p^{y_j}(1-p)^{1-y_j}}]\\<br/>
&amp;= \sum_j [\mu_{i,j}\frac{y_j(1-p)-p(1-y_j)}{p(1-p)}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}(y_j-p)}{p(1-p)}]\\<br/>
&amp;= \frac{\sum_j \mu_{i,j} y_j - \sum_j \mu_{i,j}p}{p(1-p)} = 0\\<br/>
\Rightarrow \quad &amp; p = \frac{\sum_j \mu_{i,j}y_j}{\sum_j \mu_{i,j}}<br/>
\end{align*}<br/>
\]</p>

<p>Q函数对参数 \(q\)求导，同上，直接写出结果：</p>

<p>\[<br/>
q = \frac{\sum_j (1-\mu_{i,j})y_j}{\sum_j (1-\mu_{i,j})}<br/>
\]</p>

<p>综合三式得：</p>

<p>\[<br/>
\begin{align}<br/>
\pi^{(i+1)} &amp;= \frac 1 n \sum_j \mu_{i,j}\label{pii1}\\<br/>
p^{(i+1)} &amp;= \frac{\sum_j \mu_{i,j}y_j}{\sum_j \mu_{i,j}}\label{pi1}\\<br/>
q^{(i+1)} &amp;= \frac{\sum_j (1-\mu_{i,j})y_j}{\sum_j (1-\mu_{i,j})}\label{qi1}<br/>
\end{align}<br/>
\]</p>

<p>当给定初值便可以进行迭代求解了。</p>

<p>假设三硬币模型的结果如下：</p>

<p>\[<br/>
1,1,0,1,0,0,1,0,1,1<br/>
\]</p>

<p>假定一开始我们设初始值 \(\pi^{(0)}=0.5,p^{(0)} = 0.5,q^{(0)} = 0.5\)，由式 \ref{muij} 对 \(y_j=0\) 或 \(y_j=1\) ，都有：<br/>
\[<br/>
\mu_{0,0} = \frac{\pi^{(0)} (p^{(0)})^{y_0}(1-p^{(0)})^{1-y_0}}{\pi^{(0)} (p^{(0)})^{y_0}(1-p^{(0)})^{1-y_0} + (1-\pi^{(0)}) (q^{(0)})^{y_0}(1-q^{(0)})^{1-y_0}} = 0.5\\<br/>
\mu_{0,1} = \frac{\pi^{(0)} (p^{(0)})^{y_1}(1-p^{(0)})^{1-y_1}}{\pi^{(0)} (p^{(0)})^{y_1}(1-p^{(0)})^{1-y_1} + (1-\pi^{(0)}) (q^{(0)})^{y_1}(1-q^{(0)})^{1-y_1}} = 0.5\\<br/>
\]</p>

<p>利用式 \ref{pii1}、式\ref{pi1}、式 \ref{qi1} 迭代可得：<br/>
\[<br/>
\pi^{(1)} = 0.5,\quad p^{(1)} = 0.6,\quad q^{(1)} = 0.6<br/>
\]</p>

<p>由 \ref{muij} 得：</p>

<p>\[<br/>
\mu_{1,0} = 0.5,\quad \mu_{1,1} = 0.5<br/>
\]</p>

<p>继续迭代得：<br/>
\[<br/>
\pi^{(2)} = 0.5,\quad p^{(2)} = 0.6,\quad q^{(2)} = 0.6<br/>
\]</p>

<p>于是得到 \(\theta\) 的极大似然估计为：<br/>
\[<br/>
\hat \pi = 0.5,\quad \hat p = 0.6,\quad \hat q = 0.6<br/>
\]</p>

<p>另外我们可以试一下，设置不同的初值，最终结果可能不同，也就是说EM算法与初值的选取有关，选择不同的初值可能会得到不同的结果。</p>

<hr/>

<p><a href="http://www.cs.tau.ac.il/%7Ershamir/algmb/archive/EM-BW.pdf">Introduction to Expectation Maximization</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15084379846372.html">维特比算法 Viterbi Algorithm</a></h1>
			<p class="meta"><time datetime="2017-10-20T02:33:04+08:00" 
			pubdate data-updated="true">2017/10/20</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>维特比算法是一个特殊但应用最广的动态规划算法。利用动态规划，可以解决任何一个图中的最短路径问题。而维特比算法是针对一个特殊的图-篱笆网洛（Lattice）的有向图最短路径问题而提出来的。</p>

<p>篱笆网络有向图的特点是同一列节点有多个，并且和上一列节点交错地连接起来。同一列节点代表同一个时间点上不同的状态的并列，大概因为这种一列一列整齐的节点和交错的边很像篱笆而得名。篱笆网络的特点：有向、无环图，上一层节点只能指向下一层节点。</p>

<p>篱笆网络如下图：</p>

<div align="center">
    <img src="media/15084379846372/15353808478263.jpg" width="330" />
</div>

<p>用一个简单的例子来说明维特比算法的过程。如下图，求 \(S\) 到 \(E\) 的最短距离</p>

<div align="center">
    <img src="media/15084379846372/15353808997732.jpg" width=370 />
</div>

<p>这个例子中总共有 3 列节点，每一列有 4 个节点，总共有 4\(\times\)4\(\times\)4 = 64 种不同的走法。一个“容易”想到的方法是穷举法，列出每一种走法，如 \(\text{S}\rightarrow \text{A}_1\rightarrow \text{B}_1\rightarrow \text{C}_1\rightarrow \text{E}\)，\(\text{S}\rightarrow \text{A}_1\rightarrow \text{B}_1\rightarrow \text{C}_2\rightarrow \text{E}\)，...。再求出每一种走法的距离，选出最短的路径。这种方法虽简单，但是复杂度很高，不可行。</p>

<p>我们可以采用动态分布的方式考虑最短路径的求法，如下图</p>

<div align="center">
    <img src="media/15084379846372/15353812595725.jpg" width=370 />
</div>

<p>假设红色路径为最短路径，即 \(\text{S}\rightarrow \text{A}_1\rightarrow \text{B}_2\rightarrow \text{C}_1\rightarrow \text{E}\) ，易知 \(\text{S}\) 到 \(\text{B}_2\) 的路径 \(\text{S}\rightarrow \text{A}_1\rightarrow \text{B}_2\) 也是最短的，因为如果存在更短的路径，比如 \(\text{S}\) 经过 \(\text{A}_i\) 到 \(\text{B}_2\) 更短 ，即 \(\text{S}\rightarrow \text{A}_i \rightarrow \text{B}_2\)，那么必然 \(\text{S}\rightarrow \text{A}_i \rightarrow \text{B}_2\rightarrow \text{C}_1\rightarrow \text{E}\) 比红色路径更短，与我们假设不符。</p>

<p>那现在算法便很明显了，维比特算法在选择每一列的节点时，都会保存到这个节点最短的路径，比如到达 \(\text{B}_2\) 的节点总共有四条：\(\text{S}\rightarrow \text{A}_1\rightarrow \text{B}_2\)、\(\text{S}\rightarrow \text{A}_2\rightarrow \text{B}_2\)、\(\text{S}\rightarrow \text{A}_3\rightarrow \text{B}_2\) 和 \(\text{S}\rightarrow \text{A}_4\rightarrow \text{B}_2\)，已知其中经过 \(\text{A}_1\) 的节点最短后，我们舍弃到达 \(\text{B}_2\) 其他的路线，后面考虑到达 \(\text{C}\) 的路径时，经过 \(\text{B}_2\) 的只需要考虑一条路径 \(\text{S}\rightarrow \text{A}_1\rightarrow \text{B}_2\) 即可。</p>

<h4 id="toc_0">算法步骤</h4>

<p>以上面图的例子：从点 \(\text{S}\) 出发。对于第一层的4个节点，算出它们的距离 \(d(\text{S},\text{A}_1),d(\text{S},\text{A}_2),d(\text{S},\text{A}_3),d(\text{S},\text{A}_4)\)，因为只有一步，所以这些距离都是 \(\text{S}\) 到它们的最短距离。</p>

<div align="center">
    <img src="media/15084379846372/15353823866019.jpg" width=390 />
</div>

<p>对于 \(\text{B}\) 层的所有节点 \((\text{B}_1,\text{B}_2,\text{B}_3,\text{B}_4)\)，要计算出 \(\text{S}\) 到它们的最短距离。对于节点 \(\text{B}_1\)，计算 \(\text{S}\) 经过 \(\text{A}\) 的任何一个节点到 \(\text{B}_1\) 的距离，即 \(d(\text{S,B}_1) = d(\text{S,A}_i) + d(\text{A}_i,\text{B}_1),i=1,2,3,4\)，选出使距离最小的 \(i\) ，假设此时 \(\text{S}\) 到 \(\text{B}_1\) 的最短路径为 \(\text{S}\rightarrow \text{A}_3\rightarrow \text{B}_1\)。再用同样的方式计算 \(\text{S}\) 到 \(\text{B}_2\)、\(\text{B}_3\) 和 \(\text{B}_4\) 的最短路径，如下图：</p>

<div align="center">
    <img src="media/15084379846372/15353827099886.jpg" width="390" />
</div>

<p>同理对于 \(\text{C}\) 层的所有节点 \((\text{C}_1,\text{C}_2,\text{C}_3,\text{C}_4)\)，分别对于每一个 \(\text{C}_i\)，计算 \(\text{S}\) 经过 \(\text{B}_j\) 到 \(\text{C}_i\) 的距离，即 \(\text{S}\) 到 \(\text{B}_j\) 的最短距离加上 \(\text{B}_j\) 到 \(\text{C}_i\) 的距离，选出使距离最小的中转点 \(\text{B}_j\)，即可得 \(\text{S}\) 到 \(\text{C}_i\) 的最短距离。</p>

<div align="center">
    <img src="media/15084379846372/15353829712126.jpg" width="390" />
</div>

<p>最后对于 \(\text{C}\) 层的每一个节点计算 \(d(S,\text{C}_i)+d(\text{C}_i,E);i=1,2,3,4\) 的距离，选择最小的 \(\text{C}_i\)，再回溯回去，变可以得到最短路径。</p>

<hr/>

<p><a href="https://www.jianshu.com/p/218c1e4f0891">viterbi算法：利用动态规划寻找最短路径</a><br/>
<a href="https://blog.csdn.net/dearwind153/article/details/56009839">理解维特算法</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15080791229681.html">SPFA算法</a></h1>
			<p class="meta"><time datetime="2017-10-15T22:52:02+08:00" 
			pubdate data-updated="true">2017/10/15</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>SPFA算法全称是Short Path Faster Algorithm，是单源最短路径算法Bellman-Ford算法的改进算法，用来改进Floyd算法复杂度高的缺点。如同Bellman-Ford算法，SPFA不能解决负权回路的问题，也就是肯定存在最短路径。</p>

<h4 id="toc_0">算法介绍</h4>

<p>SPFA算法维护着一个先进先出的队列，初识时队列里只有源结点 \(s\) 。每次从队列里拿出队首元素 \(u\) ，用 \(u\) 到其直接相连的点 \(v\) 作松弛操作，如果\(D(s,u)+dist(u,v)&lt;D(s,v)\)则代表可以松弛\(D(s,v)=D(s,u)+dist(u,v)\)，如果松弛成功且 \(v\) 不在队列中，则将 \(v\) 加入队列中。如果队列不为空，再从队列中拿出队首元素，重复这个操作直到队列为空。如果某一个元素 \(x\) 进入队列的次数超过 N 次，则含有负权回路。</p>

<p>我们依旧使用一个简单的示例来讲解这个算法：</p>

<div align=center>
    <img width=280 src='media/15080791229681/15298534336535.jpg' />
</div>

<p>我们定义两个数据结构，一个数组用于存源结点到每个结点的距离，初始化时源结点到自身为0，到其他结点为无穷大；一个先进先出队列用于存放即将松弛的点，初始化时只包含源结点。</p>

<p>\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;\infty&amp;\infty&amp;\infty&amp;\infty\\\hline<br/>
\end{array}\qquad\text{队列}=\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
\text{A}&amp;\quad&amp;\quad&amp;\quad&amp;\quad&amp;\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>从队首取出第一个元素即结点A，结点A出队，结点A直接可达C、D、E，比较\(\text{D(A,A)+dist(A,C)}\)与\(\text{D(A,C)}\)的大小（可对比\(D(s,u)+dist(u,v)&lt;D(s,v)\)，其中s=A，u=A，v=C），所以结点C可以松弛，并将C入队。同理可操作D和E，松弛后：<br/>
\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;\infty&amp;7&amp;1&amp;5\\\hline<br/>
\end{array}\qquad\text{队列}=\begin{array}{|c|c|c|c|c|c|}<br/>
\hline<br/>
\quad&amp;\text{C}&amp;\text{D}&amp;\text{E}&amp;\quad&amp;\quad&amp;\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>从队首中取出第一个结点即结点C出队列，C直接可达结点B，满足松弛条件\(\text{D(A,C)+dist(C,B)}&lt;\text{D(A,B)}\)，松弛后\(\text{D(A,B)=D(A,C)+dist(C,B)}=7+2=9\)，结点B不在队列中需要入队：<br/>
\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;9&amp;7&amp;1&amp;5\\\hline<br/>
\end{array}\qquad\text{队列}=\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
\quad&amp;\quad&amp;\text{D}&amp;\text{E}&amp;\text{B}&amp;\quad&amp;\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>结点D出队列，结点D直接可达结点E，满足松弛条件\(\text{D(A,D)+dist(D,E)}&lt;\text{D(A,E)}\)，所以松弛后\(\text{D(A,E)=D(A,D)+dist(D,E)}=1+2=3\)，且结点E已经在队列中，不需要再入队，结果如下：<br/>
\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;9&amp;7&amp;1&amp;3\\\hline<br/>
\end{array}\qquad\text{队列}=\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
\quad&amp;\quad&amp;\quad&amp;\text{E}&amp;\text{B}&amp;\quad&amp;\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>结点E出队列，结点E直接可达结点C，满足松弛条件\(\text{D(A,E)+dist(E,C)}&lt;\text{D(A,C)}\)，所以松弛后\(\text{D(A,C)=D(A,E)+dist(E,C)}=3+1=4\)，且结点C不在队列中，结点C入队，结果如下：<br/>
\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;9&amp;4&amp;1&amp;3\\\hline<br/>
\end{array}\qquad\text{队列}=\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
\quad&amp;\quad&amp;\quad&amp;\quad&amp;\text{B}&amp;\text{C}&amp;\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>结点B出队列，结点B直接可达结点A，不满足松弛条件\(\text{D(A,B)+dist(B,A)}&lt;\text{D(A,A)}\)，不松弛得：<br/>
\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;9&amp;4&amp;1&amp;3\\\hline<br/>
\end{array}\qquad\text{队列}=\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
\quad&amp;\quad&amp;\quad&amp;\quad&amp;\quad&amp;\text{C}&amp;\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>结点C出队列，结点C直接可达结点B，满足松弛条件，松弛后\(\text{D(A,B)=D(A,C)+dist(C,B)}=4+2=6\)，且结点B不在队列中需要入队，结果如下：<br/>
\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;6&amp;4&amp;1&amp;3\\\hline<br/>
\end{array}\qquad\text{队列}=\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
\quad&amp;\quad&amp;\quad&amp;\quad&amp;\quad&amp;\quad&amp;\text{B}\\\hline<br/>
\end{array}<br/>
\]</p>

<p>结点B出队，结点B直接可达结点A，不满足松弛条件，此时队列已空，算法结束，最终最短路径为：<br/>
\[<br/>
\begin{array}{c|c|c|c|c}<br/>
\hline<br/>
i&amp;\text{A}&amp;\text{B}&amp;\text{C}&amp;\text{D}&amp;\text{E}\\\hline<br/>
\text{D(A,}i)&amp;0&amp;6&amp;4&amp;1&amp;3\\\hline<br/>
\end{array}<br/>
\]</p>

<h4 id="toc_1">最短路径</h4>

<p>如同Bellman-Ford方法，可以在每一个结点内部维护着一个前置对象的变量，初识时前置变量都设为-1，当每一次松弛时，更新最短距离同时更新前置对象。算法结束后，可以反向输出最短路径。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15078988726664.html">Bellman-Ford算法</a></h1>
			<p class="meta"><time datetime="2017-10-13T20:47:52+08:00" 
			pubdate data-updated="true">2017/10/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>Bellman-Ford算法是一种单源最短路径算法，它解决了Dijkstra算法中不能存在负权值的问题。Bellman-Ford以下简称BF算法，BF算法是由Richard Bellman（动态规划的提出者） 和 Lester Ford提出，它利用了动态规划的思想，而前面所说的Dijkstra算法是采用贪心算法的思想。</p>

<h3 id="toc_0">算法描述</h3>

<p>BF算法的核心操作在于松弛（Relaxation），松弛的对象也很明显就是源结点到各结点的距离，经过多轮的松弛，最终会达到一个稳定值，就是问题的最优解。首先还是看一个简单的示例：</p>

<div align="center">
    <img width='250' src='media/15078988726664/15297485777277.jpg'>
</div>

<p>其中源结点为A，开始时A到自身的距离为0，到其他各结点的距离设为\(\infty\)：</p>

<div align="center">
    <img width='260' src='media/15078988726664/15297501679735.jpg'>
</div>

<p>按照(A,B)、(A,C)、(B,C)、(C,D)来进行第一轮松弛就会得到最优解：</p>

<div align="center">
    <img width='220' src='media/15078988726664/15297536078192.jpg'>
</div>

<p>但是如果我们松弛顺序不是这样，而是 (B,C)、(A,B)、(A,C)、(C,D) 一轮松弛将不能得到最优解，还需要进行二轮松弛......但是我们怎么找这样的最优顺序呢？其实并不需要，只要一直进行松弛下去都会有最优解。</p>

<h3 id="toc_1">算法步骤</h3>

<ol>
<li>初始化：建立一个数组 Q 存储源结点到各个结点的距离，初始化时源结点最短距离为0，其他设为无穷大。</li>
<li>进行n-1次循环，循环下标为从1到n－1，n是边的个数：
<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;循环每一条边，当存在 Q(A) + dist(A,B) 小于 Q(B) 时，松弛结点B的最短距离为 Q(A) + dist(A,B)</li>
<li>遍历途中所有的边，判断是否存在这样情况 Q(A) + dist(A,B) 小于 Q(B) ，如果存在则代表图中存在负权回路，问题无解。</li>
</ol>

<h5 id="toc_2">负权回路</h5>

<p>如果存在下面的负权回路，在每一次收敛后，都会进行松弛，即在第n次循环时还可以松弛。因此我们也可以对上述步骤的第二步改进一下：直接进行n次循环，如果第n次循环仍可以进行松弛代表存在负权回路。如果在n次循环前就没有对象可再被松弛，可以直接退出循环。</p>

<p>部分实现如下：</p>

<pre><code class="language-python">def bellman_ford(G, s):
    D, P = {s: 0}, {s: None}
    for _ in G: # 轮数等于节点数
        improved = False
        for u in G:
            for v in G[u]:
                if relax(G, u, v, D, P):
                    improved = True
        if not improved: # 如果某轮没有任何改进
            break        # 说明问题已经解决，退出循环
    else:                # 否则，说明第n轮也有改进，存在负权环
        raise ValueError(&#39;negative cycle&#39;)
    return D, P
</code></pre>

<h5 id="toc_3">最短路径</h5>

<p>上述算法只是简单的输出源结点到各结点的最短距离，假设我们还需要知道最短路径经过的结点，那么还需要一些其他的操作。我们在每一个结点内部维护着一个存储前置结点的变量，初始化时都为-1，在每一次松弛过程中，记录松弛过程的前置的对象。所有松弛过程结束后，倒序迭代输出边可以得到完整的路径。</p>

<p>可以看个简单的完整例子来讲解这个算法：</p>

<div align=center>
    <img width=250 src="media/15078988726664/15297728142160.jpg">
</div>

<p>开始时，我们定义源结点到各结点的距离，到自身为0，其余为无穷大；每个结点内部的前置结点设为-1，为了表示方便，这里我将结点内部前置对象写在括号里：<br/>
\[<br/>
\begin{array}{c|ccccc}<br/>
         &amp; \text{A(-1)} &amp; \text{B(-1)} &amp; \text{C(-1)} &amp; \text{D(-1)} &amp; \text{E(-1)} \\<br/>
\hline<br/>
\text{Q} &amp; 0        &amp; \infty   &amp; \infty   &amp; \infty   &amp; \infty  \\<br/>
\end{array}<br/>
\]</p>

<p>假设我们的松弛顺序是(D,B)，(A,B)，(B,E)，(A,C)，(B,D)，(D,C)，(B,C)，(E,D)。</p>

<p>首先是第一轮松弛：<br/>
经过(D,B)边，不满足松弛条件Q(D)+dist(Q,B) &lt; Q(B)，不处理。<br/>
经过(A,B)边，存在Q(A)+dist(A,B) &lt; Q(B)，松弛Q(B)=Q(A)+dist(A,B)，并将B的前置对象设为A：<br/>
\[<br/>
\begin{array}{c|ccccc}<br/>
         &amp; \text{A(-1)} &amp; \text{B(A)} &amp; \text{C(-1)} &amp; \text{D(-1)} &amp; \text{E(-1)} \\<br/>
\hline<br/>
\text{Q} &amp; 0 &amp; -1   &amp; \infty   &amp; \infty   &amp; \infty  \\<br/>
\end{array}<br/>
\]<br/>
经过(B,E)边，存在松弛条件Q(B)+dist(B,E) &lt; Q(E)，松弛Q(E)=Q(B)+dist(B,E)，并将E的前置对象设为B：<br/>
\[<br/>
\begin{array}{c|ccccc}<br/>
         &amp; \text{A(-1)} &amp; \text{B(A)} &amp; \text{C(-1)} &amp; \text{D(-1)} &amp; \text{E(B)} \\<br/>
\hline<br/>
\text{Q} &amp; 0 &amp; -1   &amp; \infty   &amp; \infty   &amp; 1  \\<br/>
\end{array}<br/>
\]<br/>
经过(A,C)边，存在松弛条件Q(A)+dist(A,C) &lt; Q(C)，松弛Q(C)=Q(A)+dist(A,C)，并将C的前置对象设为A：<br/>
\[<br/>
\begin{array}{c|ccccc}<br/>
         &amp; \text{A(-1)} &amp; \text{B(A)} &amp; \text{C(A)} &amp; \text{D(-1)} &amp; \text{E(B)} \\<br/>
\hline<br/>
\text{Q} &amp; 0 &amp; -1   &amp; 4   &amp; \infty   &amp; 1  \\<br/>
\end{array}<br/>
\]<br/>
经过(B,D)边，存在松弛条件Q(B)+dist(B,D) &lt; Q(D)，松弛Q(D)=Q(B)+dist(B,D)，并将D的前置对象设为B：<br/>
\[<br/>
\begin{array}{c|ccccc}<br/>
         &amp; \text{A(-1)} &amp; \text{B(A)} &amp; \text{C(A)} &amp; \text{D(B)} &amp; \text{E(B)} \\<br/>
\hline<br/>
\text{Q} &amp; 0 &amp; -1   &amp; 4   &amp; 1   &amp; 1  \\<br/>
\end{array}<br/>
\]<br/>
经过(D,C)边，不满足Q(D)+dist(D,C) &lt; Q(C)，不处理。<br/>
经过(B,C)边，存在松弛条件Q(B)+dist(B,C) &lt; Q(C)，松弛Q(C)=Q(B)+dist(B,C)，并将C的前置对象设为B：<br/>
\[<br/>
\begin{array}{c|ccccc}<br/>
         &amp; \text{A(-1)} &amp; \text{B(A)} &amp; \text{C(B)} &amp; \text{D(B)} &amp; \text{E(B)} \\<br/>
\hline<br/>
\text{Q} &amp; 0 &amp; -1   &amp; 2   &amp; 1   &amp; 1  \\<br/>
\end{array}<br/>
\]<br/>
经过(E,D)边，存在松弛条件Q(E)+dist(E,D) &lt; Q(D)，松弛Q(D)=Q(E)+dist(E,D)，并将D的前置对象设为E：<br/>
\[<br/>
\begin{array}{c|ccccc}<br/>
         &amp; \text{A(-1)} &amp; \text{B(A)} &amp; \text{C(B)} &amp; \text{D(E)} &amp; \text{E(B)} \\<br/>
\hline<br/>
\text{Q} &amp; 0 &amp; -1   &amp; 2   &amp; -2   &amp; 1  \\<br/>
\end{array}<br/>
\]</p>

<p>到此第一轮松弛结束，开始第二轮松弛，很巧合，第二轮没有对象将被松弛，循环会被提前结束。因此我们知道了源结点A到各结点的最短距离，并且可以输出最短路径。比如A到D的最短距离为-2，D的前置结点为E，E的前置结点为B，B的前置结点是A，A的前置结点是-1（不存在），所以A到D的最短路径为\(\text{A}\Rightarrow\text{B}\Rightarrow\text{E}\Rightarrow\text{D}\)</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15071722270628.html">弗洛伊德算法 Floyd</a></h1>
			<p class="meta"><time datetime="2017-10-05T10:57:07+08:00" 
			pubdate data-updated="true">2017/10/5</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>Floyd算法又称为插点法，是一种利用动态规划的思想寻找给定的加权图中多源点之间最短路径的算法，与Dijkstra算法类似。该算法名称以创始人之一、1978年图灵奖获得者、斯坦福大学计算机科学系教授罗伯特·弗洛伊德命名。Floyd算法是一种多源最短距离算法，可以正确处理有向图和负权（但是不能有负权回路）</p>

<h3 id="toc_0">算法介绍</h3>

<p>通过一个简单的例子来说明Floyd算法，如问题是下图的多源最短距离计算，首先我们使用一个5*5的邻接矩阵来存储这个数据结构，每个点到自身的距离为0，直接不可达的点距离为无穷大：</p>

<div align=center>
    <img width='450' src="media/15071722270628/15298123109953.jpg">
</div>

<p>我们知道如果两个点不经过第三个点，那么两个点最短的距离就如上邻接表所示，但是如果我们引入第三个点中转，有可能能达到更小的距离，如上图中A直接到D的距离为3，但是如果通过E中转A\(\Rightarrow\)E\(\Rightarrow\)D的距离为2，那么我们自然联想到通过两个点，甚至多个点中转也能使源结点到目标结点之间的距离缩短，这就是Floyd算法的核心思想。</p>

<p>Floyd算法是动态规划算法，动态规划算法不要求我们一次性求出最优解，而是分解为多个子问题，通过子问题再解出最优解。同理，Floyd算法在需要多个中转点的时候，也并不需要我们一次性知道源结点到目标结点需要经过哪些中转点。如上图A到B，我们直观可以感受到A到B，通过E和C中转后距离会更短，A\(\Rightarrow\)E\(\Rightarrow\)C\(\Rightarrow\)B，但是我们并不需要一次性知道中转点是选E、C还是只经过C中转，我们只需要知道子问题A到C需要经过E中转，AC最短距离为2，在此基础上，A到B需要经过C中转就可以得出最优结果，AB最短距离=AC(之前求出等于2)+CB=2+2=4。</p>

<p>现在我们来详细看一下流程：<br/>
（1）所有结点通过A中转，也就是两层循环，设外层循环点为X，内层循环点为Y，比较\(\text{dist[X,A]+dist[A,Y]}\)和\(\text{dist[X,Y]}\)的距离，如果\(\text{dist[X,A]+dist[A,Y]}&lt;dist[X,Y]\)，那么说明X、Y经过A点中转距离会更短。如外层循环到点B，内层循环到点D，有\(\text{dist[B,A]+dist[A,D]}=7+3=10\) 小于\(\text{dist[B,D]}=\infty\)，所以B到D经过A点距离会更短。所有循环完成之后如下：</p>

<div align=center>
    <img width='450' src="media/15071722270628/15298136842811.jpg">
</div>

<p>（2）所有结点通过B中转，在上面得到的邻接表的基础上进行两层循环，当满足\(\text{dist[X,B]+dist[B,Y]} &lt; \text{dist[X,Y]}\)时，更新邻接表。所有循环完成后如下：</p>

<div align=center>
    <img width='450' src="media/15071722270628/15298145692854.jpg">
</div>

<p>（3）在上述邻接表基础上用C做中转点：</p>

<div align=center>
    <img width='450' src="media/15071722270628/15298156211235.jpg">
</div>

<p>（4）在上述邻接表基础上用D做中转点：</p>

<div align=center>
    <img width='450' src="media/15071722270628/15298158613120.jpg">
</div>

<p>（5）在上述邻接表基础上用E做中转点：</p>

<div align=center>
    <img width='450' src="media/15071722270628/15298162951672.jpg">
</div>

<p>当所有点都做过中转点后，算法结束，此时得到了各结点之间的最短距离。整个算法比较实现比较简单，总共是三层循环，最外层循环可以理解为用哪个点作为中转点，里面两层循环就是任意两个结点之间通过这个中转点之后是否能减少距离，代码如下：</p>

<pre><code class="language-python">for i in range(lengthD):
    for j in range(lengthD):
        for k in range(lengthD):
            if(D[j,k] &gt; D[j,i]+D[i,k]):         
                D[j,k] = D[j,i]+D[i,k]          #两个顶点直接较小的间接路径替换较大的直接路径       
</code></pre>

<h3 id="toc_1">最短路径</h3>

<p>我们用一个简单的示例说明最短路径输出的原理：</p>

<div align=center>
    <img width='280' src="media/15071722270628/15298290214504.jpg">
</div>

<p>这里我们忽略最短距离，只考虑路径，初始化时先建立一个4*4的矩阵 \(\text{Pre}\) ，令\(\text{Pre(i , j)}\)表示从 \(i\) 到 \(j\) 的最短路径， \(j\) 的前置对象。初始化时 \(i\) 到 \(j\) 不经过任何结点， \(j\) 的前置对象就是 \(i\) ，所以\(\text{Pre(i , j)}=i\)，其中如果 \(j=i\) ，那么令\(\text{Pre(i , i)}=-1\)：</p>

<pre><code class="language-python">for (i=0;i&lt;n;i++)  
        for (j=0;j&lt;n;j++)  
            pre[i][j]=(i==j)?-1:i;
</code></pre>

<p>所以可知：\(\text{Pre(A,C) = A}，\text{Pre(C,B) = C}，\text{Pre(A,B) = A}\)，按照前面我们的步骤，当执行到使用C作为中转点时存在\(\text{dist(A,C)+dist(C,B)&lt;dist(A,B)}\)时，更新距离表，并且更新 \(\text{Pre}\) 矩阵，更新 \(\text{Pre(A,B)=Pre(C,B)=C}\)。所以当我们要输出 \(\text{A}\) 到 \(\text{B}\) 的路径时， \(\text{Pre(A,B)=C}\)，到 \(\text{B}\) 的前置结点是 \(\text{C}\) ，所以 \(\text{A}\) 到 \(\text{B}\) 先要到 \(\text{C}\) ，然后再看 \(\text{Pre(A,C)=A}\)，即 \(\text{A}\) 直接到达 \(\text{C}\) ，所以 \(\text{A}\) 到  \(\text{B}\) 的路径为 \(\text{A}\Rightarrow\text{C}\Rightarrow\text{B}\)。</p>

<p>所以核心算法为：</p>

<pre><code class="language-python">for i in range(lengthD):
    for j in range(lengthD):
        for k in range(lengthD):
            if(D[j,k] &gt; D[j,i]+D[i,k]):         
                D[j,k] = D[j,i]+D[i,k]          #两个顶点直接较小的间接路径替换较大的直接路径
                pre[j][k] = pre[i,k]            #更新前置结点 
</code></pre>

<h3 id="toc_2">负权回路</h3>

<p>在Floyd算法中不能存在负权回路，因为Floyd算法是动态规划算法，如果存在负权回路，每次循环最短路径都在更新，最短路径会一直减小下去，这里不再赘述。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15067401646591.html">迪杰斯特拉算法 Dijkstra</a></h1>
			<p class="meta"><time datetime="2017-09-30T10:56:04+08:00" 
			pubdate data-updated="true">2017/9/30</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>迪杰斯特拉算法是由荷兰计算机科学家狄克斯特拉于1959 年提出的，因此又叫狄克斯特拉算法。是从一个顶点到其余各顶点的最短路径算法，解决的是有向图中最短路径问题。迪杰斯特拉算法主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。</p>

<p>对于这个算法如果只靠文字讲解将不够生动好理解，下面准备结合算法的内存结构进行讲解步骤，首先我们看下面的无向图：</p>

<div align=center>
    <img width='350' src="media/15067401646591/15293659850697.jpg">
</div>

<h4 id="toc_0">算法步骤</h4>

<p>下面的例子是输出结点A到各结点的最短距离，如果还需要输出最短路径，看<font color=blue>蓝字</font>的描述，如果仅仅需要距离，可以不用。</p>

<h6 id="toc_1">初始化：</h6>

<p>定义两个队列，一个是已用结点队列 UQ（Used Queue），一个是未用结点队列 UUQ（UnUsed Queue）。初始化时UQ为空；UUQ包含所有所有结点，初始化结点A到自身距离为0，其他结点为无穷大，用UUQ（X）表示队列中结点X的当前值；<font color=blue>每一个结点内部维护着一个变量 pre ，储存每一个结点到最短距离时的前置结点，初始化时值都为-1</font>：</p>

<div align=center>
    <img width='520' src="media/15067401646591/15297227420859.jpg">
</div>

<p>接下来循环未用结点队列UUQ ，查找距离最短的结点，将该结点加入已用结点队列UQ则处理该结点。上例中此时结点A是最短的，选取结点A，从UUQ中去掉该结点加入UQ队列；更新UUQ中的最短距离，结点A到结点B的距离为5，结点A到结点D的距离为3，结点A到E的距离为2；<font color=blue>在更新距离的同时更新结点内部pre变量为前置结点，结点B、结点D、结点E的pre都更新为A：</font></p>

<div align=center>
    <img width='500' src="media/15067401646591/15297234449500.jpg">
</div>

<p>从UUQ中选择一个距离最短的结点，上例中此时选择结点E，从UUQ中去掉该结点E加入UQ队列；通过结点E更新UUQ中的最短距离，结点E到D的距离为1， 此时 UUQ(E)+ dist(E,D)=2+1=3不小于UUQ(D)=3，所以不更新D。结点E到结点A，因为结点A在UQ中不更新，结点E到F的距离为1，此时 UUQ(E)+ dist(E,F)=2+1=3 小于 UUQ(F)=\(\infty\)，所以更新UUQ中结点F为3，<font color=blue>同时更新结点F的前置结点为E</font>：</p>

<div align=center>
    <img width='500' src="media/15067401646591/15297246241834.jpg">
</div>

<p>从UUQ中选择一个距离最短的结点，上例中此时结点D和结点F的距离都为3，假设选择的是结点D，将结点D从UUQ中去掉加入UQ队列，结点D可到达的结点都在UQ队列中，不更新。</p>

<div align=center>
    <img width='500' src="media/15067401646591/15297254145110.jpg">
</div>

<p>从UUQ中选择一个距离最短的点——结点F，结点F到结点B的距离为1，此时 UUQ(F)+dist(F,B)=3+1=4 小于 UUQ(B)=5，更新UUQ(B)为4，<font color=blue>并更新结点B的前置结点为F；</font>结点F到结点G的距离4，此时 UUQ(F)+dist(F,G)=3+4=7 小于 UUQ(G)=\(\infty\)，更新UUQ(G)为7，<font color=blue>并更新结点G的前置结点为F：</font></p>

<div align=center>
    <img width='500' src="media/15067401646591/15297259293986.jpg">
</div>

<p>从UUQ中选择一个距离最短的点——结点B，结点B到结点C的距离为2，此时 UUQ(B)+dist(B,C)=4+2=6 小于 UUQ(B)=\(\infty\)，更新 UUQ(C)为6，<font color=blue>并更新C的前置结点为B：</font></p>

<div align=center>
    <img width='500' src="media/15067401646591/15297263977068.jpg">
</div>

<p>从UUQ中选择一个距离最短的点——结点C，结点C到结点G的距离为1，此时 UUQ(C)+dist(C,G)=6+1=7 不小于 UUQ(G)=7，不更新：</p>

<div align=center>
    <img width='500' src="media/15067401646591/15297266129228.jpg">
</div>

<p>从UUQ中选择一个距离最短的点——结点G，结点G没有到达的点在UUQ中，不更新：</p>

<div align=center>
    <img width='500' src="media/15067401646591/15297267591638.jpg">
</div>

<p>现在通过UQ可以知道A到E的最短距离为2，A到D最短距离为3，A到F最短距离为3，A到B最短距离为4，A到C最短距离为6，A到G最短距离为7。如果需要输出A到结点G的最短路径，可以通过前置结点倒序输出，结点G的前置结点为F，F的前置结点为E，E的前置结点为A：A \(\Rightarrow\) E \(\Rightarrow\) F \(\Rightarrow\) G</p>

<h4 id="toc_2">算法限制</h4>

<p>如果各结点间不能存在负的权值，如下图：</p>

<div align=center>
    <img width='180' src="media/15067401646591/15297437390198.jpg">
</div>

<p>计算从A到E的距离，开始时B和C在UUQ队列，UUQ(B)=3，UUQ(C)=2，然后第二轮开始处理结点C，将C从UUQ移除，加入UQ队列，按照我们的流程，后面C的最短距离将不会再被更新，那么我们计算出的A到C的最短距离将为2，实际我们从图中很容易看出存在更短的路线A\(\Rightarrow\)B\(\Rightarrow\)C，距离为1。</p>

<p>这是因为Dijkstra算法有一个前提：<font color=red>对于处理过的节点，没有前往该节点的更短路径，处理过的结点不会再被更新。</font></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15061862782517.html">最大后验概率估计 MAP</a></h1>
			<p class="meta"><time datetime="2017-09-24T01:04:38+08:00" 
			pubdate data-updated="true">2017/9/24</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>最大后验概率估计的全称是 Maximum a posteriori estimation，简称MAP。极大似然估计是通过求参数 \(\theta\) ，使似然函数估计 \(P(x_0|\theta)\)最大。最大后验概率估计顾名思义就是最大化后验概率，看一下后验概率的定义：<br/>
\[<br/>
p(\theta|x) = \frac{\pi(\theta)\prod_{i=1}^N p(x_i|\theta)}{\prod_{i=1}^N p(x_i)}<br/>
\]</p>

<p>因为样本是固定的，所以认为分母是固定的，所以最大后验概率与使 \(\pi(\theta)\prod_{i=1}^N p(x_i|\theta)\) 最大的 \(\theta\) 值同解：<br/>
\[<br/>
\hat \theta = \arg\max_\theta p(\theta|x) = \arg\max_\theta \pi(\theta)\prod_{i=1}^N p(x_i|\theta)<br/>
\]</p>

<p>其中 \(p(x|\theta)=\prod_{i=1}^N p(x_i|\theta)\) 就是似然函数，\(\pi(\theta)\) 是参数的先验知识，所以我们可以认为最大后验估计就是规则化的极大似然估计，对上式加上对数处理后：<br/>
\[<br/>
\begin{align}<br/>
\arg\max_\theta p(\theta|x) &amp;= \arg\max_\theta [\ln \prod_{i=1}^N p(x_i|\theta) + \ln\pi(\theta)]\nonumber\\<br/>
&amp;= \arg\max_\theta[\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta)] \label{hygl}<br/>
\end{align}<br/>
\]</p>

<h4 id="toc_0">二项分布</h4>

<p>在二项分布中，假设参数的先验分布满足贝塔分布 \(Be(\alpha,\beta)，\)即：<br/>
\[<br/>
\pi(\theta) = \frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}<br/>
\]</p>

<p>而二项分布中每次的结果都用 \(\theta\) 表示为：<br/>
\[<br/>
p(x_i|\theta) = \theta^{x_i}(1-\theta)^{1-x_i}<br/>
\]<br/>
将上两式带入式\ref{hygl}中，很容易得到对数后验概率为：<br/>
\[<br/>
\begin{align}<br/>
\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta) &amp;= \sum_{i=1}^N \ln [\theta^{x_i}(1-\theta)^{1-x_i}] + \ln[\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}]\label{dshy}\\<br/>
\end{align}<br/>
\]</p>

<p>要想求出对数后验概率的最大值，需要对其求导。可以分成两部分对 \(\theta\) 求导，前面一项在极大似然估计已经求出，直接给出结果：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\{\sum_{i=1}^N[ \ln[\theta^{x_i}(1-\theta)^{1-x_i}]\} = \frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i)<br/>
\end{align*}<br/>
\]</p>

<p>我们来看式\ref{dshy}的后一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\{\ln[\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}]\} &amp;= \frac{\partial}{\partial \theta}[-\lnB(\alpha,\beta)+(\alpha-1)\ln\theta+(\beta-1)\ln(1-\theta)]\\<br/>
&amp;=\frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta}<br/>
\end{align*}<br/>
\]</p>

<p>所以对数后验概率对 \(\theta\) 求导结果为上面两项之和，即：<br/>
\[<br/>
\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) + \frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta}<br/>
\]</p>

<p>为求得最大值，令上式为0：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) + \frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta} = 0\\<br/>
\Rightarrow &amp;(1-\theta)\sum_{i=1}^N x_i-\theta\sum_{i=1}^N(1-x_i)+(\alpha-1)(1-\theta) - (\beta-1)\theta = 0\\<br/>
\Rightarrow &amp;\sum_{i=1}^N x_i - \theta\sum_{i=1}^N x_i-n\theta+\theta\sum_{i=1}^N x_i + \alpha - 1 -\alpha\theta + \theta - \beta\theta + \theta = 0\\<br/>
\Rightarrow &amp; \sum_{i=1}^N x_i -n\theta + \alpha - 1 -\alpha\theta - \beta\theta +2\theta= 0\\<br/>
\Rightarrow &amp; \frac{\sum_{i=1}^N x_i + \alpha -1}{n+\alpha+\beta-2}<br/>
\end{align*}<br/>
\]</p>

<p>所以先验概率满足 \(Be(\alpha,\beta)\) 的二项分布的最大后验估计：<br/>
\[<br/>
\hat\theta = \frac{\sum_{i=1}^N x_i + \alpha -1}{n+\alpha+\beta-2}<br/>
\]</p>

<p>在投硬币的例子中这里的 \(\sum_{i=1}^N x_i\) 即为硬币正面朝上的次数， \(\sum_{i=1}^N x_i=7\) 。与MLE不同的是我们由经验一般会认为硬币的正面出现的概率为0.5，即先验概率 \(\pi(\theta) \sim Be(1,1)\)，所以由最大后验概率求得 \(\theta\) 的值为：<br/>
\[<br/>
\theta = \frac{7+1-1}{10+1+1-2} = 0.7<br/>
\]</p>

<p>有人可能会说，MLE和MAP不就是一样的吗？不是的，可以说这里只是一个偶然，如果说先验知识是硬币是均匀的，也就是这里的 \(\alpha=\beta\) ，但是他们的大小可以表示先验概率的确信度。当我们取\(\alpha=200,\beta=200\)时，在MLE中，没有考虑先验仍旧是0.7。但是在MAP中，\(\theta=\frac{7+200-1}{10+200+200-2} =0.5049\)，也就是说10次实验中7次正面朝上并不能动摇我们对先验概率的坚持。要想改变我们的看法，需要做更多的实验才可以，从这一点上来MAP比MLE有更多的可信性。</p>

<h4 id="toc_1">正太分布</h4>

<p>设 \(x_1\) , \(x_2\) , …, \(x_n\)是来自正态分布 \(N(\theta,\sigma^2)\)的一个样本，其中 \(\sigma^2\) 已知， \(\theta\)未知，假设 \(\theta\) 的先验分布亦为正态分布 \(N(\mu,\tau^2)\)，其中先验均值 \(\mu\) 和先验方差 \(\tau^2\) 均已知。</p>

<p>\[<br/>
\pi(\theta) = \frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\\<br/>
p(x_i|\theta) = \frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\\<br/>
\]</p>

<p>所以对数后验概率为：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta)] = \sum_{i=1}^N \ln\{\frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\}+\ln\{\frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\}\\<br/>
\end{align*}<br/>
\]</p>

<p>将等式对 \(\theta\) 求导分成两部分，前面一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\sum_{i=1}^N \ln\{\frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\} &amp;= \frac{\partial}{\partial \theta}\sum_{i=1}^N [\ln\frac{1}{\sqrt{2\pi}\sigma} -\frac{(x_i-\theta)^2}{2\sigma^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta}\frac{\sum_{i=1}^N(x_i-\theta)^2}{2\sigma^2}\\<br/>
&amp;= -\frac{\partial}{\partial \theta}\frac{\sum_{i=1}^N x_i^2-2\sum_{i=1}^N \theta x_i + \sum_{i=1}^N\theta^2}{2\sigma^2}\\<br/>
&amp;= \frac{n\theta-\sum_{i=1}^N x_i}{\sigma^2}<br/>
\end{align*}<br/>
\]</p>

<p>后面一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta} \{\ln\{\frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\} &amp;= \frac{\partial}{\partial \theta} [\ln\frac{1}{\sqrt{2\pi}\tau} - \frac{(\theta-\mu)^2}{2\tau^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta} [\frac{(\theta-\mu)^2}{2\tau^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta} (\frac{\theta^2-2\mu\theta+\mu^2}{2\tau^2}) \\<br/>
&amp;= \frac{\theta-\mu}{\tau^2}<br/>
\end{align*}<br/>
\]</p>

<p>前后两项的和相加，再令其等于0：<br/>
\[<br/>
\begin{align*}<br/>
&amp; \frac{n\theta-\sum_{i=1}^N x_i}{\sigma^2} + \frac{\theta-\mu}{\tau^2} = 0\\<br/>
\Rightarrow &amp;n\tau^2\theta-\tau^2\sum_{i=1}^N x_i + \theta\sigma^2 - \mu\sigma^2 = 0\\<br/>
\Rightarrow &amp; \hat\theta = \frac{\tau^2\sum_{i=1}^N x_i + \mu\sigma^2}{n\tau^2+\sigma^2}<br/>
\end{align*} <br/>
\]</p>

<p>这里的结果和贝叶斯参数估计的结果表现形式一模一样。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15058431971790.html">极大似然估计 MLE</a></h1>
			<p class="meta"><time datetime="2017-09-20T01:46:37+08:00" 
			pubdate data-updated="true">2017/9/20</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>极大似然估计的英文全称是Maximum -likelihood Estimate，是指利用现有样本，反推能导致这样结果的最大可能的参数值（模型已定参数未知）。在一篇文章看到这样的比喻：某位同学和一个猎人出去打猎，他们同时看到了一个兔子，同时开枪，兔子应声而倒，如果要你猜测兔子是谁打死的？你可能很容易想到是猎人打死的，因为猎人命中的概率很大。这就是极大似然的思路，反推能导致这样结果的的最大可能参数。</p>

<h4 id="toc_0">算法步骤</h4>

<p>当从总体模型中选取n组观察样本后，可以这样认为，我们一次就选取到这n组观察样本，那么这n组样本的组合在总体模型中的联合概率密度最大。所以一般算法步骤如下：</p>

<p>记样本集 \(D = \{x_1,x_2,...,x_n\}\)，参数估计为 \(\theta\) ，最优参数为 \(\theta^*\)。</p>

<p>1）写出似然函数。联合概率密度 \(p(D|\theta)\) 称为相对于 \(D\) 的 \(\theta\) 的似然函数：<br/>
\[<br/>
L(\theta) = p(D|\theta) = p(x_1,x_2,...,x_n|\theta) = \prod_{i=1}^N p(x_i|\theta)<br/>
\] </p>

<p>2) 在实际分析中，累乘会不太好计算，通常作为是取对数，这里也不例外，定义对数似然函数：<br/>
\[<br/>
H(\theta) = \text{In} L(\theta) = \sum_{i=1}^N \text{In} p(x_i|\theta)<br/>
\]</p>

<p>2）对对数似然函数求导，求出令对数似然函数最大的参数值。<br/>
\[<br/>
\theta^* = arg\max_\theta L(\theta) = arg\max_\theta H(\theta) = arg\max \limits_\theta \sum_{i=1}^N \text{In} p(x_i|\theta)<br/>
\]</p>

<h4 id="toc_1">二项分布</h4>

<p>先以简单的抛硬币的例子来讲解，假设我们有一个质量不均匀的硬币，我们想知道这个硬币抛出去正面出现的概率 \(\theta\)，于是做了一个实验，抛了10次，得到的结果是（正面是1，反面是0）：<br/>
\[<br/>
\text{1}\quad\text{1}\quad\text{0}\quad\text{1}\quad\text{0}\quad\text{1}\quad\text{1}\quad\text{1}\quad\text{1}\quad\text{0}\quad<br/>
\]<br/>
如果我们抛开算法，会很容易得出 \(\theta=\frac{\text{正面次数}}{\text{正面次数}+\text{反面次数}}=0.7\)，现在通过MLE来求解一下。</p>

<p>通过上述的算法步骤先写出似然函数，假设正面出现的次数时，\(x_i=1\)：<br/>
\[<br/>
L(\theta) = \prod_{i=1}^N p(x_i|\theta) = \prod_{i=1}^N \theta^{x_i}(1-\theta)^{1-x_i}<br/>
\]<br/>
所以对数似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
H(\theta) &amp;= \text{In}L(\theta) = \sum_{i=1}^N \text{In} \theta^{x_i}(1-\theta)^{1-x_i} \\<br/>
&amp;= \sum_{i=1}^N[ \text{In} \theta^{x_i}+\text{In}(1-\theta)^{1-x_i} ]\\<br/>
&amp;= \sum_{i=1}^N[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ]<br/>
\end{align*}<br/>
\]</p>

<p>对对数似然函数求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial H(\theta)}{\partial \theta} &amp;= \frac{\partial \sum_{i=1}^N[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ]}{\partial \theta}\\<br/>
&amp;= \sum_{i=1}^N \frac{\partial}{\partial \theta}[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ] \\<br/>
&amp;= \sum_{i=1}^N (\frac{x_i}{\theta} - \frac{1-x_i}{1-\theta}) = \frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i)<br/>
\end{align*}<br/>
\]</p>

<p>令求导结果为0，来求得令 \(l(\theta)\)最大值的 \(\theta^*\)：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) = 0\\<br/>
&amp;\Rightarrow (1-\theta) \sum_{i=1} x_i = \theta (n-\sum_{i=1} x_i)\\<br/>
&amp;\Rightarrow \sum_{i=1} x_i - \theta\sum_{i=1} x_i = \theta (n-\sum_{i=1} x_i)\\<br/>
&amp;\Rightarrow \sum_{i=1} x_i = n\theta\\<br/>
&amp;\Rightarrow \theta = \frac 1 n \sum_{i=1} x_i<br/>
\end{align*}<br/>
\]</p>

<p>所以 \(\theta=0.7\) ，与我们用常识估计的相同。</p>

<h4 id="toc_2">正态分布</h4>

<p>假设样本X服从正态分布：<br/>
\[<br/>
x \sim N(\mu,\sigma^2)<br/>
\]</p>

<p>则似然函数为：<br/>
\[<br/>
L(\mu,\sigma^2) = \prod_{i=1}^N \frac 1{\sqrt{2\pi}\sigma}exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) = (2\pi\sigma^2)^{-n/2} exp(-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2})<br/>
\]</p>

<p>则对数似然函数为：<br/>
\[<br/>
H(\mu,\sigma^2) = \text{In}L(\mu,\sigma^2) = -\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}+\text{In}[(2\pi\sigma^2)^{-n/2}] = -\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)<br/>
\]</p>

<p>分别用对数似然函数对 \(\mu\) 和 \(\sigma^2\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial H(\mu,\sigma^2)}{\partial \mu} &amp;= \frac{\partial}{\partial \mu}[-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)] \\<br/>
&amp;=\frac{\partial}{\partial \mu}[-\frac{\sum_{i=1}^N (x_i^2-2x_i\mu+\mu^2)}{2\sigma^2}]\\<br/>
&amp;=\frac{-2\sum_{i=1}^N x_i + 2\sum_{i=1}^N \mu}{2\sigma^2}\\<br/>
\Rightarrow &amp; \mu^* = \frac 1 n \sum_{i=1}^N x_i\\<br/>
\frac{\partial H(\mu,\sigma^2)}{\partial \sigma^2} &amp;= \frac{\partial}{\partial \sigma^2}[-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)]\\<br/>
&amp;=\frac{\sum_{i=1}^N(x_i-\mu)^2}{2\sigma^4} - \frac{n}{2\sigma^2} \\<br/>
\Rightarrow &amp; \sigma^{2*} = \frac{1}{n}\sum_{i=1}^N (x_i-\mu)^2<br/>
\end{align*}<br/>
\]</p>

<p>所以极大似然估计为 \((\mu^*,\sigma^{2*})\)。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15055294223433.html">朴素贝叶斯 Native Bayes</a></h1>
			<p class="meta"><time datetime="2017-09-16T10:37:02+08:00" 
			pubdate data-updated="true">2017/9/16</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在概率论和统计学中，贝叶斯理论（或者贝叶斯法则、贝叶斯规则）通常是基于和事件相关的先验知识来描述概率事件。贝叶斯定理在很多地方都应用广泛，比如垃圾邮件、疾病预测等。</p>

<h3 id="toc_0">条件概率公式与贝叶斯定理</h3>

<p>设A、B是两个事件，在事件A发生的条件下，事件B发生的条件概率（conditional probability）为：<br/>
\[<br/>
P(B|A)<br/>
\]</p>

<p>同理在事件B发生的条件下，事件A发生的条件概率为\(P(A|B)\)<br/>
很容易想到事件A、事件B同时发生的概率等于事件A发生的概率乘上在事件A发生的条件下事件B发生的概率，即：<br/>
\[<br/>
P(AB) = P(A)P(B|A)<br/>
\]<br/>
同理也可得：\(P(AB) = P(B)P(A|B)\)<br/>
结合两式：<br/>
\[<br/>
\begin{eqnarray}<br/>
P(A)P(B|A) = P(B)P(A|B) \nonumber\\<br/>
\Rightarrow P(B|A) = \frac{P(B)P(A|B)}{P(A)} \label{bayes}<br/>
\end{eqnarray}<br/>
\]<br/>
上式（\ref{bayes}）就是贝叶斯定理公式，其中\(P(B)\)称之为先验概率（prior probability），是指在没有任何条件下事件B发生的概率，\(P(A|B)\)是事件B发生的条件事件A发生的条件概率，分母的\(P(A)\)被称为整体概率，因为它起到归一化的作用，所以又称为归一化常量。</p>

<h3 id="toc_1">全概率公式和贝叶斯定理</h3>

<p>如果事件组\(B_1\),\(B_2\),...,\(_n\)是样本空间\(\Omega\)的一个划分，A为任意事件，则：<br/>
\[<br/>
P(A) = P(A|B_1)+P(A|B_2)+...+P(A|B_n) = \sum_{i=1}^N P(A|B_i)P(B_i)<br/>
\]<br/>
全概率公式的意义在于，当直接计算\(P(A)\)不好计算时，而\(P(A|B_i)\)比较容易计算时，可以使用全概率公式计算\(P(A)\)。举个天气的实例，假设6月的某一天天晴的概率是0.4，多云的概率是0.4，下雨的概率是0.2。天晴的天气我出去玩的概率是0.4，多云的天气出去的概率是0.7，下雨的天气出去的概率是0.3，那么这一天我出去玩的概率设为\(P(play)\)：<br/>
\[<br/>
\begin{align*}<br/>
P(play) &amp;= P(play|sunny)P(sunny)+P(play|cloudy)P(cloudy)+P(play|rain)P(rain) \\<br/>
&amp;= 0.4\times 0.4 + 0.7\times 0.4 + 0.3\times 0.2 = 0.16+0.28+0.06=0.5<br/>
\end{align*}<br/>
\]<br/>
计算得出去玩的概率为0.5。</p>

<p>结合全概率公式和公式（\ref{bayes}）得：<br/>
\[<br/>
\begin{equation}<br/>
P(B_j|A) = \frac{P(B_j)P(A|B_j)}{\sum_{i=1}^N P(A|B_i)P(B_i)} \label{bayes_q}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_2">贝叶斯定理</h3>

<p>在上面的例子中，换一种问法，假设那一天如果在我出门的条件下，各个天气状况的概率分别是多少？那么便可以使用贝叶斯定理计算：<br/>
\[<br/>
P(sunny|play) = \frac{P(sunny)P(play|sunny)}{P(play)} = \frac{0.4\times 0.4}{0.5} = 0.32\\<br/>
P(cloudy|play) = \frac{P(cloudy)P(play|cloudy)}{P(play)} = \frac{0.4\times 0.7}{0.5} = 0.56\\<br/>
P(rain|play) = \frac{P(rain)P(play|rain)}{P(play)} = \frac{0.2\times 0.3}{0.8} = 0.12\\<br/>
P(\Omega)=P(sunny|play) + P(cloudy|play) + P(rain|play) = 0.32+0.56+0.12 = 1<br/>
\]<br/>
我觉得从这个实例中已经完全可以理解贝叶斯定理了。</p>

<h3 id="toc_3">先验概率谬误</h3>

<p>先通过一个经典的例子开始说明，假设某种疾病在所有人群中的感染率是 \(0.1\%\)，医院现有的技术对于已知患病情况下，\(99\%\)的可能性可以检查出阳性；对于正常人\(99\%\)的可能性检查为正常，如果从人群中随机抽一个人去检测，医院给出的检测结果为阳性，那么这个人实际得病的概率是多少？从直观上来看，很多人会直接说\(99\%\)，那么真实情况我们来通过贝叶斯定理计算一下:<br/>
\[<br/>
\begin{align*}<br/>
P(患病|阳性) &amp;= \frac{P(患病)P(阳性|患病)}{P(阳性)} = \frac{P(患病)P(阳性|患病)}{P(阳性|患病)P(患病)+P(阳性|正常)P(正常)} \\<br/>
&amp;= \frac{0.1\%\times 99\%}{99\%\times 0.1\%+1\%\times 99.9\%} = \frac{9.9‱}{9.9‱+99.9‱} \approx 9.02\%<br/>
\end{align*}<br/>
\]</p>

<p>可知其实被检测出来是阳性，患病机率也不高。这种情况下，先验概率的大小会严重影响检测结果，很多时候会反直觉。先验概率数据不一定在每种情况下都存在，但是假如确实有这个数据你却不用，那么，你将毁于先验概率谬误，即忽略事前数据并因此作出错误决策。</p>

<p>来一句题外话：如果这个人再去医院复检，检测结果仍为阳性，那么患病概率可以算一下：<br/>
\[<br/>
\begin{align*}<br/>
P(患病|(阳性\cap 阳性)) &amp;= \frac{P(患病)P((阳性\cap 阳性)|患病)}{P((阳性\cap 阳性)|患病)P(患病)+P((阳性\cap 阳性)|正常)P(正常)} \\<br/>
\because  P((阳性\cap 阳性)|患病) &amp;= P(阳性|患病)P(阳性|患病) = 99\% \times 99\%=98.01‱\\<br/>
P((阳性\cap 阳性)|正常) &amp;= P(阳性|正常)P(阳性|正常) = 1\%\times 1\%=0.01‱ \\<br/>
\therefore P(患病|(阳性\cap 阳性)) &amp;= \frac{0.1\%\times 98.01‱}{98.01‱\times 0.1\%+0.01‱\times 99.9\%} = 90.75\%\\ <br/>
\end{align*}<br/>
\]<br/>
可见复检后患病的可信度一下子高出了10倍，还是很有效果的。</p>

<h2 id="toc_4">贝叶斯参数估计</h2>

<p>对于参数估计，一直存在两个学派的不同解决方案。频率派把需要推断的<font color=red>参数θ看做是固定的</font>未知常数，即概率虽然是未知的，但最起码是确定的一个值，同时，<font color=red>样本X 是随机的</font>，所以频率派重点研究样本空间，大部分的概率计算都是针对样本X 的分布；；贝叶斯派的观点则截然相反，他们认为<font color=red>参数是随机变量，而样本X 是固定的</font>，由于样本是固定的，所以他们重点研究的是参数的分布。在两种学派里后面要学的极大似然估计便是频率派的代表算法。而接下来的贝叶斯参数估计和后面需要学习的最大后验概率估计毫无疑问便是贝叶斯派的代表算法。</p>

<p>贝叶斯参数估计是以贝叶斯公式为理论基础的参数估计方法。假设有一个样本集\(x=(x_1,x_2,...,x_n)\)，其中参数是\(\theta=(\theta_1,\theta_2,...,\theta_k)\)，贝叶斯估计的本质就是通过固定的样本利用贝叶斯方法得到参数\(\theta\)的分布。</p>

<p>人们根据先验信息对参数 \(\theta\) 有个基本的认识，这个认识就是先验分布。然后我们通过实验对先验分布进行调整，调整的方法就是贝叶斯方程，调整的结果就是后验分布。</p>

<h4 id="toc_5">先验分布</h4>

<p>将总体中的未知参数 \(\theta\) 看作是变量，样本 \(x\) 看作是常量，可以得到关于 \(\theta\) 的方程\(\pi(\theta)\)，\(\pi(\theta)\)认为是待估计参数\(\theta\) 的先验分布，且 \(\theta\) 的取值和样本集 \(x\) 有关（以下说明中都忽略数据集，如先验分布 \(\pi(\theta,D)\) 写成 \(\pi(\theta)\) ，样本 \(\pi(x|\theta,\text{D})\) 写成 \(\pi(x|\theta)\) ）。</p>

<h4 id="toc_6">后验分布</h4>

<p>考虑到联合概率分布：<br/>
\[<br/>
h(x_1,x_2,...,x_n,\theta)=p(x_1,x_2,...,x_n|\theta)\pi(\theta)=p(\theta|x_1,x_2,...,x_n)p(x_1,x_2,...,x_n)<br/>
\]<br/>
所以可得：<br/>
\[<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{p(x_1,x_2,...,x_n|\theta)\pi(\theta)}{p(x_1,x_2,...,x_n)} = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{p(x_1,x_2,...,x_n)}<br/>
\]<br/>
对于\(p(x_1,x_2,...,x_n)\)，我们称之为边缘分布函数，记为 \(m(x)\)，如果参数空间\(\Theta=(\theta_1,\theta_2,...,\theta_n)\)是离散的，应用全概率公式，可得离散边缘分布：<br/>
\[<br/>
\begin{align*}<br/>
m(x) &amp;= p(x_1,x_2,...,x_n) = \prod_{i=1}^n p(x_i) =\prod_{i=1}^n p(x_i|\theta_1)\pi(\theta_1)+\prod_{i=1}^n p(x_i|\theta_2)\pi(\theta_2)+...+\prod_{i=1}^n p(x_i|\theta_n)\pi(\theta_n)\\<br/>
&amp;= \sum_{j}\pi(\theta_j)\prod_{i=1}^n p(x_i,\theta_j)\\<br/>
\end{align*}<br/>
\]<br/>
如果参数空间\(\Theta\)是连续的，应用积分可得连续边缘分布：<br/>
\[<br/>
m(x) = p(x_1,x_2,...,x_n) = \prod_{i=1}^n p(x_i) = \prod_{i=1}^n [\int_\theta p(x_i,\theta)\pi(\theta)d\theta]=\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta<br/>
\]<br/>
这里我们称\(p(\theta|x_1,x_2,...,x_n)\)为后验分布，可以分情况写出后验分布的公式：<br/>
1）参数空间\(\Theta=(\theta_1,\theta_2,...,\theta_n)\)是离散<br/>
\[<br/>
\begin{align}<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\sum_{j}\pi(\theta_j)\prod_{i=1}^n p(x_i,\theta_j)} \label{ls}<br/>
\end{align}<br/>
\]<br/>
2）参数空间\(\Theta\)是连续<br/>
\[<br/>
\begin{align}<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} \label{lx}<br/>
\end{align}<br/>
\]</p>

<p>这里介绍一些常用分布的后验分布：</p>

<h4 id="toc_7">二项分布 binomial distribution</h4>

<p>在n重伯努利试验（同样的条件下重复地、相互独立地进行的一种随机试验）中，如果它分别以概率 \(\theta\) 和 \((1-\theta)\) 取1和0为值，恰好出现 k 次1的概率为 \(p(X=k|\theta)= \text{C}_n^k\theta^k(1-\theta)^{n-k}\)，这就是二项分布的分布律，记为\(\text{X}\sim B(n,\theta)\)，当 \(n=1\) 时二项分布又称为伯努利分布。</p>

<p>假设我们实现对概率\(\theta\)没有任何信息，这种情形贝叶斯本人建议使用“等同无知”的原则，使用(0,1)上的均匀分布U(0,1)作为 \(\theta\) 的先验分布，因为在(0,1)上每一点的概率都相等，这被人称为贝叶斯假设。所以 \(\theta\) 出现的概率为\(\pi(\theta)\)<br/>
\[<br/>
\pi(\theta) = \left \{ \begin{array}\\<br/>
1\qquad 0\lt \theta \lt 1\\<br/>
0\qquad \text{其他}<br/>
\end{array}\right.<br/>
\]</p>

<p>考虑上述二项分布事件与概率 \(\theta\) 的联合概率分布：<br/>
\[<br/>
h(X=k,\theta) = f(X=k|\theta)\pi(\theta) = \text{C}_n^k\theta^k(1-\theta)^{n-k},\qquad k=1,2,...,n,0\lt \theta \lt 1<br/>
\]</p>

<p>考虑到该参数空间\(\theta\)是连续的，结合（\ref{lx}）式：<br/>
\[<br/>
\begin{align}<br/>
\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta &amp;= \int_\theta f(X=k|\theta)\pi(\theta)d\theta = \int_\theta \text{C}_n^k\theta^k(1-\theta)^{n-k} d\theta = \text{C}_n^k\int_0^1 \theta^k(1-\theta)^{n-k} d\theta \label{lllx}\\<br/>
\end{align}<br/>
\]</p>

<p>为方便令 \(j=n-k\) ，设：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j) &amp;= \int_0^1 \theta^k(1-\theta)^j d\theta<br/>
\end{align*}<br/>
\]<br/>
利用分部积分法，令 \(\mu(\theta) = (1-\theta)^j\)，令 \(v(\theta) = \frac{1}{k+1}\theta^{k+1}\)，则：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j)&amp;=\int_0^1 \theta^k(1-\theta)^j d\theta = \int_0^1 \mu(\theta)\nu(\theta)&#39; = [u(\theta)v(\theta)]^1_0-\int_0^1 \nu(\theta) \mu(x)&#39;dx \\<br/>
&amp;= [u(\theta)v(\theta)]^1_0-\int_0^1 \frac{1}{k+1}\theta^{k+1}(-j)(1-\theta)^{j-1}d\theta\\<br/>
&amp;= [u(\theta)v(\theta)]^1_0 + \frac{j}{k+1}\int_0^1 \theta^{k+1}(1-\theta)^{j-1}d\theta\\<br/>
&amp;= [u(1)v(1)-u(0)v(0)] + \frac{j}{k+1} J(k+1,j-1)\\<br/>
&amp;= \frac{j}{k+1} J(k+1,j-1)\\<br/>
\end{align*}<br/>
\]<br/>
以此类推：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j) &amp;= \frac{j}{k+1} J(k+1,j-1) = \frac{j(j-1)}{(k+1)(k+2)}J(k+2,j-2) = ... = \frac{j(j-1)\cdots 2\cdot 1}{(k+1)\cdots (k+j)}J(k+j,0) \\<br/>
\end{align*}<br/>
\]<br/>
其中：<br/>
\[<br/>
J(k+j,0) = \int_0^1 \theta^{k+j}(1-\theta)^0 d\theta = \int_0^1 \theta^{k+j}d\theta = \frac{1}{k+j+1}\theta^{k+j+1}|^1_0 = \frac{1}{k+j+1}<br/>
\]<br/>
所以：<br/>
\[<br/>
J(k,j) = \frac{j(j-1)\cdots 2\cdot 1}{(k+1)\cdots (k+j)(k+j+1)} = \frac{j!}{(k+1)\cdots (k+j)(k+j+1)}<br/>
\]<br/>
考虑到伽马函数 \(\Gamma(n) = (n-1)!\)（这里不叙述伽马函数的由来，后面会有伽马函数的介绍）：<br/>
\[<br/>
J(k,j) = \frac{j!}{(k+1)\cdots (k+j)(k+j+1)} = \frac{\Gamma(j+1)\Gamma(k+1)}{\Gamma(j+k+2)}<br/>
\]<br/>
至此我们可以再看看式\ref{lllx}，代入得：<br/>
\[<br/>
\begin{align*}<br/>
\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta &amp; = \text{C}_n^k\int_0^1 \theta^k(1-\theta)^{n-k} d\theta = \text{C}_n^k \frac{\Gamma(n-k+1)\Gamma(k+1)}{\Gamma(n+2)}\\<br/>
\end{align*}<br/>
\]<br/>
将上式带入后验公式（\ref{lx}）便可得二项分布的后验概率：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta|x_1,x_2,...,x_n) &amp;= \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} = \frac{h(X=k,\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} \\<br/>
&amp;= \frac{\Gamma(n+2)}{\text{C}_n^k\Gamma(n-k+1)\Gamma(k+1)} \text{C}_n^k\theta^k(1-\theta)^{n-k} \\<br/>
&amp;= \frac{\Gamma(n+2)}{\Gamma(n-k+1)\Gamma(k+1)} \theta^k(1-\theta)^{n-k},\qquad k=1,2,...,n,0\lt \theta \lt 1<br/>
\end{align*}<br/>
\]<br/>
对比 Beta 分布的概率密度函数：<br/>
\[<br/>
f(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1−x)^{\beta−1} = \frac{1}{B(\alpha,\beta)}x^{\alpha−1}(1−x)^{\beta−1}<br/>
\]<br/>
只要令\(\alpha=k+1,\beta = n-k+1\)，就会发现这两者形式完全一致，所以我们可以说二项分布的后验分布服从 Beta 分布，即 \(\theta|X \sim \text{Be}(k+1,n-k+1)\)，由 Beta 分布的性质可知，二项分布后验分布的期望为：<br/>
\[<br/>
\theta^* = E(\theta|X) = \frac{\alpha}{\alpha+\beta} =  \frac{k+1}{n+2}<br/>
\]</p>

<p>这里举个例子：Laplace在1786年研究了巴黎的男婴出生的比率,他希望检验男婴出生的概率 \(\theta\) 是否大于0.5.为此,他收集到1745~1770年在巴黎出生的婴儿数据.其中,男婴251527个,女婴241945个,他选用U(0,1)作为 \(\theta\) 的先验分布,则 \(\theta\) 的后验分布服从 \(\beta\) 分布，即 \(\beta\sim Be(k+1,n-k+1) = Be(251528,241946)\)，所以：<br/>
\[<br/>
\begin{align*}<br/>
&amp;n = 251527 + 241945 = 493472\\<br/>
&amp;\hat\theta = \frac{k+1}{n+2} = \frac{251527+1}{493472+2} = 0.5097<br/>
\end{align*}<br/>
\]</p>

<h4 id="toc_8">高斯分布</h4>

<p>设 \(x_1\) , \(x_2\) , …, \(x_n\)是来自高斯分布 \(N(\mu,\sigma^2)\)的一个样本，其中 \(\sigma^2\) 已知， \(\mu\)未知，假设 \(\mu\) 的先验分布亦为高斯分布 \(N(\theta,\tau^2)\)，其中先验均值 \(\theta\) 和先验方差 \(\tau^2\) 均已知。</p>

<p>由高斯分布可知样本 \(\mu\) 的先验分布概率密度函数为：<br/>
\[<br/>
\pi(\mu) = \frac{1}{\sqrt{2\pi}\tau}\exp(-\frac{(\mu-\theta)^2}{2\tau^2})<br/>
\]<br/>
样本 \(x_1\), \(x_2\) , …, \(x_n\) 的条件概率密度函数为：<br/>
\[<br/>
p(x|\mu) =\prod_i^n p(x_i|\mu) = (\frac{1}{\sqrt{2\pi}\sigma})^n \exp(\sum_i^n -\frac{(x_i-\mu)^2}{2\sigma^2})\\<br/>
\]<br/>
所以联合概率密度为：<br/>
\[<br/>
\begin{align*}<br/>
h(x,\mu) &amp;= p(x|\mu)\pi(\mu) = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(\sum_i^n -\frac{(x_i-\mu)^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(-\sum_i^n \frac{x_i^2-2\mu x_i + \mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(- \frac{\sum_i^n x_i^2-2 \sum_i^n \mu x_i + \sum_i^n \mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(- \frac{\sum_i^n x_i^2-2 n \mu \overline x + n\mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp;=  (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(-(\frac{n}{2\sigma^2}+\frac{1}{2\tau^2})\mu^2  + (\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2})\mu - (\frac{\sum_i^n x_i^2}{2\sigma^2}+\frac{\theta^2}{2\tau^2}))\\<br/>
\end{align*}<br/>
\]<br/>
其中 \(\overline x = \frac{1}{n} \sum_i^n x_i\)。若令\(k = \frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau}\)，\(A = (\frac{n}{\sigma^2}+\frac{1}{\tau^2})\)，所以 \(A&gt;0\)，\(B = (\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2})\)，\(C = (\frac{\sum_i^n x_i^2}{\sigma^2}+\frac{\theta^2}{\tau^2})\)，则：<br/>
\[<br/>
\begin{align*}<br/>
h(x,\mu) &amp;= k\cdot \exp[-\frac{1}{2}(A\mu^2-2B\mu+C)] \\<br/>
&amp;= k\cdot \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})]\nonumber\\<br/>
\end{align*}<br/>
\]</p>

<p>由于参数空间 \(\mu\) 是连续的，所以边缘分布 \(m(x)\)为：<br/>
\[<br/>
\begin{align}<br/>
m(x) &amp;= \int_\mu\prod_{i=1}^n  p(x_i,\mu)\pi(\mu)d\mu = \int_\mu h(x,\mu) d\mu\nonumber\\<br/>
&amp;=k\cdot \int_\mu \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})] d\mu\nonumber\\<br/>
&amp;=k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})]\int_\mu \exp([-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu\label{mx}\\<br/>
\end{align}<br/>
\]</p>

<p>我们先来求解这个式子<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu \label{yiim}<br/>
\end{equation}<br/>
\]<br/>
用 \(\nu\) 替换其中的 \(\mu\) 得：<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\nu \label{yiin}<br/>
\end{equation}<br/>
\]<br/>
用式\ref{yiim}和式\ref{yiin}相乘得：<br/>
\[<br/>
\begin{align*}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu \int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\nu &amp;= \int\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\mu d\nu \\<br/>
&amp;= \int\int_{-\infty}^{\infty} \exp\{-\frac{A}{2} [(\mu-\frac{B}{A})^2+(\nu-\frac{B}{A})^2]\}d\mu d\nu<br/>
\end{align*}<br/>
\]<br/>
令\(\mu-\frac{B}{A} = r\cos\alpha\)，\(\nu-\frac{B}{A} = r\sin\alpha\)，其中\(\alpha\in[0,2\pi]，r\in[0,\infty]\)，为方便计算令\(f^2\)等于等式左边：<br/>
\[<br/>
\begin{align*}<br/>
f^2 &amp;= \int_{0}^{\infty}\int_{0}^{2\pi} \exp\{-\frac{A}{2} [(r\cos\alpha)^2+(r\sin\alpha)^2]\}r dr d\alpha\\<br/>
&amp;= \int_{0}^{\infty}\int_{0}^{2\pi} \exp(-\frac{A}{2}r^2)r dr d\alpha\\<br/>
&amp;= \int_{0}^{\infty}\exp(-\frac{A}{2}r^2)r\int_0^{2\pi} d\alpha\\<br/>
&amp;= 2\pi \int_0^\infty \exp(-\frac{A}{2}r^2)rdr\\<br/>
&amp;= 2\pi \cdot [-\frac{1}{A} \exp(-\frac{A}{2}r^2) ]^\infty_0\\<br/>
\end{align*}<br/>
\]<br/>
由前面定义\(A = (\frac{n}{\sigma^2}+\frac{1}{\tau^2})\)，显然 \(A&gt;0\)，所以：<br/>
\[<br/>
f^2 =2\pi \cdot [-\frac{1}{A} \exp(-\frac{A}{2}r^2) ]^\infty_0 = 2\pi \frac{1}{A} [\exp(0)-\exp(-\infty)] = \frac{2\pi}{A}\\<br/>
\Rightarrow f = (\frac{2\pi}{A})^{1/2}<br/>
\]</p>

<p>将上述结果带入式\ref{mx}，可知：<br/>
\[<br/>
\begin{align*}<br/>
m(x) &amp;= k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})]\int_\mu \exp([-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu \\<br/>
&amp;= k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})] (\frac{2\pi}{A})^{1/2}<br/>
\end{align*}<br/>
\]<br/>
由后验公式（\ref{lx}）可得：<br/>
\[<br/>
\begin{align*}<br/>
p(\mu|x) &amp;= \frac{\pi(\mu)\prod_{i=1}^n p(x_i|\mu)}{\int_\mu\prod_{i=1}^n  p(x_i,\mu)\pi(\mu)d\mu} = \frac{h(x,\mu)}{m(x)} = \frac{k\cdot \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})]}{k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})] (\frac{2\pi}{A})^{1/2}} \\<br/>
&amp;= (\frac{A}{2\pi})^{1/2} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2]\\<br/>
&amp;= \frac{1}{2\pi\sqrt{1/A}} \exp[-\frac{(\mu - \frac{B}{A})^2}{2/A}]<br/>
\end{align*}<br/>
\]<br/>
对比高斯分布可知\(p(\mu|x)\sim N(B/A,1/A)\)，即：<br/>
\[<br/>
p(\mu|x) \sim N(\frac{\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2}}{\frac{n}{\sigma^2}+\frac{1}{\tau^2}},\frac 1{\frac{n}{\sigma^2}+\frac{1}{\tau^2}}) = N(\frac{n\tau^2\overline x+\theta\sigma^2}{n\tau^2+\sigma^2},\frac{\tau^2\sigma^2}{n\tau^2+\sigma^2})<br/>
\]</p>

<p>后验均值即为贝叶斯估计：<br/>
\[<br/>
\hat u = \frac{n\tau^2\overline x+\theta\sigma^2}{n\tau^2+\sigma^2}<br/>
\]</p>

<h4 id="toc_9">共轭分布法</h4>

<p>我们前面再二项分布时说如果一个没有任何先验知识的分布可以看作为“等同无知”，采用均匀分布U(0,1)作为先验分布，这里均匀分布也可以看作是贝塔分布 \(\text{Beta}(1,1)\)，所以二项分布 \(\text{B}(n,\theta)\) 的先验分布为 \(\text{Beta}(1,1)\) 时，后验分布为 \(\text{Beta}(k+1,n-k+1)\) ，其中k表示n次独立试验中正例出现的次数。这种先验分布和后验分布属于同一个分布类型的现象并不是偶然的，在上文的高斯分布也证明了这一点，先验分布是高斯分布，后验分布也是高斯分布。</p>

<p>共轭分布法就是指<strong>先验分布和后验分布属于同一个分布类型</strong>。</p>

<h4 id="toc_10">贝叶斯估计举例</h4>

<p>这个举个例子，为了提高某产品质量，某部门经理希望引入不同厂家生产的一种设备，两厂家招标时称：<br/>
<font color='#666'>1）使用厂家一设备生产后，高质量产品将占90%；</font><br/>
<font color='#666'>2）使用厂家二设备生产后，高质量产品将占70%；</font><br/>
部门经理根据以往两厂家的用户评价，认为厂家一的可信度为40%，厂家二的可信度为60%。</p>

<p>首先来数学化这些数字，将厂家一、厂家二认为是两个不同的参数\(\theta_1\)，\(\theta_2\)，那么可知 \(p(\theta_1) = 40\%;p(\theta_2) = 60\%\)，将生产高质量产品看作概率分布 \(p(x,\theta)\)，可知\(p(x,\theta_1) = 90\%\)，\(p(x,\theta_2)=70\%\)。</p>

<p>部门经理为此做了小型试验，第一次实验分别使用两厂家的设备进行生产，生产5件产品，都是高质量产品，记第一次实验为事件A，高质量产品记为1，否则为0，则：<br/>
\[<br/>
A|\theta_1 = (1,1,1,1,1)\\<br/>
A|\theta_2 = (1,1,1,1,1)<br/>
\]<br/>
第二次实验，再生产5件产品，使用设备一都是高质量产品，使用设备二4件高质量产品，记第二次实验为事件B，则：<br/>
\[<br/>
B|\theta_1 = (1,1,1,1,1)\\<br/>
B|\theta_2 = (1,1,1,1,0)\\<br/>
\]<br/>
我们利用事件A使用离散性后验分布概率：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta_1|A) &amp;= p(\theta_1|x_1,x_2,...,x_n) = \frac{p(\theta_1)\prod_{i=1}^n p(x_i|\theta_1)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} \\<br/>
&amp;= \frac{0.9^5*0.4}{0.4*0.9^5+0.6*0.7^5} = \frac{0.236}{0.236 + 0.101} = 0.700\\<br/>
p(\theta_2|A) &amp;= p(\theta_2|x_1,x_2,...,x_n) = \frac{p(\theta_2)\prod_{i=1}^n p(x_i|\theta_2)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} =0.300<br/>
\end{align*}<br/>
\]</p>

<p>通过实验一（事件A）更新了我们对厂家的可信度，计算得厂家一的可信度为0.7，厂家二的可信度为0.3，再来看第二次实验（事件B）计算可信度：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta_1|A) &amp;= p(\theta_1|x_1,x_2,...,x_n) = \frac{p(\theta_1)\prod_{i=1}^n p(x_i|\theta_1)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} \\<br/>
&amp;= \frac{0.9^5*0.7}{0.7*0.9^5+0.3*0.7^4*0.3} = \frac{0.413}{0.413+0.022} = 0.949\\<br/>
p(\theta_2|A) &amp;= p(\theta_2|x_1,x_2,...,x_n) = \frac{p(\theta_2)\prod_{i=1}^n p(x_i|\theta_2)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} = 0.051\\<br/>
\end{align*}<br/>
\]</p>

<p>通过实验二（事件B）计算已经可以得出厂家一的可信度为0.949，所以我们很有理由可以选择采进此设备。</p>

<p><strong>关于贝叶斯的知识还有很多，以后遇见再继续讨论~</strong></p>

<p><font color="#666"></p>

<p>我们来求解这个式子的另一种方法（只解出了一半，如果有人可以继续解下去，希望能联系我）<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu<br/>
\end{equation}<br/>
\]</p>

<p>这个函数的定积分不容易直接求得，我们先看一下伽马函数 \(\Gamma(s)\) ，定义如下：<br/>
\[<br/>
\begin{equation}<br/>
\Gamma(s) = \int_0^\infty e^{-x} x^{s-1} dx\qquad (s&gt;0) \label{Gamma}<br/>
\end{equation}<br/>
\]<br/>
由余元公式可知：<br/>
\[<br/>
\Gamma(s)\Gamma(1-s) = \frac{\pi}{\sin\pi s} \qquad (0\lt s \lt 1)<br/>
\]<br/>
所以：<br/>
\[<br/>
\Gamma(\frac1 2) = \sqrt{\pi}<br/>
\]</p>

<p>对\ref{Gamma}式利用定积分换元法，\(A&gt;0\) 情况下，令 \(x = \frac{A}{2}(\mu-\frac{B}{A})^2\)，则：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad dx = A(\mu-\frac{B}{A})d\mu\\<br/>
&amp;\therefore\quad \Gamma(s) = \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] [\frac{A}{2}(\mu-\frac{B}{A})^2]^{s-1} [A (\mu-\frac{B}{A})]d\mu \\<br/>
&amp;\qquad\qquad = \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] (\frac{A}{2})^{s-1}\cdot (\mu-\frac{B}{A})^{2s-1}\cdot Ad\mu \\<br/>
\end{align*}<br/>
\]<br/>
令 \(s=\frac 1 2\)：<br/>
\[<br/>
\begin{align}<br/>
\Gamma(\frac 1 2) &amp;= \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] (\frac{A}{2})^{-1/2}\cdot (\mu-\frac{B}{A})^0\cdot Ad\mu\nonumber\\<br/>
&amp;= \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2](2A)^{1/2} d\mu = \sqrt{\pi}\nonumber\\<br/>
&amp;\Rightarrow \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu = (\frac{\pi}{2A})^{1/2}\label{G0I}<br/>
\end{align}<br/>
\]<br/>
关于<br/>
\[<br/>
\begin{align}<br/>
\int_{-\infty}^0 \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu\label{GI0}<br/>
\end{align}<br/>
\]<br/>
怎么解，还没有一个好的方法，希望以后能解决。</p>

<p></font></p>

<hr/>

<p>[1] &nbsp;&nbsp;<a href="https://cosx.org/2013/01/lda-math-gamma-function">神奇的 Gamma 函数</a><br/>
[2] &nbsp;&nbsp;<a href="https://blog.csdn.net/u010945683/article/details/48950063">贝塔与伽马分布</a><br/>
[3] &nbsp;&nbsp;<a href="https://mp.weixin.qq.com/s/ZEoxYPgenFgzHuNnI2IieQ">贝塔分布生动的棒球例子</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15042890159558.html">随机领域嵌入算法 SNE</a></h1>
			<p class="meta"><time datetime="2017-09-02T02:03:35+08:00" 
			pubdate data-updated="true">2017/9/2</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>SNE算法，英文全称是stochastic neighbor embedding，它是将高维向量或成对的不相似度描述的对象“嵌入（Embed）”到低维空间中，并保持对象邻居间的特性。SNE将高维或低维空间的点都看做高斯分布，在这个高斯分布下的密度，用来定义对象所有潜在邻居点的概率分布。SNE属于一种流行学习的降维方法，首先我们介绍一下流行学习。</p>

<h3 id="toc_0">前置知识</h3>

<h4 id="toc_1">流形学习</h4>

<p>关于“流形”两个字一直不好理解，如果按照字面意思翻译，那么“manifold”翻译成“多样体”的意思。看到一篇论文上说到，中国第一个拓扑学家江泽涵（北大老教授）把这个词翻译为 “流形”，取自文天祥《正气歌》，“天地有正气，杂然赋流形”，而其原始出处为《易经》，“大哉乾元，万物资始，乃统天。云行雨施，品物流形。” 这个翻 译比英文翻译更加符合黎曼的原意，即多样化的形体。黎曼定义的“n 维流形”大概是这个样子的：以其中一个点为基准，则周围每个点的位置都可以用 n 个实数来确定，比如圆形如果用极坐标表示以圆心作为基点，那么只需要一个实数（坐标）就可以确定，所以称圆形为一维流形，再比如如果是一个圆球，假设为地球，那么如果以某个点为基点，作经纬线，那么只需要两个个实数（经度值、纬度值）便能确定其他点，可以称圆球为二维流形。</p>

<p>在流形空间里，存在一些性质：（1）流形空间中，过任意两点都不存在平行线，即任意两线都会相交，这个性质很容易在球面上看出来，球面上任意两线都会相交。（2）流形空间里，三角形的内角和不一定等于180度，也容易在一个球面上看出来。（3）总有一点是风平浪静的，如果放到一维流形中便是极坐标远点，如果在二维流形中便是极点了。</p>

<p>那么什么样的空间是流形空间呢？一个直观的感受是在空间内任意一个足够小的区域内，可以近似为欧式空间，这样的空间就是流形空间。比如圆球上任意一个足够小的区域，都可以看做欧式空间，可以找到平行线，三角形内角和为180度，所以认为圆球是流形空间。而假设圆球上竖起了一个直杆，假设直杆可以看做一条线，那么它将不能被看做是一个流形空间了，因为考虑到这个直杆所在的微小区域无法描述为欧式空间。</p>

<p>流形学习的英文名称叫做manifold Learning，是机器学习、模式识别中的一种方法，其主要思想是把一个高维的数据非线性映射到低维，该低维数据能够反映高维数据的本质，当然有一个前提假设就是高维观察数据存在流形结构，其优点是非参数，非线性，求解过程简单。</p>

<p>总体上来说这里关于流形的介绍不够严谨科学，仅是作为我对流形的初步理解，推荐几篇比较好的文章：<a href="http://blog.pluskid.org/?p=533">浅谈流形学习</a>，<a href="http://www.cad.zju.edu.cn/reports/%C1%F7%D0%CE%D1%A7%CF%B0.pdf">浙大流形学习PPT</a></p>

<h3 id="toc_2">SNE基本原理</h3>

<p>SNE是由Geoffrey Hinton 和 Sam Roweis在2012年提出的算法，原始论文看<a href="https://www.cs.toronto.edu/%7Ehinton/absps/sne.pdf">这里</a>，论文提出了用邻居点概率分布的方式来将高维空间点映射到低维空间。</p>

<h4 id="toc_3">SNE原理推导</h4>

<p>对于每一个对象 \(i\) ，和它潜在的邻居点 \(j\) ,我们来计算它们之间的非对称概率 \(p_{j|i}\) ，即 \(i\) 选择 \(j\) 作为邻居的概率：<br/>
\[<br/>
p_{j|i} = \frac{\exp(-{d_{i|j}}^2)}{\sum_{k\neq i}\exp(-{d_{i,k}}^2)}<br/>
\]<br/>
其中不相似度\({d_{i|j}}^2\)可以是问题定义时给定的（不需要是对称的）也可以能是两个高维点 \(x_i\) 和 \(x_j\) 通过缩放的平方欧几里得距离计算得到的：<br/>
\[<br/>
{d_{j|i}}^2 = \frac{||x_i - x_j||^2}{2\sigma_i^2}<br/>
\]<br/>
这里的 \(\sigma_i\) 可以手动设置或者（在我们的经验里）通过二分搜索法找到使邻居分布的熵等于 \(\log(k)\) 的 \(\sigma_i\)值，其中这里 \(k\) 是附近有效邻居点个数或者我们手动设置的困惑度（perplexity）。原文中的这段话比较拗口，简单来说就是我们可以先手动选取一个困惑度（proplexity）通常选取的依据是点 \(i\) 附近有效邻居点的个数，SNE对困惑度的调整比较有鲁棒性，通常选择5-50之间，假设这个值为 \(k\) 。由概率分布中困惑度通常写作：<br/>
\[<br/>
\text{Perplexity}(P_i) = b^{H(P_i)}<br/>
\]<br/>
通常这里的b取2，其中\(H(P_i)\)表示 \(P_i\)的熵：<br/>
\[<br/>
H(P_i) = -\sum_j p_{j|i}\log_2(p_{j|i})<br/>
\]<br/>
所以可得\(\log_2(\text{Perplexity}(P_i))\) 等于 \(P_i\)的熵，即 \(\log_2(k) = H(P_i)\)，而我们需要做的就是通过二分法找到合适的 \(\sigma_i\) 使这个等式成立。</p>

<p>而在低维空间中我们也用高斯邻居，但是使用一个固定的方差（这里我们不失一般性的设置为 \(\sigma_i^2=\frac{1}{2}\) ），因此低维空间点 \(i\) 选择点 \(j\) 作为它的邻居的概率 \(q_{i|j}\) 是关于低维图像中对象 \(y_i\) 的函数，通过下面的表达式给出：<br/>
\[<br/>
\begin{equation}<br/>
q_{j|i} = \frac{\exp(-||y_i - y_j||^2)}{\sum_{k\neq i}\exp(-||y_i - y_k||^2)} \\\label{q_j_i}<br/>
\end{equation}<br/>
\]</p>

<p>嵌入的目的是使这两个分布尽可能的匹配。我们可以用最小化原始概率 \(p_{ij}\) 和归纳概率 \(q_{ij}\) 之间的KL散度（Kullback-Leibler divergences）之和作为损失函数，并通过最小化这个损失函数来达到目的：<br/>
\[<br/>
C = \sum_i \sum_j p_{j|i}\log\frac{p_{j|i}}{q_{j|i}} = \sum_{i} KL(P_i || Q_i)<br/>
\]</p>

<p>这里 \(y\) 空间（即降维后空间）的维度也是手动选择的（远小于对象的个数），由于KL散度具有不对称性,在低维映射中不同的距离对应的惩罚权重是不同的，直观上来看SNE强调局部距离，它的损失函数倾向使对象附近的图像靠近，使对象分离的图像相对较远。具体来说：距离较远的两个点来表达距离较近的两个点会产生更大的cost，相反，用较近的两个点来表达较远的两个点产生的cost相对较小。</p>

<p>代价函数C对 \(y_i\) 求导可得：<br/>
\[<br/>
\frac{\partial C}{\partial y_i} = \sum_j 2(y_i-y_j)(p_{i|j} - q_{i|j} + p_{j|i} -q_{j|i} )<br/>
\]<br/>
具体推导过程如下：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= \frac{\partial \sum_i \sum_j p_{j|i} \log(p_{j|i}/q_{j|i})}{\partial q_{j|i}} \cdot \frac{\partial q_{j|i}}{\partial y_i} \\<br/>
&amp;= -\sum_i\sum_j \frac{p_{j|i}}{q_{j|i}} \frac{\partial q_{j|i}}{\partial y_i}\\<br/>
&amp;= -\sum_m\sum_n \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{i|m}}{q_{i|m}} \frac{\partial q_{i|m}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{n|i}}{q_{n|i}} \frac{\partial q_{n|i}}{\partial y_i}\\<br/>
\end{align*}<br/>
\]</p>

<p>先看第一项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i} &amp;=  -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial \big[{\exp(-||y_m-y_n||^2)}/{\sum_{k\neq m} \exp(-||y_k-y_m||^2)}\big]}{\partial y_i} \\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i}\frac{\exp(-||y_m-y_n||^2)\exp(-||y_i-y_m||^2)(-2y_i+2y_m)}{(\sum_{k\neq m} \exp(-||y_k -y_m||^2))^2} \\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{n|m} \frac{\exp(-||y_i-y_m||^2)(-2y_i+2y_m)}{\sum_{k\neq m} \exp(-||y_k -y_m||^2)} \\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{n|m} q_{i|m}(2y_m-2y_i)\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第二项：</p>

<p>\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n=i}  \frac{p_{i|m}}{q_{i|m}} \frac{\partial q_{i|m}}{\partial y_i} &amp;= -\sum_{m\neq i}\frac{p_{i|m}}{q_{i|m}} \frac{\partial \big[{\exp(-||y_m-y_i||^2)}/{\sum_{k\neq m} \exp(-||y_k-y_m||^2)}\big]}{\partial y_i} \\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{i|m}}{q_{i|m}} \bigg(\frac{\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{\sum_{k\neq m} \exp(-||y_k-y_m||^2)}-\frac{\exp(-||y_m-y_i||^2)\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{(\sum_{k\neq m} \exp(-||y_k-y_m||^2))^2} \bigg)\\<br/>
&amp;= -\sum_{m\neq i} \frac{p_{i|m}}{q_{i|m}} \bigg(q_{i|m} (2y_m-2y_i)-q_{i|m}\frac{\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{\sum_{k\neq m} \exp(-||y_k-y_m||^2)} \bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{i|m}} \bigg((2y_m-2y_i)-\frac{\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{\sum_{k\neq m} \exp(-||y_k-y_m||^2)} \bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{i|m}} \bigg((2y_m-2y_i)-{q_{i|m}(2y_m-2y_i)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} p_{i|m}(2y_m-2y_i) + \sum_{m\neq i}p_{i|m} q_{i|m}(2y_m-2y_i)\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第三项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{n|i}}{q_{n|i}} \frac{\partial q_{n|i}}{\partial y_i} &amp;= -\sum_{n\neq i}\frac{p_{n|i}}{q_{n|i}} \frac{\partial \big[{\exp(-||y_n-y_i||^2)}/{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}\big]}{\partial y_i} \\<br/>
&amp;= -\sum_{n\neq i}  \frac{p_{n|i}}{q_{n|i}} \bigg(\frac{\exp(-||y_n-y_i||^2)(2y_n-2y_i)}{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}-\frac{\exp(-||y_n-y_i||^2)(\sum_{k\neq i} \exp(-||y_k-y_i||^2)(2y_k-2y_i))}{(\sum_{k\neq i} \exp(-||y_k-y_i||^2))^2}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  \frac{p_{n|i}}{q_{n|i}} \bigg({q_{n|i}(2y_n-2y_i)}-\frac{q_{n|i}(\sum_{k\neq i} \exp(-||y_k-y_i||^2)(2y_k-2y_i))}{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  p_{n|i}\bigg({(2y_n-2y_i)}-\frac{\sum_{k\neq i} \exp(-||y_k-y_i||^2)(2y_k-2y_i)}{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  p_{n|i}\bigg({(2y_n-2y_i)}-\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{n\neq i}  p_{n|i}\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\\<br/>
\end{align*}<br/>
\]</p>

<p>将上面三式代入，其中\(p_{i|i} = 0\)：<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial C}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{i|m}}{q_{i|m}} \frac{\partial q_{i|m}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{n|i}}{q_{n|i}} \frac{\partial q_{n|i}}{\partial y_i}\nonumber\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{n|m} q_{i|m}(2y_m-2y_i) - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) + \sum_{m\neq i}p_{i|m} q_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{n\neq i}  p_{n|i}\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\nonumber\\<br/>
&amp;= \sum_{m\neq i}\sum_{n} p_{n|m} q_{i|m}(2y_m-2y_i) - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{n\neq i}  p_{n|i}\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\nonumber\\<br/>
&amp;= \sum_{m\neq i}q_{i|m}(2y_m-2y_i) \sum_{n} p_{n|m} - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\sum_{n\neq i}  p_{n|i}\label{ttd}\\<br/>
\end{align}<br/>
\]</p>

<p>考虑到：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{n\neq i} p_{n|i} = \sum_{n\neq i} \frac{\exp(-{||x_i - x_n||^2}/{2\sigma_i^2})}{\sum_{k\neq i}\exp(-{||x_i - x_k||^2}/{2\sigma_i^2})} = \frac{\sum_{n\neq i}\exp(-{||x_i - x_n||^2}/{2\sigma_i^2})}{\sum_{k\neq i}\exp(-{||x_i - x_k||^2}/{2\sigma_i^2})} = 1\\<br/>
&amp;\sum_n p_{n|i} = \sum_{n\neq i} p_{n|i}  + p_{i|i} = 1 <br/>
\end{align*}<br/>
\]</p>

<p>上结论代入 \ref{ttd} 可得：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;=\sum_{m\neq i}q_{i|m}(2y_m-2y_i) - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\\<br/>
&amp;=\sum_{j\neq i}q_{i|j}(2y_j-2y_i) - \sum_{j\neq i}p_{i|j}(2y_j-2y_i) -\sum_{j\neq i}  p_{j|i} (2y_j-2y_i)+\sum_{j\neq i} q_{j|i}(2y_j-2y_i)\\<br/>
&amp;=\sum_{j\neq i}2(y_i-y_j)(p_{i|j} - q_{i|j} + p_{j|i} - q_{j|i})\\<br/>
&amp;=\sum_{j}2(y_i-y_j)(p_{i|j} - q_{i|j} + p_{j|i} - q_{j|i})\\<br/>
\end{align*}<br/>
\]</p>

<p>推导结束。</p>

<p>初始化时，可以以原点为中心选择较小的 \(\sigma\) 的高斯分布。为了避免陷入局部最优解，梯度中还需要一个相对较大的动量 momentum。即参数更新中除了当前梯度，还要引入之前梯度累加的指数衰减项，如下：<br/>
\[<br/>
Y^{(t)} = Y^{(t-1)} + \eta \frac{\partial C}{\partial Y} + \alpha^{(t)}(Y^{(t-1)} - Y^{(t-2)})<br/>
\]</p>

<p>这里 \(Y^{(t)}\) 表示迭代 \(t\) 次的解，\(\eta\) 表示学习速率，\(\alpha^{(t)}\) 表示迭代 \(t\) 次的动量。</p>

<p>此外，在优化的早期阶段，在每一轮迭代后向映射点中间加入一些高斯噪声，之后像模拟退火一样逐渐减小该噪声的方差，可以用来避免局部最优解。如果噪声的方差在全局结构开始形成临界点处改变非常慢，SNE 倾向于找到更好的全局结构的映射。不幸的是，这需要明智的选择一个高斯噪声的初始值和衰减速率，进一步来说，这个选择与动量大小及梯度下降中步长大小相互作用。因此通常在数据集上多次进行优化来寻找一个合适的参数。从这个角度来说，SNE 不如一些允许凸优化和不用引入模拟退火花费额外的计算时间和参数选择，就能给出很好的结果的优化方法。</p>

<h3 id="toc_4">T-SNE(t-Distributed Stochastic Neighbor Embedding)</h3>

<p>上一节介绍了 2002 年 Hinton 和 Roweis 提出的 SNE ，尽管 SNE 构造了相当好的可视化，但是它被难以优化的损失函数所束缚，我们把这个问题称为“crowding（拥挤）问题”。在这一小节中，我们将介绍一个新技术“T-SNE”来缓解这个问题。t-SNE 的损失函数和 SNE 的损失函数在两个地方有点不同：</p>

<ol>
<li>使个对称版本的 SNE ，其损失函数有着更简单的梯度。</li>
<li>使用 t 分布代替了高斯分布来计算在低维空间两个点的相似度。</li>
</ol>

<p>t-SNE 在低维空间使用一个重尾分布来避免 SNE 的拥挤问题和优化问题。在这一小节中，我们首先来介绍一下对称 SNE ，然后再来介绍拥挤问题，和使用重尾分布来处理这个问题。我们最后来介绍我们的方法来优化 t-SNE 损失函数。</p>

<h4 id="toc_5">对称 SNE（Symmetric SNE）</h4>

<p>对称 SNE 可以作为优化条件概率 \(p_{j|i}\) 和 \(p_{i|j}\) 的 KL 散度之和一个替代方案，还可以最小化高维空间中的联合概率分布 \(P\) 和低维空间的联合分布概率 \(Q\) 的单个 KL 散度：<br/>
\[<br/>
C = KL(P||Q) = \sum_{i} \sum_{j} p_{ij} \log \frac{p_{ij}}{q_{ij}}<br/>
\]</p>

<p>这里我们还是将 \(p_{ii}\) 和 \(q_{ii}\) 设为 0，我们称这种 SNE 叫做对称 SNE，因为联合概率分布有个特性 \(p_{ij} = p_{ji}\) 和 \(q_{ij} = q{ji}\)，在对称 SNE 中，低维空间映射的成对相似度 \(q_{ji}\) 可以表示为：<br/>
\[<br/>
\begin{equation}<br/>
q_{ij} = \frac{\exp(-||y_i-y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)} \label{qij}<br/>
\end{equation}<br/>
\]</p>

<p>显而易见定义在高维空间的成对相似度 \(p_{ij}\) 为：<br/>
\[<br/>
p_{ij} = \frac{\exp(-||x_i-x_j||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}<br/>
\]</p>

<p>但是考虑到高维数据点 \(x_i\) 是异常点时将产生问题（所有的点关于 \(x_i\) 的成对距离 \(||x_i-x_j||^2\) 都很大）。对于这样的异常点，\(p_{ij}\) 对于所有的 \(j\) 都非常小（之前仅是在 \(x_i\) 下很小），因此低维空间映射点 \(y_i\) 位置对损失函数的影响会很小，结果就是映射点的位置不能很好的由其他映射点的位置确定。我们可以通过定义高维空间的联合概率 \(p_{ij}\) 为对称条件概率来回避这个问题，即：<br/>
\[<br/>
p_{ij} = \frac{p_{j|i} + p_{i|j}}{2n}<br/>
\]</p>

<p>这即保证了 \(p_{ij}\) 的对称性，且对于所有的数据点 \(x_i\) 都有 \(\sum_{j} p_{ij} &gt; \frac{1}{2n}\) ，使每一个点 \(x_i\) 对损失函数都有一定的贡献。在低维空间里，对称 SNE 简单的使用式 \ref{qij} 。对称 SNE 最大的优点是梯度的形式更简单，可以更快的计算。来计算一下梯度，对称 SNE 的梯度与不对称 SNE 相似，如下：<br/>
\[<br/>
\frac{\partial C}{\partial y_i} = 4\sum_{j} (p_{ij} - q_{ij})(y_i - y_j)<br/>
\]</p>

<p>详细推导过程如下：<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial C}{\partial y_i} &amp;= \frac{\partial \sum_i \sum_j p_{ij} \log(p_{ij}/q_{ij})}{\partial q_{ij}} \cdot \frac{\partial q_{ij}}{\partial y_i} \nonumber\\<br/>
&amp;= -\sum_i\sum_j \frac{p_{ij}}{q_{ij}} \frac{\partial q_{ij}}{\partial y_i}\nonumber\\<br/>
&amp;= -\sum_m\sum_n \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}\nonumber\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\label{mnf}\\<br/>
\end{align}<br/>
\]</p>

<p>先看第一项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial \big[{\exp(-||y_m-y_n||^2)}/{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\big]}{\partial y_i}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\exp(-||y_m-y_n||^2)(\sum_{k \neq i,l=i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{k=i,l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2))}{(\sum_{k\neq l} \exp(-||y_k - y_l||^2))^2}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \frac{\sum_{j \neq i} 2(y_j-y_i) \exp(-||y_j - y_i||^2) - \sum_{j\neq i} 2(y_i - y_j)\exp(-||y_i - y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \frac{\sum_{j \neq i} 2(y_j-y_i-y_i+y_j) \exp(-||y_k - y_i||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij}\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第二项<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} &amp;=-\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \frac{\partial \big[{\exp(-||y_i-y_m||^2)}/{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\big]}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(\frac{-2(y_i-y_m)\exp(-||y_i-y_m||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}- \frac{\exp(-||y_i-y_m||^2)(\sum_{k \neq i,l=i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{k=i,l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2))}{(\sum_{k\neq l} \exp(-||y_k - y_l||^2))^2}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(-2q_{mi}(y_i-y_m) - q_{mi}\frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - \frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - \frac{\sum_{j \neq i} 2(y_j-y_i) \exp(-||y_j - y_i||^2) - \sum_{j\neq i} 2(y_i - y_j)\exp(-||y_i - y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - \frac{\sum_{j \neq i} 2(y_j-y_i-y_i + y_j) \exp(-||y_j - y_i||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\bigg)\\<br/>
&amp;= 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + \sum_{m\neq i}{p_{mi}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第三项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i} &amp;=-\sum_{n\neq i}\frac{p_{in}}{q_{in}} \frac{\partial \big[{\exp(-||y_i-y_n||^2)}/{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\big]}{\partial y_i}\\<br/>
&amp;= -\sum_{n\neq i}\frac{p_{in}}{q_{in}} \bigg(\frac{-2(y_i-y_n)\exp(-||y_i-y_n||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}- \frac{\exp(-||y_i-y_n||^2)(\sum_{k \neq i,l=i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{k=i,l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2))}{(\sum_{k\neq l} \exp(-||y_k - y_l||^2))^2}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}\frac{p_{in}}{q_{in}} \bigg(-2q_{in}(y_i-y_n) - q_{in}\frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - \frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - \frac{\sum_{j \neq i} 2(y_j-y_i) \exp(-||y_j - y_i||^2) - \sum_{j\neq i} 2(y_i - y_j)\exp(-||y_i - y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - \frac{\sum_{j \neq i} 2(y_j-y_i-y_i + y_j) \exp(-||y_j - y_i||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\bigg)\\<br/>
&amp;= 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n\neq i}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
\end{align*}<br/>
\]</p>

<p>代入式 \ref{mnf} 得：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + \sum_{m\neq i}{p_{mi}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}} + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n\neq i}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n\neq i}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
&amp;\because \quad p_{ii} = 0 \quad\Rightarrow\quad \sum_{n\neq i}p_{in} = \sum_{n}p_{in}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
&amp;= \sum_{m}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) \\<br/>
\end{align*}<br/>
\]</p>

<p>考虑到：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{m} \sum_{n} p_{mn} &amp;= \sum_{m}\sum_{n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}\\<br/>
&amp;= \sum_{m\neq n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)} + \sum_{m=n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}\\<br/>
&amp;= \sum_{m\neq n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}\\<br/>
&amp;= 1<br/>
\end{align*}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= \sum_{m}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n)\\<br/>
&amp;= \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n)\\<br/>
&amp;= \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{j\neq i}{p_{ij}} (y_i-y_j) + 2\sum_{j\neq i}{p_{ij}} (y_i-y_j)\\<br/>
&amp;= \sum_{j\neq i} 4(y_i-y_j)(p_{ij} - q_{ij})\\<br/>
&amp;= \sum_{j} 4(y_i-y_j)(p_{ij} - q_{ij})\\<br/>
\end{align*}<br/>
\]</p>

<p>推导结束。</p>

<p>在初步实验中，我们观察到对称 SNE 产生的映射和非对称 SNE 的一样好，有时候甚至会略好一点。</p>

<h4 id="toc_6">拥挤问题 crowding problem</h4>

<p>考虑一组嵌在高维空间里的二维曲线流形上的数据点，在小范围内可以近似于线形。它可以很好地在二维图上模拟数据点之间小的成对距离，这通常有个经典的“Swiss roll”的例子。现在设想一下一个具有10个维度的流形，它嵌在一个更高维的空间中。有几个原因导致在二维空间里的成对距离不能如实地模拟在10维空间里的数据点的距离。例如，在10维中可能有11个数据点之间的距离相等，在二维空间里无法得到可信的映射（二维空间最多就3个距离相等的点）。以数据点 \(i\) 为中心的球体体积是 \(r^m\) ，其中 \(r\) 是半径，\(m\) 是球体的维度，假设球体中数据点是均匀分布在 \(i\) 的周围的，看一下从 \(i\) 到其他点的距离随维度增加参生的变化：</p>

<p>代码如下：</p>

<pre><code class="language-python"># -*- coding: utf-8 -*-
import matplotlib.pyplot as plt
import numpy as np
from numpy.linalg import norm

npoints = 1000 # 抽取1000个m维球内均匀分布的点
plt.figure(figsize=(20, 4))
for i, m in enumerate((2, 3, 5, 10)):
    # 这里模拟m维球中的均匀分布用到了拒绝采样，即先生成m维立方中的均匀分布，再剔除m维球外部的点
    accepts = []
    while len(accepts) &lt; 1000:
        points = np.random.rand(500, m)
        accepts.extend([d for d in norm(points, axis=1) if d &lt;= 1.0]) # 拒绝采样
    accepts = accepts[:npoints]
    ax = plt.subplot(1, 4, i+1)
    ax.set_xlabel(&#39;distance&#39;) # x轴表示点到圆心的距离
    if i == 0:
        ax.set_ylabel(&#39;count&#39;) # y轴表示点的数量
    ax.hist(accepts, bins=np.linspace(0., 1., 50), color=&#39;green&#39;)
    ax.set_title(&#39;m={0}&#39;.format(str(m)), loc=&#39;left&#39;)
plt.show()
</code></pre>

<p>效果如下：</p>

<div align="center">
    <img width="700" src="media/15042890159558/15333754587813.jpg" />
</div>

<p>图中可以看出随着维度 \(m\) 的增大，大多数数据点都分布在球体的表面，与点 \(x_i\) 的距离分布极不平衡。如果将这种距离保留到低维空间中，肯定会出现拥挤问题。注意，拥挤问题并非只会出现在 SNE 中，实际上很多维度缩放技术上都会出现。</p>

<h4 id="toc_7">t 分布 Student-t distribution</h4>

<p>由于对称 SNE 实际上匹配高维空间和低维空间数据点的联合概率而不是它们的距离，因此我们有更自然的方式去缓解拥挤问题。在高维空间中，我们使用高斯分布将距离转换为概率，在低维映射中，我们使用比高斯分布更重尾部的 \(t\) 分布来转换距离为概率，这允许高维空间中低等距离在映射后有一个较大的距离。</p>

<p>假设 \(X\) 服从标准正态分布</p>

<p>在 t-SNE 中，我们使用有一个自由度的 t 分布(n=1)作为低维映射中的重尾分布，使用这个分布，联合概率分布 \(q_{ij}\) 可以被定义为：<br/>
\[<br/>
q_{ij} = \frac{(1+||y_i-y_j||^2)^{-1}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}<br/>
\]</p>

<p>此外，t分布是无限多个高斯分布的叠加，计算上不是指数的，会方便很多。优化的梯度如下：<br/>
\[<br/>
\frac{\partial C}{\partial y_i} = 4\sum_{j} (p_{ij}-q_{ij}) (y_i-y_j) (1+||y_i-y_j||^2)^{-1}<br/>
\]</p>

<p>推导过程如下：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= \frac{\partial \sum_{i} \sum_{j} p_{ij} \log (p_{ij} / q_{ij})}{\partial y_i} \\<br/>
&amp;= -\sum_{i}\sum_{j} \frac{p_{ij}}{q_{ij}} \frac{\partial q_{ij}}{\partial y_i}\\<br/>
&amp;= -\sum_{m}\sum_{m} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} - \sum_{m \neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} - \sum_{m=i}\sum_{n \neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\\<br/>
\end{align*}<br/>
\]</p>

<p>先看第一项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial [(1+||y_m-y_n||^2)^{-1}]/[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{-(1+||y_m-y_n||^2)^{-1}[2\sum_{k\neq i}\sum_{l=i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k=i} \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}]}{[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]^2}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{mn} \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2 \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\\ <br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{mn} \big[2\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} -2 \sum_{l\neq i} q_{li} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-1}\big]\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{mn} \big[2\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} -2 \sum_{k\neq i} q_{ki} (y_i - y_k)( 1+ ||y_i - y_k||^2)^{-1}\big]\\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n\neq i} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} \\<br/>
\end{align*}<br/>
\]</p>

<p>再看第二项：<br/>
\[<br/>
\begin{align*}<br/>
- \sum_{m \neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} &amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \frac{\partial [(1+||y_m-y_i||^2)^{-1}]/[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]}{\partial y_i}\\<br/>
&amp;=-\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(\frac{2(y_m-y_i)[(1+||y_m-y_i||^2)^{-2}]}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}} -\frac{(1+||y_m-y_i||^2)^{-1}[2\sum_{k\neq i}\sum_{l=i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k=i} \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}]}{[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]^2}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(2 q_{mi} (y_m-y_i)(1+||y_m-y_i||^2)^{-1}- q_{mi} \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k\neq i} (y_i - y_k)( 1+ ||y_i - y_k||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- \frac{4\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- {4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\bigg)\\<br/>
&amp;= -2\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} + 4\sum_{m\neq i}\sum_{n=i} {p_{mi}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第三项：<br/>
\[<br/>
\begin{align*}<br/>
- \sum_{m= i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i} &amp;= -\sum_{n\neq } \frac{p_{in}}{q_{in}} \frac{\partial [(1+||y_n-y_i||^2)^{-1}]/[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]}{\partial y_i}\\<br/>
&amp;=-\sum_{n\neq i} \frac{p_{in}}{q_{in}} \bigg(\frac{2(y_n-y_i)[(1+||y_n-y_i||^2)^{-2}]}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}} -\frac{(1+||y_n-y_i||^2)^{-1}[2\sum_{k\neq i}\sum_{l=i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k=i} \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}]}{[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]^2}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} \frac{p_{in}}{q_{in}} \bigg(2 q_{in} (y_n-y_i)(1+||y_n-y_i||^2)^{-1}- q_{in} \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k\neq i} (y_i - y_k)( 1+ ||y_i - y_k||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- \frac{4\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- {4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\bigg)\\<br/>
&amp;= -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n\neq i}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
\end{align*}<br/>
\]</p>

<p>三项相加，所以：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} - \sum_{m \neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} - \sum_{m=i}\sum_{n \neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n\neq i} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} + 4\sum_{m\neq i}{p_{mi}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n\neq i}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n\neq i}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
&amp;\because \quad p_{ii} = 0 \quad\Rightarrow\quad \sum_{n\neq i}{p_{in}}  = \sum_{n}{p_{in}} \\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
&amp;= 4\sum_{m}\sum_{n} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i}\sum_{n=i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} \\<br/>
&amp;= 4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} \sum_{m}\sum_{n} p_{mn}  -4\sum_{m\neq i}\sum_{n=i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} \\<br/>
\end{align*}<br/>
\]</p>

<p>考虑到（证明如对称 SNE）：<br/>
\[<br/>
\sum_m \sum_n p_{mn} = 1<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= 4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} \sum_{m}\sum_{n} p_{mn}  -4\sum_{m\neq i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} \\<br/>
&amp;= 4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} -4\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} \\<br/>
&amp;= 4\sum_{j\neq i} q_{ij} (y_j-y_i) (1+||y_i-y_j||^2)^{-1} -4\sum_{j\neq i}{p_{ij}} (y_j-y_i)(1+||y_i-y_j||^2)^{-1} \\<br/>
&amp;= 4\sum_{j\neq i} (p_{ij}  - q_{ij})(y_i-y_j)(1+||y_i-y_j||^2)^{-1} \\<br/>
\end{align*}<br/>
\]</p>

<p>推导结束。</p>

<p>t-sne的有效性，也可以从上图中看到：横轴表示距离，纵轴表示相似度, 可以看到，对于较大相似度的点，t分布在低维空间中的距离需要稍小一点；而对于低相似度的点，t分布在低维空间中的距离需要更远。这恰好满足了我们的需求，即同一簇内的点(距离较近)聚合的更紧密，不同簇之间的点(距离较远)更加疏远。</p>

<p>总结一下，t-SNE的梯度更新有两大优势：</p>

<ol>
<li>对于不相似的点，用一个较小的距离会产生较大的梯度来让这些点排斥开来。</li>
<li>这种排斥又不会无限大(梯度中分母)，避免不相似的点距离太远。</li>
</ol>

<h3 id="toc_8">算法步骤</h3>

<p><b>输入</b>：数据集 \(\mathcal X = \{x_1,x_2,...,x_n\}\)，困惑度 \(\text{Perplexity}\)，迭代次数 \(T\) ，学习速率 \(\eta\) ，动量 \(\alpha^{(t)}\)<br/>
<b>输出</b>：在低维空间的表现 \(\mathcal Y= \{y_1,y_2,...,y_n\}\)<br/>
<b>算法过程</b>：</p>

<ul>
<li>计算在给定困惑度 \(\text{Perplexity}\) 下的 \(p_{j|i}\)</li>
<li>计算 \(p_{ij} = \frac{1}{2n}(p_{j|i} + p_{i|j}) \)</li>
<li>使用 (0,10<sup>{-4}I)</sup> 随机初始化 \(\mathcal Y\)</li>
<li><p>迭代，从 \(t = 1\) 到 \(T\)， 做如下操作:</p>

<ul>
<li>计算低维空间的 \(q_{ij}\) </li>
<li>计算梯度</li>
<li>更新 \(Y^{(t)}=Y^{(t−1)}+ \eta \frac{\partial C}{\partial Y}+ \alpha^{(t)}(Y^{(t−1)}−Y^{(t−2)})\)</li>
<li>结束</li>
</ul></li>
<li><p>结束</p></li>
</ul>

<p>优化过程中可以尝试的两个trick:</p>

<ol>
<li>提前压缩 (early compression) :开始初始化的时候，各个点要离得近一点。这样小的距离，方便各个聚类中心的移动。可以通过引入 L2 正则项(距离的平方和)来实现。</li>
<li>提前夸大 (early exaggeration) ：在开始优化阶段，\(p_{ij}\) 乘以一个大于1的数进行扩大，来避免因为 \(q_{ij}\) 太小导致优化太慢的问题。比如前50次迭代，\(p_{ij}\) 乘以4。</li>
</ol>

<h4 id="toc_9">不足</h4>

<p>主要不足有四个:</p>

<ol>
<li>主要用于可视化，很难用于其他目的。比如测试集合降维，因为他没有显式的预估部分，不能在测试集合直接降维；比如降维到10维，因为t分布偏重长尾，1个自由度的t分布很难保存好局部特征，可能需要设置成更高的自由度。</li>
<li>t-SNE倾向于保存局部特征，对于本征维数(intrinsic dimensionality)本身就很高的数据集，是不可能完整的映射到2-3维的空间</li>
<li>t-SNE没有唯一最优解，且没有预估部分。如果想要做预估，可以考虑降维之后，再构建一个回归方程之类的模型去做。但是要注意，t-sne中距离本身是没有意义，都是概率分布问题。</li>
<li>训练太慢。有很多基于树的算法在t-sne上做一些改进</li>
</ol>

<hr/>

<p><a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">Visualizing Data Using T-SNE</a><br/>
<a href="http://www.datakit.cn/blog/2017/02/05/t_sne_full.html">t-SNE完整笔记</a> <br/>
<a href="http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/?from=timeline&amp;isappinstalled=0">从SNE到t-SNE再到LargeVis</a><br/>
<a href="https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/">t-SNE原生numpy实现</a><br/>
<a href="https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm">t-SNE介绍与实现</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15041093080052.html">线性判别分析 LDA</a></h1>
			<p class="meta"><time datetime="2017-08-31T00:08:28+08:00" 
			pubdate data-updated="true">2017/8/31</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>前面我们讨论过PCA、SVD对数据降维，但是PCA和SVD都是无监督的方法，而在一些有标签的数据中，如果能结合标签对数据降维，效果会更好。因此产生了LDA的方法，LDA英文全称是Linear Discriminant Analysis，线性判别方法，LDA作为一种降维方法，在有效降低维度的同时保证了数据的可分性。</p>

<div align="center">
    <img src="media/15041093080052/15274469363430.jpg" width="400px" />
</div>
如上图如果不考虑数据的标签，采用PCA方法对数据降维到一维空间，由PCA可知将按照最大方差的方向进行映射也就是映射到红线的位置，本来易分的数据将会变得不易分，对于这个例子来说是得不偿失的。而我们如果将所有点都投影到黑线上，效果将非常好，这就是LDA方法所考虑的。

LDA方法的基本思想是将高维数据映射到最佳鉴别空间，达到降维和提取特征的目的，投影后保证在新空间数据点具有最大的类间距离和最小的类内距离。也就是上图中蓝色点之间的距离最小，而蓝色点和绿色点之间的距离最大。在继续讨论LDA之前，先看一些相关的前置知识。

#前置知识

#### 投影

对于一个高维空间里的样本$X_i$投影到一个向量$W$上，如果$X_i$在投影前是在是一个$n$维空间，我们期望投影后降低到$k$维空间，那么$W$将是一个$n\times k$形状的矩阵。设在新空间中（可能是低维）的点为$Z_i$，满足：
$$
Z_i = W^T X_i
$$

其中$Z_{ij}=W_j^TX_i$表示点$X_i$在新坐标空间中第$j$维的坐标。如果我们将$Z_i$还原到原空间，可以通过$X^*_i = WZ_i$，其中$X_{ij} = W_jZ_i$表示新空间点$Z_i$转换回原空间在第j维的坐标。在本文中如果我们将二维空间数据点投影到一条直线上，如下图所示，点$X=(2,4)^T$在向量$w=(-\frac{\sqrt{2}}{2},\frac{\sqrt{2}}{2})^T$上的投影为$Z=W^TX = \sqrt{2}$。

<div align="center">
    <img src="media/15041093080052/15276993092656.jpg" width="350px" />
</div>

<p>在SVD的前置知识里，我们已经提到过通过正交矩阵将点可以从一个坐标系转换到另一个坐标系，这是一种\(W\)是正交矩阵的投影特例。</p>

<h4 id="toc_0">Rayleigh商矩阵</h4>

<p>定义Rayleigh商矩阵：<br/>
\[<br/>
R(A,x) = \frac{x^HAx}{x^Hx}<br/>
\]</p>

<p>其中\(x\)是非零向量，而\(A\)是\(n\times n\)的Hermitian矩阵（厄米特矩阵），厄米特矩阵是共轭转置等于本身的矩阵。假设\(A\)的\(n\)个特征值依次为\(\lambda_1\le\lambda_2\le...\le\lambda_n\)，则有：<br/>
\[<br/>
\lambda_1 \le R(A,x) \le \lambda_n<br/>
\]</p>

<p>证明：假设特征值\(\lambda_1,\lambda_2,...,\lambda_n\)对应的单位特征向量为：\(x_1,x_2,...,x_n\)，由于\(A\)是厄米特矩阵，可知\(A\)可以正交对角化，即特征矩阵\(X=(x_1,x_2,...,x_n)\)同时也是个单位正交矩阵，每一个元素都可看成向量空间的一组正交基。将向量\(x\)用这组正交基表示：<br/>
\[<br/>
x = a_1x_1+a_2x_2+....a_nx_n=(x_1,x_2,...,x_n)(a_1,a_2,...,a_n)^H = X\boldsymbol a<br/>
\]</p>

<p>其中\(\boldsymbol a = (a_1,a_2,...,a_n)^H\)，将上式代入Rayleigh矩阵可得：<br/>
\[<br/>
\begin{align*}<br/>
R(A,x) = \frac{x^HAx}{x^Hx} &amp;= \frac{(X\boldsymbol a)^HA(X\boldsymbol a)}{(X\boldsymbol a)^H(X\boldsymbol a)} \\<br/>
&amp;= \frac{\boldsymbol a^H X^H A X \boldsymbol a}{\boldsymbol a^H X^H X \boldsymbol a}<br/>
\end{align*}<br/>
\]</p>

<p>由实对称矩阵对角会性质可知：\(X^TAX=\Lambda\)，其中每一个对角线元素都是\(A\)的特征值。且正交矩阵\(X\)满足\(X^HX = 1\)所以：<br/>
\[<br/>
\begin{align*}<br/>
R(A,x) = \frac{x^HAx}{x^Hx} &amp;= \frac{\boldsymbol a^H X^H A X \boldsymbol a}{\boldsymbol a^H X^H X \boldsymbol a} \\<br/>
&amp;= \frac{\boldsymbol a^H \Lambda \boldsymbol a}{\boldsymbol a^H \boldsymbol a} \\<br/>
&amp;= \frac{[a_1,a_2,...,a_n] \left[ \begin{array}\\\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n\\\end{array}\right] \left[\begin{array}\\a_1\\a_2\\...\\a_n\\\end{array}\right]}{\boldsymbol a^H \boldsymbol a} \\<br/>
&amp;=\frac{\sum_{i=1}^N\lambda_i a_i^2}{\sum_{i=1}^N a_i^2}<br/>
\end{align*}<br/>
\]</p>

<p>所以我们可以将\(R(A,x)\)看成\(\lambda_n\)的加权平均值，权系数是\(a_i^2\)，假设\(\lambda_1\le\lambda_2\le...\le\lambda_n\)，明显对于任意\(i=(1,2,...,n)\)有\(\lambda_ia_i^2\ge \lambda_1a_i^2\)，所以\(\sum_{i=1}^N\lambda_ia_i^2\ge n\lambda_1a_i^2=\sum_{i=1}^N\lambda_1a_i^2 \)，所以：<br/>
\[<br/>
R(A,x) = \frac{\sum_{i=1}^N\lambda_i a_i^2}{\sum_{i=1}^N a_i^2} \ge \frac{\sum_{i=1}^N\lambda_1a_i^2}{\sum_{i=1}^N a_i^2} = \lambda_1<br/>
\]</p>

<p>同理可证：\(R(A,x) \le \lambda_n\)。综合可知：<br/>
\[<br/>
\lambda_1 \le R(A,x) \le \lambda_n<br/>
\]</p>

<p>当\(R(A,x)\)取最大值或最小值时，令\(R(A,x)=\lambda\)，此时\(\lambda\)是A的特征值：<br/>
\[<br/>
\begin{align*}<br/>
&amp;R(A,x) = \frac{x^HAx}{x^Hx} = \lambda \\<br/>
&amp;\Rightarrow x^HAx = \lambda x^Hx<br/>
\end{align*}<br/>
\]</p>

<p>两边同时左乘\((x^{H})^{-1}\)得：\(Ax = \lambda x\)，所以此时\(\lambda\)对应的特征向量为\(x\)。</p>

<p>另外当\(x\)是正交矩阵时，\(x^Hx=1\)，\(R(A,x) = x^HAx\)，这个形式在很多理论中都有使用。</p>

<h4 id="toc_1">广义Rayleigh商矩阵</h4>

<p>定义广义Rayleigh商矩阵:<br/>
\[<br/>
R(A,B,x) = \frac{x^HAx}{x^HBx}<br/>
\]</p>

<p>其中A,B都是\(n\times n\)的厄米特矩阵，且B正定，那么这种形式的R(A,B,x)最大值与最小值是多少呢？其实很容易想到，只要我们设\(x^{&#39;}\)，然后能将上式化为R(A,x)形式即可。</p>

<p>首先看分母，我们希望\(x^HBx=x^{&#39;H}x^{&#39;}\)，所以可以分解得：<br/>
\[<br/>
x^HBx =x^H(B^{1/2})^2x= x^H(B^{1/2})^HB^{1/2}x=(B^{1/2}x)^H(B^{1/2}x)<br/>
\]</p>

<p>这样如果令\(x{&#39;} = B^{1/2}x\)，则满足我们期望，此时\(x = B^{-1/2}x^{&#39;}\)，代入得：<br/>
\[<br/>
\begin{align*}<br/>
x^HBx &amp;= (B^{-1/2}x^{&#39;})^HBB^{-1/2}x^{&#39;} = x^{&#39;H}(B^{-1/2})^HBB^{-1/2}x^{&#39;} = x^{&#39;H}B^{-1/2}BB^{-1/2}x^{&#39;}  = x^{&#39;H}x^{&#39;} \\<br/>
x^HAx &amp;= (B^{-1/2}x^{&#39;})^HAB^{-1/2}x^{&#39;} = x^{&#39;H}(B^{-1/2})^HAB^{-1/2}x^{&#39;} = x^{&#39;H}B^{-1/2}AB^{-1/2}x^{&#39;} <br/>
\end{align*}<br/>
\]</p>

<p>所以\(R(A,B,x)\)可以化为\(R(A,B,x{&#39;})\)：<br/>
\[<br/>
R(A,B,x&#39;) = \frac{x^{&#39;H}B^{-1/2}AB^{-1/2}x^{&#39;} }{x^{&#39;H}x^{&#39;}}<br/>
\]</p>

<p>由普通Rayleigh商的性质可知\(R(A,B,x^{&#39;})\)的最大值为\(B^{-1/2}AB^{-1/2}\)特征值的最大值，最小值为\(B^{-1/2}AB^{-1/2}\)特征值的最小值。此时我们考虑假设特征值为\(\lambda\)，对应的特征向量为\(x^{&#39;}\)，有：<br/>
\[<br/>
B^{-1/2}AB^{-1/2} x^{&#39;} = \lambda x^{&#39;}<br/>
\]</p>

<p>两边同左乘上\(B^{-1/2}\)，可得：<br/>
\[<br/>
B^{-1}AB^{-1/2} x^{&#39;} = \lambda B^{-1/2} x^{&#39;} \Leftrightarrow B^{-1}A(B^{-1/2} x^{&#39;}) = \lambda (B^{-1/2} x^{&#39;})<br/>
\]</p>

<p>所以\(B^{-1}AB^{-1/2}\)的特征值等同于\(B^{-1}A\)的特征值，所以\(R(A,B,x)\)的最大值为\(B^{-1}A\)特征值的最大值，最小值为\(B^{-1}A\)特征值的最小值，对应的特征向量为\(B^{-1/2}x^{&#39;}\)，即\(x\)，实现了一个完美的统一。</p>

<h1 id="toc_2">LDA解释</h1>

<p>为什么叫线性判别分析呢？所谓的线性是将高维空间投影到直线上（可能是多条直线），直线的函数解析式叫做线性函数，通常函数解析式如下面的形式：<br/>
\[<br/>
y=w^Tx+b<br/>
\]</p>

<p>由前面可知如果将两个数据点\(x_i\)投影到直线上，那么投影后的点的坐标为\(W^Tx_i\)，LDA希望通过线性函数投影后的数据点可以很好通过一个判别式划分。我们首先来看一下二分类问题，然后将其推广到多分类问题上。</p>

<h2 id="toc_3">二分类问题</h2>

<p>假设我们有数据集\(D = ((x_1,y_1),(x_2,y_2),...,(x_m,y_m))\)，其中任意\(x_i\)一个\(n\)维的向量，\(y_i \in (0,1)\)。我们使用\(X_i(i=0,1)\)表示\(D\)中的两类样本集，\(N_i(i=0,1)\)表示样本集\(X_i\)的数量，\(u_i(i=0,1)\)表示样本集\(X_i\)的均值向量，\(\Sigma_i(i=0,1)\)表示样本集\(X_i\)的方差（没有分母的）。</p>

<p>\(u_i\)方程表示为：<br/>
\[<br/>
u_i = \frac{1}{N_i}\sum_{x \in X_i}x\quad(i=0,1)<br/>
\]<br/>
\(\Sigma_i\)方程表示：<br/>
\[<br/>
\Sigma_{i} = \sum_{x\in X_i}(x-u_i)(x-u_i)^T\quad(i=0,1)<br/>
\]</p>

<p>由于是二分类问题，当我们将数据投影到一条直线上，假设投影向量为\(W\)，由\(W\)投影后两类样本集的中心点分别为\(W^Tu_0\)和\(W^Tu_1\)，投影后的方差为：<br/>
\[<br/>
\begin{align*}<br/>
\Sigma^{new}_{i} &amp;= \sum_{x\in X_i}(w^Tx-w^Tu_i)^2 = \sum_{x\in X_i}(w^Tx-w^Tu_i)(w^Tx-w^Tu_i)^T \\<br/>
&amp;= \sum_{x\in X_i} w^T(x-u_i)(x-u_i)^Tw = w^T\Sigma_iw<br/>
\end{align*}<br/>
\]</p>

<p>LDA期望投影后的数据易区分，满足同类数据尽可能密集，也就是希望最小化方差\(w^T\Sigma_0w+w^T\Sigma_1w\)。非同类元素尽可能分离，即最大化均值距离\(||w^Tu_0-w^Tu_1||^2\)，综上可以定义优化目标为：<br/>
\[<br/>
\begin{equation}<br/>
J=\frac{||w^Tu_0-w^Tu_1||^2}{w^T\Sigma_0w+w^T\Sigma_1w} = \frac{w^T(u_0-u_1)(u_0-u_1)^Tw}{w^T(\Sigma_0+\Sigma_1)w} \label{J}<br/>
\end{equation}<br/>
\]</p>

<p>定义类内方差\(S_w\)为：<br/>
\[<br/>
S_w = \Sigma_0+\Sigma_1 = \sum_{x\in X_0}(x-u_0)(x-u_0)^T + \sum_{x\in X_1}(x-u_1)(x-u_1)^T<br/>
\]</p>

<p>定义类间距离\(S_b\)为：<br/>
\[<br/>
S_b = (u_0-u_1)(u_0-u_1)^T<br/>
\]</p>

<p>这样优化目标可以改写为：<br/>
\[<br/>
J = \frac{w^TS_bw}{w^TS_ww}<br/>
\]</p>

<p>对比广义Rayleigh商矩阵，发现形式一模一样，现在利用广义Rayleigh商矩阵的性质可知\(J\)的最大值即为矩阵\(S_w^{-1}S_b\)的最大特征值，此时对应的特征向量为\(w\)。</p>

<p>对于二分类问题来说，设\(\lambda_w = (u_0-u_1)^Tw\)，所以\(S_bw = (u_0-u_1)\lambda_w\)，将其代入特征方程\(S_w^{-1}S_bw = \lambda w\)得\(S_w^{-1} (u_0-u_1)\lambda_w = \lambda w\)，可解得\(w = \frac{\lambda_w}{\lambda}S_w^{-1} (u_0-u_1)\)。</p>

<p>由于\((u_0-u_1)\)是一个\(n\)维数据，并由前面投影的知识\(w\)的形状为\((n \times 1)\)，所以乘积\(\lambda_w=(u_0-u_1)^Tw\)是一个标量。由\(J\)的方程（\ref{J}）可知我们\(w\)的大小增大或缩小多少倍对于结果并没有影响，所以我们并不关心\(w\)的大小，只关心\(w\)的方向，将常数省去可得\(w = S_w^{-1} (u_0-u_1)\)，也就意味着当我们求出二分类的方差和均值就可以确定最佳投影方向\(w\)了。</p>

<h2 id="toc_4">多分类问题</h2>

<p>同样我们假设数据集\(D=((x_0,y_0),(x_1,y_1),...,(x_m,y_m))\)，其中任意的\(x_i\)是一个\(n\)维向量；\(y_i\in (C_1,C_2,...,C_k)\)，也就是数据集包含\(k\)类数据；数据集大小为\(N\)。在二类LDA中，是将原数据投影到一条直线（一维）上，由前置知识中可知\(W\)是一个\((n \times 1)\)的矩阵，而在多分类中，需要将数据投影到低维空间上，假设投影后的维度为 \(d\) ，投影向量\(W\)是一个\((n\times d)\)的矩阵，定义\(u_i\)为第\(\,i\,\)类的均值向量。<br/>
\[<br/>
u_i = \frac{1}{N_i}\sum_{x \in X_i} x<br/>
\]</p>

<p>此时需要将之前我们定义的概念做一下替换，定义类内散度矩阵\(S_W\)替换二分类LDA中的方差，即：<br/>
\[<br/>
S_W = \sum_{i=1}^k \Sigma_i = \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T<br/>
\]</p>

<p>定义投影后的类内距离\(J_W\)，其中点\(x\)投影后为\(W^Tx\)，中心点\(u_i\)投影后为\(W^Tu_i\)，可得：<br/>
\[<br/>
J_W = \sum_{i=1}^k \sum_{x\in X_i}(W^Tx-W^Tu_i)(W^Tx-W^Tu_i)^T = W^T\sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^TW = W^TS_WW<br/>
\]</p>

<p>定义类间散度矩阵\(S_B\)替换二分类LDA中的类间距离，但是此时已经不能用两个类中心的距离来表示类间散度距离了，考虑下图：</p>

<div align="center">
    <img width="300px" src="media/15041093080052/15280361373656.jpg" />
</div>

<p>定义全局中心点 \(u\) ：<br/>
\[<br/>
\begin{equation}<br/>
u = \frac{1}{N}\sum_{i=1}^N x_i = \frac{1}{N} \sum_{i=1}^k \sum_{x\in X_i} x= \frac{1}{N} \sum_{i=1}^k N_i u_i \label{u_u_i}<br/>
\end{equation}<br/>
\]</p>

<p>定义全局散度矩阵\(S_t\)为每一个点到全局中心点\(u\)的向量距离：<br/>
\[<br/>
S_t = \sum_{i=1}^N (x_i-u)(x_i-u)^T<br/>
\]</p>

<p>考虑到全局散度矩阵\(S_t\)=类内散度矩阵\(S_W\)+类间散度矩阵\(S_B\)，所以：<br/>
\[<br/>
\begin{align}<br/>
S_B &amp;= S_t - S_W = \sum_{i=1}^N (x_i-u)(x_i-u)^T - \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T \nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}(x - u)(x-u)^T - \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T \nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}[(x - u)(x-u)^T-(x-u_i)(x-u_i)^T ]\nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}(xx^T - xu^T-ux^T+uu^T-xx^T+xu_i^T+u_ix^T-u_iu_i^T) \nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}(- xu^T-ux^T+uu^T+xu_i^T+u_ix^T-u_iu_i^T) \nonumber\\<br/>
&amp;=\sum_{i=1}^k(-\sum_{x\in X_i}xu^T-\sum_{x\in X_i}ux^T+\sum_{x\in X_i}uu^T+\sum_{x\in X_i}xu_i^T+\sum_{x\in X_i}u_ix^T-\sum_{x\in X_i}u_iu_i^T) \label{S_B_T_W}\\<br/>
\end{align}<br/>
\]</p>

<p>考虑到\(u_i\)为第\(i\)类的均值向量，即：<br/>
\[<br/>
\begin{align*}<br/>
&amp;u_i = \frac{1}{N_i}\sum_{x\in X_i}x \quad\Rightarrow\quad \sum_{x\in X_i}x = N_iu_i \\<br/>
&amp;u_i^T = \frac{1}{N_i}\sum_{x\in X_i}x^T \quad\Rightarrow\quad \sum_{x\in X_i}x^T = N_iu_i^T \\<br/>
\end{align*}<br/>
\]</p>

<p>将上式代入公式（\ref{S_B_T_W}）中得：<br/>
\[<br/>
\begin{align}<br/>
S_B &amp;= \sum_{i=1}^k(-\sum_{x\in X_i}xu^T-\sum_{x\in X_i}ux^T+\sum_{x\in X_i}uu^T+\sum_{x\in X_i}xu_i^T+\sum_{x\in X_i}u_ix^T-\sum_{x\in X_i}u_iu_i^T)  \nonumber\\<br/>
&amp;= \sum_{i=1}^k(-N_iu_iu^T-N_iuu_i^T+N_iuu^T+N_iu_iu_i^T+N_iu_iu_i^T-N_iu_iu_i^T) \nonumber\\<br/>
&amp;= \sum_{i=1}^kN_i(-u_iu^T-uu_i+uu^T+u_iu_i^T) \nonumber\\<br/>
&amp;= \sum_{i=1}^kN_i(u_i-u)(u_i-u)^T \label{S_B}<br/>
\end{align}<br/>
\]</p>

<p>抛去数学推导，直观上看，观察类间散度矩阵\(S_B\)，其实就是每一个类的中心点到全局中心点\(u\)的向量距离，由于每一个类包含数据数量不同，使用了\({N_i}\)作为第\(i\)类的权重。</p>

<p>定义投影后的类间距离\(J_B\)，局部中心点\(u_i\)投影后为\(W^Tu_i\)，全局中心点\(u\)在投影后为\(W^Tu\)，得：<br/>
\[<br/>
J_B = \sum_{i=1}^kN_i(W^Tu_i-W^Tu)(W^Tu_i-W^Tu)^T = W^T\sum_{i=1}^kN_i(u_i-u)(u_i-u)^TW = W^TS_BW<br/>
\]</p>

<p>则目标函数\(J(W)为\)：<br/>
\[<br/>
J(W) = \frac{J_B}{J_W} = \frac{W^TS_BW}{W^TS_WW}<br/>
\]</p>

<p>我们的目标是最大化\(J(W)\)，而当成比例的放大或缩小\(W\)时，并不影响\(J(W)\)的取值，因此我们关心的是\(W\)的方向，而不在意\(W\)的大小。因此我们可以固定分母为1，那么目标方程组为（这里我将求最大化问题变成了求最小值问题，其实等价）：<br/>
\[<br/>
\begin{align*}<br/>
&amp;min_W\quad -W^TS_BW \\<br/>
&amp;s.t. \quad \quad W^TS_WW = 1<br/>
\end{align*}<br/>
\]</p>

<p>利用拉格朗日乘子法定义拉格朗日朗日方程：<br/>
\[<br/>
L(W,\alpha) = -W^TS_BW + \alpha(W^TS_WW-1)<br/>
\]</p>

<p>其中\(\lambda\)为乘子，满足\(\lambda \neq 0\)。<br/>
先求\(L(W,\alpha)\)对\(W\)求导，并令其等于0，即：<br/>
\[<br/>
\begin{align}<br/>
\frac{\nabla L(W,\alpha)}{\nabla W} &amp;= \frac{-W^TS_BW + \lambda(W^TS_WW-1)}{\nabla W} \nonumber\\<br/>
&amp;= -(S_B+S_B^T)W+\alpha(S_W+S_W^T)W \label{LW}\\<br/>
\end{align}<br/>
\]</p>

<blockquote>
<p>矩阵求导公式，\(\alpha\)是实数，\(\beta\)和\(X\)为向量，\(A\),\(B\),\(C\)是与\(X\)无关的矩阵：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial \beta X}{\partial X^T} = \beta \\<br/>
&amp;\frac{\partial X^T\beta}{\partial X} = \beta \\<br/>
&amp;\frac{\partial X^TAX}{\partial X} = (A+A^T)X \\<br/>
\end{align*}<br/>
\]</p>
</blockquote>

<p>因为：<br/>
\[<br/>
S_B^T = （\sum_{i=1}^kN_i(u_i-u)(u_i-u)^T)^T = \sum_{i=1}^kN_i(u_i-u)(u_i-u)^T = S_B \\<br/>
S_W^T = (\sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T)^T = \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T = S_W <br/>
\]</p>

<p>上式带入公式（\ref{LW}）可得：<br/>
\[<br/>
\frac{\nabla L(W,\alpha)}{\nabla W} = -2S_BW + 2\lambda S_WW = 0<br/>
\]</p>

<p>如果\(S_W\)为非奇异，即\(S_W^{-1}\)存在，上式可得：\(S_W^{-1}S_BW = \lambda W\)，也就是\(W\)的每一列都是\(S_W^{-1}S_B\)的特征向量。特征值越大的特征向量包含的信息越丰富，所以首先求出\(S_W^{-1}S_B\)的特征值，\(W\)为前 \(d\) 个非零特征值对应的特征向量组成的特征矩阵。</p>

<h4 id="toc_5">多分类的维度问题</h4>

<p>多分类中我们假设经过\(W\)投影后的数据集在 \(d\) 维空间，那么接下来将讨论 \(d\) 的范围。由于 \(S_B\) 矩阵中的 \(\mu_i-\mu\) 的秩为1，结合（\ref{S_B}）和秩的性质6（见附录：矩阵的秩小于等于各个相加矩阵的秩的和），因此SB的秩最多为k。由公式（\ref{u_u_i}）知\(\mu_k\) 可以用前k-1个 \(\mu_i\) 表示出来，因此 \(S_B\) 的秩最多为k-1，由秩的性质7可知\(R(S_W^{-1}S_B) \le min\{R(S_W^{-1}),R(S_B)\}\) ，所以\(S_W^{-1}S_B\)的秩最大为k-1。</p>

<p>由矩阵的秩与非零特征值的关系：对于任何n阶方阵，都有\(\mu (A) \le R(A)\)，即非零特征值的个数小于矩阵的秩。具体证明见文章最后。所以可以得出\(S_W^{-1}S_B\)非零特征值个数最大为k-1个，所以对应的特征向量最多也为k-1个，即\(W\)的列数最多有\(k-1\)列，那么 \(d\) 也最大为k-1维。</p>

<h2 id="toc_6">LDA算法流程</h2>

<p>输入：同样我们假设数据集\(D=((x_0,y_0),(x_1,y_1),...,(x_m,y_m))\)，其中任意的\(x_i\)是一个\(n\)维向量；\(y_i\in (C_1,C_2,...,C_k)\)，也就是数据集包含\(k\)类数据；<br/>
输出：降维后的样本集\(D′\)。</p>

<p>1） 计算类内散度矩阵\(S_W\)<br/>
2） 计算类间散度矩阵\(S_B\)<br/>
3） 计算矩阵\(S_W^{-1}S_B\)<br/>
4） 计算\(S_W^{-1}S_B\)的最大的 \(d\) 个特征值和对应的 \(d\) 个特征向量\((w_1,w_2,...,w_d)\),得到投影矩阵\(W\)<br/>
5） 对样本集中的每一个样本特征\(x_i\)，转化为新的样本\(z_i=W^Tx_i\)<br/>
6） 得到输出样本集\(D′={(z_1,y_1),(z_2,y_2),...,((z_m,y_m))}\)</p>

<h2 id="toc_7">LDA的局限性</h2>

<ol>
<li><p>存在秩限制，对于 \(k\) 类问题，至多可生成 \(k-1\) 维子空间。LDA降维后的维度区间在 \([1,k-1]\) ，与原始特征数 \(m\) 无关，对于二值分类，最多投影到1维。</p></li>
<li><p>类间散度矩阵必须非奇异。在一些小样本数据集中，样本总数可能小于样本维数，此时\(S_W\)奇异，将不能使用上述LDA算法。</p></li>
</ol>

<h2 id="toc_8">LDA 改进算法</h2>

<h4 id="toc_9">PCA + LDA</h4>

<p>在一些人脸识别等小样本问题上，需要面对的一个小问题是类内散度奇异，这是由于训练图像的个数 N 远小于每一个图像的维度。Belhomecour 等人提出一个解决方案，先做一次PCA降维，解决\(S_W\)的奇异问题，然后再应用LDA将训练集将维到\(k-1\)维度。</p>

<h6 id="toc_10">还有一些其他的改进算法 MLDA 等，相关文献较少，以后需要时再看吧</h6>

<h2 id="toc_11">附录：</h2>

<h4 id="toc_12">秩的性质：</h4>

<p>1） \(0 \le R(A_{m\times n}) \le min\{m,n\}\)<br/>
2） \(R(A^T) = R(A)\)<br/>
3） 若A~B，则\(R(A) = R(B)\)<br/>
4） 若P,Q可逆，则\(R(PAQ) = R(A)\)<br/>
5） \(max\{R(A),R(B)\} \le R(A,B) \le R(A)+R(B)\)<br/>
6） \(R(A+B) \le R(A)+R(B)\)<br/>
7） \(R(AB) \le min\{R(A),R(B)\}\)<br/>
8） 若\(A_{m\times n}B_{n\times l} = O\)，则\(R(A) + R(B) \le n\)</p>

<h4 id="toc_13">矩阵的秩与非零特征值的关系</h4>

<p>论文看<a href="http://xueshu.baidu.com/s?wd=paperuri%3A%28f0a2034422bc0816eb555fa33cb95b1f%29&amp;filter=sc_long_sign&amp;tn=SE_xueshusource_2kduw22v&amp;sc_vurl=http%3A%2F%2Fwww.doc88.com%2Fp-317741888504.html&amp;ie=utf-8&amp;sc_us=4282568566058718085">这里</a>(Chrome打开)</p>

<h6 id="toc_14">定理：对于任意 \(n\) 阶方阵，都有 \(\mu (A) \le r(A)\)，即矩阵的非零特征值的个数不大于矩阵的秩。</h6>

<p>证明：<br/>
当\(|A|\neq 0\)时，此时\(A\)可逆，并有\(r(A) = n\)。假设\(\lambda_1,\lambda_2,...,\lambda_n\)是方阵\(A\)的全部特征值，那么\(|A| = \lambda_1\lambda_2...\lambda_n\neq 0\)，所以\(\lambda_i\neq 0(i=1,2,...,n)\)，所以\(\mu(A) = r(A)\)。</p>

<p>当\(|A| = 0\)时，设\(r(A) = r &lt; n\)，对于特征值\(\lambda\)满足：<br/>
\[<br/>
|\lambda I-A| = \left ( \begin{array}{cccccc} <br/>
\lambda-a_{11}&amp;-a_{12}&amp;...&amp;-a_{1r}&amp;...&amp;-a_{1n}\\<br/>
-a_{21}&amp;\lambda-a_{22}&amp;...&amp;-a_{2r}&amp;...&amp;-a_{2n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
-a_{r1}&amp;-a_{r2}&amp;...&amp;\lambda-a_{rr}&amp;...&amp;-a_{rn}\\<br/>
-a_{r+1,1}&amp;-a_{r+1,2}&amp;...&amp;\lambda-a_{r+1,r}&amp;...&amp;-a_{r+1,n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
-a_{n1}&amp;-a_{n2}&amp;...&amp;-a_{nr}&amp;...&amp;\lambda-a_{nn}<br/>
\end{array} \right )<br/>
\]</p>

<p>考虑矩阵的行向量组\((a_1,a_2,...,a_n)^T\)，这里不妨设\(a_1,a_2,...,a_r\)为线形无关的 \(r\) 个向量。则\(a_{r+1},a_{r+2},...,a_n\)均可由\(a_1,a_2,...,a_r\)线形表示，设\(a_i=k_{i1}a_1+k_{i2}a_2+...+k_{ir}a_r\)，其中\(i=r+1,r+2,...,n\)，我们现在只看第 \(r+1\) 行的每一个元素，用前 \(r\) 行表示得：<br/>
\[<br/>
\begin{align*}<br/>
a_{r+1,1}&amp;=k_{r+1,1}a_{11}+k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1}\\<br/>
a_{r+1,2}&amp;=k_{r+1,1}a_{12}+k_{r+1,2}a_{22}+...+k_{r+1,r}a_{r2}\\<br/>
&amp;...\\<br/>
a_{r+1,n}&amp;=k_{r+1,1}a_{1n}+k_{r+1,2}a_{2n}+...+k_{r+1,r}a_{rr}<br/>
\end{align*}<br/>
\]</p>

<p>现在对\(|\lambda I-A|\)的第\((r+1)\)行做行列式变换，分别用\(k_{r+1,j}\)乘上\(|\lambda I-A|\)的第 \(j\)(\(j=1,2,...,r\)) 行后加上它，我们知道行列式变换结果不变，分开计算每一个元素，先看第一项：</p>

<p>\[<br/>
\begin{align*}<br/>
|\lambda I-A|_{r+1,1} &amp;\sim |\lambda I-A|_{r+1,1} + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1} \\<br/>
&amp;= -a_{r+1,1} + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1} \\<br/>
\end{align*}<br/>
\]</p>

<p>将之前\(a_{r+1,1}\)的线形表示形式带入上式得：</p>

<p>\[<br/>
\begin{align*}<br/>
|\lambda I-A|_{r+1,1} &amp;\sim -a_{r+1,1} + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1}\\<br/>
&amp;= (-k_{r+1,1}a_{11}-k_{r+1,2}a_{21}-...k_{r+1,r}a_{r1}) + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1} = k_{r+1,1}\lambda<br/>
\end{align*}<br/>
\]</p>

<p>同理可得其他项，按照这种方式最终可得：<br/>
\[<br/>
\begin{align*}<br/>
|\lambda I-A| &amp;\sim \left ( \begin{array}{cccccc} <br/>
\lambda-a_{11}&amp;-a_{12}&amp;...&amp;-a_{1r}&amp;-a_{1,r+1}&amp;...&amp;-a_{1n}\\<br/>
-a_{21}&amp;\lambda-a_{22}&amp;...&amp;-a_{2r}&amp;-a_{2,r+1}&amp;...&amp;-a_{2n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;..&amp;...\\<br/>
-a_{r1}&amp;-a_{r2}&amp;...&amp;\lambda-a_{rr}&amp;a_{r,r+1}&amp;...&amp;-a_{rn}\\<br/>
k_{r+1,1}\lambda&amp;k_{r+1,2}\lambda&amp;...&amp;k_{r+1,r}\lambda&amp;\lambda&amp;...&amp;0\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
k_{n,1}\lambda&amp;k_{n,2}\lambda&amp;...&amp;k_{n,r}\lambda&amp;0&amp;...&amp;\lambda<br/>
\end{array} \right ) \\<br/>
&amp;= \lambda^{n-r}\left ( \begin{array}{cccccc} <br/>
\lambda-a_{11}&amp;-a_{12}&amp;...&amp;-a_{1r}&amp;-a_{1,r+1}&amp;...&amp;-a_{1n}\\<br/>
-a_{21}&amp;\lambda-a_{22}&amp;...&amp;-a_{2r}&amp;-a_{2,r+1}&amp;...&amp;-a_{2n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;..&amp;...\\<br/>
-a_{r1}&amp;-a_{r2}&amp;...&amp;\lambda-a_{rr}&amp;a_{r,r+1}&amp;...&amp;-a_{rn}\\<br/>
k_{r+1,1}&amp;k_{r+1,2}&amp;...&amp;k_{r+1,r}&amp;1&amp;...&amp;0\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
k_{n,1}&amp;k_{n,2}&amp;...&amp;k_{n,r}&amp;0&amp;...&amp;1<br/>
\end{array} \right ) \\<br/>
\end{align*}<br/>
\]</p>

<p>由此可见至少\(|\lambda I-A| = 0\)有\((n-r)\)个零特征值，也就是它最多拥有\(n-(n-r)=r\)个非零特征值。结合\(r(A) = r\)，所以\(u(A) \le r(A)\)。<br/>
得证。</p>

<h6 id="toc_15">其他关于矩阵秩的论文：<a href="https://wenku.baidu.com/view/f0deb94a8762caaedc33d426.html">方阵的秩与特征值的关系</a></h6>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15037711738928.html">奇异值分解 SVD</a></h1>
			<p class="meta"><time datetime="2017-08-27T02:12:53+08:00" 
			pubdate data-updated="true">2017/8/27</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>SVD，英文全称是Singular Values Decomposition，关于奇异值的解释，参考一下百度百科里的介绍，设\(A\)是一个m*n的矩阵，那么\(AA^T\)的q个特征值得平方根叫做\(A\)的特征值。在PCA的介绍中，我们提到了特征值分解的方式来实现提取特征，特征值分解要求必须是方阵。而奇异值分解的目的也是提取特征值，但是针对的是任意矩阵。SVD除此之外还可以用来做图片压缩，在推荐系统中的应用也是名声大噪。</p>

<h2 id="toc_0">前置知识</h2>

<p>在学习SVD之前需要一些线性代数的知识，下面做一些简单介绍。</p>

<h4 id="toc_1">正交矩阵</h4>

<p>在线形代数里，若矩阵\(A\)满足\(AA^T=I\)或\(A^TA=I\)，其中\(E\)为单位矩阵，那么可以说\(n\)阶实矩阵为正交矩阵。<br/>
\[<br/>
\begin{align*}<br/>
(AA^T)_{ij} = \sum_{k=0}^N a_{ik} a_{kj} = I_{ij}<br/>
\end{align*}<br/>
\]</p>

<p>由单位矩阵的性质可知主对角线上的元素不为0，其他元素都为0，可知\(A\)的各行两两相交，且\(||A^T||=1\)，同理\(A\)的列向量两两正交且\(||A||=1\)。</p>

<p>一个正交矩阵对应的变换叫做正交变换，这个变换有一些特点。假设我们在空间里有一个点\(X=(2,4)^T\)，那么现在我们用一个正交矩阵\(A=\left [ \begin{array}{cc}\frac{\sqrt{2}}{2} &amp; -\frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} &amp; \frac{\sqrt{2}}{2} \end{array} \right ]\)来对其做正交变换，所以得到的新的坐标点的位置为\(X^{&#39;}=A^TX=(3\sqrt{2},\sqrt{2})^T\)，我们将得到的新的坐标点在新的正交基构成的坐标系中表示出来，如下图：</p>

<div align="center">
    <img src="media/15037711738928/15273990942816.jpg" width="500px" />
</div>

<p>由上图可知，坐标点的\(X\)的位置其实并没有发生改变，只是在相对应不同的坐标系位置发生了改变，实际上也就是只是将坐标系旋转了。</p>

<p>正交矩阵其实是一种特殊的每一个元素都是实数的酉矩阵，一个\(n\times n\)的复数矩阵\(U\)，满足：<br/>
\[<br/>
U^{H}U = UU^{H} = I<br/>
\]<br/>
其中\(U^{H}\)是\(U\)的共轭转置矩阵，那么\(U\)则被称为酉矩阵。</p>

<h2 id="toc_2">SVD介绍</h2>

<p>设\(X\)是一个\(m*n\)的矩阵，则存在\(m\)阶正交矩阵\(U\)和\(n\)阶正交矩阵\(V\)，在复数领域就是酉矩阵，满足：<br/>
\[<br/>
X = U\Sigma V^T = U\left [ \begin{array}{cccc}\sigma_1&amp;&amp;&amp;\\&amp;\sigma_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\sigma_r\\&amp;&amp;&amp;0\\\end{array}\right ]V<br/>
\]</p>

<p>其中\(\sigma_1&gt;\sigma_2&gt;\sigma_r\)被称为奇异值，\(U\)和\(V\)的前r列向量被称为奇异向量。一般前10%甚至1%的奇异值，将能代表超过99%的信息量。关于奇异值和奇异向量的求解就是SVD分解。</p>

<h2 id="toc_3">SVD分解</h2>

<p>在PCA中操作往往是对数据集\(X\)的协方差矩阵\((X-\overline{X})(X-\overline{X})^T\)进行提取特征值，但是特征值提取只能是方阵，那么对于非方阵提取特征值便可以通过SVD的方式。奇异值分解是一种能分解任意矩阵的方法，对于\(m\times n\)的矩阵\(X\)有：<br/>
\[<br/>
X = U\Sigma V^T<br/>
\]</p>

<p>其中\(\Sigma\)是一个\(m\times n\)的矩阵，除主对角线的元素外都为0，主对角线的元素则是奇异值，按照从大到小排列。\(U\)是一个\(m\times m\)的方阵，称为\(X\)的左奇异向量，\(V\)是一个\(n \times n\)的方阵，称为\(X\)的右奇异向量，它们都是正交矩阵，满足\(UU^T=I,VV^T=I\)。</p>

<p>现在开始讨论\(U\)和\(V\)和\(\Sigma\)的求解：<br/>
\[<br/>
X = U\Sigma V^T \Rightarrow X^T = V\Sigma^TU^T \Rightarrow XX^T = U\Sigma V^TV\Sigma^TU^T=U(\Sigma\Sigma^T)U^T<br/>
\]</p>

<p>因为\((XX^T)^T = XX^T\)，所以\(XX^T\)是一个对称向量，由对称向量的性质，\(n\)阶对称向量，必有正交矩阵\(P\)，满足\(A = P\Lambda P^T\)，所以结合上式可以认为左奇异向量\(U\)是对称矩阵\(XX^T\)的特征向量。同理：<br/>
\[<br/>
X^TX = V\Sigma^TU^TU\Sigma V^T = V(\Sigma^T\Sigma) V^T<br/>
\]</p>

<p>可知右奇异向量\(V\)可看做对称矩阵\(X^TX\)的特征向量。同时我们也能将\(\Sigma^T\Sigma\)看做对称矩阵\(XX^T\)或\(X^TX\)的特征值组成的矩阵，也就是奇异值可以通过\(X^TX\)或\(XX^T\)特征值取平方根来求得。</p>

<p>这里说奇异值可以通过\(X^TX\)或\(XX^T\)特征值取平方根来求得，那就必然存在两个必然条件：<br/>
(1) \(X^TX\)或\(XX^T\)的特征值必须是非负数<br/>
(2) \(A^TA\)和\(AA^T\)的非零特征值必须相等（为了说明清楚，换个表示）</p>

<p>证明（1）：假设矩阵的\(X^TX\)的特征值\(\sigma\)对应的特征向量是\(v\)，有正交矩阵的性质可知\(v^Tv = 1\)：<br/>
\[<br/>
X^TX v = \sigma v \Rightarrow \sigma=v^TX^TX v = ||Xv||^2<br/>
\]</p>

<p>所以得证\(\sigma\ge 0\)，同理可知\(XX^T\)的特征向量必是非负数。</p>

<p>证明（2）：首先证明向量\(A^TA\)与\(AA^T\)有相等个非零特征值：<br/>
设矩阵\(A\)是\(m\times n\)的矩阵，由矩阵秩的性质可知\(r(A)=r(A^T)\)。对于任意的向量\(x\)，如果\(Ax = 0\)则 \(A^TAx = A^T0 = 0\)，即\(Ax=0\)的解空间是\(A^Ax=0\)的解空间。如果\(A^TAx = 0\)时，两边同左乘\(x^T\)得\(x^TA^TAx = (Ax)^TAx= 0 \)，也就是\(||Ax||=0\)，所以\(Ax=0\)，即\(A^TAx=0\)的解空间是\(Ax=0\)的解空间。结合前面知：\(Ax=0\)与\(A^TAx=0\)拥有相同的解空间，所以\(r(A)=r(A^TA)\)，同理可证：\(r(A^T)=r(AA^T)\)。</p>

<p>设\(r(A) = r\)，所以\(r=r(A)=r(A^TA)\)=\(r(A^T)=r(AA^T)\)，因为\(AA^T\)是实对称向量，并由秩的定义可知\(AA^T\)化成行列式后有\(r\)个非零行，即\(AA^T\sim\left[\begin{array}\\\sigma_1&amp;&amp;&amp;\\&amp;\ddots&amp;&amp;\\&amp;&amp;\sigma_r&amp;\\&amp;&amp;&amp;0\\\end{array}\right]\)，其中\(\sigma_n\)是\(AA^T\)的特征值，\(r=AA^T\)非零特征值得个数。同理\(r=A^TA\)非零特征值得个数。</p>

<p>再证明\(A^TA\)的非零特征值也是\(AA^T\)的特征值：<br/>
设\(\sigma\)是\(A^TA\)的特征值，所以有\(A^TAv=\sigma v\)，两边同时左乘\(A\)得：\(AA^T(Av) = \sigma Av\)，这可以看成\(\sigma\)是\(AA^T\)的特征值，其中对应的特征向量是\(Av\)，所以\(A^TA\)的特征值也是\(AA^T\)的特征值。反之也可证明\(AA^T\)的特征值也是\(A^TA\)的特征值。</p>

<p>综上（1）（2）可知\(A^TA\)与\(AA^A\)特征值的区别就在零特征值的数量。</p>

<p>那么我们在求出\(X^TX\)或\(XX^T\)任意一个特征值后，可以利用左右奇异向量的关系，在求出其中一个的前提下，求出另一个，而不用再通过特征值得方式计算，假设\(\sigma_i\)为\(X\)的奇异值：<br/>
\[<br/>
X = U\Sigma V^T \Rightarrow AV = U\Sigma \Rightarrow Xv_i = \sigma_iu_i\\\Rightarrow u_i = Xv_i/\sigma_i<br/>
\]</p>

<p>因为特征值与奇异值的关系，可知\(X^TX\)的特征值为\(\sigma_i^2\)，假设\(X^TX\)对应的特征向量为\(v_i\)，则：<br/>
\[<br/>
\begin{align*}<br/>
&amp;X^TX v_i = \sigma_i^2 v_i \\<br/>
&amp;\Rightarrow v_i^T X^TXv_i = \sigma_i^2 v_i^Tv_i \\<br/>
&amp;\Rightarrow \sigma_i^2 = ||Xv_i||^2 \\<br/>
\end{align*}<br/>
\]</p>

<p>注意到：<br/>
\[<br/>
XX^Tu_i = XX^T\frac{Xv_i}{\sigma_i} = X\frac{X^TXv_i}{\sigma_i}=X\frac{\sigma_i^2 v_i}{\sigma_i} = \sigma_i^2\frac{Xv_i}{\sigma_i} = \sigma_i^2p_i<br/>
\]</p>

<p>所以\(u_i\)是\(XX^T\)的特征向量，其实这个在上面已经知道了。</p>

<p>且有：<br/>
\[<br/>
u_i^Tu_j = (\frac{Xv_i}{\sigma_i})^T\frac{Xv_j}{\sigma_j} = \frac{(Xv_i)^T}{\sigma_i}\frac{Xv_j}{\sigma_j} = \frac{v_i^TX^TXv_j}{\sigma_i\sigma_j} = \frac{v_i^T\sigma_j^2v_j}{\sigma_i\sigma_j}=\frac{\sigma_j}{\sigma_i}v_i^Tv_j<br/>
\]</p>

<p>令\(\delta_{ij}=v_i^Tv_j\)，则：<br/>
\[<br/>
u_i^Tu_j=\frac{\sigma_j}{\sigma_i}\delta_{ij}<br/>
\]</p>

<p>当特征向量\(v_i\)是一组正交单位特征向量时：<br/>
当\(i \neq j\)时\(\delta_{ij}=v_iv_j=0\)，此时\(u_i^Tu_j=\frac{\sigma_j}{\sigma_i}\delta_{ij}=0=\delta_{ij}\)；<br/>
当\(i = j\)时\(\sigma_i=\sigma_j\)，此时\(u_i^Tu_j=\frac{\sigma_j}{\sigma_i}\delta_{ij}=\delta_{ij}\)，<br/>
所以\(u_i\)也是一组正交单位特征向量。</p>

<h4 id="toc_4">SVD分解实例</h4>

<p>求解\(A = \left ( \begin{array}{cc} 1 &amp; 0\\ 1&amp;1\\ 0&amp;0\\0&amp;1\\ \end{array} \right)\)<br/>
首先计算\(AA^T=\left ( \begin{array}{cc} 1 &amp; 0\\ 1&amp;1\\ 0&amp;0\\0&amp;1\\ \end{array} \right)\cdot\left ( \begin{array}{cc}  1&amp;1&amp;0&amp;0\\ 0&amp;1&amp;0&amp;1\\ \end{array} \right) = \left(\begin{array}{cc}1 &amp; 1&amp;0&amp;0\\1&amp;2&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;1&amp;0&amp;1\\\end{array}\right)\) ，然后计算\(A^TA\)的特征向量就是左奇异矩阵\(U\)。<br/>
\[<br/>
|AA^T-\lambda I| = \left | \begin{array}{cccc}1-\lambda &amp;1&amp;0&amp;0 \\ 1&amp;2-\lambda &amp;0&amp;1 \\0&amp;0&amp; -\lambda&amp;0 \\0&amp;1&amp;0&amp;1-\lambda \\\end{array}\right | = -\lambda\left | \begin{array}{cc}1-\lambda&amp;1&amp;0\\1&amp;2-\lambda&amp;1\\0&amp;1&amp;1-\lambda\end{array}\right|=0\\<br/>
\Rightarrow -\lambda[(1-\lambda)^2(2-\lambda)-2(1-\lambda)] =0<br/>
\]</p>

<p>可以求出\(\lambda_1=3\,,\lambda_2=1\,,\lambda_3=\lambda_4=0\)。<br/>
当\(\lambda_1=3\)时：<br/>
\[<br/>
(AA^T-\lambda I)\overrightarrow{\nu} = \left(\begin{array}{cccc}-2&amp;1&amp;0&amp;0\\1&amp;-1&amp;0&amp;1\\0&amp;0&amp;-3&amp;0\\0&amp;1&amp;0&amp;-2\\\end{array}\right)\left(\begin{array}{c}x_1\\x_2\\x_3\\x_4\\\end{array}\right) \\<br/>
\Rightarrow \left \{ \begin{array}\\-2x_1+x_2=0\\x_1-x_2+x_4=0\\-3x_3=0\\x_2-2x_4=0\\\end{array}\right .<br/>
\]</p>

<p>可以求得其中一个解为\(x1=1\,,x2=2\,,x_3=0\,,x4=1\)，归一化后得：<br/>
\[<br/>
\overrightarrow{\nu} = \left ( \begin{array}{c}<br/>
\frac{1}{\sqrt{6}}\\\frac{2}{\sqrt{6}}\\0\\\frac{1}{\sqrt{6}}\\\end{array}\right)<br/>
\]</p>

<p>同样的方式，可以求出特征矩阵为：<br/>
\[<br/>
V = \left ( \begin{array}{c}<br/>
\frac{1}{\sqrt{6}}&amp;\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\frac{2}{\sqrt{6}}&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
0&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
\frac{1}{\sqrt{6}}&amp;-\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\end{array}\right)<br/>
\]</p>

<p>我们知道这就是左奇异矩阵\(U\)，同理再计算\(A^TA\)的特征值\(\lambda_1=3\,,\lambda_2=1\)，代入求得右奇异矩阵\(V\)：<br/>
\[<br/>
V=\left ( \begin{array}{cc}<br/>
\frac{\sqrt{2}}{2}&amp;\frac{\sqrt{2}}{2}\\\frac{\sqrt{2}}{2}&amp;-\frac{\sqrt{2}}{2}\\<br/>
\end{array} \right )<br/>
\]</p>

<p>前面我们说过\(\Sigma\)主对角线的元素，也就是奇异值，是特征值得平方根，所以可求得：<br/>
\[<br/>
\Sigma = \left ( \begin{array}{cc}<br/>
\sqrt{3}&amp;0\\0&amp;1\\0&amp;0\\0&amp;0\\<br/>
\end{array} \right )<br/>
\]</p>

<p>所以矩阵\(A\)被分解为了3个矩阵的乘积：<br/>
\[<br/>
A = \left ( \begin{array}{c}<br/>
\frac{1}{\sqrt{6}}&amp;\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\frac{2}{\sqrt{6}}&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
0&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
\frac{1}{\sqrt{6}}&amp;-\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\end{array}\right) \cdot \left ( \begin{array}{cc}<br/>
\sqrt{3}&amp;0\\0&amp;1\\0&amp;0\\0&amp;0\\<br/>
\end{array} \right ) \cdot \left( \begin{array}{cc}<br/>
\frac{\sqrt{2}}{2}&amp;\frac{\sqrt{2}}{2}\\\frac{\sqrt{2}}{2}&amp;-\frac{\sqrt{2}}{2}\\<br/>
\end{array} \right )<br/>
\]</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15034227314732.html">主成分分析 PCA</a></h1>
			<p class="meta"><time datetime="2017-08-23T01:25:31+08:00" 
			pubdate data-updated="true">2017/8/23</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在介绍主成分分析之前，简单看一下方差、协方差，特征值，特征向量的概念，了解这些后才能更好了解主成分分析。</p>

<h2 id="toc_0">代数基础知识</h2>

<h4 id="toc_1">方差 variance</h4>

<p>在统计学中，方差被描述为样本与总体平均数之间的差异，假设样本数据为\(X_i\,:\,i=1;2;...;N\)，定义：<br/>
\[<br/>
\mu = \frac{\sum_{i=1}^N X_i}{N}<br/>
\]</p>

<p>为总体平均数，对于总体的方差公式为（\(\sigma^2\)代表方差，\(\sigma\)代表标准差）：<br/>
\[<br/>
\sigma^2 = \frac{\sum_{i=1}^N (X_i - \mu)^2}{N}<br/>
\]</p>

<p>假设样本均值为\(\overline{X}\)，样本方差定义为为：<br/>
\[<br/>
S^2 = \frac{\sum_{i=1}^N(x_i-\overline{X})^2}{n-1}<br/>
\]</p>

<p>这里的n为样本x的数量，这里和总体方差不同的是除以的是n-1，而不是n，这是由于除以n-1是无偏方差，如果除以n会比总体方差要小。</p>

<blockquote>
<h4 id="toc_2">无偏方差为什么除以n-1？</h4>

<p>假设数据集X上，有多次抽样\(X_1\)、\(X_2\)、...、\(X_n\)，每一个样本的平均值即为\(\overline{X_1}\)、\(\overline{X_2}\)、...、\(\overline{X_n}\)，随着抽样的次数逐渐增多，样本平均值的平均值将会越来越近总体平均值，即\(E(\overline{X}) = \mu\)，此时也就是无偏估计。</p>

<p>首先我们来假设无偏方差是如下形式：<br/>
\[<br/>
S^2 = \frac{1}{n}\sum_{i=1}^N(x_i-\overline X)^2<br/>
\]<br/>
所以求无偏方差的期望为：<br/>
\[<br/>
\begin{align*}<br/>
E[S^2] &amp;= E[\frac{1}{n} \sum_{i=1}^N(x_i-\overline X)^2] \\<br/>
&amp;= E[\frac{1}{n} \sum_{i=1}^N (x_i - \mu + \mu - \overline X)^2] \\<br/>
&amp;= E[\frac{1}{n} \sum_{i=1}^N [(x_i - \mu)^2 + 2(x_i - \mu)(\mu - \overline{X}) + (\mu - \overline{X})^2]] \\<br/>
&amp;= E[\frac{1}{n} \sum_{i=1}^N(x_i-\mu)^2 + \frac{1}{n}\sum_{i=1}^N 2(x_i - \mu)(\mu-\overline{X})+\frac{1}{n}\sum_{i=1}^N(\mu-\overline{X})^2] \\<br/>
&amp;\because\quad\frac{1}{n}\sum_{i=1}^N(x_i-\mu) = \frac{1}{n}\sum_{i=1}^Nx_i-\frac{1}{n}\sum_{i=1}^N\mu = \overline{X} - \mu \\<br/>
E[S^2]&amp;= E[\frac{1}{n}\sum_{i=1}^N(x_i-\mu)^2 + 2(\overline{X}-\mu)(\mu - \overline{X}) + (\mu-\overline{X})^2] \\<br/>
&amp;=E[\frac{1}{n}\sum_{i=1}^N(x_i-\mu)^2 - (\overline{X} - \mu)^2] \\<br/>
&amp;=E[\frac{1}{n}\sum_{i=1}^N(x_i-\mu)^2] - E[(\overline{X}-\mu)^2] \\<br/>
&amp;=\sigma^2-E[(\overline{X} - \mu)^2]<br/>
\end{align*} <br/>
\]</p>

<p>并有：<br/>
\[<br/>
\begin{align*}<br/>
E[(\overline{X}-\mu)^2] &amp;= E[(\overline{X}-E(\overline{X}))^2] = var(\overline{X})\\<br/>
&amp;= var(\frac{\sum_{i=1}^n X_i}{n}) \\<br/>
&amp;= \frac{1}{n^2}var(\sum_{i=1}^n X_i) \\<br/>
&amp;= \frac{1}{n^2}\sum_{i=1}^N var(X_i) \\<br/>
&amp;= \frac{1}{n}\sigma^2<br/>
\end{align*}<br/>
\]<br/>
所以：<br/>
\[<br/>
E(S^2) = \sigma^2 - E[(\overline{X} - \mu)^2] = \sigma^2-\frac{\sigma^2}{n} = \frac{n-1}{n}\sigma^2<br/>
\]<br/>
由证明其实可知我们假设的无偏方差其实是有偏差的，它比总体方差要小，此时如果我们想要得到无偏方差\(\sigma^2\)，我们希望\(S^2\)乘上\(\frac{n}{n-1}\)，得到：<br/>
\[<br/>
S^2 = \frac{n}{n-1}(\frac{1}{n} \sum_{i=1}^N(x_i-\overline X)^2) = \frac{1}{n-1}\sum_{i=1}^N(x_i-\overline X)^2<br/>
\]<br/>
证明：<br/>
\[<br/>
\begin{align*}<br/>
E[S^2] &amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i - \mu + \mu - \overline{X})^2] \\<br/>
&amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2+\frac{1}{n-1}\sum_{i=1}^N2(x_i-\mu)(\mu-\overline{X}) + \frac{1}{n-1}\sum_{i=1}^N (\mu-\overline{X})^2] \\<br/>
&amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2 - \frac{2n}{n-1}(\mu-\overline{X})^2 + \frac{n}{n-1}(\mu-\overline{X})^2] \\<br/>
&amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2 - \frac{n}{n-1}(\mu-\overline{X})^2] \\<br/>
&amp;=E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2] - E[\frac{n}{n-1}(\mu-\overline{X})^2] \\<br/>
&amp;=\frac{n}{n-1}E[\frac{1}{n}\sum_{i=1}^N (x_i-\mu)^2] - \frac{n}{n-1}E[(\mu-\overline{X})^2] \\<br/>
&amp;=\frac{n}{n-1}\sigma^2-\frac{n}{n-1} \cdot\frac{\sigma^2}{n} \\<br/>
&amp;= \sigma^2<br/>
\end{align*}<br/>
\]<br/>
得证。无偏方差为：<br/>
\[<br/>
S^2 = \frac{1}{n-1}\sum_{i=1}^N(x_i-\overline X)^2<br/>
\]</p>
</blockquote>

<h4 id="toc_3">协方差 Covariance</h4>

<p>由前面对方差的定义可知，方差是衡量数据集中数据与平均值的偏离程度，方差处理的是一维数据的情况，而在现实生活中我们处理的多是多维数据，描述的往往是多个数据同时偏离平均值的程度。我们可以仿照方差的形式：<br/>
\[<br/>
var(X) = \frac{1}{n-1}\sum_{i=1}^N (X_i - \overline{X}) = \frac{1}{n-1} \sum_{i=1}^N (X_i - \overline{X})(X_i-\overline{X})<br/>
\]<br/>
定义协方差：<br/>
\[<br/>
cov(X,Y) = \frac{1}{n-1}(X_i - \overline{X})(Y_i - \overline{Y})<br/>
\]</p>

<p>通常我们可以用偏方差来描述两个维度的数据的相关性，偏方差为正数表示两者是正相关的，反之为负数表示两者负相关，如果为0，表示两者互相独立。由协方差的定义容易知：<br/>
\[<br/>
var(X) = cov(X,X)<br/>
cov(X,Y) = cov(Y,X)<br/>
\]</p>

<p>由定义可知，协方差每次只可以描述两个维度数据，如果我们有n维数据，那么往往就需要计算\(\frac{1}{2}n(n-1)\)个协方差，于是便引入了协方差矩阵。一个三维的协方差矩阵如下所示：<br/>
\[<br/>
C = \left ( \begin{array}{ccc}<br/>
cov(x,x) &amp;&amp; cov(x,y) &amp;&amp; cov(x,z) \\<br/>
cov(y,x) &amp;&amp; cov(x,x) &amp;&amp; cov(y,z) \\<br/>
cov(z,x) &amp;&amp; cov(z,y) &amp;&amp; cov(z,z) \\<br/>
\end{array} \right)<br/>
\]</p>

<blockquote>
<p>散度矩阵：协方差矩阵的计算有除以\((n-1)\)的步骤，如果没有没有这个步骤获得的矩阵即是散度矩阵。换言之，散度矩阵等于协方差矩阵乘以\((n-1)\)。</p>
</blockquote>

<h4 id="toc_4">特征值和特征向量</h4>

<p>对于一个向量\(A\)，通过应用非零向量\(\overrightarrow{\nu}\)后仅仅相当于将\(\overrightarrow{\nu}\)同比例的缩放\(\gamma\)倍，那么我们称\(\overrightarrow{\nu}\)是特征向量，\(\gamma\)是特征值：<br/>
\[<br/>
A\overrightarrow{\nu} = \lambda\overrightarrow{\nu}<br/>
\]</p>

<p>1、对于一个方阵A，如果存在可逆向量P，满足\(P^{-1}AP=\Lambda\)，\(\Lambda\)是一个对角矩阵，这样我们可以说方阵A可对角化。</p>

<p>首先变换表示形式，将P用其列向量的形式表示\(P = (p_1,p_2,...,p_n)\)，对角矩阵\(\Lambda\)的表示形式如下：<br/>
\[<br/>
\Lambda = \left [ \begin{array} \\<br/>
\lambda_1&amp;&amp;           &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp; \lambda_2 &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp; \ddots &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp;        &amp;&amp; \lambda_n \\<br/>
\end{array}\right ]<br/>
\]</p>

<p>得：<br/>
\[<br/>
P^{-1}AP=\Lambda \Rightarrow AP = P\Lambda<br/>
\Rightarrow A(p_1,p_2,...,p_n) = (p_1,p_2,...,p_n)\left [\begin{array} \\<br/>
\lambda_1&amp;&amp;           &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp; \lambda_2 &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp; \ddots &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp;        &amp;&amp; \lambda_n \\<br/>
\end{array}\right] \\<br/>
\Rightarrow (Ap_1,Ap_2,...,Ap_n) = (\lambda_1p_1,\lambda_2p_2,...,\lambda_np_n)<br/>
\]</p>

<p>由上式可知：\(Ap_n=\lambda_np_n\)，所以可以看成对角矩阵的每一个元素\(\lambda_n\)都是方阵A的特征值，可逆矩阵P对应位置的列向量\(p_n\)是其特征向量。</p>

<p>2、对于一个可逆矩阵A，它的逆矩阵的特征值是原矩阵的倒数。设\(\lambda\)是其特征值，\(\overrightarrow{\nu}\)是特征向量，则有：<br/>
\[<br/>
A\overrightarrow{\nu} = \lambda\overrightarrow{\nu}<br/>
\] </p>

<p>两边同时左乘\(A^{-1}\)，可得：<br/>
\[<br/>
\overrightarrow{\nu} = \lambda A^{-1}\overrightarrow{\nu} \\<br/>
\Rightarrow \frac{1}{\lambda}\overrightarrow{\nu} = A^{-1} \overrightarrow{\nu} \\<br/>
\]</p>

<p>所以可知，逆矩阵的特征值是原矩阵的倒数。</p>

<p>3、复正规矩阵的特征向量和特征值</p>

<p>对角矩阵、实对称矩阵(\(A^T=A\))、反实对称矩阵(\(A^T = -A\))、厄米特矩阵(\(A^H=A\))、反厄米特矩阵(\(A^H=-A\))、正交矩阵(\(AA^T=A^TA=I\))、酉矩阵(\(AA^H=A^HA=I\))等满足\(AA^H=A^HA\)条件的矩阵都叫正规矩阵。并不是正规矩阵，都是对角矩阵、实对称、反实对称矩阵等，比如\(\left [ \begin{array}{lr} 1&amp; -1\\1&amp;1\\\end{array}\right]\)，不属于上面，但是它满足\(AA^T=A^TA\)，因此也是正规矩阵。</p>

<p>定理：对于正规矩阵\(A\)都存在酉矩阵\(Q\)使得：<br/>
\[<br/>
Q^HAQ = Q^{-1}AQ = \Sigma=\left [ \begin{array}\\\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n\\\end{array}\right]<br/>
\]</p>

<p>证明：可以通过\(A\)可以通过酉向量\(P\)化为上（下）三角矩阵\(B\)，即\(B=P^TAP\)，再由\(B^TB=P^TA^TPP^TAP=P^TA^TAP=P^TAA^TP=BB^T\)，因为\(B\)是上（下）三角矩阵，通过比较\(BB^T=B^TB\)对角线位置的元素，可知\(B\)是对角矩阵。</p>

<p>所以对于任意的复正规矩阵具有一组正交特征向量基，复正规矩阵可以被分解为：<br/>
\[<br/>
A = U \Sigma U^H<br/>
\]</p>

<p>其中U为一个酉矩阵，进一步：<br/>
\(A\)为厄米特矩阵\(\quad\Leftrightarrow\quad\)\(\Sigma\)的每个对角元都为实数。<br/>
\(A\)为反厄米特矩阵\(\quad\Leftrightarrow\quad\)\(\Sigma\)的每个对角元都为0或虚数。<br/>
\(A\)为酉矩阵\(\quad\Leftrightarrow\quad\)\(\Sigma\)的全部特征元的模为1。</p>

<p>继续：<br/>
\[<br/>
\begin{align*}<br/>
&amp;A = U \Sigma U^H \\<br/>
\Rightarrow &amp;AU = U\Sigma\\<br/>
\Rightarrow &amp;A(u_1,u_2,...,u_3) = (u_1,u_2,...,u_3)\left [ \begin{array}\\\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n\\\end{array}\right]\\<br/>
\Rightarrow &amp;(Au_1,Au_2,...,Au_3) = (\lambda_1u_1,\lambda_2u_2,...,\lambda_nu_n)\\<br/>
\Rightarrow &amp; Au = \lambda u\\<br/>
\end{align*}<br/>
\]</p>

<p>4、求解特征值和特征矩阵。由特征值和特征向量的定义易看出如何求解，首先是求出其特征值：<br/>
\[<br/>
A\overrightarrow{\nu} = \lambda \overrightarrow{\nu} \\<br/>
\Rightarrow (A-\lambda I)\overrightarrow{\nu} = 0<br/>
\]</p>

<p>由于特征向量\(\overrightarrow{\nu}\)不为0，所以可知\(|A-\lambda I| = 0\)，这样便可以求出特征值\(\lambda\)，再带回原式中求出特征向量\(\overrightarrow{\nu}\)</p>

<p>假设求解\(A = \left( \begin{array}{ccc}<br/>
-1 &amp;&amp; 1 &amp;&amp; 0 \\<br/>
-4 &amp;&amp; 3 &amp;&amp; 0 \\<br/>
1 &amp;&amp; 0 &amp;&amp; 2 \\<br/>
\end{array} \right)<br/>
\)的特征向量和特征值，按照之前描述需要先求出特征值，所以：<br/>
\[<br/>
\begin{align*}<br/>
|A - \lambda I | &amp;= \left | \begin{array}{ccc}<br/>
-1-\lambda &amp;&amp; 1 &amp;&amp; 0 \\<br/>
-4 &amp;&amp; 3 - \lambda &amp;&amp; 0\\<br/>
1 &amp;&amp; 0 &amp;&amp; 2-\lambda \\<br/>
\end{array} \right| = (2-\lambda)\left | \begin{array}{ccc}<br/>
-1-\lambda &amp;&amp; 1 \\<br/>
-4 &amp;&amp; 3-\lambda \\<br/>
\end{array} \right | \\<br/>
&amp;=(2-\lambda)[(-1-\lambda)(3-\lambda)+4] \\<br/>
&amp;=(2-\lambda)(\lambda^2-3\lambda+\lambda+1) \\<br/>
&amp;=(2-\lambda)(\lambda^2-2\lambda+1) \\<br/>
&amp;=(2-\lambda)(\lambda-1)^2 = 0<br/>
\end{align*}<br/>
\]</p>

<p>所以可得\(\lambda=1\)或\(\lambda=2\)。<br/>
当\(\lambda=1\)时：<br/>
\[<br/>
(A-\lambda I)\overrightarrow{\nu} = \left ( \begin{array}{ccc}<br/>
-2 &amp;&amp; 1 &amp;&amp; 0 \\<br/>
-4 &amp;&amp; 2 &amp;&amp; 0 \\<br/>
1 &amp;&amp; 0 &amp;&amp; 1 \\<br/>
\end{array} \right )\left( \begin{array} \\<br/>
x_1 \\<br/>
x_2 \\<br/>
x_3 \\<br/>
\end{array} \right) = 0\\<br/>
\Rightarrow \left \{ \begin{array}\\<br/>
-2x_1 + x_2 = 0\\<br/>
-4x_1 + 2x_2 = 0\\<br/>
x_1 + x_3 = 0\\<br/>
\end{array} \right.<br/>
\]</p>

<p>易得相应的特征向量为：\(P=\left( \begin{array}{ccc} -1 \\ -2 \\ 1 \\ \end{array} \right)\)，<br/>
同理可求得当\(\lambda=2\)是，特征向量为：\(P=\left( \begin{array}{ccc} 0 \\ 0 \\ 1 \\ \end{array} \right)\)</p>

<h2 id="toc_5">主成分分析 PCA</h2>

<p>PCA的英文名称就做Principle Component analysis，是一种常用的数据分析方法。他通过对原始数据进行线性变换，将数据转变为各维度线性无关的表示，可以用于数据降维和压缩。在机器学习中，经常我们需要处理的数据是几千维甚至是几十万维度的数据，如果直接处理，不论是对计算机性能、算法性能还是对训练时间度的要求都大大增大，这时候对高维数据降维，且不能丢失主要的信息。那么我们该如何确定该删掉哪些维度的数据呢？还有如何在最大限度减小维度的同时又能让信息损失最低呢？这就是PCA可以做的事。</p>

<p>PCA的主要目的在于保留最大信息量的同时降噪，如图：</p>

<div align="center">
    <img src="media/15034227314732/15272993250127.jpg" width="400px" />
</div>

<p>直观上来看将元素在红线上的投影来描述信息对信息的损失比蓝线要小很多，所以也就是希望投影后的方差最大化。信息处理认为信号具有较大的方差，噪音拥有较小的方差，信噪比就是信号与噪音的方差比。因此在PCA中，我们需要将数据有原始的m维数据转换到新的k维空间中，也就是我们需要找到k个正交基来描述空间。新的坐标系的选择与原始数据的构成有关，通常我们选择能使原始数据方差最大的方向作为第一个坐标轴，第二个坐标轴的选择是与第一个坐标轴正交且原始数据的投影方差最大的方向，依次类推选择k个坐标轴。</p>

<p>用一个例子来描述PCA的过程，假设我们有一个数据集如下：</p>

<p>\[<br/>
Data = \left . \begin{array}{c|c}<br/>
x &amp; y \\<br/>
\hline<br/>
2.5 &amp; 2.4 \\<br/>
0.5 &amp; 0.7 \\<br/>
2.2 &amp; 2.9 \\<br/>
1.9 &amp; 2.2 \\<br/>
3.1 &amp; 3.0 \\<br/>
2.3 &amp; 2.7 \\<br/>
2 &amp; 1.6 \\<br/>
1 &amp; 1.1 \\<br/>
1.5 &amp; 1.6 \\<br/>
1.1 &amp; 0.9 \\<br/>
\end{array} \right .<br/>
\]</p>

<p>我们首先需要求出数据集的协方差，由协方差计算公式可知需要先求出x和y分别的平均数：\(\overline{x} = 1.81,\,\overline{y} = 1.91\)，然后易求出协方差：<br/>
\[<br/>
Cov(Data) = \left ( \begin{array}{cc}<br/>
cov(x,x) &amp; cov(x,y) \\<br/>
cov(y,x) &amp; cov(y,y) \\<br/>
\end{array}\right) = \left ( \begin{array}{cc}<br/>
0.616555556 &amp; 0.615444444 \\<br/>
0.615444444 &amp; 0.716555556 \\<br/>
\end{array} \right )<br/>
\]</p>

<p>接下来求出该协方差矩阵的特征值，令\(A = Cov(Data)\)：<br/>
\[<br/>
\begin{align*}<br/>
| A - \lambda I| &amp;= \left | \begin{array}{cc}<br/>
0.616555556-\lambda &amp; 0.615444444 \\<br/>
0.615444444 &amp; 0.716555556-\lambda \\<br/>
\end{array} \right | = (0.616555556-\lambda)(0.716555556-\lambda)-0.615444444^2 \\<br/>
&amp;= \lambda^2 - 1.333111112\lambda + 0.06302445 = 0 \\<br/>
\end{align*}<br/>
\]</p>

<p>由一元二次方程的求解易得：<br/>
\[<br/>
\lambda = \left ( \begin{array}{cc}<br/>
1.28402770 \\<br/>
0.04908340 \\<br/>
\end{array}\right )<br/>
\]</p>

<p>将特征值排序后，选择k个最大的特征值，因为这里只有2个特征值，假设k=1，则取最大特征值\(\lambda\)=1.28402770，然后计算对应的特征向量：<br/>
\[<br/>
(A - \lambda I )\overrightarrow{\nu} = \left ( \begin{array}{cc}<br/>
-0.667472144 &amp; 0.615444444 \\<br/>
0.615444444 &amp; -0.567472144 \\<br/>
\end{array} \right ) \left(\begin{array} \\<br/>
x_1\\<br/>
x_2\\<br/>
\end{array} \right ) \\<br/>
\Rightarrow \left \{ \begin{array}\\<br/>
-0.667472144 x_1 + 0.615444444 x_2 = 0\\<br/>
0.615444444 x_1 - 0.567472144 x_2 = 0<br/>
\end{array} \right .<br/>
\]</p>

<p>很容易算出其中一个解:<br/>
\[<br/>
\overrightarrow{\nu} = \left \{ \begin{array} \\0.67787339 \\0.73517867 \\\end{array} \right.<br/>
\]</p>

<p>再将样本数据乘上特征向量，得到投影后的在一维空间内新数据：<br/>
\[<br/>
data^1 = \left ( \begin{array}{cc}<br/>
3.45911228 \\<br/>
0.85356176\\<br/>
3.6233396 \\<br/>
2.90535252 \\<br/>
4.30694352 \\<br/>
3.54409121 \\<br/>
2.53203265 \\<br/>
1.48656993 \\<br/>
2.19309596 \\<br/>
1.40732153 \\<br/>
\end{array} \right )<br/>
\]</p>

<p>如果说我们的目的是将原数据从二维空间降维到一维空间，那么现在已经完成了。这里也完成了对数据的压缩，现在我们可以通过\(data^1\)和\(\overrightarrow{\nu}\)来表示原始数据，可以用\(data^1\)乘上\(\overrightarrow{\nu}^T\)来还原原始数据：<br/>
\[<br/>
data^{new} = data^1 \overrightarrow{\nu}^T = \left ( \begin{array}{cc}<br/>
2.34484017 &amp;  2.54306557\\<br/>
0.57860681 &amp;  0.6275204 \\<br/>
2.4561655 &amp;  2.66380199\\<br/>
1.96946116 &amp;  2.1359532 \\<br/>
2.9195624 &amp;  3.16637301\\<br/>
2.40244512 &amp;  2.60554026\\<br/>
1.71639756&amp;   1.8614964 \\<br/>
1.0077062 &amp;   1.0928945 \\<br/>
1.48664139&amp;  1.61231737 \\<br/>
0.95398582&amp;  1.03463277 \\<br/>
\end{array} \right )<br/>
\]</p>

<p>和原始数据对比发现，压缩后的数据保留了大多数信息。</p>

<h4 id="toc_6">矩阵的迹</h4>

<p>在继续下面的PCA的最近重构解释小节之前，需要一些矩阵的迹的了解。在线性代数中，一个n*n的方阵A，主对角线上的各元素之和为矩阵的迹或者迹数，一般即为tr(A)。</p>

<p>矩阵\(A=(a_1,a_2,...,a_i)\)的F范数与矩阵的迹的关系为\(||A||_F^2 = tr(AA^T)\)：<br/>
\[<br/>
||A||_F^2 = \sum_{i=1}^N \sum_{j=1}^N a_{ij}^2 \\<br/>
(AA^T)_{ij} = A_i^TA_j = \sum{k=1}^N a_{ik}a_{jk} \\<br/>
tr(AA^T) = \sum_{i=1}^N (AA^T)_{ii} = \sum_{i=1}^N \sum_{k=1}^N a_{ik}^2 = ||A||_F^2<br/>
\]</p>

<p>矩阵的迹满足几个性质：</p>

<p>(1) \(tr(A+B) = tr(A)+tr(B)\)</p>

<p>证明：<br/>
\[<br/>
\because\quad(A+B)_{ij} = A_{ij}+B_{ij} \\<br/>
\therefore\quad tr(A+B) = \sum_i^N (A+B)_{ii} = \sum_{i=1}^N (A_{ii}+B_{ii}) = \sum_{i=1}^N A_{ii} + \sum_{j=1}^N B_{jj} = tr(A) + tr(B)<br/>
\]</p>

<p>(2) \(tr(AB) = tr(BA)\)</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\because \quad &amp;(AB)_{ij} = \sum_{k=1}^N a_{i,k}b_{k,j} \\<br/>
&amp;(BA)_{ij} = \sum_{k=1}^N b_{i,k} a_{k,j} \\<br/>
\therefore \quad &amp; tr(AB) = \sum_{i=1} (AB)_{ii} = \sum_{i=1}^N \sum_{k=1}^N a_{i,k} b_{k,i} =    tr(BA)<br/>
\end{align*}<br/>
\]</p>

<p>(3) 由(2)知：\(tr(ABC)=tr(CAB) = tr(CBA)\)<br/>
(4) 由转置的性质可知：\(tr(A) = tr(A^T)\)<br/>
(5) \(\nabla_{A} tr(AB) = B^T \)<br/>
(6) \(\nabla_{A} tr(ABA^TC) = CAB+C^T+AB^T \)<br/>
使用链式求导证明：<br/>
\[<br/>
\nabla_A tr(ABA^TC) = (A^TC)^T\nabla_A tr(AB) + AB \nabla_A tr(A^TC) = C^TAB^T + C^TAB<br/>
\]</p>

<h4 id="toc_7">PCA的最近重构解释</h4>

<p>假设数据集\(D=(x_1,x_2,...,x_m)\)，样本大小为m，原始数据为x_i为\(n\)维数据，再假定投影变换后得到的新坐标系为\((w_1,w_2,...,w_n)\)，正交向量有\(||w_i||=1,||w_iw_j||=0:j\neq i\)，若丢弃了部分新坐标系的坐标，即维度降低到\(k\)维（\(k&lt;m\)），那么\(x_i\)在低维坐标系中\(z_i=(z_{i1},z_{i2},...,z_{ik})\)，其中\(z_{ij}=w_j^Tx_i\)是\(x_i\)在低维坐标系第\(j\)维的坐标，若基于\(z_i\)来重构\(x_i\)，则\(\hat{x_i} = \sum_{j=1}^k z_{ij}w_j\)：</p>

<p>我们希望在映射到新空间后保存最大信息，定义损失函数为：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^m ||\hat {x_i}-x_i||_F^2 &amp;= \sum_{i=1}^m ||\sum_{j=1}^k z_{ij}w_j - x_i||_F^2 \\<br/>
&amp;= \sum_{i=1}^m(\sum_{j=1}^k\sum_{l=1}^k z_{ij}w_jz_{il}w_l - 2\sum_{j=1}^k z_{ij}w_j x_i + x_i^2) \\<br/>
\end{align*}<br/>
\]</p>

<p>由\(w_i^2 = 1\)和\(w_iw_j=0\)可知：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^m ||\hat {x_i}-x_i||_F^2 &amp;= \sum_{i=1}^m z^Tz - 2\sum_{i=1}^m z_i^TW^Tx_i + const<br/>
\end{align*}<br/>
\]</p>

<p>根据\(tr(AB)=tr(BA)\)以及\(z = W^Tx_i\)（关于矩阵的迹的性质不了解的可以，看文章最后），得：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^m ||\hat {x_i}-x_i||_F^2 &amp;= -tr(W^T(\sum_{i=1}^m x_ix_i^T) W) + const \\<br/>
&amp;= -tr(W^TXX^TW) + const<br/>
\end{align*}<br/>
\]</p>

<p>所以原始问题方程组为求解方程组的极大值：<br/>
\[<br/>
\begin{align*}<br/>
min_{W}\quad&amp; -tr(W^TXX^TW) + const\\<br/>
s.t. \quad&amp;WW^T = I \\<br/>
\end{align*}<br/>
\]</p>

<p>利用拉格朗日乘子法，引入拉格朗日乘子\(\alpha\)：<br/>
\[<br/>
L(W,\alpha) = -tr(W^TXX^TW) + const + \alpha(I-WW^T)<br/>
\]</p>

<p>那现在原始问题便变成了求解拉格朗日函数极大极小问题，先求\(L(W,\alpha)\)的最小值，让\(L(W,\alpha)\)对\(W\)求导得：<br/>
\[<br/>
\nabla_W L(W,\alpha) = X^TXW - \alpha W = 0 \\<br/>
\Rightarrow X^TXW = \alpha W<br/>
\]</p>

<p>所以求得最优解时\(W\)为协方差矩阵\(X^TX\)的特征向量，特征值越大的特征向量所包含的信息越丰富。</p>

<h4 id="toc_8">高维空间的PCA运算</h4>

<p>在现实生活中，由于样本的高维特征，比如在图像处理中，图像的每一个像素都是一个维度。如果我们采用上面的PCA方法运算，先计算协方差，那么我们将会得到一个n*n的协方差矩阵，这个矩阵不论是计算还是存储都比较复杂，因此不可取。</p>

<p>在高维特征中，假设有100个样本组成数据集\(X=(x_1,x_2,...,x_{100})\)，每一个样本的维度为10000维，那么协方差矩阵\(C=XX^T\)将是10000维的方阵，考虑一个替代的矩阵\(T=X^T\)代替协方差矩阵，，假设\(\lambda\)和\(P\)分别为协方差矩阵的特征值和特征向量，所以有：<br/>
\[<br/>
XX^TP = \lambda P \Leftrightarrow CP = \lambda P<br/>
\]</p>

<p>若\(\lambda^{new}\)和\(P^{new}\)为替代矩阵的特征值和特征向量：<br/>
\[<br/>
X^TXP^{new} = \lambda^{new} P^{new}<br/>
\]</p>

<p>两边同时左乘\(X\)，那么：<br/>
\[<br/>
XX^TXP^{new} = X\lambda^{new} P^{new} \Rightarrow XX^T(XP^{new}) = \lambda^{new}(XP^{new}) \\<br/>
\Rightarrow C(XP^{new}) = \lambda (XP^{new})<br/>
\]</p>

<p>通过上式可以知道协方差矩阵的特征值等于替代矩阵的特征值，其特征向量等于替代矩阵的特征向量左乘上\(X\)，所以我们可以通过求解替代矩阵的特征值和特征向量来完成PCA操作。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15029730205260.html">不等式约束问题</a></h1>
			<p class="meta"><time datetime="2017-08-17T20:30:20+08:00" 
			pubdate data-updated="true">2017/8/17</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>拉格朗日乘子法求解不等式约束问题：</p>

<h4 id="toc_0">原始问题</h4>

<p>假设函数：<br/>
\[<br/>
\begin{align*}<br/>
\min\quad &amp;f(x) \nonumber\\<br/>
s.t.\quad &amp;h_j(x) = 0,\quad j=1,2,...,p\\<br/>
s.t.\quad &amp;c_i(x) \le 0,\quad i=1,2,...,q<br/>
\end{align*}<br/>
\]</p>

<p>为了解决问题，定义拉格朗日函数：<br/>
\[<br/>
L(x,\alpha,\beta)=f(x)+\sum_{i=1} \alpha_i c_i(x）+ \sum_{j=1} \beta_j h_j(x)<br/>
\]</p>

<p>这里\(\alpha_i\)和\(\beta_j\)是拉格朗日乘子，其中\(\alpha_i\ge0\)、\(\beta_j \ne 0\)<br/>
\[<br/>
\begin{align}<br/>
&amp;\because h_j(x)=0 \Rightarrow \sum_{j=1} \beta_j h_j(x) = 0 \nonumber\\<br/>
&amp;\therefore L(x,\alpha,\beta) = f(x)+\sum_{i=1} \alpha_i c_i(x) \nonumber\\<br/>
&amp;\because \left.<br/>
             \begin{array}{lcl}<br/>
             \alpha_i \ge 0 \nonumber\\<br/>
             c_i(x) \le 0 <br/>
             \end{array}  <br/>
        \right\} \Rightarrow \sum_{i=1} \alpha_i c_i(x) \le 0 \nonumber\\<br/>
\label{max_L}<br/>
&amp;\therefore \max_{\alpha_i,\beta_j:\alpha_i \ge 0} L(x,\alpha,\beta) = f(x) \\<br/>
\end{align}<br/>
\]</p>

<p>易知，当\(L(x,\alpha,\beta)\)函数取最大值的时候，\(\alpha_i=0\,\)或\( c_i(x) = 0\,\)，也就是\(\alpha_i c_i(x) = 0\,\)。</p>

<p>考虑关于\(x\)的函数<br/>
\[<br/>
\begin{equation}<br/>
\label{theta_p}<br/>
    \theta_P(x)=\max_{\alpha,\beta:\alpha\ge0} L(x,\alpha\beta)<br/>
\end{equation}<br/>
\]</p>

<p>那么现在求解原始问题\(\,\min f(x)\)，等价于求解\(\,\min_x\max_{\alpha,\beta:\alpha_i \ge 0} L(x,\alpha,\beta)\,\)，即\(\min_x \theta_P(x)\)，这样原始问题就变成了拉格朗日函数的极小极大问题，公式如下：<br/>
\[<br/>
\label{min_f_x}<br/>
\begin{equation}<br/>
\min_x f(x) = \min_x\max_{\alpha,\beta:\alpha_i \ge 0} L(x,\alpha,\beta) = \min_x \theta_P(x)<br/>
\end{equation}<br/>
\]</p>

<p>这个方程先是求解含有\(\alpha\)和\(\beta\)的极大值，它直接求导后并不容易得出结果，所以这里我们定义一个它的对偶函数（交换极小极大位置）来方便计算。</p>

<h4 id="toc_1">对偶问题</h4>

<p>定义<br/>
\[<br/>
\begin{equation}<br/>
\label{theta_d}<br/>
\theta_D(\alpha,\beta) = \min_x L(x,\alpha,\beta) \\<br/>
\end{equation}<br/>
\]</p>

<p>那么原始问题的对偶问题就是极大化\(\theta_D(\alpha,\beta)\)，这被称为拉格朗日函数的极大极小化问题。</p>

<p>展开拉格朗日极大极小问题：<br/>
\[<br/>
\begin{align}<br/>
\max_{\alpha,\beta} \theta_D(\alpha,\beta) &amp;= \max_{\alpha,\beta} \min_x L(x,\alpha,\beta) \nonumber\\<br/>
&amp;= \max_{\alpha,\beta}[\min_x(f(x)+\sum_{i=1}^N \alpha_i c_i(x）+ \sum_{j=1}^N \beta_j h_j(x))] \nonumber\\<br/>
&amp;= \max_{\alpha,\beta}(\min_x f(x)+\min_x\sum_{i=1}^N \alpha_i c_i(x)) \nonumber\\<br/>
&amp;= \max_{\alpha,\beta}\min_x f(x)+\max_{\alpha,\beta}\min_x \sum_{i=1}^N \alpha_i c_i(x) \nonumber\\<br/>
\label{max_theta_d_m}<br/>
&amp;= \min_x f(x)+\max_{\alpha,\beta}\min_x \sum_{i=1}^N \alpha_i c_i(x) \\<br/>
\end{align} <br/>
\]</p>

<p>在上面推导公式中，由于\(f(x)\)与\(\alpha\)和\(\beta\)无关，所有\(\max_{\alpha,\beta}\min_x f(x)=\min_x f(x)\)</p>

<h3 id="toc_2">对偶问题与原始问题的关系</h3>

<p>设原始问题的最优值为\(p^*\)，对偶问题的最优解为\(d^*\)，则有：<br/>
\[<br/>
\begin{align*}<br/>
p^* &amp;= \min_x f(x) = \min_x \max_{\alpha,\beta:\alpha_i \ge 0}L(x,\alpha,\beta) = \min_x\theta_P(x) \\<br/>
d^* &amp;= \max_{\alpha,\beta} \theta_D(\alpha,\beta)<br/>
\end{align*}<br/>
\]结合公式（\ref{theta_p}）和（\ref{theta_d}）可知：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because \min_x L(x,\alpha,\beta) \le L(x,\alpha,\beta) \le \max_{\alpha,\beta}L(x,\alpha,\beta) \\<br/>
&amp;\Rightarrow \theta_D(\alpha,\beta) \le \theta_P(x) \\<br/>
&amp;\Rightarrow \max_{\alpha,\beta}\theta_D(\alpha,\beta) \le \min_x \theta_P(x)<br/>
\end{align*}<br/>
\]</p>

<p>即<br/>
\[<br/>
\begin{equation}<br/>
\label{d_p}<br/>
d^* = \max_{\alpha,\beta}\theta_D(\alpha,\beta) \le \min_x \theta_P(x) = p^*<br/>
\end{equation}<br/>
\]</p>

<p>可以得知在某些条件下，原始问题和对偶问题的最优值会相等，即\(d^* = p^*\)，而这里某些条件就是下面讨论的KKT条件。</p>

<h4 id="toc_3">KKT条件</h4>

<p>结合公式（\ref{max_theta_d_m}）继续推导公式（\ref{d_p}）：<br/>
\[<br/>
\begin{align*}<br/>
d^* &amp;= \max_{\alpha,\beta}\theta_D(\alpha,\beta) \\<br/>
&amp;= \min_x f(x)+\max_{\alpha,\beta}\min_x \sum_{i=1}^N \alpha_i c_i(x) \\<br/>
&amp;= p^* + \max_{\alpha,\beta}\min_x \sum_{i=1}^N \alpha_i c_i(x)<br/>
\end{align*}<br/>
\]</p>

<p>在上面推导过程中，假设\(x^*\)是原始问题的可行解，并且\(d^* = p^*\)，所以有<br/>
\[<br/>
\begin{equation}<br/>
\alpha_i c_i(x^*) = 0 <br/>
\end{equation}<br/>
\]</p>

<p>因此：<br/>
\[<br/>
\begin{align*}<br/>
d^* &amp;= \max_{\alpha,\beta}\theta_D(\alpha,\beta) \\<br/>
&amp;= \min_x f(x)+\max_{\alpha,\beta}\min_x \sum_{i=1}^N \alpha_i c_i(x) \\<br/>
&amp;= \min_x f(x) \\<br/>
\end{align*}<br/>
\]</p>

<p>结合公式（\ref{theta_d}）和上面结果，可知：<br/>
\[<br/>
\begin{equation}<br/>
\label{max_d_m}<br/>
\max_{\alpha,\beta}\theta_D(x) = \max_{\alpha,\beta}\min_x L(x,\alpha,\beta) = \min_x f(x) = f(x^*)<br/>
\end{equation}<br/>
\]</p>

<p>将\(x^*\)代入公式（\ref{max_L}）得：<br/>
\[<br/>
\begin{equation}<br/>
\label{f_m_L}<br/>
f(x^*) = \max_{\alpha,\beta}L(x^*,\alpha,\beta)<br/>
\end{equation}<br/>
\]</p>

<p>由上面公式公式（\ref{max_d_m}）和（\ref{f_m_L}）可知：<br/>
\[<br/>
\min_x L(x,\alpha,\beta) = L(x^*,\alpha,\beta)<br/>
\]</p>

<p>所以\(x^*\)是\(L(x,\alpha,\beta)\)的极值，可以得出结论：</p>

<p>\[<br/>
\begin{equation}<br/>
\nabla_xL(x^*,\alpha,\beta) = 0<br/>
\end{equation}<br/>
\]</p>

<p>所以KKT条件为：<br/>
\[<br/>
\begin{equation*}<br/>
\nabla_xL(x^*,\alpha,\beta) = 0 \\<br/>
h_j(x^*) = 0:j=1;2;...;N \\<br/>
c_i(x^*) \le 0:i=1;2;...;N \\<br/>
\alpha_ic_i(x^*) = 0:i=1;2;...;N \\<br/>
\alpha_i \ge 0:i=1;2;...;N \\<br/>
\beta_j \ne 0:j=1;2;...;N \\<br/>
\end{equation*}<br/>
\]</p>

<p>上面KKT条件中，第一个称为极值条件，第二个第三个是拉格朗日原约束条件，第四个是互补松弛条件，第五个第六个是拉格朗日系数约束。</p>

<p>推导说明，在满足KKT条件的情况下，对原始问题的求解可以转换为对偶问题\(\max_{\alpha,\beta}\min_x L(x,\alpha,\beta)\)的求解。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15025588355749.html">支持向量机 SVM</a></h1>
			<p class="meta"><time datetime="2017-08-13T01:27:15+08:00" 
			pubdate data-updated="true">2017/8/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>支持向量机（support vector machine，SVM）是一个有监督的机器学习算法，它的基本模型是定义在特征空间的间隔最大的线性分类器。利用核技巧将输入数据映射到高维空间，来实现非线性分类器。</p>

<h2 id="toc_0">支持向量机基础</h2>

<p>为了方便讲明白SVM的工作原理，下面主要结合图片和公式说明，如图1，假设在二维空间里有两类线性可分的数据，直观上看，很容易在中间画出一条线将两类数据分开。</p>

<div align="center">
    <img src="media/15025588355749/15263132529256.jpg" width="350"></img>
    <center>图1：二维空间里数据</center>
    <br/>
</div>

<p>定义超平面（即分割线）可以通过如下线性方程组来描述：<br/>
\[<br/>
\begin{equation}<br/>
\boldsymbol w^T \boldsymbol x + b = 0<br/>
\end{equation}<br/>
\]</p>

<p>其中\(\boldsymbol w=(w_1;w_2;w_3;...;w_d)\,\)为法向量，\(b\,\)是超平面的截距，显然这个划分超平面可以被这两个参数\(\boldsymbol w\,\)和\(\,b\,\)确定，后面此超平面将简称为超平面（\(\boldsymbol w\),\(b\)）。</p>

<p>假设超平面能很好的将训练样本分类，如果定义图1中红色点为正类，即\(y_i=1\)，此时希望\(\boldsymbol w^T \boldsymbol x &gt; 0\)，另一侧蓝色点为负类，即\(y_i=-1\)，此时希望\(\boldsymbol w^T \boldsymbol x &lt; 0\)，易知分类决策函数可以定义为：</p>

<p>\[<br/>
\begin{equation}<br/>
y = sign(\boldsymbol w_T \boldsymbol x + b)<br/>
\end{equation}<br/>
\]</p>

<p>如图2所示，两个超平面都能满足条件，那到底哪个超平面才是最优的超平面呢？也就是\(\boldsymbol w \)和\(\,b\,\)应该如何确定其最优值。</p>

<div align="center">
    <img width="350" src="media/15025588355749/15263148208656.jpg" />
    <p>图2：超平面</p>
</div>

<h4 id="toc_1">函数间隔（Function Margin）</h4>

<p>对于给定的超平面（\(\boldsymbol w,b\)），定义超平面关于点（\(x_i,y_i\)）的函数间隔为<br/>
\[<br/>
\begin{equation}<br/>
\label{gammahat}<br/>
    \hat\gamma_i=y_i(\boldsymbol w^T \boldsymbol x_i+b)<br/>
\end{equation}<br/>
\]</p>

<p>定义超平面关于整个数据集\(\,T\,\)的函数间隔为数据集内关于所有点函数间隔的最小值：<br/>
\[<br/>
    \hat\gamma = \min \hat\gamma_i\,,i=1;2;...;N<br/>
\]</p>

<p>函数间隔可以表示分类预测的正确性和确信度，但是选择分离超平面仅靠函数间隔是不够的。超平面的选择是希望间隔最大化，如果使用函数间隔表示，那么成比例的增大\(\boldsymbol w\)和\(b\)，比如将它们改为\(2\boldsymbol w\)和\(2b\)，那么就能使函数间隔增大2倍，可是实际我们知道这对超平面的选择没有任何帮助。因此我们需要对函数间隔归一化，这也就变成了几何间隔。</p>

<p>\[<br/>
\gamma_i = \frac{y_i(\boldsymbol w^T \boldsymbol x_i + b)}{||\boldsymbol w||}<br/>
\]</p>

<h4 id="toc_2">几何间隔（Geometric Margin)</h4>

<p>如图3，定义点\(A\)与超平面的距离为超平面关于点\(A\)的几何间隔，由距离公式可知<br/>
\[<br/>
    \gamma_i = \frac{|\boldsymbol w^T \boldsymbol x_i + b|}{||\boldsymbol w||}<br/>
\]</p>

<blockquote>
<p>距离公式：点（\(x_0,y_0\)）到点\(Ax+By+C=0\)的距离为：<br/>
\[d = \frac{|Ax_0+By_0+C|}{\sqrt{A^2+B^2}}\]</p>
</blockquote>

<p>当点\(y_i=1\)时，\(\boldsymbol w^T \boldsymbol x_i + b&gt;0\)，有：<br/>
\[|\boldsymbol w^T \boldsymbol x_i + b| = y_i(\boldsymbol w^T \boldsymbol x_i + b) \]<br/>
当点\(y_i=-1\)时，\(\boldsymbol w^T \boldsymbol x_i + b&lt;0\)，有：<br/>
\[|\boldsymbol w^T \boldsymbol x_i + b| = y_i(\boldsymbol w^T \boldsymbol x_i + b) \]</p>

<p>所以超平面关于点\(A\)（\(x_0,y_0\)）的几何间隔可以表示为：<br/>
\[<br/>
\begin{equation}<br/>
\label{gamma}<br/>
\gamma_i = y_i(\frac{\boldsymbol w^T x_i + b}{||w||})=y_i(\frac{\boldsymbol w^T}{|\boldsymbol w|}x_i+\frac{b}{||\boldsymbol w||})<br/>
\end{equation}<br/>
\]</p>

<p>定义超平面关于整个数据集\(\,T\,\)的几何间隔为数据集内关于所有点的几何间隔的最小值：<br/>
\[<br/>
    \gamma = \min \gamma_i\,,i=1;2;...;N<br/>
\]</p>

<p>从公式\((\ref{gammahat})和(\ref{gamma})\)可知函数间隔和几何间隔的关系为：<br/>
\[<br/>
    \gamma_i = \frac{\hat\gamma_i}{||\boldsymbol w||}\\<br/>
    \gamma = \frac{\hat\gamma}{||\boldsymbol w||}<br/>
\]</p>

<p>如果\(||w||=1\)时，函数间隔和几何间隔相等，当\(\boldsymbol w\)和\(b\)成比例的增大时，函数间隔相应增大，而几何间隔不变。</p>

<p>现在可以知道，最大间隔分离超平面的问题可以表示为如下的方程组：</p>

<p>\[<br/>
\begin{align}<br/>
\max_{\boldsymbol w,b}\quad&amp;\gamma \\<br/>
s.t\quad&amp;y_i(\frac{\boldsymbol w^T}{|\boldsymbol w|}x_i+\frac{b}{||\boldsymbol w||}) \ge \gamma\,,i=1;2;...;N<br/>
\end{align}<br/>
\]</p>

<p>考虑到函数间隔和几何间隔的关系式，可将上面方程组改写为：</p>

<p>\[<br/>
\begin{align*}<br/>
\max_{\boldsymbol x,b}\quad&amp;\frac{\hat\gamma}{||\boldsymbol w||}\\<br/>
s.t.\quad&amp;y_i(\boldsymbol w^T x_i+b) \ge \hat\gamma<br/>
\end{align*}<br/>
\]</p>

<p>上面已经讨论过函数间隔的取值并不影响几何间隔的变化（将\(\boldsymbol w\)和\(b\)成比例的增大或缩小\(\lambda\)倍，函数间隔就能相应变化\(\lambda\)倍，而此时几何间隔不变）。因此对于求解上面方程，函数间隔\(\hat\gamma\)的取值无关紧要，为方便计算，取\(\hat\gamma=1\)，这样方程组变成求\(\frac 1{||w||}\)的最大值。</p>

<p>可以得到最优化方程组为：<br/>
\[<br/>
\begin{align}<br/>
\max_{\boldsymbol x,b}\quad&amp;\frac{1}{||\boldsymbol w||}\\<br/>
\label{8}<br/>
s.t.\quad&amp;y_i(\boldsymbol w^T x_i+b) -1 \ge 0<br/>
\end{align}<br/>
\]</p>

<div align="center">
    <img width="440" src="media/15025588355749/15263213657308.jpg" />
    <p>图3：支持向量与间隔</p>
</div>

<h4 id="toc_3">支持向量（Support Vector）</h4>

<p>如图3所示，如果定义超平面为（\(\boldsymbol w,b\)），则有两条过离超平面最近的两个点的平行线，这两条线到超平面的距离都为\(\gamma\)，其中这两个距离超平面最近的点就是支持向量。支持向量是使公式\((\ref{8})\)等号成立的点，也就是：<br/>
\[<br/>
    y_i(\boldsymbol w^T \boldsymbol x + b)-1 = 0<br/>
\]</p>

<p>这里可以注意到过支持向量的两条线形成一个长带，分离超平面位于中间，长带的宽度被称为间隔，定义间隔为\(H\)，则：<br/>
\[H=2*\gamma=2\frac{\hat\gamma}{||w||}=\frac 2{||w||}\]</p>

<p>在决定分离超平面时只有支持向量起作用，而其他点并不起作用，因此这种分离方法叫做支持向量机。</p>

<h2 id="toc_4">问题求解</h2>

<p>在前面已经提到，找到超平面使间隔最大化相当于求解最优化方程组：</p>

<p>\[<br/>
\begin{align*}<br/>
\max_{\boldsymbol w,b}\quad&amp;\frac{1}{||\boldsymbol w||}\\<br/>
s.t.\quad&amp;y_i(\boldsymbol w^T x_i+b) -1 \ge 0<br/>
\end{align*}<br/>
\]</p>

<p>由于求\(\frac 1 {||w||}\)的最大值其实等价于求解\(\frac1 2||w||^2\)的最小值，所以最优化方程组也就从求解最大值变成求解最小值，即：<br/>
\[<br/>
\begin{align}<br/>
\min_{\boldsymbol w,b}\quad&amp;\frac{1}{2}\boldsymbol ||w||^2 \label{m_w_b} \\<br/>
s.t. \quad &amp; y_i(\boldsymbol w^T \boldsymbol x_i -b) -1 \ge 0 \label{s_t_q_y}\\<br/>
\end{align}<br/>
\]</p>

<p>下面使用拉格朗日乘子法求解这个不等式约束（如果不了解拉格朗日乘子法的，可以看文章后面），定义拉格朗日函数为：<br/>
\[<br/>
\begin{equation}<br/>
\label{svm_L}<br/>
L(\boldsymbol w,b,\alpha) = \frac{1}{2} ||\boldsymbol w||^2 - \sum_{i=1}^N\alpha_i[y_i(\boldsymbol w^T \boldsymbol x+b)-1] \quad s.t. \alpha_i \ge 0<br/>
\end{equation}<br/>
\]</p>

<p>这里将对原始问题的求解变成对拉格朗日对偶问题\(\max_{\alpha} \min_{\boldsymbol w,b}L(\boldsymbol w,b,\alpha)\)求解，这个求解过程可以分成两部分：<br/>
(1)求\(\min_{\boldsymbol w,b}L(\boldsymbol w,b,\alpha)\)</p>

<p>可以直接对\(L(\boldsymbol w,b,\alpha)\)对\(\boldsymbol w\)和\(b\)求导：<br/>
\[<br/>
\begin{align*}<br/>
    \nabla_{\boldsymbol w}L(\boldsymbol w,b,\alpha) &amp;= \boldsymbol w - \sum_{i=1}^N \alpha_i y_i x_i = 0 \\<br/>
    \nabla_{\boldsymbol b}L(\boldsymbol w,b,\alpha) &amp;= -\sum_{i=1}^N \alpha_i y_i = 0<br/>
\end{align*}<br/>
\]</p>

<p>得：<br/>
\[<br/>
\begin{align}<br/>
    \boldsymbol w = \sum_{i=1}^N \alpha_i y_i x_i \label{x_z_0}\\<br/>
    \sum_{i=1}^N \alpha_i y_i = 0 \label{x_z_1}\\<br/>
\end{align}<br/>
\]</p>

<p>将上结果代入公式（\ref{svm_L}）中可得：<br/>
\[<br/>
\begin{align}<br/>
    \min_{w,b}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 - \sum_{i=1}^N \alpha_i[y_i(\sum_{j=1}^N \alpha_j y_j x_j x_i + b) -1] \nonumber\\<br/>
    &amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 - \sum_{i=1}^N \alpha_iy_i(\sum_{j=1}^N \alpha_j y_j x_j x_i + b) +\sum_{i=1}^N \alpha_i \nonumber\\<br/>
    &amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i y_i b +\sum_{i=1}^N \alpha_i \nonumber\\<br/>
    &amp;= -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
\end{align}<br/>
\]</p>

<p>(2)求\(\min_{\boldsymbol w,b}L(\boldsymbol w,b,\alpha)\)对\(\alpha\)的最大值，即：<br/>
\[<br/>
\begin{align}<br/>
&amp;\max_{\alpha} -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
&amp;s.t.\quad\sum_{i=1}^N \alpha_i y_i = 0 \nonumber \\<br/>
&amp;\qquad\quad \alpha_i \ge 0 :i=1;2;...;N \nonumber \\<br/>
\end{align}<br/>
\]</p>

<p>将这个公式变化一下，从求极大值等价转换为求极小值，就可以得到等价最优化方法：<br/>
\[<br/>
\begin{align}<br/>
&amp;\min_{\alpha} \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \alpha_i \label{d_o_0}\\<br/>
&amp;s.t.\quad\sum_{i=1}^N \alpha_i y_i = 0 \label{d_o_1}\\<br/>
&amp;\qquad\quad \alpha_i \ge 0 :i=1;2;...;N \label{d_o_2}\\<br/>
\end{align}<br/>
\]</p>

<p>现在求解原始问题（\ref{m_w_b}）和（\ref{s_t_q_y}）可以转为求解对偶问题（\ref{d_o_0}）~（\ref{d_o_2}），对于线性可分数据集，假设对偶问题（\ref{d_o_0}）~（\ref{d_o_2}）对\(\alpha\)的解为\(\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_N^*)\)。<br/>
根据公式（\ref{x_z_0}）可以求出：<br/>
\[<br/>
\begin{equation}<br/>
\boldsymbol w^* = \sum_{i=1}^N \alpha_i^* y_i x_i \label{d_2_y_0}\\<br/>
\end{equation}<br/>
\]</p>

<p>其中在KKT条件（\ref{d_o_2}）上要求至少有一个\(\alpha_j^* \gt 0\)，因为如果\(\alpha^* = 0\)，那么得出\(w^*=0\)，原始问题中分割超平面将与输入数据无关，总是将所有数据分到一侧，不符合要求。根据KKT条件的互补松弛条件可知：<br/>
\[<br/>
\begin{equation}<br/>
\alpha_i^*(y_i(w^*.x_i+b^*)-1) = 0:i=1;2;...;N<br/>
\end{equation}<br/>
\]</p>

<p>结合至少存在一个\(\alpha^*_j &gt; 0\)，易知：<br/>
\[<br/>
\begin{equation}<br/>
y_j(w^*.x_j+b^*)-1 = 0<br/>
\end{equation}<br/>
\]</p>

<p>两边同时乘以\(y_j\)，注意奥\(y_j^2=1\)，所以可得：<br/>
\[<br/>
\begin{equation}<br/>
b^* = y_j-w^*.x_j = y_j - \sum_{i=1}^N \alpha_i^* y_i (x_i.x_j) \label{d_2_y_1}\\<br/>
\end{equation}<br/>
\]</p>

<p>至此，可以知道在求得对偶问题的解\(\alpha^*\)后，可以通过（\ref{d_2_y_0}）和（\ref{d_2_y_1}）求得原始问题的解\(w^*\)和\(b^*\)，在这个计算中由于对于每一个符合\(\alpha_j &gt; 0\)条件的\(\alpha_j\)都能求出一个\(b^*\)，所以实际计算过程时可以取所有满足条件的样本点上的平均值。</p>

<h2 id="toc_5">软间隔最大化</h2>

<p>在实际问题中，并不是所有问题都是绝对的线性可分的，比如在一些存在噪音的情况下，此时我们需要分割超平面具有一定的容错性，我们给函数间隔加上一定的松弛变量，这样约束条件变为：<br/>
\[<br/>
y_i(\boldsymbol x_i+b)\ge 1-\zeta_i<br/>
\]</p>

<p>对每一个\(\zeta_i\)都要支付一个代价\(\zeta_i\)，所以目标函数变为：<br/>
\[<br/>
\frac{1}{2}||\boldsymbol w||^2+\text{C}\sum_{i=1}^N \zeta_i<br/>
\]</p>

<p>这里的\(\text{C}\gt 0\)被称为惩罚系数，当\(\text{C}\)越大对误分类的惩罚越大，反之越小。</p>

<p>那么对于软间隔最大化的线性支持向量机问题最优化方程组如下：<br/>
\[<br/>
\begin{align}<br/>
\min_{\boldsymbol w,b,\zeta} \quad &amp; \frac{1}{2}||\boldsymbol w||^2+\text{C}\sum_{i=1}^N \zeta_i \label{o_with_z_0}\\<br/>
s.t. \quad&amp; y_i(\boldsymbol w x_i + b) \ge 1 - \zeta_i:i=1;2;...;N \label{o_with_z_1}\\<br/>
\quad&amp;\zeta_i \gt 0:i = 1;2;...;N \label{o_with_z_2}\\<br/>
\end{align}<br/>
\]</p>

<h4 id="toc_6">原始问题与对偶问题</h4>

<p>直接求解原始问题比较困难，可以通过对偶问题间接求解，原始问题（\ref{o_with_z_0}）~（\ref{o_with_z_2}）的拉格朗日函数为：<br/>
\[<br/>
\begin{equation}<br/>
L(\boldsymbol w,b,\zeta,\alpha,\mu) = \frac{1}{2}||\boldsymbol w||^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N \alpha_i(y_i(\boldsymbol w x_i + b) -1 + \zeta_i) - \sum_{i=1}^N\mu_i \zeta_i<br/>
\end{equation}<br/>
\]</p>

<p>其中\(\alpha \ge 0,\mu \ge 0\).<br/>
对偶问题是求拉格朗日函数的极大极小值，先求\(L(\boldsymbol w,b,\zeta,\alpha,\mu)\)对\(\boldsymbol w\)，\(b\)和\(\zeta\)的极小值：<br/>
\[<br/>
\begin{align*}<br/>
\nabla_{\boldsymbol w}L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= \boldsymbol w - \sum_{i=1}^N \alpha_i y_i x_i = 0 \\<br/>
\nabla_{b}L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= -\sum_{i=1}^N \alpha_i y_i = 0 \\<br/>
\nabla_{\zeta}L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= C-\alpha_i-\mu_i = 0<br/>
\end{align*}<br/>
\]</p>

<p>得：<br/>
\[<br/>
\begin{align}<br/>
&amp;\boldsymbol w = \sum_{i=1}^N \alpha_i y_i x_i \label{o_with_z_r_0}\\<br/>
&amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{o_with_z_r_1}\\<br/>
&amp;\text{C} - \alpha_i - \mu_i = 0 \label{o_with_z_r_2}\\<br/>
\end{align}<br/>
\]</p>

<p>将结果（\ref{o_with_z_r_0}）~（\ref{o_with_z_r_2}）代入到拉格朗日函数中：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w,b,\zeta} L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= \frac{1}{2}||\boldsymbol w||^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N \alpha_i(y_i(\boldsymbol w x_i + b) -1 + \zeta_i) - \sum_{i=1}^N\mu_i \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N \alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b) -1 + \zeta_i) - \sum_{i=1}^N\mu_i \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i(1-\zeta_i) - \sum_{i=1}^N\mu_i \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i - \sum_{i=1}^N (\alpha_i + \mu_i) \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i - \text{C}\sum_{i=1}^N\zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i \\<br/>
&amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i \\<br/>
&amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \alpha_i y_i b + \sum_{i=1}^N \alpha_i \\<br/>
&amp;= -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
\end{align*}<br/>
\]</p>

<p>在对\(\min_{\boldsymbol w,b,\zeta}L(\boldsymbol w,b,\zeta,\alpha,\mu)\)求 \(\alpha\) 的极大值：<br/>
\[<br/>
\begin{align}<br/>
\max_{\alpha} \quad &amp;-\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
s.t. \quad &amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{s_t_with_r_1}\\<br/>
\quad\quad\quad &amp;\alpha_i \ge 0:i=1;2;...;N \label{s_t_with_r_2}\\<br/>
\quad\quad\quad &amp;\text{C} - \alpha_i - \mu_i = 0:i=1;2;...;N \label{s_t_with_r_3}\\<br/>
\quad\quad\quad &amp;\mu_i \ge 0:i=1;2;...;N \label{s_t_with_r_4}\\<br/>
\end{align}<br/>
\]</p>

<p>结合（\ref{s_t_with_r_3}）和（\ref{s_t_with_r_4}）可知：<br/>
\[<br/>
\mu_i = \text{C} - \alpha_i \ge 0 \Rightarrow \alpha_i \le \text{C}<br/>
\]</p>

<p>再结合（\ref{s_t_with_r_2}）可得：<br/>
\[<br/>
0 \le \alpha_i \le \text{C}<br/>
\]</p>

<p>所以软间隔原始问题的对偶问题为：<br/>
\[<br/>
\begin{align}<br/>
\max_{\alpha} \quad &amp;\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \alpha_i \label{d_t_with_r_0}\\<br/>
s.t. \quad &amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{d_t_with_r_1}\\<br/>
\quad\quad\quad &amp;0 \le \alpha_i \le C:i=1;2;...;N \label{d_t_with_r_2}\\<br/>
\end{align}<br/>
\]</p>

<h4 id="toc_7">软间隔问题求解</h4>

<p>已经将求解原始问题的最小值转变为求对偶问题 \ref{d_t_with_r_0} 的最大值，，设 \(\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_N^*)\) 是对偶问题的一个解， \(\boldsymbol w^*\)，\(b^*\) 是原始问题的解。由拉格朗日乘子法可知对偶问题等价于原始问题需要满足KKT条件，如下：<br/>
\[<br/>
\begin{eqnarray}<br/>
&amp;\nabla_{\boldsymbol w}L(\boldsymbol w^*,b^*,\zeta^*,\alpha^*,\mu^*) = \boldsymbol w^* - \sum_{i=1}^N \alpha_i^* y_i x_i = 0 \label{d_with_z_kkt_1}\\<br/>
&amp;\nabla_{b}L(\boldsymbol w^*,b^*,\zeta^*,\alpha^*,\mu^*) = -\sum_{i=1}^N \alpha^*_i y_i = 0 \nonumber\\<br/>
&amp;\nabla_{\zeta}L(\boldsymbol w^*,b^*,\zeta^*,\alpha^*,\mu^*) = C-\alpha^*_i-\mu^*_i = 0 \label{d_with_z_kkt_2}\\<br/>
&amp;\sum_{i=1}^N \alpha^*_i(y_i(w^*x_i+b^*) - 1 + \zeta_i^*) = 0 \label{d_with_z_kkt_3}\\<br/>
&amp;\sum_{i=1}^N \mu^*_i \zeta^*_i = 0 \label{d_with_z_kkt_4}\\<br/>
&amp;y_i(w^*x_i + b^*) - 1 + \zeta^*_i \ge 0 \label{d_with_z_kkt_5} \\<br/>
&amp;\zeta_i^* \ge 0 \nonumber \\<br/>
&amp;\alpha^*_i \ge 0 \nonumber \\<br/>
&amp;\mu^*_i \ge 0 \nonumber \\<br/>
\end{eqnarray}<br/>
\]</p>

<p>由公式（\ref{d_with_z_kkt_1}）易得：<br/>
\[<br/>
\begin{equation}<br/>
\boldsymbol w^* = \sum_{i=1}^N \alpha_i^* y_i x_i \label{d_with_z_r_b_a_1}\\<br/>
\end{equation}<br/>
\]</p>

<p>由\(0 \le \alpha_i \le \text{C}\)结合公式（\ref{d_with_z_kkt_2}）可知：<br/>
\[<br/>
\begin{equation}<br/>
\mu_i^* = C - \alpha_i^*<br/>
\end{equation}<br/>
\]</p>

<ol>
<li>当\(\alpha_i^*=0\)时，可知\(w^*=0\)此时样本点对分离超平面的选择没有任何作用，</li>
<li>当\(\alpha_i^*=C\)时，可知\(\mu_i^* = 0\)，结合公式（\ref{d_with_z_kkt_4}）知存在\(\zeta_i^* \gt 0\)，此时\(y_i y=1-\zeta_i^* \lt 0\)，会出现样本点被误分类。</li>
<li><p>当\(0 \lt\alpha_i^* \lt C\)时，可知\(\mu_i^* &gt; 0\)，结合公式（\ref{d_with_z_kkt_4}）知任意\(\zeta_i^* = 0\).<br/>
将\(0 \lt\alpha_i^* \lt C\)和\(\zeta_i^* = 0\)代入公式（\ref{d_with_z_kkt_3}）得：<br/>
\[<br/>
\begin{equation}<br/>
y_j(w^*+b^*)-1 = 0 \Rightarrow b^* = y_j - \sum_{i=1}^N \alpha_i^* y_i x_i x_j  \label{d_with_z_r_b_a_2}<br/>
\end{equation}<br/>
\]</p>

<p>所以当我们求出对偶问题的结果\(\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_i^*)\)时，可以通过公式（\ref{d_with_z_r_b_a_1}）和（\ref{d_with_z_r_b_a_2}）求出\(w^*\)和\(b^*\).在这个计算中由于对于每一个符合\(0 &lt; \alpha_j^* &lt; C\)条件的\(\alpha_j^*\)都能求出一个\(b^*\)，所以实际计算过程时可以取所有满足条件的样本点上的平均值。</p>

<p>分割超平面为：<br/>
\[<br/>
\begin{equation}<br/>
y = \boldsymbol w^{*T} \boldsymbol x + b^* = \sum_{i=1}^N\alpha^*_i y_i x_i x + b^* \label{with_z_r} <br/>
\end{equation}<br/>
\]</p></li>
</ol>

<h2 id="toc_8">核技巧（Kernel trick）</h2>

<p>首先通过一个简单的例子来了解一下核技巧，如下图是两类数据（用不同颜色区分）：</p>

<div align="center">
    <img width="350px" src="media/15025588355749/15265669014230.jpg" />
</div>

<p>显然这两类数据是线性不可分的，需要一个分段函数才能将其分开，但是如果我们通过某种核技巧将数据中的点，映射到高维空间，这两类数据就会变的线性可分，如下图所示：</p>

<div align="center">
    <img width="350px" src="media/15025588355749/15265668464657.jpg" />
</div>

<p>在这个例子中，从原空间到新空间的映射函数\(\varphi(x) = (x-a)(x-b) \)。这个例子说明用线性分类方法求解非线性问题通常分为两步，首先使用合适的映射函数将数据点从低维空间映射到新空间（一般是高维空间或无限维空间），使数据线性可分的可能性增大，然后在新空间内用线性分类方法从训练数据中学习分类模型。</p>

<p>在实际问题中，往往直接定义映射函数是难以做到的，所以往往只定义核函数\(K(x,z)\)。在前面对SVM的讲解中，我们可以看到数据点往往都是都是以内积的形式出现的，假设我们定义一个函数\(f(x_i,x_j)\)满足：<br/>
\[<br/>
f(x_i,x_j) = &lt;\varphi(x_i),\varphi(x_j)&gt;<br/>
\]</p>

<p>也就是原样本点数据经过一个函数的输出与原样本点经过一个映射函数之后的新数据点\(\varphi(x_i)\)，\(\varphi(x_j)\)的内积相同。<br/>
这里举个简单的例子，数据空间里有两个数据点\(x_i=(\eta_1,\eta_2)\)和\(x_j=(\xi_1,\xi_2)\)，设想我们有一个函数：\(f(x_i,x_j)=(&lt;x_i,x_j&gt;)^2\)，映射函数为：\(\varphi(x_i,x_j) = (x_i^2,2x_ix_j,x_j^2)\)，那么：<br/>
\[<br/>
\begin{align*}<br/>
&lt;\varphi(x_i),\varphi(x_j)&gt; &amp;= &lt;(\eta_1^2,\eta_1\eta_2,\eta_2^2),(\xi_1,\xi_1\xi_2,\xi_2^2)&gt; \\&amp;=\eta_1^2\xi_1^2+ +2\eta_1\eta_2\xi_1\xi_2+\eta_2^2 \xi_2^2 \\<br/>
&amp; = (\eta_1\xi_1+\eta_2\xi_2)^2 \\<br/>
&amp; = f(x_i,x_j)<br/>
\end{align*}<br/>
\]</p>

<p>两种计算方式不同但是结果相同，一种是在低维空间直接通过核函数运算结果，一种是在转换后的高维空间进行计算内积。在实际项目中，可能我们需要映射到的高维空间是维度很大，甚至是无限维，所以映射后再计算内积计算量很大，所以我们通常只需要一个核函数计算低维度的数据，这种情况下我们也并不需要知道映射函数，可能也并不能知道具体的映射函数。</p>

<p>那什么样的函数可以被用作核函数呢？开始讨论：</p>

<p>定义一个核矩阵\(K\)，其中\(K_{i,j}=K(x_i,x_j)\)，根据核函数的定义：\(K_{ij}=K(x_i,x_j) = &lt;\varphi(x_i),\varphi(x_j)&gt;=&lt;\varphi(x_j),\varphi(x_i)&gt; = K(x_j,x_i) = K_{ji}\)，矩阵\(K\)是一个对称矩阵。<br/>
对于任意一个向量\(\boldsymbol z\)，得：<br/>
\[<br/>
\begin{align*}<br/>
\boldsymbol z^TK\boldsymbol z &amp;= \left[\begin{array}{ccc}<br/>
z_1\\<br/>
z_2\\<br/>
...\\<br/>
z_i\\<br/>
...\\<br/>
z_n <br/>
\end{array}<br/>
\right]^T \cdot \left[ \begin{array}{ccc}<br/>
K_{1,1} &amp;&amp; K_{1,2} &amp;&amp; ... &amp;&amp; K_{1,j} &amp;&amp; ... &amp;&amp; K_{1,n} \\<br/>
K_{2,1} &amp;&amp; K_{2,2} &amp;&amp; ... &amp;&amp; K_{2,j} &amp;&amp; ... &amp;&amp; K_{2,n} \\<br/>
... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... \\<br/>
K_{i,1} &amp;&amp; K_{i,2} &amp;&amp; ... &amp;&amp; K_{i,j} &amp;&amp; ... &amp;&amp; K_{i,n} \\<br/>
... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... \\<br/>
K_{n,1} &amp;&amp; K_{n,2} &amp;&amp; ... &amp;&amp; K_{n,j} &amp;&amp; ... &amp;&amp; K_{n,n} \\<br/>
\end{array}<br/>
\right] \cdot \left[ \begin{array}{ccc}<br/>
z_1\\<br/>
z_2\\<br/>
...\\<br/>
z_i\\<br/>
...\\<br/>
z_n <br/>
\end{array}<br/>
\right] \\<br/>
&amp;= \left[ \begin{array}{ccc}<br/>
z_1K_{1,1} + z_2K_{2,1} + ... + z_iK_{i,1} + ... + z_nK_{n,1} \\<br/>
z_1K_{1,2} + z_2K_{2,2} + ... + z_iK_{i,2} + ... + z_nK_{n,2} \\<br/>
...\\<br/>
z_1K_{1,j} + z_2K_{2,j} + ... + z_iK_{i,j} + ... + z_nK_{n,j} \\<br/>
...\\<br/>
z_1K_{1,n} + z_2K_{2,n} + ... + z_iK_{i,n} + ... + z_nK_{n,n} \\<br/>
\end{array} \right] ^T \cdot \left[ \begin{array}{ccc}<br/>
z_1\\<br/>
z_2\\<br/>
...\\<br/>
z_i\\<br/>
...\\<br/>
z_n <br/>
\end{array}<br/>
\right] \\<br/>
&amp;= (z_1K_{1,1} + z_2K_{2,1} + ... + z_iK_{i,1} + ... + z_nK_{n,1}).z_1+(z_1K_{1,2} + z_2K_{2,2} + ... + z_iK_{i,2} + ... + z_nK_{n,2}).z_2\\<br/>
&amp;\quad\,+...+(z_1K_{1,n} + z_2K_{2,n} + ... + z_iK_{i,n} + ... + z_nK_{n,n}).z_n\\<br/>
&amp;=\sum_{i=1}^N \sum_{j=1}^N z_iK_{i,j}z_j \\<br/>
&amp;=\sum_{i=1}^N \sum_{j=1}^N z_i&lt;\varphi(x_i)\cdot\varphi(x_j)&gt;z_j \\<br/>
&amp;=\sum_{i=1}^N \sum_{j=1}^N z_i\sum_{k=1}^N ([\varphi(x_i)]_k[\varphi(x_j)]_k) z_j \\<br/>
&amp;=\sum_{k=1}^N \sum_{i=1}^N \sum_{j=1}^N z_i[\varphi(x_i)]_k[\varphi(x_j)]_k z_j \\<br/>
&amp;=\sum_{k=1}^N \sum_{i=1}^N z_i [\varphi(x_i)]_k \sum_{j=1}^N z_j [\varphi(x_j)]_k\\<br/>
&amp;=\sum_{k=1}^N (\sum_{i=1}^N z_i [\varphi(x_i)]_k)^2\\<br/>
&amp;\ge 0<br/>
\end{align*} <br/>
\]</p>

<p>所以核函数矩阵\(K\)应该是半正定矩阵，这里证明了核函数矩阵的一个必要条件，核函数矩阵是对称半正定矩阵。</p>

<p>以下证明核函数矩阵的充分条件，假设\(K(x_i,x_j)\)是空间里的对称函数，考虑矩阵\(K = [K(x_i,x_j)]^n_{i,j}\)，因为\(K_{i,j}=K(x_i,x_j)=K(x_j,x_i)=K_{j,i}\)易知矩阵\(K\)是对称矩阵。</p>

<p>由同济大学线性代数第二版P128定理5可知，对于n阶对称矩阵\(K\)，则必有正交矩阵\(P\)，使\(P^{-1}KP=P^TKP=\Lambda\)，其中\(\Lambda\)是以\(K\)的n个特征值为对角元的对角矩阵：<br/>
\[<br/>
\begin{align*}<br/>
P^{-1} K P &amp;= \Lambda \Rightarrow K = P\Lambda P^{-1} = P\Lambda P^T<br/>
\end{align*}<br/>
\]</p>

<p>将\(P\)的用其列向量表示为：<br/>
\[<br/>
P = (p_1,p_2,...,p_n)<br/>
\]</p>

<p>由\(P^{-1}KP = \Lambda\)，得\(\,KP = P\Lambda\,\)，即：<br/>
\[<br/>
\begin{align*}<br/>
K(p_1,p_2,...,p_n) &amp;= (p_1,p_2,...,p_n)\left (\begin{array}<br/>
\lambda\lambda_1 &amp;&amp;           &amp;&amp;        &amp;&amp; \\<br/>
          &amp;&amp; \lambda_2 &amp;&amp;        &amp;&amp; \\<br/>
          &amp;&amp;           &amp;&amp; \ddots &amp;&amp; \\<br/>
          &amp;&amp;           &amp;&amp;        &amp;&amp; \lambda_n \\<br/>
\end{array} \right ) \\<br/>
&amp;=(p_1\lambda_1,p_2\lambda_2,\cdots,p_n\lambda_n)<br/>
\end{align*}<br/>
\]</p>

<p>于是有：<br/>
\[<br/>
Kp_i = \lambda_i p_i \quad(i=1;2;...;n)<br/>
\]</p>

<p>易知\(\lambda_i\)是\(K\)的特征值，\(P\)的列\(p_i\)是对应的特征向量。</p>

<p>我们先来展开一下\(PKP^T\)，令\(\lambda_t\)对应的特征向量\(\,p_t\,\)的第\(i\)个元素为\(p_{it}\)：<br/>
\[<br/>
\begin{align*}<br/>
P\Lambda P^T &amp;= \left[ \begin{array}{ccc}<br/>
p_{1,1}&amp;&amp;p_{1,2}&amp;&amp;\cdots&amp;&amp;p_{1,j}&amp;&amp;\cdots \\<br/>
p_{2,1}&amp;&amp;p_{2,2}&amp;&amp;\cdots&amp;&amp;p_{2,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{i,1}&amp;&amp;p_{i,2}&amp;&amp;\cdots&amp;&amp;p_{i,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{n,1}&amp;&amp;p_{n,2}&amp;&amp;\cdots&amp;&amp;p_{n,j}&amp;&amp;\cdots\\<br/>
\end{array} \right ] \left [ \begin{array}{ccc}<br/>
\lambda_{1,1}&amp;&amp;\lambda_{1,2}&amp;&amp;\cdots&amp;&amp;\lambda_{1,j}&amp;&amp;\cdots\\<br/>
\lambda_{2,1}&amp;&amp;\lambda_{2,2}&amp;&amp;\cdots&amp;&amp;\lambda_{2,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
\lambda_{i,1}&amp;&amp;\lambda_{i,2}&amp;&amp;\cdots&amp;&amp;\lambda_{i,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
\lambda_{n,1}&amp;&amp;\lambda_{n,2}&amp;&amp;\cdots&amp;&amp;\lambda_{n,j}&amp;&amp;\cdots\\<br/>
\end{array} \right ] P^T \\<br/>
&amp;= \left[ \begin{array}{ccc}<br/>
(\sum_{t=1}^N p_{1,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{1,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{1,t}\lambda_{t,j}) &amp;&amp; ... \\<br/>
(\sum_{t=1}^N p_{2,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{2,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{2,i}\lambda_{t,j}) &amp;&amp; ... \\<br/>
... &amp;&amp; ... &amp;&amp; \cdots &amp;&amp; ... &amp;&amp; ... \\<br/>
(\sum_{t=1}^N p_{i,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{i,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{i,t}\lambda_{t,j}) &amp;&amp; ... \\<br/>
... &amp;&amp; ... &amp;&amp; \cdots &amp;&amp; ... &amp;&amp; ... \\<br/>
(\sum_{t=1}^N p_{n,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{n,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{n,t}\lambda_{t,j}) &amp;&amp; ... \\<br/>
\end{array} \right] \left[ \begin{array}{ccc}<br/>
p_{1,1}&amp;&amp;p_{2,1}&amp;&amp;\cdots&amp;&amp;p_{i,1}&amp;&amp;\cdots \\<br/>
p_{1,2}&amp;&amp;p_{2,2}&amp;&amp;\cdots&amp;&amp;p_{i,2}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{1,j}&amp;&amp;p_{2,j}&amp;&amp;\cdots&amp;&amp;p_{i,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{1,n}&amp;&amp;p_{2,n}&amp;&amp;\cdots&amp;&amp;p_{i,n}&amp;&amp;\cdots\\<br/>
\end{array} \right ] \\<br/>
\end{align*}<br/>
\]</p>

<p>整个式子计算起来太长，我们只考虑\((P\Lambda P^T)_{ij}\)：<br/>
\[<br/>
\begin{align*}<br/>
(P\Lambda P^T)_{ij} &amp;= p_{j,1}(\sum_{t=1}^N p_{i,t}\lambda_{t,1}) + p_{j,2}(\sum_{t=1}^N p_{i,t}\lambda_{t,2}) + \cdots + p_{j,i}(\sum_{t=1}^N p_{i,t}\lambda_{t,j}) + ... +  p_{j,n}(\sum_{t=1}^N p_{n,t}\lambda_{t,j}) \\<br/>
&amp;= \sum_{m=1}^N [p_{j,m}\sum_{t=1}^N p_{i,t}\lambda_{t,m}] \\<br/>
&amp;= \sum_{t=1}^N \sum_{m=1}^N p_{i,t} \lambda_{t,m} p_{j,m} \\<br/>
\end{align*}<br/>
\]</p>

<p>因为\(\Lambda\)是对角矩阵，所以：<br/>
\[<br/>
\begin{align*}<br/>
\lambda_{t,m} = \left \{ \begin{array}{ccc}<br/>
\lambda_{t} &amp; t = m \\<br/>
0 &amp; e \neq m \\<br/>
\end{array} \right .<br/>
\end{align*}<br/>
\]</p>

<p>得：<br/>
\[<br/>
K = (P\Lambda P^T)_{ij} = \sum_{t=1}^N \sum_{m=1}^N p_{i,t} \lambda_{t,m} p_{j,m} = \sum_{t=1}^N p_{i,t} \lambda_t p_{j,t}<br/>
\]</p>

<p>现在假设所有的特征值都是非负的，考虑特征映射：<br/>
\[<br/>
\begin{align*}<br/>
\varphi(x_i) &amp;= (\sqrt{\lambda_t}p_{t,i})^n_{t=1}:i=1;2;...N \\<br/>
&amp;=(\sqrt{\lambda_1}p_{1,i},\sqrt{\lambda_2}p_{2,i},...,\sqrt{\lambda_t}p_{t,i},...,\sqrt{\lambda_n}p_{n,i}) \\<br/>
\end{align*}<br/>
\]</p>

<p>所以有：<br/>
\[<br/>
\begin{align*}<br/>
&lt;\varphi(x_i)\varphi(x_j)&gt; &amp;= (\sqrt{\lambda_1}p_{1i},\sqrt{\lambda_2}p_{2i},...,\sqrt{\lambda_t}p_{ti},...,\sqrt{\lambda_n}p_{ni})\cdot(\sqrt{\lambda_1}p_{1i},\sqrt{\lambda_2}p_{2i},...,\sqrt{\lambda_t}p_{ti},...,\sqrt{\lambda_n}p_{ni}) \\<br/>
&amp;= \sum_{t=1}^N \lambda_t p_{t,i} p_{t,j} = (P\Lambda P^T)_{ij} = K_{i,j} = K(x_i,x_j)<br/>
\end{align*}<br/>
\]</p>

<p>这里已经完成了充分性证明：半正定对称向量是核函数矩阵。之后，我们可以将前面的一些结论写成核函数的方式，如公式（\ref{with_z_r}）分割超平面写成核函数的形式为：<br/>
\[<br/>
\begin{equation}<br/>
y = \sum_{i=1}^N \alpha_i y_i k(x_i,x) + b^* \label{with_z_r_h}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_9">常见的核函数</h3>

<p>线性核函数（Linear kernel function）：<br/>
\[<br/>
K(x,z) = x^tz + c<br/>
\]</p>

<p>多项式核函数（Polynomial kernel function）：<br/>
\[<br/>
K(x,z) = (x\cdot z + 1)^p<br/>
\]</p>

<p>高斯核函数（Gaussian kernel function）：一个理论上可以将数据从低维空间映射到无穷维空间，使用很广泛。<br/>
\[<br/>
K(x,z) = exp(-\frac{||x-z||^2}{2\sigma^2})<br/>
\] </p>

<h2 id="toc_10">SMO算法</h2>

<p>SMO算法，英文名称：Sequence minimal optimization，中文名称：序列化最小最优算法。它是1996年有Platt发布的一个强大的算法，它将大优化问题分解成多个小优化的问题来求解。这些小优化的方法往往比较容易求解，并且对它们进行顺序求解的结果与将它们作为整体来求解的结果完全一致，在结果相同的情况下，SMO算法的效率会提升很多。</p>

<p>SMO算法的目标是求出一系列的\(\alpha\)和\(b\)，由前面可知，一旦求出\(\alpha\)，就很容易计算出权重向量\(\boldsymbol w\)和\(b\)，并得到分割超平面。SMO算法的工作原理是：每次循环中选择两个\(\alpha\)来进行优化处理。一旦找到一堆合适的\(\alpha\)，那么就增大其中一个同时减小另一个。这里所谓的“合适”就是指两个\(\alpha\)必须满足一定的条件，后面会讨论这个条件。</p>

<p>我们先来回顾一下我们SMO算法要求解的一般方程组：<br/>
\[<br/>
\begin{align}<br/>
\min_{\boldsymbol w,b,\zeta} \quad &amp; \frac{1}{2}||\boldsymbol w||^2+\text{C}\sum_{i=1}^N \zeta_i \label{smo_o_q_0}\\<br/>
s.t. \quad&amp; y_i(\boldsymbol w x_i + b) \ge 1 - \zeta_i:i=1;2;...;N \label{smo_o_q_1}\\<br/>
\quad&amp;\zeta_i \gt 0:i = 1;2;...;N \label{smo_o_q_2}\\<br/>
\end{align}<br/>
\]</p>

<p>然后引入拉格朗日方程，根据其对偶问题求出\(\boldsymbol w\)以及\(\alpha_i\)的关系：<br/>
\[<br/>
\begin{align}<br/>
&amp;\boldsymbol w = \sum_{i=1}^N \alpha_i y_i x_i \label{smo_r_0}\\<br/>
&amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{smo_r_1}\\<br/>
&amp;\text{C} - \alpha_i - \mu_i = 0 \label{smo_r_2}\\<br/>
\end{align}<br/>
\]</p>

<p>然后将这个结果带入拉格朗日对偶问题，这里使用核函数的形式，直接给出结果：<br/>
\[<br/>
\begin{align}<br/>
\min_{\alpha} \quad &amp;\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j k(x_i,x_j) - \sum_{i=1}^N \alpha_i \\<br/>
s.t. \quad &amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{smo_d_r_0}\\<br/>
\quad\quad\quad &amp;0 \le \alpha_i \le C:i=1;2;...;N \label{smo_d_r_1}\\<br/>
\end{align}<br/>
\]</p>

<p>前面我们已经说明了\(\alpha_i\)的取值范围及其意义，现在继续探究\(\alpha_i\)与\(yy_i\)的关系（这里\(y\)代表预测值\(y=\boldsymbol w^T \boldsymbol x + b\)，\(y_i\)是真实值）：</p>

<ol>
<li><p>当\(\alpha_i = 0\)时，由公式（\ref{d_with_z_kkt_2}）可知\(\mu_i=C&gt;0\)，由公式（\ref{d_with_z_kkt_4}）可知\(\zeta_i = 0\)，所以公式（\ref{d_with_z_kkt_5}）可以改写为：<br/>
\[<br/>
\begin{equation}<br/>
y_i(\boldsymbol w^{*T}x_i + b^*) - 1 + \zeta_i \ge 0 \Rightarrow y_i y \ge 1 \label{y_i_w_b_z_1} \\<br/>
\end{equation}<br/>
\]</p></li>
<li><p>当\(\alpha_i = C\)时，由公式（\ref{d_with_z_kkt_2}）可知\(\mu_i = 0\)，由公式（\ref{d_with_z_kkt_4}）可知存在\(\zeta_i &gt; 0\)，所以公式（\ref{d_with_z_kkt_3}）可以改写为：<br/>
\[<br/>
\begin{equation}<br/>
y_i(\boldsymbol w^{*T}x_i + b^*) - 1 + \zeta_i = 0 \Rightarrow y_i y = 1 - \zeta_i \le 1 \label{y_i_w_b_z_2} \\<br/>
\end{equation}<br/>
\]</p></li>
<li><p>当\(0 \le \alpha_i \le C\)时，由公式（\ref{d_with_z_kkt_2}）可知\(\mu_i &gt; 0\)，由公式（\ref{d_with_z_kkt_4}）可知存在\(\zeta_i = 0\)，所以公式（\ref{d_with_z_kkt_3}）可以改写为：<br/>
\[<br/>
\begin{equation}<br/>
y_i(\boldsymbol w^{*T}x_i + b^*) - 1 + \zeta_i = 0 \Rightarrow y_i y = 1 - \zeta_i = 1 \label{y_i_w_b_z_3} \\<br/>
\end{equation}<br/>
\] </p></li>
</ol>

<p>在SMO算法中，我们通常要选择不满足上述条件的\(\alpha_i\)来进行更新，下面来讨论不满足这些条件的情况：</p>

<ol>
<li>\(y_iy \ge 1\)时\(\alpha_i &gt;0 \)，因为原始的\(\alpha_i = 0\)</li>
<li>\(y_iy \le 1\)时\(\alpha_i &lt;C \)，因为原始的\(\alpha_i = C\)</li>
<li>\(y_iy =   1\)时\(\alpha_i = 0\)或\(\alpha_i = C\)时，因为原始的\(0 &lt; \alpha_i &lt; C\)</li>
</ol>

<p>在更新这些不满足条件的\(\alpha_i\)时，还需要满足公式（\ref{d_t_with_r_1}）\(\sum_{i=1}^N \alpha_i = 0\)条件，因此通常我们同时选择两个\(\alpha\)更新，增大其中一个，减小另外一个。假设选择的两个值是\(\alpha_1\)和\(\alpha_2\)，更新前值为\(\alpha_1^{old}\)和\(\alpha_2^{old}\)，更新后值为\(\alpha_1^{new}\)和\(\alpha_2^{new}\)，那么有：<br/>
\[<br/>
\begin{equation}<br/>
\alpha_1^{old}y_1 + \alpha_2^{old}y_2 = \alpha_1^{new}y_1 + \alpha_2^{new}y_2 = - \sum_{k \neq 1,2}^N \alpha_k \label{a_i_j_r}<br/>
\end{equation}<br/>
\]</p>

<p>令\(- \sum_{k \neq 1,2}^N \alpha_k = \varepsilon\)，这里分两种情况讨论：<br/>
第一种情况：\(y_1\)与\(y_2\)同号：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\alpha_1^{new} + \alpha_2^{new} = \varepsilon \Leftrightarrow \alpha_1^{new} = \varepsilon - \alpha_2^{new} \\<br/>
\because \quad&amp;0 \le \alpha_1^{new} \le C \\<br/>
\therefore \quad&amp;0 \le \varepsilon - \alpha_2^{new} \le C \\<br/>
\Rightarrow \quad &amp;\varepsilon - C \le \alpha_2^{new} \le \varepsilon \\<br/>
\Rightarrow \quad &amp;\alpha_1^{old} + \alpha_2^{old} -C \le \alpha_2^{new} \le \alpha_1^{old} + \alpha_2^{old} \\<br/>
\because \quad &amp; 0 \le \alpha_2^{new} \le C \\<br/>
\therefore \quad &amp; \max(0,\alpha_1^{old} + \alpha_2^{old} -C) \le \alpha_2^{new} \le \min(C,\alpha_1^{old} + \alpha_2^{old}) \\<br/>
\end{align*}<br/>
\]</p>

<p>令\(L = \max(0,\alpha_1^{old} + \alpha_2^{old} -C),\, H = \min(C,\alpha_1^{old} + \alpha_2^{old})\)，则\(L \le \alpha_2^{new} \le H\)</p>

<p>第二种情况：\(y_1\)与\(y_2\)异号：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\alpha_1^{new} - \alpha_2^{new} = \varepsilon \Leftrightarrow \alpha_1^{new} = \alpha_2^{new}  - \varepsilon \\<br/>
\because \quad&amp;0 \le \alpha_1^{new} \le C \\<br/>
\therefore \quad&amp;0 \le \alpha_2^{new} - \varepsilon \le C \\<br/>
\Rightarrow \quad &amp;\varepsilon \le \alpha_2^{new} \le C + \varepsilon \\<br/>
\Rightarrow \quad &amp;\alpha_1^{old} - \alpha_2^{old} \le \alpha_2^{new} \le C + \alpha_1^{old} - \alpha_2^{old} \\<br/>
\because \quad &amp; 0 \le \alpha_2^{new} \le C \\<br/>
\therefore \quad &amp; \max(0,\alpha_1^{old} - \alpha_2^{old}) \le \alpha_2^{new} \le \min(C,C+\alpha_1^{old} - \alpha_2^{old}) \\<br/>
\end{align*}<br/>
\]</p>

<p>令\(L = \max(0,\alpha_1^{old} - \alpha_2^{old}),\, H = \min(C,C+\alpha_1^{old} - \alpha_2^{old})\)，则\(L \le \alpha_2^{new} \le H\)</p>

<p>在知道了\(\alpha_2^{new}\)的范围之后，继续探究\(\alpha_2^{new}\)的值，由公式（\ref{a_i_j_r}）知\(\alpha_1 y_1 + \alpha_2 y_2 = \varepsilon \Rightarrow \alpha_1 y_1 = \varepsilon - \alpha_2 y_2 \)，两边同乘上\(y_1\)，因为\(y_1^2 = 1\)，所以得：\(\alpha_1 = y_1(\varepsilon - \alpha_2 y_2)\)，我们将软间隔最大化的对偶问题公式（\ref{d_t_with_r_0}）加上核函数，然后进行推导：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j k(x_i,x_j) - \sum_{i=1}^N \alpha_i \\<br/>
&amp;= \frac{1}{2}\alpha_1^2y_1^2k(x_1,x_1)+\frac{1}{2}\alpha_2^2y_2^2k(x_2,x_2)+\alpha_1\alpha_2y_1y_2k(x_1,x_2)+\alpha_1y_1\sum_{i=3}^N\alpha_iy_ik(x_1,x_i)\\<br/>
&amp;+\alpha_2y_2\sum_{i=3}^N\alpha_iy_ik(x_2,x_i)+\frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) - \alpha_1 - \alpha_2 - \sum_{i=3}^N\alpha_i<br/>
\end{align*}<br/>
\]</p>

<p>将\(\alpha_1=y_1(\varepsilon - \alpha_2y_2)\)代入式：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}[y_1(\varepsilon -\alpha_2y_2)]^2y_1^2k(x_1,x_1)+\frac{1}{2}\alpha_2^2y_2^2k(x_2,x_2)+y_1(\varepsilon -\alpha_2y_2)\alpha_2y_1y_2k(x_1,x_2) \\<br/>
&amp;+y_1(\varepsilon - \alpha_2y_2)y_1\sum_{i=3}\alpha_iy_ik(x_1,x_i) + \alpha_2y_2\sum_{i=3}^N\alpha_iy_ik(x_2,x_i) + \frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) \\<br/>
&amp;- y_1(\varepsilon - \alpha_2y_2) - \alpha_2 - \sum_{i=3}^N\alpha_i \\<br/>
&amp;=\frac{1}{2}(\varepsilon - \alpha_2y_2)^2k(x_1,x_1) + \frac{1}{2}\alpha_2^2k(x_2,x_2) + (\varepsilon-\alpha_2y_2)\alpha_2y_2k(x_1,x_2) \\<br/>
&amp;+(\varepsilon-\alpha_2y_2)\sum_{i=3}^N\alpha_iy_ik(x_1,x_i)+ \alpha_2y_2\sum_{i=3}^N\alpha_iy_ik(x_2,x_i) + \frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) \\<br/>
&amp;- y_1(\varepsilon - \alpha_2y_2) - \alpha_2 - \sum_{i=3}^N\alpha_i \\<br/>
\end{align*}<br/>
\]</p>

<p>因为在操作过程中只变化\(\alpha_1\)和\(\alpha_2\)，所以可以将不包含\(\alpha_1\)和\(\alpha_2\)的项看作常数，令\(v_1=\sum_{i=3}^N\alpha_iy_ik(x_1,x_i)\)，\(v_2 = \sum_{i=3}^N\alpha_iy_ik(x_2,x_i)\)，\(const=\frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) - \sum_{i=3}^N\alpha_i\)，所以上式可以改写为：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}(\varepsilon - \alpha_2y_2)^2k(x_1,x_1) + \frac{1}{2}\alpha_2^2k(x_2,x_2) + (\varepsilon-\alpha_2y_2)\alpha_2y_2k(x_1,x_2) \\<br/>
&amp;- y_1(\varepsilon - \alpha_2y_2) - \alpha_2 +(\varepsilon-\alpha_2y_2)v_1+ \alpha_2y_2v_2 + const \\<br/>
\end{align*}<br/>
\]</p>

<p>上式可以看成只包含\(\alpha_2\)的函数，令\(W(\alpha_2)=\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha)\)，然后对\(\alpha_2\)求导数：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial W(\alpha_2)}{\partial \alpha_2} &amp;= -(\varepsilon-\alpha_2y_2)y_2k(x_1,x_1) + \alpha_2k(x_2,x_2)-y_2\alpha_2y_2k(x_1,x_2) + (\varepsilon-\alpha_2y_2)y_2k(x_1,x_2) +y_1y_2 - 1 \\<br/>
&amp;- y_2v_1 + y_2v_2 \\<br/>
&amp;=\alpha_2k(x_1,x_1)+\alpha_2k(x_2,x_2)-2\alpha_2k(x_1,x_2) - \varepsilon y_2k(x_1,x_1) + \varepsilon y_2k(x_1,x_2) +y_1y_2 - 1 - y_2v_1 \\<br/>
&amp;+ y_2 v_2<br/>
\end{align*}<br/>
\]</p>

<p>令其等于0，并将核函数写成核矩阵形式得：<br/>
\[<br/>
\begin{equation}<br/>
(K_{11}+K_{22}-2K_{12})\alpha_2 = y_2(y_2 - y_1 + \varepsilon K_{11} - \varepsilon K_{12} + v_1 -v_2) \label{kk_2_a}<br/>
\end{equation}<br/>
\]</p>

<p>在前面化简时，我们曾令\(v_1 = \sum_{i=3}^N\alpha_iy_ik(x_1,x_i)\)，结合公式（\ref{with_z_r_h}）考虑：<br/>
\[<br/>
\begin{align*}<br/>
v_1 &amp;= \sum_{i=1}^N\alpha_iy_ik(x_1,x_i) + b^* - \sum_{i=1}^2\alpha_iy_ik(x_1,x_i) - b^* \\<br/>
&amp;= f(x_1) -  \alpha_1^{old} y_1 K_{11} - \alpha_2^{old} y_2 K_{12} - b^*<br/>
\end{align*}<br/>
\]</p>

<p>同理：\(v_2 =f(x_2) -  \alpha_1^{old} y_1 K_{21} - \alpha_2^{old} y_2 K_{22} - b^*\)<br/>
将\(v_1\)和\(v_2\)代入式（\ref{kk_2_a}）中得：<br/>
\[<br/>
\begin{align*}<br/>
(K_{11}+K_{22}-2K_{12})\alpha_2 &amp;= y_2(y_2 - y_1 + \varepsilon K_{11} - \varepsilon K_{12} + v_1 -v_2) \\<br/>
&amp;=y_2(y_2 - y_1 + \varepsilon K_{11} - \varepsilon K_{12} + f(x_1) -  \alpha_1^{old} y_1 K_{11} - \alpha_2^{old} y_2 K_{12} -f(x_2) +  \alpha_1^{old} y_1 K_{21} \\<br/>
&amp;+ \alpha_2^{old} y_2 K_{22})<br/>
\end{align*}<br/>
\]</p>

<p>将\(\varepsilon = \alpha_1^{old}y_1 + \alpha_2^{old}y_2\)代入上式，并用\(E_i\)表示预测值\(f(x_i)\)与真实值\(y_i\)的差：<br/>
\[<br/>
\begin{align*}<br/>
(K_{11}+K_{22}-2K_{12})\alpha_2^{new,unc} &amp;=y_2(y_2 - y_1 + (\alpha_1^{old}y_1 + \alpha_2^{old}y_2) K_{11} - (\alpha_1^{old}y_1 + \alpha_2^{old}y_2) K_{12} \\<br/>
&amp;+ f(x_1) -  \alpha_1^{old} y_1 K_{11} - \alpha_2^{old} y_2 K_{12} -f(x_2) +  \alpha_1^{old} y_1 K_{21} + \alpha_2^{old} y_2 K_{22}) \\<br/>
&amp;=y_2(y_2 - y_1 + \alpha_2^{old}y_2 K_{11} - 2\alpha_2^{old}y_2K_{12} + \alpha_2^{old} y_2 K_{22}+ f(x_1) -f(x_2) \\<br/>
&amp;=(K_{11}-2K_{12}+K_{22})\alpha_2^{old} + y_2[(f(x_1) - y_1)-(f(x_2) - y_2)] \\<br/>
\Rightarrow \alpha_2^{new,unc} &amp;= \alpha_2^{old} + \frac{y_2(E_1-E_2)}{K_{11}-2K_{12}+K_{22}}<br/>
\end{align*}<br/>
\]</p>

<p>令\(\eta=K_{11}+K_{22}-2K_{12}\)，则\(\alpha_2^{new,unc}=\alpha_2^{old} + \frac{y_2(E_1-E_2)}{\eta}\)，前面我们已经求出了\(\alpha_2^{new}\)的范围，所以经剪辑后：<br/>
\[<br/>
\begin{align*}<br/>
\alpha_2^{new} = \left \{ \begin{array}<br/>
HH \quad &amp; \alpha_2^{new,unc} &gt; H \\<br/>
a_2^{new,unc} \quad &amp; L \le a_2^{new,unc} \le H \\<br/>
L \quad &amp; \alpha_2^{new,unc} &lt; L<br/>
\end{array} \right .<br/>
\end{align*}<br/>
\]</p>

<p>再由\(\alpha_2^{new}\)求解\(\alpha_1^{new}\)得：<br/>
\[<br/>
\begin{align*}<br/>
\because\quad&amp;\alpha_1^{new}y_1 + \alpha_2^{new}y_2 = \alpha_1^{old}y_1 + \alpha_2^{old}y_2 \\<br/>
\therefore\quad&amp;\alpha_1^{new} = \alpha_1^{old} + y_1y_2(\alpha_2^{old} - \alpha_2^{new})<br/>
\end{align*}<br/>
\]</p>

<p>在每次完成\(\alpha\)更新后，接下来重新计算阈值\(b\)，由公式（\ref{with_z_r_h}）可知，当\(0 &lt; \alpha_1^{new} &lt; C\)时：<br/>
\[<br/>
\sum_{i=1}^N\alpha_iy_iK_{i1} + b^* = y_i \Rightarrow b^* = y_i - \sum_{i=1}^N\alpha_iy_iK_{i1}\<br/>
\]</p>

<p>于是：<br/>
\[<br/>
b_1^{new} = y_1 - \sum_{i=3}^N\alpha_iy_iK_{i1} - \alpha_1^{new}y_iK_{11} - \alpha_2^{new}y_2K_{21}<br/>
\]</p>

<p>由\(E_1\)的定义有：<br/>
\[<br/>
E_1 = \sum_{i=1}^N \alpha_i y_i K_{i1} = \sum_{i=3}^N \alpha_i y_i K_{i1} + \alpha_1^{old}y_1K_{11} + \alpha_2^{old}y_2K_{21} + b^{old} - y_1<br/>
\]</p>

<p>前面两项可以结合得：<br/>
\[<br/>
b_1^{new} = - E_1 + (\alpha_1^{old}-\alpha_1^{new})y_1K_{11} + (\alpha_2^{old}-\alpha_2^{new})y_2K_{21} + b^{old} <br/>
\]</p>

<p>那么同理有：\(b_2^{new} = - E_2 + (\alpha_1^{old}-\alpha_1^{new})y_1K_{12} + (\alpha_2^{old}-\alpha_2^{new})y_2K_{22} + b^{old}\)<br/>
所以\(b\)的更新规则如下：<br/>
\[<br/>
\begin{equation}<br/>
b^* = \left \{ \begin{array}<br/>
bb_1 \quad&amp; 0 &lt; \alpha_1 &lt; C \\<br/>
b_2 \quad&amp; 0 &lt; \alpha_2 &lt; C \\<br/>
\frac{1}{2}(b_1+b_2) \quad&amp; 其他<br/>
\end{array} \right .<br/>
\end{equation}<br/>
\]</p>

<h2 id="toc_11">多分类问题</h2>

<p>对于多分类问题，比如手写数字识别的问题，类别的数量超过2种，此时变出现多分类问题。通常使用的解决方案有两种：一对多训练和多一对一训练。</p>

<h4 id="toc_12">一对多训练 one-versus-the-rest</h4>

<p>这种方法是在K分类的数据集上训练处K个分类器，每个分类器将样本分为\(k_i\)类与非\(k_i\)类。每个样本在测试的时候需要被分类K次，预测出是否属于\(k_i\)数据分类，但是很可能一个数据会被分为到几个类。这时候就需要函数间隔作为分类的确信度，取确信度最大的分类作为预测分类。</p>

<p>这种方法的弊端在于可能出现样本不平衡的情况，一边是1类数据，一边是K-1类数据，这种情况可以通过欠采样解决，但是效果不好。在实际工作中往往不采用，而是采用下面多一对一的分类器。</p>

<h4 id="toc_13">多一对一训练 one-versus-one</h4>

<p>这种方式在K分类的数据集上训练\(\frac{K(K-1)}{2}\)个分类器，也就是在每两个分类上训练处一个分类器，在测试环境，每个样本都需要被分类K-1次，然后采取投票的方式决定最终预测分类。假设有三类数据A类、B类和C类，将会训练A-B分类器，A-C分类器，B-C分类器，对于测试样本x，在A-B分类器上分为A类，在A-C分类器上分为C，在B-C分类器上分为C类，那么C得两票，A得一票，最终x被预测为C。但是这种方法也可能导致分不了类，刚才的例子中，x在B-C分类器上分为B类，那么A、B、C各得一票，x归属哪一类就不好判断了。</p>


		</div>

		

	</article>
  
	<div class="pagination">
	
<a href="archives.html">Blog Archives</a>
	 
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98.html"><strong>最短路径问题&nbsp;(5)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E8%81%9A%E7%B1%BB%E9%97%AE%E9%A2%98.html"><strong>聚类问题&nbsp;(9)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%85%B6%E4%BB%96%E7%AE%97%E6%B3%95.html"><strong>其他算法&nbsp;(6)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95.html"><strong>基础算法&nbsp;(23)</strong></a>
	         <p class="cat-children-p"> 
	        
	        	<a href="SVM.html">SVM&nbsp;(1)</a>&nbsp;&nbsp;
	        
	        	<a href="SNE.html">SNE&nbsp;(1)</a>&nbsp;&nbsp;
	        
	        	<a href="EM.html">EM&nbsp;(5)</a>&nbsp;&nbsp;
	        
	        	<a href="%E5%86%B3%E7%AD%96%E6%A0%91.html">决策树&nbsp;(2)</a>&nbsp;&nbsp;
	        
	        	<a href="HMM.html">HMM&nbsp;(3)</a>&nbsp;&nbsp;
	        
	        	<a href="%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.html">集成学习&nbsp;(8)</a>&nbsp;&nbsp;
	        
	        	<a href="%E9%99%8D%E7%BB%B4.html">降维&nbsp;(3)</a>&nbsp;&nbsp;
	        
	         </p> 
	      </li>
	  
	      <li class="post">
	        <a href="%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.html"><strong>数学基础&nbsp;(14)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="Python%E5%AD%A6%E4%B9%A0.html"><strong>Python学习&nbsp;(2)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html"><strong>神经网络&nbsp;(15)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0.html"><strong>增强学习&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15454660806753.html">深度学习中的正则化-Dropout方法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15446218642343.html">图像相似度方法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15436296136092.html">蒙特卡罗树搜搜 MCTS</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15424711438602.html">人工神经网络-GAN</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15418610530072.html">人工神经网络-SOM自组织系统</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    

<script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>