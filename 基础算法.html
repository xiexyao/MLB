
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  基础算法 - 邪逍遥
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="历经千重罪，练就不死心">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="邪逍遥" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">邪逍遥</a></h1>
  
    <h2>历经千重罪，练就不死心</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15230159235437.html">算法稳定性 stability</a></h1>
			<p class="meta"><time datetime="2018-04-06T19:58:43+08:00" 
			pubdate data-updated="true">2018/4/6</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>无论是基于 VC 维还是 Rademacher 复杂度来推导泛化误差界，所得到的结果均与具体学习算法无关，对所有学习算法都适用。这使得人们能够脱离具体学习算法的设计来考虑学习问题本身的性质，但在另一方面，若希望获得与算法有关的分析结果，则需另辟蹊径。稳定性分析是这方面的一个值得关注的方向。</p>

<p>顾名思义，算法的“稳定性”考察的是算法在输入发生变化时，输出是否会随之发生较大的变化。学习算法的输入是训练集，因此下面我们先定义训练集的两种变化。</p>

<p>给定 \(D=\{z_1=(x_1,y_1),z_2=(x_2,y_2),...,z_m=(x_m,y_m)\}\)，\(x_i\in\mathcal X\) 是来自分布 \(\mathcal D\) 的独立同分布示例，\(y_i=\{-1,+1\}\)。对假设空间 \(\mathcal H:\mathcal X\rightarrow\{-1,+1\}\) 和学习算法 \(\mathcal L\)，令 \(\mathcal L_D\in\mathcal H\) 表示基于训练集 \(D\) 从假设空间 \(\mathcal H\) 中学得的假设。考虑 \(D\) 的以下变化：</p>

<ul>
<li><p>\(D^{\backslash i}\) 表示移除 \(D\) 中第 \(i\) 个样例得到的集合<br/>
\[<br/>
D^{\backslash i} = \{z_1,z_2,...,z_{i-1},z_{i+1},...,z_m\},<br/>
\]</p></li>
<li><p>\(D^i\) 表示替换 \(D\) 中第 \(i\) 个样例得到的集合<br/>
\[<br/>
D^i = \{z_1,z_2,...,z_{i-1},z&#39;_i,z_{i+1},...,z_m\},<br/>
\]</p></li>
</ul>

<p>其中 \(z&#39;_i=(x&#39;_i,y&#39;_i)\)，\(x&#39;_i\) 服从分布 \(\mathcal D\) 并独立于 \(D\)。</p>

<p>损失函数 \(\ell(\mathcal L_D(x),y):\mathcal Y\times \mathcal Y\rightarrow \mathbb R^{+}\) 刻画了假设 \(\mathcal L_D\) 的预测标记 \(\mathcal L_D(x)\) 与真实标记 \(y\) 之间的差别，简记为 \(\ell(\mathcal L_D,z)\)。下面定义关于假设 \(\mathcal L_D\) 的几种损失。</p>

<ul>
<li><p>泛化损失<br/>
\[<br/>
\ell(\mathcal L_D,\mathcal D) = \mathbb E_{x\in\mathcal X,z=(x,y)}[\ell(\mathcal L_D,z)]<br/>
\]</p></li>
<li><p>经验损失<br/>
\[<br/>
\hat \ell(\mathcal L,D) = \frac 1 m\sum_{i=1}^m \ell(\mathcal L_D,z_i)<br/>
\]</p></li>
<li><p>留一 (leave-one-out) 损失<br/>
\[<br/>
\ell_{loo}(\mathcal L,D) = \frac 1 m \sum_{i=1}^m \ell(\mathcal L_{D^{\backslash i}},z_i)<br/>
\]</p></li>
</ul>

<p>下面定义算法的均匀稳定性（uniform stability)：<br/>
<strong>均匀稳定性</strong>：对任何 \(x\in\mathcal X\)，\(z=(x,y)\)，若学习算法 \(\mathcal L\) 满足<br/>
\[<br/>
|\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i},z})| \le \beta,\quad i=1,2,...,m<br/>
\]</p>

<p>则称 \(\mathcal L\) 关于损失函数 \(\ell\) 满足 \(\beta\)-均匀稳定性。</p>

<p>显然，若算法 \(\mathcal L\) 关于损失函数 \(\ell\) 满足 \(\beta\)-均匀稳定性，则有：<br/>
\[<br/>
\begin{align*}<br/>
&amp;|\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{i}},z)|\\<br/>
&amp;\le |\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i}},z)| + |\ell(\mathcal L_{D^i},z) - \ell(\mathcal L_{D^{\backslash i}},z)|\\<br/>
&amp;\le 2\beta<br/>
\end{align*}<br/>
\]</p>

<p>也就是说移除示例的稳定性包含替换示例的稳定性。</p>

<p>再来看几个稍弱一点的概念：</p>

<p><strong>误差稳定性</strong>：对任意 \(D\)，对于所有 \(i\in [0,m]\)，都有：<br/>
\[<br/>
\begin{align*}<br/>
|\ell(\mathcal L_D,\mathcal D) - \ell(\mathcal L_{D^{\backslash i}},\mathcal D)| &amp;=  \Big|\mathbb E\big[\ell(\mathcal L_D,z)\big] - \mathbb E\big[\ell(\mathcal L_{D^{\backslash i}},z)\big]\Big| \\<br/>
&amp;= \Big|\mathbb E\big[\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i}},z)\big]\Big|\\<br/>
&amp;\le \beta<br/>
\end{align*}<br/>
\] </p>

<p><strong>假设稳定性</strong>：对于任意 \(i\in [0,m]\)，当训练数据集 \(D\) 被移除后有：<br/>
\[<br/>
\begin{align*}<br/>
|\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{\backslash i}) | &amp;= \frac 1 m\sum_{j\neq i}\Big| \ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{\backslash i}},z_j)\Big| + \frac 1 m \ell(\mathcal L_{D},z_i)\\<br/>
&amp;\le \frac{(m-1)\beta}{m} + \frac{M}{m}\\<br/>
&amp;\le \beta + \frac M m<br/>
\end{align*}<br/>
\]</p>

<p>若损失函数 \(\ell\) 有界，即对所有 \(D\) 和 \(z=(x,y)\) 有 \(0\le \ell(\mathcal L_D,z) \le M\)，则有</p>

<p><strong>定理1</strong>：给定从分布 \(\mathcal D\) 上独立同分布采样得到的大小为 \(m\) 的示例集 \(D\)，若学习算法 \(\mathcal L\) 满足关于损失函数 \(L\) 的 \(\beta\)-均匀稳定性，且损失函数 \(L\) 的上界为 \(M\)，\(0\lt \delta\lt 1\)，则对任意 \(m\ge 1\)，以至少 \(1-\delta\) 的概率有<br/>
\[<br/>
\begin{align}<br/>
\ell(\mathcal L_D,\mathcal D) &amp;\le \hat \ell(\mathcal L,D) + 2\beta + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\label{lmlm1}\\<br/>
\ell(\mathcal L_D,\mathcal D) &amp;\le \ell_{loo}(\mathcal L,D) + \beta + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\label{lmlm2}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：类比<strong>误差稳定性</strong>，我们可以通过三角不等式得出：<br/>
\[<br/>
\begin{align*}<br/>
|\ell(\mathcal L_D,\mathcal D) - \ell(\mathcal L_{D^{i}},\mathcal D)| &amp;= \Big|\mathbb E\big[\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{i}},z) \big]\Big| \\<br/>
&amp;\le \Big|\mathbb E\big[\ell(\mathcal L_D,z) - \ell(\mathcal L_{D^{\backslash i}},z) \big]\Big| + \Big|\mathbb E\big[\ell(\mathcal L_{D^i},z) - \ell(\mathcal L_{D^{\backslash i}},z) \big]\Big|\\<br/>
&amp;\le 2\beta\\<br/>
\end{align*}<br/>
\]</p>

<p>而使用<strong>假设稳定性</strong>，我们可以得出<br/>
\[<br/>
\begin{align*}<br/>
|\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{i}) | &amp;\le |\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{\backslash i})| + |\hat \ell(\mathcal L,D^{\backslash i}) - \hat \ell(\mathcal L,D^{i})|\\<br/>
&amp;\le 2(\beta + \frac M m)\\<br/>
&amp;= 2\beta + 2\frac M m\\<br/>
\end{align*}<br/>
\]</p>

<p>实际上我们还有更好的上界表示：<br/>
\[<br/>
\begin{align*}<br/>
|\hat \ell(\mathcal L,D) - \hat \ell(\mathcal L,D^{i}) |&amp;= \frac 1 m\sum_{j\neq i}\Big| \ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{i}},z_j)\Big| + \frac 1 m \Big(\ell(\mathcal L_{D},z_i) - \ell(\mathcal L_{D},z&#39;_i)\Big)\\<br/>
&amp;\le \frac 1 m \sum_{j\neq i}\Big(|\ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{\backslash i}},z_j)| + |\ell(\mathcal L_{D^{\backslash i}},z_j) - \ell(\mathcal L_{D^{i}},z_j)| \Big)+ \frac 1 m \Big(\ell(\mathcal L_{D},z_i) - \ell(\mathcal L_{D},z&#39;_i)\Big)\\<br/>
&amp;= \frac 1 m \sum_{j\neq i}|\ell(\mathcal L_{D},z_j) - \ell(\mathcal L_{D^{\backslash i}},z_j)| +\frac 1 m \sum_{j\neq i} |\ell(\mathcal L_{D^{\backslash i}},z_j) - \ell(\mathcal L_{D^{i}},z_j)|+ \frac 1 m \Big(\ell(\mathcal L_{D},z_i) - \ell(\mathcal L_{D},z&#39;_i)\Big)\\<br/>
&amp;\le 2\beta + \frac M m<br/>
\end{align*}<br/>
\]</p>

<p>定义随机变量 \(Z\) 为<br/>
\[<br/>
Z = \ell(\mathcal L_D,\mathcal D) - \hat \ell(\mathcal L,D)<br/>
\]</p>

<p>则 \(Z^i\) 是 \(D\) 被替换为 \(D^{i}\) 的随机变量<br/>
\[<br/>
Z^i = \ell(\mathcal L_{D^i},\mathcal D) - \hat \ell(\mathcal L,D^i)<br/>
\]</p>

<p>所以有<br/>
\[<br/>
\begin{align*}<br/>
|Z-Z^{i}| &amp;= \Big|\big(\ell(\mathcal L_D,\mathcal D) - \hat \ell(\mathcal L,D)\big) - \big(\ell(\mathcal L_{D^{i}},\mathcal D) - \hat \ell(\mathcal L,D^{i})\big) \Big|\\<br/>
&amp;= \Big|\big(\ell(\mathcal L_D,\mathcal D) -\hat \ell(\mathcal L_{D^{i}},\mathcal D)\big) + \big(\ell(\mathcal L,D^{i}) -  \hat \ell(\mathcal L,D)\big) \Big|\\<br/>
&amp;\le \Big|\ell(\mathcal L_D,\mathcal D) -\ell(\mathcal L_{D^{i}},\mathcal D)\Big| + \Big|\hat \ell(\mathcal L,D^{i}) -  \hat \ell(\mathcal L,D)\Big|\\<br/>
&amp;\le 2\beta + 2\beta + \frac M m\\<br/>
&amp;\le 4\beta + \frac M m\\<br/>
\end{align*}<br/>
\]</p>

<p>在 Mcdiarmid 不等式中有 \(c_i = 4\beta + \frac M m\)。</p>

<p>为了求随机变量期望值的边界，我们需要两个特性：</p>

<ul>
<li>\(\mathbb E_D[\ell(\mathcal L_D,z_i)] = \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^{j}},z&#39;)]\)：这个特性成立是因为 \(z_i\) 是从 \(\mathcal D\) 中取样的，\(P(D) = P(D^j)\)。</li>
<li>\(\mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^j},z&#39;)] = \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^{i}},z&#39;)]\)：为了看这个特性成立，我们令 \(D&#39;\) 是一个和 \(D\) 包含相同元素的集合，但是交换 \(z_i\) 和 \(z_j\) 的位置。因为学习算法是顺序要求的，所以 \(\mathcal L_D = \mathcal L_{D&#39;}\)，结合 \(P(D) = P(D&#39;)\) 和上一个特性可以得到此特性。</li>
</ul>

<p>用这两个特性，我们有<br/>
\[<br/>
\begin{align}<br/>
\mathbb E(Z) &amp;= \mathbb E_D[\ell(\mathcal L_D,\mathcal D) - \hat \ell(\mathcal L,D)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;) - \hat \ell(\mathcal L,D)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \mathbb E_{D}[\hat \ell(\mathcal L,D)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \mathbb E_{D}[\frac 1 m \sum_{i=1}^m \ell(\mathcal L_D,z_i)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \frac 1 m \sum_{i=1}^m \mathbb E_{D}[\ell(\mathcal L_D,z_i)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \frac 1 m \sum_{i=1}^m \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^j},z&#39;)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \frac 1 m m \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^j},z&#39;)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;)] - \mathbb E_{D,z&#39;}[\ell(\mathcal L_{D^i},z&#39;)]\nonumber\\<br/>
&amp;= \mathbb E_{D,z&#39;}[\ell(\mathcal L_D,z&#39;) - \ell(\mathcal L_{D^i},z&#39;)]\nonumber\\<br/>
&amp;\le 2\beta\label{mb2b}\\<br/>
\end{align}<br/>
\]</p>

<p>通过 Mcdiarmid 不等式，有<br/>
\[<br/>
\begin{align*}<br/>
P\big[Z - \mathbb E[Z] \le \epsilon\big] &amp;\ge 1- \exp\bigg(\frac{-2\epsilon^2}{\sum_{i=1}^m c_i^2 } \bigg)\\<br/>
&amp;= 1- \exp\bigg(\frac{-2\epsilon^2}{\sum_{i=1}^m (4\beta+\frac M m)^2 } \bigg)\\<br/>
&amp;= 1- \exp\bigg(\frac{-2\epsilon^2}{m (4\beta+\frac M m)^2 } \bigg)\\<br/>
&amp;= 1- \exp\bigg(\frac{-2m\epsilon^2}{(4m\beta+M)^2 } \bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>令<br/>
\[<br/>
\delta = \exp\bigg(\frac{-2m\epsilon^2}{(4m\beta+M)^2 } \bigg)<br/>
\]</p>

<p>如果我们用 \(\delta\) 来表示 \(\epsilon\) 便有<br/>
\[<br/>
\epsilon = (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}<br/>
\]</p>

<p>所以我们知<br/>
\[<br/>
\begin{align*}<br/>
&amp;Z - \mathbb E[Z] \le (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
\end{align*}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立。</p>

<p>结合(\ref{mb2b})可得<br/>
\[<br/>
\begin{align*}<br/>
&amp;Z \le \mathbb E[Z] + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\le 2\beta + (4m\beta + M)\sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
\end{align*}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立。再将 \(Z\) 的定义代入，便可以证明式(\ref{lmlm1})。</p>

<p>类比可以得出式(\ref{lmlm2})的证明，这里不再叙述。</p>

<p>本文<strong>定理1</strong>给出了基于稳定性分析推导出的学习算法 \(\mathcal L\) 学得假设的泛化误差界。从(\ref{lmlm1})可以看出，经验损失与泛化损失之间差别的收敛率为 \(\beta\sqrt{m}\)；若令 \(\beta=O(\frac 1 m)\)，则可保证收敛率为 \(O(\frac{1}{\sqrt{m}})\)，这与VC维(该文章中的<strong>定理1</strong>)和Rademacher复杂度(该文章中的<strong>定理1</strong>)得到的收敛率一致。</p>

<p>需注意，学习算法稳定性分析所关注的是 \(|\hat\ell(\mathcal L,D)-\ell(\mathcal L,\mathcal D)|\)，而假设空间复杂度分析所关注的是 \(\sup_{h\in \mathcal H}|\hat E(h) - E(h)|\)；也就是说稳定性分析不必考虑假设空间所有可能的假设，只需根据自身的特性（稳定性）来讨论输出假设 \(\mathcal L_D\) 的泛化误差界。那么稳定性与可学习性之间有什么关系呢？</p>

<p>首先，必须假设 \(\beta\sqrt{m} \rightarrow 0\)，这样才能保证稳定的学习算法 \(\mathcal L\) 具有一定的泛化能力，即经验损失等于泛化损失，否则可学习性无从谈起。为了方便计算，假定 \(\beta = \frac 1 m\)，代入式(\ref{lmlm1})可得：<br/>
\[<br/>
\begin{equation}<br/>
\ell(\mathcal L,\mathcal D) \le \hat \ell(\mathcal L,D) + \frac 2 m + (4+M)\sqrt{\frac{\ln(1/\delta)}{2m}}\label{lmlm3}\\<br/>
\end{equation}<br/>
\]</p>

<p>对损失函数 \(\ell\) ，若学习算法 \(\mathcal L\) 所输出的假设满足经验损失最小化，则称算法 \(\mathcal L\) 满足经验损失最小化原则，简称算法是 ERM 的。关于学习算法的稳定性和可学习性，有如下定理：</p>

<p><strong>定理2</strong>：若学习算法 \(\mathcal L\) 是 ERM 且稳定的，则假设空间 \(\mathcal H\) 可学习。</p>

<p>证明：令 \(g\) 表示 \(\mathcal H\) 中具有最小泛化损失的假设，即<br/>
\[<br/>
\ell(g,\mathcal D) = \min_{h\in\mathcal H}\ell(h,\mathcal D)<br/>
\]</p>

<p>再令<br/>
\[<br/>
\begin{align*}<br/>
\epsilon&#39; &amp;= \frac{\epsilon}{2},\\<br/>
\frac{\delta}{2} &amp;= 2\exp\Big(-2m(\epsilon&#39;)^2 \Big)<br/>
\end{align*}<br/>
\]</p>

<p>由 Hoeffding 不等式可知，当 \(m\le \frac{2}{\epsilon^2}\ln\frac 4 \delta\) 时<br/>
\[<br/>
|\ell(g,\mathcal D) - \hat \ell(g,D) | \le \frac \epsilon 2<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。令式(\ref{lmlm3})中<br/>
\[<br/>
\frac 2 m + (4+M)\sqrt{\frac{\ln(2/\delta)}{2m}} = \frac \epsilon 2<br/>
\]</p>

<p>解得 \(m=O(\frac{1}{\epsilon^2} \ln \frac 1 \delta)\) 使<br/>
\[<br/>
\ell(\mathcal L,\mathcal D) \le \hat\ell(\mathcal L,D) + \frac \epsilon 2<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 得概率成立，从而可得<br/>
\[<br/>
\begin{align*}<br/>
\ell(\mathcal L,\mathcal D) - \ell(g,\mathcal D) &amp;\le \hat\ell(\mathcal L,D) + \frac{\epsilon}{2} - \bigg(\hat \epsilon(g,D) - \frac \epsilon 2 \bigg)\\<br/>
&amp;\le \hat\ell(\mathcal L,D) - \hat\ell(g,D) + \epsilon\\<br/>
&amp;\le \epsilon<br/>
\end{align*}<br/>
\]</p>

<p>以至少 \(1-\delta\) 得概率成立。<strong>定理2</strong>成立。</p>

<hr/>

<p><a href="">周志华 机器学习</a><br/>
<a href="http://www.jmlr.org/papers/volume2/bousquet02a/bousquet02a.pdf">Stability and Generalization</a><br/>
<a href="https://courses.cs.washington.edu/courses/cse522/11wi/scribes/lecture19.pdf">Algorithmic Stability</a><br/>
<a href="http://101.96.10.64/www.mit.edu/%7E9.520/spring08/Classes/class14.pdf">Generalization Bounds and Stability</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15218222204104.html">Rademacher 复杂度</a></h1>
			<p class="meta"><time datetime="2018-03-24T00:23:40+08:00" 
			pubdate data-updated="true">2018/3/24</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>VC 维的泛化误差是分布无关、数据独立的，也就是对于任何数据分布都成立，这使得基于 VC 维的可学习分析结果具有一定的“普适性”；但从另一方面来说，由于没有考虑数据自身，基于 VC 维得到的泛化误差界通常比较 “松”，对那些与学习问题的典型情况相差甚远的较“坏”分布尤其如此。</p>

<p>Rademacher 复杂度是另一种刻画假设空间复杂度的途径，与 VC 维不同的是，它在一定程度上考虑了数据分布。</p>

<p>给定训练集 \(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)，假设 \(h\) 的经验误差为：<br/>
\[<br/>
\begin{align*}\\<br/>
\hat E(h) &amp;= \frac 1 m \sum_{i=1}^m \mathbf I(h(x_i) \neq y_i )\\<br/>
&amp;= \frac 1 m \sum_{i=1}^m \frac{1-y_ih(x_i)}{2}\\<br/>
&amp;= \frac 1 {2} - \frac 1{2m} \sum_{i=1}^m y_i h(x_i)<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\frac 1 m \sum_{i=1}^m y_ih(x_i)\) 体现了预测值 \(h(x_i)\) 和样例真实标记 \(y_i\) 之间的一致性，若对于所有的 \(i\in\{1,2,...,m\}\) 都有 \(y_i = h(x_i)\) ，则 \(\frac 1 m \sum_{i=1}^m y_ih(x_i)\) 取最大值 1 。也就是说，经验误差最小的假设是：<br/>
\[<br/>
\begin{equation}<br/>
{\arg\min}_{h\in \mathcal H}\frac 1 m \sum_{i=1}^m y_i h(x_i)\label{ahm}\\<br/>
\end{equation}<br/>
\]</p>

<p>在现实任务中，样本标记可能受到噪音影响，即对某些样例 \((x_i,y_i)\)，\(y_i\) 可能或许已经受到影响，不再是 \(x_i\) 的真实标记，在此情形下，选择假设空间 \(\mathcal H\) 中表现最好的假设，有时还不如选择 \(\mathcal H\) 中事先考虑了随机噪声影响的假设。</p>

<p>考虑随机变量 \(\sigma_i\) ，它以 0.5 的概率取值 -1，以 0.5 的概率取值 +1，称为 Radermacher 随机变量：<br/>
\[<br/>
P(\sigma_i = 1) = P(\sigma_i = -1) = 0.5<br/>
\]</p>

<p>基于 \(\sigma_i\)，可将式 \ref{ahm} 重写为：<br/>
\[<br/>
\begin{equation}<br/>
\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \label{shm}<br/>
\end{equation}<br/>
\]</p>

<p>\(\mathcal H\) 是无限假设空间，有可能取不到最大值，因此使用上确界带条最大值。</p>

<p>考虑 \(\mathcal H\) 中的所有假设，对 \ref{shm} 式取期望可得：<br/>
\[<br/>
\begin{equation}<br/>
\mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \bigg] \label{eshm}\\<br/>
\end{equation}<br/>
\]</p>

<p>其中 \(\mathbb \sigma=\{\sigma_1,\sigma_2,...,\sigma_m\}\) ，式 \ref{eshm} 的取值范围为 \([0,1]\)，它体现了假设空间 \(\mathcal H\) 的表达能力，例如当 \(|\mathcal H| =1 \) 时，\(\mathcal H\) 中仅有一个假设，这时可计算出式 \ref{eshm} 的值为0：<br/>
\[<br/>
\mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \bigg] = 0.5 \cdot h(x_i) - 0.5\cdot h(x_i) = 0<br/>
\]</p>

<p>当 \(|\mathcal H|=2^m\) 且 \(\mathcal H\) 能打散 \(D\) 时，对于任意的 \(\mathbb \sigma\) 都存在一个假设 \(h(x_i) = \sigma_i;i=1,2,...,m\)，这时可计算出式 \ref{eshm} 的值为1：<br/>
\[<br/>
\mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i h(x_i) \bigg] =  \frac 1 m\bigg(\sum_{h(x_i)=1} 1\cdot h(x_i) + \sum_{h(x_i) = -1} (-1)\cdot h(x_i)\bigg) = \frac 1 m \sum_{i=1}^m |h(x_i)| = 1<br/>
\]</p>

<p>考虑实值函数空间 \(\mathcal F:\mathcal Z\rightarrow \mathbb R\)。令 \(Z=\{z_1,z_2,...,z_m \}\)，其中 \(z_i \in \mathcal Z\)，将 \ref{eshm} 中的 \(\mathcal X\) 和 \(\mathcal H\) 替换为 \(\mathcal Z\) 和 \(\mathcal F\) 可得</p>

<p><strong>定义1</strong>：函数空间 \(\mathcal F\) 关于 \(Z\) 的经验 Rademacher 复杂度：<br/>
\[<br/>
\begin{equation}<br/>
\hat R_Z(\mathcal F) = \mathbb E_\sigma\bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i f(z_i) \bigg]\label{hrme}\\<br/>
\end{equation}<br/>
\]</p>

<p>经验 Rademacher 复杂度衡量了函数空间 \(\mathcal F\) 与随机噪声在集合 \(Z\) 中的相关性。通常我们希望了解函数空间 \(\mathcal F\) 在 \(\mathcal Z\) 上关于 \(\mathcal D\) 的相关性，因此，对所有从 \(\mathcal D\) 独立同分布采样而得的大小为 \(m\) 的集合 \(Z\) 求期望可得：</p>

<p><strong>定义2</strong>：函数空间 \(\mathcal F\) 关于 \(\mathcal Z\) 上分布 \(\mathcal D\) 的 Rademacher 复杂度：<br/>
\[<br/>
\begin{equation}<br/>
R_m(\mathcal F) = \mathbb E_{Z\subset \mathcal Z:|Z|=m}\bigg[ \hat R_Z(\mathcal F) \bigg] \label{rmmm}\\<br/>
\end{equation}<br/>
\]</p>

<p>基于 Rademacher 复杂度可得关于函数空间 \(\mathcal F\) 的泛化误差界。</p>

<p><strong>定理1</strong> 对实数函数空间 \(\mathcal F:\mathcal Z\rightarrow[0,1]\)，根据分布 \(\mathcal D\) 从 \(\mathcal Z\) 中独立同分布采样得到示例集集 \(Z=\{z_1,z_2,...,z_m\}\)，\(z_i \in \mathcal Z\)，\(0\lt \delta \lt 1\)，对任意的 \(f\in \mathcal F\)，以至少 \(1-\delta\) 的概率有：<br/>
\[<br/>
\begin{align}<br/>
\mathbb E[f(z)] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\label{mdl1}\\<br/>
\mathbb E[f(z)] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2\hat R_Z(\mathcal F) + 3\sqrt{\frac{\ln(1/\delta)}{2m}}\label{mdl2}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：令<br/>
\[<br/>
\begin{align}<br/>
\hat E_Z(f) &amp;= \frac 1 m \sum_{i=1}^m f(z_i)\label{hate}\\<br/>
\Phi(Z) &amp;= \sup_{f\in\mathcal F}\mathbb E[f] - \hat E_Z(f)\label{phiz}<br/>
\end{align}<br/>
\]</p>

<p>同时令 \(Z&#39;\) 为只与 \(Z\) 有一个示例不同的训练集，不妨设 \(z_m\in Z\) 和 \(z_m&#39;\in Z&#39;\) 为不同示例，可得：<br/>
\[<br/>
\begin{align*}<br/>
\Phi(Z&#39;) - \Phi(Z) = \bigg(\sup_{f\in \mathcal F}\mathbb E[f] - \hat E_{Z&#39;}(f) \bigg) - \bigg (\sup_{f \in \mathcal F} \mathbb E[f] - \hat E_Z(f) \bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(f&#39; = {\arg\max}_{f\in \mathcal F} E[f] - \hat E_{Z&#39;}(f)\) 代入上式：<br/>
\[<br/>
\begin{align*}<br/>
\Phi(Z&#39;) - \Phi(Z) &amp;= \bigg(\sup_{f\in \mathcal F}\mathbb E[f] - \hat E_{Z&#39;}(f) \bigg) - \bigg (\sup_{f \in \mathcal F} \mathbb E[f] - \hat E_Z(f) \bigg)\\<br/>
&amp;\le \bigg(\mathbb E[f&#39;] - \hat E_{Z&#39;}(f&#39;) \bigg) - \bigg(\mathbb E[f&#39;] - \hat E_Z(f&#39;) \bigg)\\<br/>
&amp;\le \hat E_Z(f&#39;) - \hat E_{Z&#39;}(f&#39;)\\<br/>
&amp;\le \sup_{f\in \mathcal F} \hat E_Z(f) - \hat E_{Z&#39;}(f)\\<br/>
&amp;= \sum_{f\in\mathcal F} \frac {f(z_m) - f(z&#39;_m)}{m}\\<br/>
&amp;\le \frac 1 m<br/>
\end{align*}<br/>
\]</p>

<p>同理可得：<br/>
\[<br/>
\begin{align*}<br/>
\Phi(Z) - \Phi(Z&#39;) &amp;\le \frac 1 m\\<br/>
|\Phi(Z) - \Phi(Z&#39;)| &amp;\le \frac 1 m\\<br/>
\end{align*}<br/>
\]</p>

<p>根据 McDiarmid 不等式可知，对任意的 \(\delta \in (0,1)\)，<br/>
\[<br/>
\begin{align}<br/>
\Phi(Z) \le \mathbb E_Z[\Phi(Z)] + \sqrt{\frac{\ln(1/\delta)}{2m}}\label{phil}<br/>
\end{align}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立，下面来估计 \(\mathbb E_Z[\Phi(Z)]\) 的上界：<br/>
\[<br/>
\begin{align}<br/>
\mathbb E_Z[\Phi(Z)] &amp;= \mathbb E_Z\bigg[\sup_{f \in \mathcal F}\mathbb E[f] - \hat E_Z(f) \bigg]\label{mep1}\\<br/>
&amp;= \mathbb E_Z\bigg[ \sup_{f\in \mathcal F} \mathbb E_{Z&#39;}[\hat E_{Z&#39;}(f) - \hat E_Z(f)] \bigg]\label{mep2}\\<br/>
&amp;\le \mathbb E_{Z,Z&#39;} \bigg[\sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f) \bigg] \label{mep3}\\<br/>
&amp;= \mathbb E_{Z,Z&#39;} \bigg[\sup_{f\in \mathcal F} \frac 1 m \sum_{i=1}^m (f(z&#39;_i) - f(z_i))\bigg]\label{mep4}\\<br/>
&amp;= \mathbb E_{\mathbf \sigma,Z,Z&#39;} \bigg[\sup_{f\in \mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i(f(z&#39;_i) - f(z_i))\bigg]\label{mep5}\\<br/>
&amp;\le \mathbb E_{\mathbf \sigma,Z&#39;} \bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i f(z&#39;_i) \bigg] + \mathbb E_{\mathbf \sigma,Z} \bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m -\sigma_i f(z_i) \bigg]\label{mep6}\\<br/>
&amp;= 2\mathbb E_{\mathbf \sigma,Z} \bigg[\sup_{f\in\mathcal F} \frac 1 m \sum_{i=1}^m \sigma_i f(z_i) \bigg] = 2R_m(\mathcal F) \label{mep7}\\<br/>
\end{align}<br/>
\]</p>

<p>等式 \ref{mep1} 变成 \ref{mep2} 是因为 \(Z&#39;\) 是独立同分布采样于 \(\mathcal Z\) 所以 \(\mathbb E[f] = \mathbb E_{Z&#39;} \bigg[\hat E_{Z&#39;}(f)\bigg]\)。等式 \ref{mep3} 利用 Jensen 不等式和上确界函数的凸性可以得到。在等式 \ref{mep5} 中，我们引入了 Rademacher 变量 \(\sigma_i\) ，它是在 \([-1,1]\) 之间的均匀分布独立随机变量，并不会改变等式 \ref{mep4} 中的期望。当 \(\sigma_i=1\) 时，原式不变；当 \(\sigma_i=-1\) 关联的加数符号翻转，也就相当于交换在 \(Z\) 和 \(Z&#39;\) 中交换 \(z_i\) 和 \(z&#39;_i\)。因为我们是在所有可能的 \(Z\) 和 \(Z&#39;\) 上求期望，因此交换并不会影响最终期望。我们可以利用上确界加法的特性 \(\sup(U+V) \le \sup(U) + \sup(V)\) 得到等式 \ref{mep6}。最后等式 \ref{mep7} 是来源于 Rademacher 复杂度的定义和 \(\sigma_i\) 和 \(-\sigma_i\) 是同一个分布。</p>

<blockquote>
<p><strong>上确界函数的凸性</strong>：假设 \(X\) 是任意随机变量，对于任意的 \(f\) 都有<br/>
\[<br/>
\sup_{y\in Y} \mathbb E[f(X,y)] \le \mathbb E[\sup_{y\in Y} f(X,y)]<br/>
\]</p>

<p>证明很简单，因为<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad f(X,y) \le \sup_{y\in Y} f(X,y)\\<br/>
&amp;\therefore\quad \mathbb E[f(X,y)] \le \mathbb E[\sup_{y\in Y} f(X,y)]\\<br/>
&amp;\therefore\quad \sup_{y\in Y} \mathbb E[f(X,y)] \le \mathbb E[\sup_{y\in Y} f(X,y)]<br/>
\end{align*}<br/>
\]</p>

<p>等式 \ref{mep3} 可以同样由这样得到<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad \hat E_{Z&#39;}(f) - \hat E_Z(f) \le \sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f)\\<br/>
&amp;\therefore\quad \mathbb E_{Z&#39;}[\hat E_{Z&#39;}(f) - \hat E_Z(f)] \le \mathbb E_{Z&#39;}[\sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f)]\\<br/>
&amp;\therefore\quad \sup_{f\in \mathcal F}\mathbb E_{Z&#39;}[\hat E_{Z&#39;}(f) - \hat E_Z(f)] \le \mathbb E_{Z&#39;}[\sup_{f\in \mathcal F} \hat E_{Z&#39;}(f) - \hat E_Z(f)]\\<br/>
\end{align*}<br/>
\]</p>
</blockquote>

<p>将式 \ref{mep7} 、\ref{hate} 和 \ref{phiz} 代入式 \ref{phil} 可得：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sup_{f\in\mathcal F}\mathbb E[f] - \frac 1 m \sum_{i=1}^m f(z_i) \le 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
&amp;\Rightarrow \sup_{f\in\mathcal F}\mathbb E[f] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
&amp;\Rightarrow \mathbb E[f] \le \frac 1 m \sum_{i=1}^m f(z_i) + 2R_m(\mathcal F) + \sqrt{\frac{\ln(1/\delta)}{2m}}\\<br/>
\end{align*}<br/>
\]</p>

<p>至此，式 \ref{mdl1} 得证。</p>

<p>由<strong>定义2</strong>可知，改变 \(Z\) 中的一个示例对 \(\hat R_Z(\mathcal F)\) 的值所造成的改变最多为 \(1/m\)。由 McDiarmid 不等式可知：<br/>
\[<br/>
\begin{equation}<br/>
R_m(\mathcal F) \le \hat R_Z(\mathcal F) + \sqrt{\frac{\ln(2/\delta)}{2m}}\label{rmmf}<br/>
\end{equation}<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。再由 \ref{phil} 可知：<br/>
\[<br/>
\begin{equation}<br/>
\Phi(Z) \le \mathbb E_Z[\Phi(Z)] + \sqrt{\frac{\ln(2/\delta)}{2m}}\label{plme}\\<br/>
\end{equation}<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。</p>

<p>将式 \ref{mep7} 代入式 \ref{plme} 可得：<br/>
\[<br/>
\begin{align}<br/>
\Phi(Z) &amp;\le 2R_m(\mathcal F) + \sqrt{\frac{\ln(2/\delta)}{2m}}\nonumber\\<br/>
&amp;\le 2\big( \hat R_Z(\mathcal F) + \sqrt{\frac{\ln(2/\delta)}{2m}} \big) + \sqrt{\frac{\ln(2/\delta)}{2m}}\nonumber\\<br/>
&amp;= 2\hat R_Z(\mathcal F) + 3\sqrt{\frac{\ln(2/\delta)}{2m}}\label{2hrz}\\<br/>
\end{align}<br/>
\]</p>

<p>以至少 \(1-\delta\) 的概率成立。</p>

<p>将 \ref{2hrz} 、\ref{hate} 和 \ref{phiz} 代入式 \ref{phil} 得式 \ref{mdl2} 得证。</p>

<p>上面证明的<strong>定理1</strong>的函数空间 \(\mathcal F\) 是区间 \([0,1]\) 上的实值函数，因此该定理只适用于回归问题。对二分类问题，我们有下面的定理：</p>

<p><strong>定理2</strong>：对假设空间 \(\mathcal H:\mathcal X\rightarrow \{-1,+1\}\)，根据分布 \(\mathcal D\) 从 \(\mathcal X\) 中独立同分布采样得到示例集 \(D=\{x_1,x_2,...,x_m \}\)，\(x_i\in \mathcal X\)，\(0\lt \delta \lt 1\)，对任意 \(h \in \mathcal H\)，以至少 \(1-\delta\) 的概率有：<br/>
\[<br/>
\begin{align}<br/>
E(h) &amp;\le \hat E(h) + R_m(\mathcal H) + \sqrt{\frac{\ln(1/\delta)}{2m}}\label{elhe1}\\<br/>
E(h) &amp;\le \hat E(h) + R_D(\mathcal H) + 3\sqrt{\frac{\ln(1/\delta)}{2m}}\label{elhe2}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：对二分类问题的假设空间 \(\mathcal H\)，令\(\mathcal Z=\mathcal X\times \{-1,+1\}\)，对 \(\mathcal H\) 中假设 \(h\) 变形为：<br/>
\[<br/>
f_h(z) = f_h(x,y) = \mathbf I(h(x) \neq y)<br/>
\]</p>

<p>于是就可以将值域在 \(\{-1,1\}\) 的假设空间 \(\mathcal H\) 转换为值域为 \([0,1]\) 的函数空间 \(\mathcal F_{\mathcal H} = \{f_h:h\in \mathcal H\}\)，由Radermacher 复杂度的<strong>定义1</strong> 有：<br/>
\[<br/>
\begin{align}<br/>
\hat R_Z(\mathcal F_{\mathcal H}) &amp;= \mathbb E_\sigma\bigg[\sup_{f_h\in\mathcal F_{\mathcal H}} \frac 1 m \sum_{i=1}^m \sigma_i f_h(x_i,y_i) \bigg]\nonumber\\<br/>
&amp;= \mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i \mathbf I(h(x_i)\neq y_i) \bigg]\nonumber\\<br/>
&amp;= \mathbb E_\sigma\bigg[\sup_{h\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i \frac{1-y_i h(x_i)}{2} \bigg]\nonumber\\<br/>
&amp;= \frac 1 2\mathbb E_\sigma\bigg[ \frac 1 m \sum_{i=1}^m \sigma_i + \sup_{h\in \mathcal H} \frac 1 m \sum_{i=1}^m(-y_i\sigma_i h(x_i)) \bigg]\nonumber\\<br/>
&amp;= \frac 1 2\mathbb E_\sigma\bigg[\sup_{h\in \mathcal H} \frac 1 m \sum_{i=1}^m(-y_i\sigma_i h(x_i)) \bigg]\label{f12m}\\<br/>
&amp;= \frac 1 2\mathbb E_\sigma\bigg[\sup_{h\in \mathcal H} \frac 1 m \sum_{i=1}^m(\sigma_i h(x_i)) \bigg]\label{f12m2}\\<br/>
&amp;= \frac 1 2 \hat R_D(\mathcal H)\label{f12m3}\\<br/>
\end{align}<br/>
\]</p>

<p>在式 \ref{f12m} 中由于 \(-y_i\sigma_i\) 与 \(\sigma_i\) 的分布相同，所以可以转换成式 \ref{f12m2} 结果不变。</p>

<p>对上式取期望后可得<br/>
\[<br/>
\begin{align}<br/>
R_m(\mathcal F_{\mathcal H}) = \frac 1 2R_m(\mathcal H)\label{rmmfm}<br/>
\end{align}<br/>
\]</p>

<p>由<strong>定理1</strong>和式(\ref{f12m3})和(\ref{rmmfm})可知<strong>定理2</strong>成立。</p>

<p><strong>定理2</strong>给出了基于 Rademacher 复杂度的泛化误差界。我们知道VC维的泛化误差界式分布无关、数据独立的，而基于 Rademacher 复杂度的泛化误差界(\ref{mdl1})与分布 \(\mathcal D\) 有关，式(\ref{mdl2})与数据 \(D\) 有关。换言之，基于 Rademacher 复杂度的泛化误差界依赖于具体学习问题上的数据分布，有点类似于为该学习问题“量身定制”的，因此它通常比基于VC维的泛化误差界更紧一些。</p>

<p><strong>Massart引理</strong>：用 \(A\subseteq \mathbb R^m\) 是一个有限集，有 \(R=\max_{x\in A}||x||_2\)，然后满足下式：<br/>
\[<br/>
E_{\sigma} \bigg[\frac 1 m \sup_{x\in A} \sum_{i=1}^m \sigma_i x_i \bigg] \le \frac{R\sqrt{2\ln|A|}}{m}<br/>
\]</p>

<p>其中 \(\sigma_i\) 是一系列在 \(\{−1,+1\}\) 上取值的独立的符合平均分布的随机变量。</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\exp\bigg(t E_{\sigma} \bigg[\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg]\bigg) &amp;\le E_{\sigma} \bigg[\exp\bigg(t\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg)\bigg]\quad\big(\text{Jensen Inequality}\big)\\<br/>
&amp;= E_{\sigma} \bigg[\sup_{x\in A} \exp\bigg(t\sum_{i=1}^m \sigma_i x_i  \bigg)\bigg]\\<br/>
&amp;\le \sum_{x\in A} E_{\sigma} \bigg[\exp\bigg(t\sum_{i=1}^m \sigma_i x_i  \bigg)\bigg]\\ <br/>
&amp;= \sum_{x\in A} \prod_{i=1}^m E_{\sigma} \big[\exp\big(t\sigma_i x_i  \big)\big]\\ <br/>
&amp;\le \sum_{x\in A} \prod_{i=1}^m \exp\bigg( \frac{t^2(2x_i)^2}{8} \bigg)\quad\big(\text{Hoeffding Inequality}\big)\\<br/>
&amp;= \sum_{x\in A} \exp\bigg(\frac{4\sum_{i=1}^m t^2(x_i)^2}{8} \bigg)\\<br/>
&amp;= \sum_{x\in A} \exp\bigg(\frac{t^2}{2} \sum_{i=1}^m (x_i)^2\bigg)\\<br/>
&amp;\le |A| \exp\bigg(\frac{t^2R^2}{2} \bigg)<br/>
\end{align*}<br/>
\]</p>

<p>对两边取对数<br/>
\[<br/>
\begin{align*}<br/>
E_{\sigma} \bigg[\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg] &amp;\le \frac 1 t\log\bigg[|A| \exp\bigg(\frac{t^2R^2}{2} \bigg) \bigg]\\<br/>
&amp;= \frac{\ln|A|}{t} + \frac{tR^2}{2}<br/>
\end{align*}<br/>
\]</p>

<p>对上式右边对 \(t\) 取导数，并令其等于 0，可得令不等式最小的 \(t\)<br/>
\[<br/>
t = \frac{\sqrt{2\ln|A|}}{R}<br/>
\]</p>

<p>所以不等式<br/>
\[<br/>
E_{\sigma} \bigg[\sup_{x\in A} \sum_{i=1}^m \sigma_i x_i  \bigg] \le R\sqrt{2\ln|A|}<br/>
\]</p>

<p><strong>Massart引理</strong>得证。</p>

<p><strong>定理3</strong>：假设空间 \(\mathcal H\)的 Ramacher 复杂度 \(R_m(\mathcal H)\) 与增长函数 \(\Pi_\mathcal H(m)\) 满足<br/>
\[<br/>
R_m(\mathcal H) \le \sqrt{\frac{2\ln\Pi_\mathcal H(m)}{m}}<br/>
\]</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\hat R_Z(\mathcal H) &amp;= \mathbb E_\sigma\bigg[\sup_{f\in\mathcal H} \frac 1 m \sum_{i=1}^m \sigma_i f(z_i) \bigg]\\<br/>
&amp;\le \frac{\sqrt{m} \sqrt{2\ln|\{(h(x_i),...,h(x_m)):h\in \mathcal H|\}}}{m}\quad\big(\text{Massart Lemma}\big)\\<br/>
&amp;= \frac{\sqrt{m} \sqrt{2\ln \Pi_\mathcal H(m)}}{m}\\<br/>
&amp;= \sqrt{\frac{2\ln \Pi_\mathcal H(m)}{m}}<br/>
\end{align*}<br/>
\]</p>

<p>式中 \(R=\sqrt{m}\) 是因为 \(R=\max_{h\in \mathcal H}||h||_2\)，因为 \(h\) 的取值是 \(\{-1,+1\}\)，所以 \(||h||_2 = \sqrt{m}\)。</p>

<p>由式(\ref{elhe1}) 和<strong>定理3</strong>可得<br/>
\[<br/>
E(h) \le \hat E(h) + \sqrt{\frac{2d\ln(em/d)}{m}} + \sqrt{\frac{\ln(1/\delta)}{2m}}<br/>
\]</p>

<p>也就是说，我们从 Rademacher 复杂度和增长函数就能推导出基于 VC 维的泛化误差界。</p>

<hr/>

<p><a href="">周志华 机器学习</a><br/>
<a href="https://math.stackexchange.com/questions/2230255/supremum-of-expectation-le-expectation-of-supremum">supremum of expectation and expectation of supremum</a><br/>
<a href="http://www.it610.com/article/1342038.htm">FML 学习笔记三</a><br/>
<a href="https://cs.nyu.edu/%7Emohri/mls/ml_learning_with_infinite_hypothesis_sets.pdf">Foundations of Machine Learning</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15205961685497.html">隐马尔可夫模型 Hidden Markov Model</a></h1>
			<p class="meta"><time datetime="2018-03-09T19:49:28+08:00" 
			pubdate data-updated="true">2018/3/9</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>关于隐马尔可夫模型有个很生动的例子，假设有一个隐士，他不能够直接获取到天气的观察情况，但是他有一些水藻。民间传说告诉我们水藻的状态与天气状态有一定的概率关系——天气和水藻的状态是紧密相关的。在这个例子中我们有两组状态，观察的状态（水藻的状态）和隐藏的状态（天气的状态）。我们希望为隐士设计一种算法，在不能够直接观察天气的情况下，通过水藻和马尔科夫假设来预测天气。</p>

<p>在这种情况下，观察到的状态序列与隐藏过程有一定的概率关系。我们使用隐马尔科夫模型对这样的过程建模，这个模型包含了一个底层隐藏的随时间改变的马尔科夫过程，以及一个与隐藏状态某种程度相关的可观察到的状态集合。</p>

<p>下图是隐藏状态（天气）与观察序列的示意图，假设隐藏状态由一个简单的一阶马尔可夫过程描述，那么他们之间都相互连接。</p>

<div align="center">
    <img src="media/15205961685497/15366882957510.jpg" width="500" />
</div>

<p>隐藏状态和观察状态之间的连接表示：在给定的马尔可夫过程中，一个隐藏状态生成特定的观察状态的概率。可以很清晰知道一个隐藏状态到所有观察状态的概率之和为1，即图中：<br/>
\[<br/>
\begin{align*}<br/>
P(\text{Dry,Dryish,Damp,Soggy|Sun}) &amp;= 1\\<br/>
P(\text{Dry,Dryish,Damp,Soggy|Cloud}) &amp;= 1\\<br/>
P(\text{Dry,Dryish,Damp,Soggy|Rain}) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p>

<p>除了定义了马尔科夫过程的概率关系，我们还有另一个矩阵，定义为混淆矩阵（confusion matrix），它包含了给定一个隐藏状态后得到的观察状态的概率。对于天气例子，混淆矩阵是<br/>
\[<br/>
\begin{array}{c|cccc}<br/>
&amp;\quad \text{Dry}\quad &amp;\quad \text{Dryish}\quad &amp;\quad \text{Damp}\quad &amp;\quad \text{Soggy}\quad \\\hline<br/>
\text{Sun}\quad  &amp;\quad \text{0.60}\quad &amp;\quad \text{0.20}\quad &amp;\quad \text{0.15}\quad &amp;\quad \text{0.05}\quad \\<br/>
\text{Cloud}\quad &amp;\quad \text{0.25}\quad &amp;\quad \text{0.25}\quad &amp;\quad \text{0.25}\quad &amp;\quad \text{0.25}\quad \\<br/>
\text{Rain}\quad &amp;\quad \text{0.05}\quad &amp;\quad \text{0.10}\quad &amp;\quad \text{0.35}\quad &amp;\quad \text{0.50}\quad \\<br/>
\end{array}<br/>
\]</p>

<p>注意矩阵的每一行之和是 1。</p>

<h3 id="toc_0">隐马尔可夫模型</h3>

<p>一个隐马尔可夫模型通常需要三组参数组成：</p>

<ol>
<li><p>状态转移概率：模型在各个状态间转换的概率，通常记为矩阵 \(\mathbb A = [a_{ij}]_{N\times N}\)，其中：<br/>
\[<br/>
a_{ij} = P(x_{t+1} = s_j|x_t = s_i),\quad 1\le i,j\le N<br/>
\]</p>

<p>表示在任意时刻 \(t\)，状态 \(s_i\) 转移到状态 \(s_j\) 的概率。</p></li>
<li><p>输出观察概率：模型根据当前隐藏状态获得各个观察值的概率，通常记为矩阵 \(\mathbb B = [b_{ij}]_{N\times M}\)，其中<br/>
\[<br/>
b_{i}(j) = P(y_t = o_j|x_t = s_i),\quad i\le i\le N,1\le j\le M<br/>
\]</p>

<p>表示在任意时刻 \(t\)，若状态为 \(s_i\)，则观察值 \(o_j\) 被获取的概率。</p></li>
<li><p>初始状态概率：模型在初始时刻各状态出现的概率，通常记为 \(\mathbb\pi=(\pi_1,\pi_2,...,\pi_N)\)，其中：<br/>
\[<br/>
\pi_i = P(x_1 = s_i),\quad 1\le i\le N<br/>
\]</p>

<p>表示模型初始状态为 \(s_i\) 的概率。</p></li>
</ol>

<p>通过指定状态空间 \(\mathcal Y\)、观察空间 \(\mathcal X\) 和上述三组参数，就能确定一个隐马尔可夫模型，通常用其参数 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 来指代。给定隐马尔可夫模型 \(\lambda\)，它按如下过程产生观察序列 \(\{y_1,y_2,...,y_n\}\)：</p>

<p>(1)、设置 \(t=1\)，并根据初始状态概率 \(\mathbb \pi\) 选择初始状态 \(x_1\)；</p>

<p>(2)、根据状态 \(x_t\) 和输出观测概率 \(B\) 选择观测变量取值 \(y_t\)；</p>

<p>(3)、根据状态 \(x_t\) 和状态转移矩阵 \(A\) 转移模型隐藏状态，即确定 \(x_{t+1}\)；</p>

<p>(4)、若 \(t\lt n\)，设置 \(t=t+1\)，并转移到第 (2) 步，否则停止。</p>

<p>其中 \(x_t\in\{s_1,s_2,...,s_N \}\) 和 \(y_t\in\{o_1,o_2,...,o_M \}\) 分别为第 \(t\) 时刻的隐藏状态和观测状态。</p>

<p>在实际应用中，人们常关注隐马尔可夫模型的三个基本问题：</p>

<ul>
<li><p>给定模型 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\)，如何有效计算其产生观测序列 \(\mathbb y=\{y_1,y_2,...,y_n \}\) 的概率 \(P(\mathbb x|\lambda)\)，换言之，如何评估模型与观测序列之间的匹配程度？</p></li>
<li><p>给定模型 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 和观测序列 \(\mathbb y=\{y_1,y_2,...,y_n \}\)，如何找到与此观测序列最匹配的隐藏状态序列 \(\mathbb y=\{ y_1,y_2,...,y_n \}\)？换言之，如何根据观测序列推断出一串的模型状态？</p></li>
<li><p>给定模型 \(\mathbb x = \{x_1,x_2,...,x_n \}\)，如何调整模型参数 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 使得该序列出现的概率 \(\pi(\mathbb x,\lambda)\)？换言之，如何训练模型使其能最好的描述观测数据？</p></li>
</ul>

<p>现在简单说一下如何解决这三个问题：</p>

<h4 id="toc_1">评估</h4>

<p>计算模型 \(\lambda = [\mathbb A,\mathbb B,\mathbb \pi]\) 产生观测序列的状态通常有三种方法：</p>

<ol>
<li><p><strong>穷举法</strong>：</p>

<p>一种计算观察序列概率的方法是找到每一个可能的隐藏状态，并且将这些隐藏状态下的观察序列概率相加。考虑到之前的例子，隐藏状态集合为 \(S=\{\text{Sun},\text{Cloud},\text{Rain}\}\)，观测状态为 \(V=\{\text{Dry},\text{Dryish},\text{Damp},\text{Soggy}\}\)，假设现在观测序列只有一个元素“\(\text{Dry}\)”，我们知道观测值“\(\text{Dry}\)”对应的隐藏状态可能是 \(S\) 中的任意元素，所以观测序列的概率可以表示为：<br/>
\[<br/>
\begin{align*}<br/>
P(\text{Dry}) &amp;= P(\text{Dry},\{\text{Sun},\text{Cloud},\text{Rain}\})\\<br/>
&amp;= P(\text{Dry}|\text{Sun})P(\text{Sun}) + P(\text{Dry}|\text{Cloud})P(\text{Cloud}) + P(\text{Dry}|\text{Rain})P(\text{Rain})\\<br/>
&amp;= \sum_{\text{h} \in |S|} P(\text{Dry}|\text{h})\\<br/>
\end{align*}<br/>
\]</p>

<p>假设现在观测序列有两个元素 \(\{\text{Dry},\text{Soggy}\}\)，类比上面我们首先找出所有可能的隐藏状态序列：<br/>
\[<br/>
\{(\text{Sun},\text{Sun}),(\text{Sun},\text{Cloud}),(\text{Sun},\text{Rain}),(\text{Cloud},\text{Sun}),\\<br/>
  (\text{Cloud},\text{Cloud}),(\text{Cloud},\text{Rain}),(\text{Rain},\text{Sun}),(\text{Rain},\text{Cloud}),(\text{Rain},\text{Rain})\}<br/>
\]</p>

<p>总共是3*3 = 9 种可能，根据每种可能的隐藏状态序列，计算其生成观测序列的概率，比如 \((\text{Sun},\text{Cloud})\)：<br/>
\[<br/>
\begin{align}<br/>
P(\text{Dry},\text{Soggy}|\text{Sun},\text{Cloud}) &amp;= \underbrace{P(\text{Sun})P(\text{Dry}|\text{Sun})}_{t=1} \underbrace{P(\text{Sun}\rightarrow\text{Cloud})P(\text{Soggy}|\text{Cloud})}_{t=2}\nonumber\\<br/>
&amp;= \underbrace{P(\text{Sun})}_{\text{初始概率}} \underbrace{P(\text{Sun}\rightarrow\text{Cloud})}_{\text{转移概率}} \underbrace{P(\text{Dry}|\text{Sun})P(\text{Soggy}|\text{Cloud})}_{\text{观测概率}}\label{uttu}\\<br/>
\end{align}<br/>
\]</p>

<p>同理可以求出其他可能的隐藏状态序列生成观测序列的概率，将9 种可能概率加起来便是观测序列的概率。</p>

<p>由式(\ref{uttu})可以知道状态序列到观测序列的概率分成三个部分，初始概率、状态转移概率和观测概率（对应位置隐藏状态表现为观测值的概率）。现在我们推广到一般形式，列举所有可能的长度为 \(T\) 的状态序列 \(I=(i_1,i_2,...,i_T)\)，求各个状态序列 \(I\) 与观测序列 \(O=(o_1,o_2,...,o_T)\) 的联合概率 \(P(O,I,\lambda)\) ，然后对所有可能的状态序列求和得到 \(P(O|\lambda)\)。</p>

<p>状态序列 \(I=(i_1,i_2,...,i_T)\) 的初始概率为 \(\pi_{i_1}\)；<br/>
状态序列 \(I=(i_1,i_2,...,i_T)\) 的转移概率为 \(a_{i_1 i_2}a_{i_2 i_3}\cdots a_{i_{T-1} i_T}\)；</p>

<p>这两部分合起来就是状态序列 \(I=(i_1,i_2,...,i_T)\) 的概率：<br/>
\[<br/>
P(I|\lambda) = \pi_{i_1}a_{i_1 i_2}a_{i_2 i_3}\cdots a_{i_{T-1} i_T}<br/>
\]</p>

<p>对固定状态序列 \(I=(i_1,i_2,...,i_T)\) ，得到观测序列 \(O=(o_1,o_2,...,o_T)\) 的观测概率：<br/>
\[<br/>
P(O|I,\lambda) = b_{i_1}(o_1)b_{i_2}(o_2)\cdots b_{i_T}(o_T)<br/>
\]</p>

<p>所以 \(O\) 和 \(I\) 同时出现的联合概率为：<br/>
\[<br/>
\begin{align*}<br/>
P(O,I|\lambda) &amp;= \sum_{I} P(I|\lambda) P(O|I,\lambda)\\<br/>
&amp;= \sum_{I} \pi_{i_1}b_{i_1}(o_1) a_{i_1 i_2} b_{i_2}(o_2)\cdots a_{i_{T-1} i_T}b_{i_T}(o_T)<br/>
\end{align*}<br/>
\]</p>

<p>但是，利用上面公式计算量巨大，是 \(O(TN^T)\) 阶的，这种算法不可行的。</p></li>
<li><p><strong>前向算法</strong>：</p>

<p>前向算法定义局部概率 \(\alpha_t(i)\) 表示观测时刻 \(t\) 之前观测状态的序列为 \(o_1,o_2,...o_t\)的概率为前向概率。记为：<br/>
\[<br/>
\alpha_t(i) = P(o_1,o_2,...,o_t,i_t = s_i|\lambda)<br/>
\]</p>

<p>递推关系为<br/>
\[<br/>
\alpha_{t+1}(i) = \bigg[\sum_{j=1}^N \alpha_t(j) a_{ji}\bigg] b_{i}(o_{t+1})<br/>
\]</p>

<p>算法步骤为</p>

<p><strong>输入</strong>：假设隐马尔可夫模型 \(\lambda=(\mathbb A,\mathbb B,\pi)\)，观测序列 \(O=(o_1,o_2,...,o_T)\)，隐藏状态总共包含 N 种状态 \(S = (s_1,s_2,...,s_N)\)；<br/>
<strong>输出</strong>：观测序列概率 \(P(O|\lambda)\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li><p>初值<br/>
\[<br/>
\alpha_1(i) = \pi_{i}b_i(o_1),\quad i=1,2,\cdots,N<br/>
\]</p></li>
<li><p>递推 对 \(t=1,2,\cdots,T-1\)<br/>
\[<br/>
\alpha_{t+1}(i) = \bigg[ \sum_{j=1}^N \alpha_t(j)a_{ji} \bigg] b_i(o_{t+1}),\quad i=1,2,\cdots,N<br/>
\]</p></li>
<li><p>终止<br/>
\[<br/>
P(O|\lambda) = \sum_{i=1}^N \alpha_T(i)<br/>
\]</p></li>
</ul>

<p>还是以天气的例子，假设 \(T=3\)，\(O=(\text{Dry,Dryish,Soggy})\)，状态转移矩阵如下图：<br/>
\[<br/>
\begin{array}{c|ccc}<br/>
&amp;\quad \text{Sun}\quad &amp;\quad \text{Cloud}\quad &amp;\quad \text{Rain}\quad \\\hline<br/>
\text{Sun}\quad  &amp;\quad \text{0.5}\quad &amp;\quad \text{0.2}\quad &amp;\quad \text{0.3}\quad \\<br/>
\text{Cloud}\quad &amp;\quad \text{0.3}\quad &amp;\quad \text{0.5}\quad &amp;\quad \text{0.2}\quad\\<br/>
\text{Rain}\quad &amp;\quad \text{0.2}\quad &amp;\quad \text{0.3}\quad &amp;\quad \text{0.5}\quad\\<br/>
\end{array}<br/>
\]</p>

<p>初始值概率为\(\pi=(\text{Sun,Cloud,Rain})=(0.2,0.4,0.4)\)</p>

<p>按照算法，（1）计算初值<br/>
\[<br/>
\alpha_1(1) = \pi_1b_1(o_1) = 0.2*0.6 = 0.12\\<br/>
\alpha_1(2) = \pi_2b_2(o_1) = 0.4*0.25 = 0.1\\<br/>
\alpha_1(3) = \pi_3b_3(o_1) = 0.4*0.05 = 0.02\\<br/>
\]</p>

<p>（2）递推计算<br/>
\[<br/>
\alpha_2(1) = \bigg[\sum_{i=1}^3 \alpha_1(i) a_{i1} \bigg] b_1(o_2) = \bigg[ 0.12 * 0.5 + 0.1 * 0.3 + 0.02 * 0.2\bigg ] * 0.2 = 0.0188 \\<br/>
\alpha_2(2) = \bigg[\sum_{i=1}^3 \alpha_1(i) a_{i2} \bigg] b_2(o_2) = \bigg[ 0.12 * 0.2 + 0.1 * 0.5 + 0.02 * 0.3\bigg ] * 0.25 =  0.02 \\<br/>
\alpha_2(3) = \bigg[\sum_{i=1}^3 \alpha_1(i) a_{i3} \bigg] b_3(o_2) = \bigg[ 0.12 * 0.3 + 0.1 * 0.2 + 0.02 * 0.5\bigg ] * 0.10  = 0.0066\\<br/>
\\<br/>
\alpha_3(1) = \bigg[\sum_{i=1}^3 \alpha_2(i) a_{i1} \bigg] b_1(o_3) = \bigg[ 0.0188 * 0.5 + 0.02 * 0.3 + 0.0066 * 0.2 \bigg] * 0.05 = 0.000836 \\<br/>
\alpha_3(2) = \bigg[\sum_{i=1}^3 \alpha_2(i) a_{i2} \bigg] b_2(o_3) = \bigg[ 0.0188 * 0.2 + 0.02 * 0.5 + 0.0066 * 0.3 \bigg] * 0.25 = 0.003935 \\<br/>
\alpha_3(3) = \bigg[\sum_{i=1}^3 \alpha_2(i) a_{i3} \bigg] b_3(o_3) = \bigg[ 0.0188 * 0.3 + 0.02 * 0.2 + 0.0066 * 0.5 \bigg] * 0.5 = 0.00647 \\<br/>
\]</p>

<p>（3）终止：<br/>
\[<br/>
P(O|\lambda) = \sum_{i=1}^3 \alpha_3(i) = 0.000836+0.003935 + 0.00647 = 0.011241<br/>
\]</p></li>
<li><p><strong>后向算法</strong></p>

<p>后向算法与前向算法原理，定义局部概率 \(\beta_t(i)\) 表示观测时刻 \(t\) 之后的观测序列 \(o_{t+1},o_{t+2},...,o_T\) 的概率为后向概率。记为：<br/>
\[<br/>
\beta_t(i) = P(o_{t+1},o_{t+2},...,o_T|i_t=s_i,\lambda)<br/>
\]</p>

<p>后向算法的递推公式为<br/>
\[<br/>
\beta_t(i-1) = \sum_{j=1}^N \beta_t(j) a_{ij} b_{j}(o_{t+1})<br/>
\]</p>

<p>算法初始时，\(t=T\)，此时不存在后续时刻观测序列，此时 \(\beta_T(i) = 1\)。</p>

<p><strong>输入</strong>：假设隐马尔可夫模型 \(\lambda=(A,B,\pi)\)，观测序列 \(O=(o_1,o_2,...,o_T)\)。隐藏状态总共包含 \(m\) 种状态 \(S = (s_1,s_2,...,s_m)\)；<br/>
<strong>输出</strong>：观测序列概率 \(P(O|\lambda)\)<br/>
<strong>算法过程</strong>：</p>

<ul>
<li><p>初值<br/>
\[<br/>
\beta_T(i) = 1,\quad i=1,2,\cdots,T<br/>
\]</p></li>
<li><p>递推 对 \(t=T-1,T-2,\cdots,1\)<br/>
\[<br/>
\beta_{t-1}(i) = \sum_{j=1}^N \beta_t(j)a_{ij} b_j(o_{t+1}),\quad i=1,2,\cdots,N<br/>
\]</p></li>
<li><p>终止<br/>
\[<br/>
P(O|\lambda) = \sum_{i=1}^N \beta_1(i)\pi(i)b_i(o_1)<br/>
\]</p></li>
</ul>

<p>以天气的例子，假设 \(T=3\)，\(O=(\text{Dry,Dryish,Soggy})\)，状态转移矩阵如前向算法所示。初始值概率为\(\pi=(\text{Sun,Cloud,Rain})=(0.2,0.4,0.4)\)</p>

<p>按照算法，（1）计算初值<br/>
\[<br/>
\beta_3(1) = 1\\<br/>
\beta_3(2) = 1\\<br/>
\beta_3(3) = 1\\<br/>
\]</p>

<p>（2）递推计算<br/>
\[<br/>
\begin{align*}<br/>
\beta_2(1) &amp;= \sum_{j=1}^3 \beta_3(j)a_{1j}b_{j}(o_t)\\<br/>
&amp;= 1 * 0.5 * 0.05 + 1 * 0.2 * 0.25 + 1 * 0.3 * 0.5 \\<br/>
&amp;= 0.225\\<br/>
\beta_2(2) &amp;= \sum_{j=1}^3 \beta_3(j)a_{2j}b_{j}(o_t)\\<br/>
&amp;= 1 * 0.3 * 0.05 + 1 * 0.5 * 0.25 + 1 * 0.2 * 0.5 \\<br/>
&amp;= 0.24\\<br/>
\beta_2(3) &amp;= \sum_{j=1}^3 \beta_3(j)a_{3j}b_{j}(o_t)\\<br/>
&amp;= 1 * 0.2 * 0.05 + 1 * 0.3 * 0.25 + 1 * 0.5 * 0.5 \\<br/>
&amp;= 0.335\\<br/>
\beta_1(1) &amp;= \sum_{j=1}^3 \beta_2(j)a_{1j}b_{j}(o_t)\\<br/>
&amp;= 0.225 * 0.5 * 0.20 + 0.24 * 0.2 * 0.25 + 0.335 * 0.3 * 0.10 \\<br/>
&amp;= 0.04455\\<br/>
\beta_1(2) &amp;= \sum_{j=1}^3 \beta_2(j)a_{2j}b_{j}(o_t)\\<br/>
&amp;= 0.225 * 0.3 * 0.20 + 0.24 * 0.5 * 0.25 + 0.335 * 0.2 * 0.10 \\<br/>
&amp;= 0.0502\\<br/>
\beta_1(3) &amp;= \sum_{j=1}^3 \beta_2(j)a_{3j}b_{j}(o_t)\\<br/>
&amp;= 0.225 * 0.2 * 0.20 + 0.24 * 0.3 * 0.25 + 0.335 * 0.5 * 0.10 \\<br/>
&amp;= 0.04375\\<br/>
\end{align*}<br/>
\]</p>

<p>（3）终止：<br/>
\[<br/>
\begin{align*}<br/>
P(O|\lambda) &amp;= \sum_{i=1}^3 \beta_1(i) \pi(i) b_i(o_1) \\<br/>
&amp;= 0.04455 * 0.2 * 0.6 + 0.0502 * 0.4 * 0.25 + 0.04375 * 0.4 * 0.05\\<br/>
&amp;= 0.011241<br/>
\end{align*}<br/>
\]</p></li>
</ol>

<h4 id="toc_2">解码</h4>

<p>对于一个特殊的隐马尔科夫模型(HMM)及一个相应的观察序列，我们常常希望能找到生成此序列最可能的隐藏状态序列。</p>

<ol>
<li><p><strong>穷举法</strong></p>

<p>类似前面的穷举法，对于观测序列 \(O=(o_1,o_2,...,o_t)\)，总共有 \(N^t\) 个可能的隐藏状态序列，其中 \(N\) 是隐藏状态 \(S\) 的个数。然后对于每一个可能隐藏状态序列，计算生成观测序列的状态的概率，再从中选出最大的概率的隐藏状态序列。这种方法可行，但是复杂度很高，不推荐使用。</p></li>
<li><p><strong>维特比算法</strong></p>

<p>关于维特比算法可以看之前的一篇文章介绍，这里直接介绍如何用维比特算法求解解码问题。</p>

<p>导入两个变量 \(\delta\) 和 \(\psi\)，定义在时刻 \(t\) 状态为 \(i\) 的所有单个路径 \((i_1,i_2,...,i_t)\) 中的概率最大值为<br/>
\[<br/>
\delta_t(i) = \max_{i_1,i_2,...,i_{t-1}} P(i_t=i,i_{t-1},...,i_1,o_t,...,o_1|\lambda),\quad i=1,2,...,N<br/>
\]</p>

<p>由定义可得变量 \(\delta\) 的递推公式：<br/>
\[<br/>
\begin{align*}<br/>
\delta_{t+1}(i) &amp;= \max_{i_1,i_2,...,i_{t}} P(i_{t+1}=i,i_{t},...,i_1,o_{t+1},...,o_1|\lambda)\\<br/>
&amp;= \max_{1\le j\le N}[\delta_t(j) a_{ji}]b_i(o_{t+1}),\quad i=1,2,...,N<br/>
\end{align*}<br/>
\]</p>

<p>定义在时刻 \(t\) 状态为 \(i\) 的所有单个路径 \((i_1,i_2,...,i_{t-1},i)\) 中概率最大的路径的第 \(t-1\) 个结点为<br/>
\[<br/>
\psi_t(i) = \arg\max_{1\le j\le N}[\delta_{t-1}(j) a_{ji}],\quad i=1,2,...,N<br/>
\]</p>

<p>下面介绍维比特算法。</p>

<p><strong>输入</strong>：模型 \(\lambda=(A,B,\pi)\) 和观测 \(O=(o_1,o_2,...,o_T)\)；<br/>
<strong>输出</strong>：最优状态序列 \(I=(i^*_1,i^*_2,...,i^*_T)\)；<br/>
<strong>算法过程</strong>：</p>

<ul>
<li><p>初始化<br/>
\[<br/>
\delta_1(i) = \pi_i b_i(o_1),\quad i=1,2,...,N\\<br/>
\psi_1(i) = 0<br/>
\]</p></li>
<li><p>递推，对 \(t=2,3,...,T\)<br/>
\[<br/>
\delta_t(i) = \max_{1\le j\le N}[\delta_t(j) a_{ji}]b_i(o_{t+1}),\quad i=1,2,...,N\\<br/>
\psi_t(i) = \arg\max_{1\le j\le N}[\delta_{t-1}(j) a_{ji}],\quad i=1,2,...,N<br/>
\]</p></li>
<li><p>终止<br/>
\[<br/>
P^* = \max_{1\le i\le N} \delta_{T}(i)\\<br/>
i^*_T = \arg\max_{1\le i\le N}[\delta_T(i)]<br/>
\]</p></li>
<li><p>最优路径回溯，对 \(t=T-1,T-2,...,1\)<br/>
\[<br/>
i^*_t = \psi_{t+1}(i^*_{t+1})<br/>
\]</p></li>
</ul>

<p>求得最优路径 \(I^* = (i^*_1,i^*_2,...,i^*_T)\)。</p>

<p>还是以天气的例子，假设 \(T=3\)，\(O=(\text{Dry,Dryish,Soggy})\)，状态转移矩阵同前向算法中所示，初始值概率为\(\pi=(\text{Sun,Cloud,Rain})=(0.2,0.4,0.4)\)。</p>

<p>按照算法，（1） 初始化，当 \(t=1\) 时，对每一个状态 \(i\)，\(i=1,2,3\)，求状态为 \(i\) 观测 \(o_1\) 为 Dry 的概率，记此概率为 \(\delta_1(i)\)，则：<br/>
\[<br/>
\delta_1(i) = \pi_ib_i(o_i) = \pi_ib_i(\text{Dry}),\quad i=1,2,3<br/>
\]</p>

<p>代入实际数据<br/>
\[<br/>
\delta_1(1) = \pi_1b_1(o_1) = 0.2*0.6 = 0.12\\<br/>
\delta_1(2) = \pi_2b_2(o_1) = 0.4*0.25 = 0.1\\<br/>
\delta_1(3) = \pi_3b_3(o_1) = 0.4*0.05 = 0.02\\<br/>
\]</p>

<p>记录 \(\psi_1(i) = 0\)，\(i=1,2,3\)。</p>

<p>（2）在 \(t=2\) 时，对每一个状态 \(i\)，\(i=1,2,3\)，求在 \(t=1\) 时状态为 \(j\) 观测为 Dry 并在 \(t=2\) 时状态为 \(i\) 观测 \(o_2\) 为 Dryish 的最大概率，记此最大概率为 \(\delta_2(i)\)，则<br/>
\[<br/>
\delta_2(i) = \max_{1\le j\le 3}[\delta_1(j) a_{ji}] b_i(o_2)<br/>
\]</p>

<p>同时，对每一个状态 \(i\)，\(i=1,2,3\)，记录概率最大路径的前一个状态：<br/>
\[<br/>
\psi_2(i) = \arg\max_{1\le j\le 3}[\delta_1(j)a_{ji}],\quad i=1,2,3<br/>
\]</p>

<p>计算：<br/>
\[<br/>
\begin{align*}<br/>
\delta_2(1) &amp;= \max_{1\le j\le 3}[\delta_1(j)a_{j1}] b_1(o_2)\\<br/>
&amp;= \max{j}\{0.12* 0.5,0.1 * 0.3,0.02*0.2 \}*0.2\\<br/>
&amp;= 0.012\\<br/>
\psi_2(1) &amp;= 1\\<br/>
\delta_2(2) &amp;= \max_{1\le j\le 3}[\delta_1(j)a_{j2}] b_2(o_2)\\<br/>
&amp;= \max{j}\{0.12* 0.2,0.1 * 0.5,0.02*0.3 \}*0.25\\<br/>
&amp;= 0.0125\\<br/>
\psi_2(2) &amp;= 2\\<br/>
\delta_2(3) &amp;= \max_{1\le j\le 3}[\delta_1(j)a_{j3}] b_3(o_2)\\<br/>
&amp;= \max{j}\{0.12* 0.3,0.1 * 0.2,0.02*0.5 \}*0.1\\<br/>
&amp;= 0.0036\\<br/>
\psi_2(3) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p>

<p>同样在 \(t=3\) 时，<br/>
\[<br/>
\begin{align*}<br/>
\delta_3(1) &amp;= \max_{1\le j\le 3}[\delta_2(j)a_{j1}] b_1(o_3)\\<br/>
&amp;= \max{j}\{0.012* 0.5,0.0125 * 0.3,0.0036*0.2 \}*0.05\\<br/>
&amp;= 0.0003\\<br/>
\psi_3(1) &amp;= 1\\<br/>
\delta_3(2) &amp;= \max_{1\le j\le 3}[\delta_2(j)a_{j2}] b_2(o_3)\\<br/>
&amp;= \max{j}\{0.012* 0.2,0.0125 * 0.5,0.0036*0.3 \}*0.25\\<br/>
&amp;= 0.0015625\\<br/>
\psi_3(2) &amp;= 2\\<br/>
\delta_3(3) &amp;= \max_{1\le j\le 3}[\delta_2(j)a_{j3}] b_3(o_3)\\<br/>
&amp;= \max{j}\{0.012* 0.3,0.0125 * 0.2,0.0036*0.5 \}*0.5\\<br/>
&amp;= 0.0018\\<br/>
\psi_3(3) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p>

<p>（3）以 \(P^*\) 表示最优路径的概率，则<br/>
\[<br/>
P^* = \max_{1\le i\le 3}\delta_3(i) = 0.0018<br/>
\]</p>

<p>最优路径终点是 \(i^*_3\)：<br/>
\[<br/>
i^*_3 = \arg\max_{i}[\delta_3(i)] = 3<br/>
\]</p>

<p>（4）由最优路径的终点 \(i^*_3\) ，逆向找到 \(i^*_2\) 和 \(i^*_1\)：<br/>
\[<br/>
i^*_2 = \psi_3(i^*_3) = 1\\<br/>
i^*_1 = \psi_2(i^*_2) = 1\\<br/>
\]</p>

<p>最优路径为 \(I=(i^*_1,i^*_2,i^*_3) = (1,1,3)\)</p></li>
</ol>

<h4 id="toc_3">学习</h4>

<p>与HMM模型相关的“有用”的问题是评估（前向算法）和解码（维特比算法）——它们一个被用来测量一个模型的相对适用性，另一个被用来推测模型隐藏的部分在做什么（“到底发生了”什么）。可以看出它们都依赖于隐马尔科夫模型（HMM）参数这一先验知识——状态转移矩阵，混淆（观察）矩阵，以及 \(\pi\) 向量（初始化概率向量）。可以分为监督学习算法和非监督学习算法--Baum-Welch算法。</p>

<ol>
<li><p><strong>监督学习算法</strong></p>

<p>假设已给出训练数据包含 \(S\) 个长度相同的观测序列和对应的状态序列 \(\{(O_1,I_1),(O_2,I_2),...,(O_S,I_S)\}\)，那么可以利用极大似然估计法来估计隐马尔可夫模型的参数。具体方法如下.</p>

<p>（1）转移概率 \(a_{ij}\) 的估计</p>

<p>设样本中时刻 \(t\) 处于 \(i\) 状态，时刻 \(t+1\) 转移到 \(j\) 状态的频数为 \(A_{ij}\) ，那么转移概率 \(a_{ij}\) 的估计为：<br/>
\[<br/>
\hat a_{ij} = \frac{A_{ij}}{\sum_{j=1}^M A_{ij}},\quad i=1,2,...,N;j=1,2,...,N <br/>
\]</p>

<p>（2）观测概率 \(b_j(k)\) 的估计<br/>
设样本汇总状态为 \(j\) 并观测为 \(k\) 的频数为 \(B_{jk}\)，那么状态为 \(j\) 观测为 \(k\) 的概率 \(b_j(k)\) 为<br/>
\[<br/>
\hat b_j(k) = \frac{B_{jk}}{\sum_{k=1}^N B_{jk}},\quad j=1,2,...,N,k=1,2,...,M<br/>
\]</p>

<p>（3）初始状态概率 \(\pi_i\) 的估计 \(\hat \pi_i\) 为 \(S\) 个样本中初始状态为 \(q_i\) 的频率。</p>

<p>由于监督学习需要使用训练数据，而人工标注训练数据往往代价很高，有时候就会利用非监督学习的方法。</p></li>
<li><p><strong>Baum-Welch算法</strong></p>

<blockquote>
<p>在讲解Baum-Welch算法之前，我们先讲解一下单个状态和两个状态的计算公式<br/>
( a ) 给定模型 \(\lambda\) 和观测 \(O\)，在时刻 \(t\) 处于状态 \(s_i\) 的概率，记<br/>
\[<br/>
\gamma_t(i) = P(i_t = s_i|O,\lambda)<br/>
\]</p>

<p>容易得<br/>
\[<br/>
\gamma_t(i) = \frac{P(i_t = s_i,O|\lambda)}{P(O|\lambda)}<br/>
\]</p>

<p>前向概率 \(\alpha_t(i)\) 的定义为<br/>
\[<br/>
\alpha_t(i) = P(o_1,o_2,...,o_t,i_t = s_i|\lambda)<br/>
\]</p>

<p>后向概率 \(\beta_t(i)\) 的定义为<br/>
\[<br/>
\beta_t(i) = P(o_{t+1},o_{t+2},...,o_T|i_t=s_i,\lambda)<br/>
\]</p>

<p>由前向概率和后向概率的定义可知：<br/>
\[<br/>
\alpha_t(i) \beta_t(i) = P(O,i_t = s_i|\lambda)<br/>
\]</p>

<p>考虑到<br/>
\[<br/>
P(O|\lambda) = \sum_{j=1}^N P(O,i_t=s_j|\lambda)<br/>
\]</p>

<p>于是可得<br/>
\[<br/>
\begin{equation}<br/>
\gamma_t(i) = \frac{P(O,i_t=s_j|\lambda)}{P(O|\lambda)} = \frac{\alpha_t(i) \beta_t(i)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}\label{gtf1}<br/>
\end{equation}<br/>
\]</p>

<p>( b ) 给定模型 \(\lambda\) 和观测 \(O\)，在时刻 \(t\) 处于状态 \(s_i\) 在下一时刻处于 \(s_j\) 的概率，记为<br/>
\[<br/>
\begin{align*}<br/>
\xi_t(i,j) = P(i_t=s_i,i_{t+1}=s_j|O,\lambda) &amp;= \frac{P(i_t=s_i,i_{t+1}=s_j,O|\lambda)}{P(O|\lambda)}\\<br/>
&amp;= \frac{P(i_t=s_i,i_{t+1}=s_j,O|\lambda)}{\sum_{i=1}^N \sum_{j=1}^N P(i_t=s_i,i_{t+1}=s_j,O|\lambda)}<br/>
\end{align*}<br/>
\]</p>

<p>而<br/>
\[<br/>
\begin{align*}<br/>
P(i_t=s_i,i_{t+1}=s_j,O|\lambda) &amp;= P(i_t=s_i,o_1,o_2,...,o_t|\lambda)a_{ij}b_j(o_{t+1}) P(o_{t+2},o_{t+3},...,o_T|i_{t+1} = s_j,\lambda) \\<br/>
&amp;= \alpha_t(i)a_{ij} b_j(o_{t+1})\beta_{t+1}(j)<br/>
\end{align*}<br/>
\]</p>

<p>于是<br/>
\[<br/>
\begin{equation}<br/>
\xi_t(i,j) = \frac{\alpha_t(i)a_{ij} b_j(o_{t+1})\beta_{t+1}(j)}{\sum_{i=1}^N \sum_{j=1}^N \alpha_t(i)a_{ij} b_j(o_{t+1})\beta_{t+1}(j)}\label{gtf2}<br/>
\end{equation}<br/>
\]</p>

<p>( c ) 将 \(\gamma_t(i)\) 和 \(\xi_t(i,j)\) 对各个时刻 \(t\) 求和，可以得到一些有用的期望值：</p>

<ul>
<li><p>在观测 \(O\) 下状态 \(i\) 出现的期望值<br/>
\[<br/>
\sum_{t=1}^T \gamma_t(i)<br/>
\]</p></li>
<li><p>在观测 \(O\) 下由状态 \(i\) 转移的期望值<br/>
\[<br/>
\sum_{t=1}^{T-1} \gamma_t(i)<br/>
\]</p></li>
<li><p>在观测 \(O\) 下由状态 \(i\) 转移到状态 \(j\) 的期望值<br/>
\[<br/>
\sum_{t=1}^{T-1} \xi_t(i,j)<br/>
\]</p></li>
</ul>
</blockquote>

<p>假设给定训练数据只包含 \(S\) 个长度为 \(T\) 的观测序列 \(\{O_1,O_2,...,O_S\}\) 而没有对应的状态序列，目标是学习隐马尔可夫模型 \(\lambda=(\mathbb A,\mathbb B,\pi)\) 的参数，我们将观测序列看做观测数据 \(O\) ，状态序列看做不可观测的隐数据 \(I\) ，那么隐马尔可夫模型事实上是一个含有隐变量的概率模型<br/>
\[<br/>
P(O|\lambda) = \sum_{I} P(O|I,\lambda) P(I|\lambda)<br/>
\]</p>

<p>它的学习参数可以由 EM 算法实现。</p>

<p>（1）确定完全数据的对数似然函数</p>

<p>所有观测数据写成 \(O=(o_1,o_2,...,o_T)\)，所有隐数据写成 \(I=(i_1,i_2,...,i_T)\)，完全数据是 \((O,I)=(o_1,o_2,...,o_T,i_1,i_2,...,i_T)\)。完全数据的对数似然函数是 \(\log P(O,I|\lambda)\)。</p>

<p>（2）EM 的E步：求Q函数 \(Q(\lambda,\overline \lambda)\)：<br/>
\[<br/>
\begin{align}<br/>
Q(\lambda,\overline \lambda) &amp;= \mathbb E_I[\log P(O,I|\lambda)|O,\overline \lambda]\nonumber\\<br/>
&amp;= \sum_I \log P(O,I|\lambda) P(I|O,\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I \log P(O,I|\lambda) \frac{P(O,I|\overline \lambda)}{P(O|I,\overline \lambda)}\label{silp}\\<br/>
\end{align}<br/>
\] </p>

<p>其中，\(\overline \lambda\) 是隐马尔可夫模型参数的当前估计值，\(\lambda\) 是要极大化的隐马尔可夫模型参数。式(\ref{silp})中 \(P(O|I,\overline \lambda)\) 我们知道对于已知模型和隐状态序列这个概率是固定常数，可以略去。</p>

<p>Q函数可以写成<br/>
\[<br/>
\begin{equation}<br/>
Q(\lambda,\overline \lambda) = \sum_I \log P(O,I|\lambda){P(O,I|\overline \lambda)}\label{qlol}\\<br/>
\end{equation}<br/>
\]</p>

<p>在前文中，我们已经知道已知 \(\lambda\) 模型，可以通过前向算法得出给定观测序列的概率：<br/>
\[<br/>
\begin{align*}<br/>
P(O,I|\lambda) = \pi_{i_1} b_{i_1}(o_1) a_{i_1i_2}b_{i_2}(o_2) \cdots a_{i_{T-1} i_T}b_{i_T}(o_T)<br/>
\end{align*}<br/>
\]</p>

<p>于是函数 \(Q(\lambda,\overline \lambda)\) 可以写成：<br/>
\[<br/>
\begin{align}<br/>
Q(\lambda,\overline \lambda) &amp;= \sum_I \log P(O,I|\lambda){P(O,I|\overline \lambda)}\\<br/>
&amp;= \sum_I \log\Big[ \pi_{i_1} b_{i_1}(o_1) a_{i_1i_2}b_{i_2}(o_2) \cdots a_{i_{T-1} i_T}b_{i_T}(o_T) \Big]P(O,I|\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I \log\Big[ \pi_{i_1} \prod_{t=1}^{T-1} a_{i_ti_{t+1}}  \prod_{t=1}^T b_{i_t}(o_t)\Big]P(O,I|\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I \bigg\{\log\pi_{i_1} + \log\Big[\prod_{t=1}^{T-1} a_{i_ti_{t+1}}\Big] + \log\Big[\prod_{t=1}^T b_{i_t}(o_t)\Big]\bigg\}P(O,I|\overline \lambda)\nonumber\\<br/>
&amp;= \sum_I P(O,I|\overline \lambda) \log \pi_{i_1} + \sum_I P(O,I|\overline \lambda) \log\Big[\prod_{t=1}^{T-1} a_{i_ti_{t+1}}\Big] + \sum_I P(O,I|\overline \lambda) \log\Big[\prod_{t=1}^T b_{i_t}(o_t)\Big]\nonumber\\<br/>
&amp;= \sum_I P(O,I|\overline \lambda) \log \pi_{i_1} + \sum_I P(O,I|\overline \lambda) \sum_{t=1}^{T-1} \log a_{i_ti_{t+1}} + \sum_I P(O,I|\overline \lambda) \sum_{t=1}^T \log b_{i_t}(o_t)\label{sipo}\\<br/>
\end{align}<br/>
\]</p>

<p>式中求和都是对所有训练数据的序列总长度 \(T\) 进行的。</p>

<p>（3）EM算法的M步：极大化Q函数 \(Q(\lambda,\overline \lambda)\) 的模型参数 \(\mathbb A,\mathbb B,\pi\)。</p>

<p>可以看到，我们将三项中分别的对 \(I\) 的求和进行了划分。由于隐变量 \(I=(i_1,i_2,...,i_T)\) 。原来的求和需要遍历所有 \(I\) 的取值，然后进行求和，然而这基本是不可能完成的任务。改写后，我们将遍历的空间进行了划分，同时很好地将 \(P(O,I|,\overline \lambda)\) 部分改写后也融入到求和其中。比如第一项，对 \(I\) 的遍历等价于先固定状态 \(i_1\)，使其分别取值所有可能的状态（共有S个可取的离散状态），而 \(i_2,...,i_T\) 仍然像原来一样随便取值。这样，就把 \(I\) 空间划分成了S个更小的空间。然后再把这N个空间的结果相加，等价于原来对空间 \(I\) 进行遍历。</p>

<p><strong>a.式(\ref{sipo})的第一项</strong>可以写成<br/>
\[<br/>
\sum_I P(O,I|\overline \lambda) \log \pi_{i_1} = \sum_{i=1}^N P(O,i_1=i|\overline \lambda) \log \pi_{i}<br/>
\]</p>

<blockquote>
<p>之前一直很纠结为什么可以这么转换，后面通过一个小例子让我明白了，假设我们有长度为3，即 \(S=3\) 的观测数据 \(O=(o_1,o_2,o_3)\)，隐藏状态的个数为2，即 \(N=2\)，可能的隐藏状态序列有<br/>
\[<br/>
s_1 s_1 s_1;\\<br/>
s_1 s_1 s_2;\\<br/>
s_1 s_2 s_1;\\<br/>
s_1 s_2 s_2;\\<br/>
s_2 s_1 s_1;\\<br/>
s_2 s_1 s_2;\\<br/>
s_2 s_2 s_1;\\<br/>
s_2 s_2 s_2;\\<br/>
\]</p>

<p>第一项可以写成<br/>
\[<br/>
\begin{align*}<br/>
\sum_I P(O,I|\overline \lambda) \log \pi_{i_1} &amp;= P(O,\{s_1 s_1 s_1\}|\lambda)\log \pi_{s_1}  + P(O,\{s_1 s_1 s_2\}|\lambda)\log \pi_{s_1}  + P(O,\{s_1 s_2 s_1\}|\lambda)\log \pi_{s_1}  + P(O,\{s_1 s_2 s_2\}|\lambda)\log \pi_{s_1} + P(O,\{s_2,s_1,s_1\}|\pi_{s_2} + P(O,\{s_2,s_1,s_2\}|\pi_{s_2} + P(O,\{s_2,s_2,s_1\}|\pi_{s_2} + P(O,\{s_2,s_2,s_2\}|\pi_{s_2} \\<br/>
&amp;= P(O,{s_i,s_?,s_?}|\lambda)\log \pi_{s_i} \quad(i=1,2)\\<br/>
&amp;= \sum_{i=1}^2 P(O,s_i|\lambda)\log \pi_{s_i} <br/>
\end{align*}<br/>
\]</p>

<p>所以我们可以看出这样转换是可以的。</p>
</blockquote>

<p>我们又考虑到 \(\pi_i\) 满足约束条件 \(\sum_{i=1}^N \pi_i = 1\)，利用拉格朗日乘子法，写出拉格朗日函数：<br/>
\[<br/>
\sum_{i=1}^N P(O,i_1=i|\overline \lambda) \log \pi_{i} + \gamma\bigg(\sum_{i=1}^N \pi_i - 1 \bigg)<br/>
\]</p>

<p>对其求偏导并令结果为0<br/>
\[<br/>
\frac{\partial}{\partial \pi_i}\bigg[ \sum_{i=1}^N P(O,i_1=i|\overline \lambda) \log \pi_{i} + \gamma\bigg(\sum_{i=1}^N \pi_i - 1 \bigg) \bigg] = 0<br/>
\]</p>

<p>得<br/>
\[<br/>
\begin{align}<br/>
P(O,i_1=i|\overline \lambda) + \gamma \pi_i = 0\label{poli}<br/>
\end{align}<br/>
\]</p>

<p>对 \(i\) 求和得到 \(\lambda\)<br/>
\[<br/>
\lambda = -P(O|\overline \lambda)<br/>
\]</p>

<p>代入(\ref{poli})式得<br/>
\[<br/>
\pi_i = \frac{P(O,i_1=i|\overline \lambda)}{P(O|I)}<br/>
\]</p>

<p><strong>b.式(\ref{sipo})的第二项</strong>可以写成<br/>
\[<br/>
\sum_I P(O,I|\overline \lambda) \sum_{t=1}^{T-1} \log a_{i_ti_{t+1}} = \sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) \log a_{ij}<br/>
\]</p>

<p>应用具有约束条件 \(\sum_{j=1}^N a_{ij} = 1\) 的拉格朗日乘子法可以求出<br/>
\[<br/>
\sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) \log a_{ij} + \gamma\bigg(\sum_{j=1}^N a_{ij} - 1\bigg)<br/>
\]</p>

<p>对 \(a_{ij}\) 求偏导并令结果为0<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial}{\partial a_{ij}}\bigg[\sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) \log a_{ij} + \gamma\bigg(\sum_{j=1}^N a_{ij} - 1\bigg) \bigg]\\<br/>
&amp;= \frac{\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) }{a_{ij}} + \gamma = 0 \\<br/>
\end{align*}<br/>
\]</p>

<p>得<br/>
\[<br/>
\begin{equation}<br/>
\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) = \gamma a_{ij}\label{stto}<br/>
\end{equation}<br/>
\]</p>

<p>对 \(j\) 求和可得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{j=1}^N \sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) = \sum_{j=1}^N \gamma a_{ij}\\<br/>
&amp;\Rightarrow \sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda) = \gamma\\<br/>
\end{align*}<br/>
\]</p>

<p>上式代入(\ref{stto})得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda) = \sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda) a_{ij}\\<br/>
&amp;\Rightarrow a_{ij} = \frac{\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda)}{\sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda)}<br/>
\end{align*}<br/>
\]</p>

<p><strong>c.式(\ref{sipo})的第三项</strong>可以写成<br/>
\[<br/>
\sum_I P(O,I|\overline \lambda) \sum_{t=1}^T \log b_{i_t}(o_t) = \sum_{j=1}^N\sum_{t=1}^T  P(O,i_t=j|\overline \lambda) \log b_j(o_t)<br/>
\]</p>

<p>同样用拉格朗日乘子法，约束条件是 \(\sum_{k=1}^M b_j(k) = 1\)，拉格朗日方程为<br/>
\[<br/>
\sum_{j=1}^N \sum_{t=1}^TP(O,i_t=j|\overline \lambda)  \log b_j(o_t) + \gamma\bigg(\sum_{k=1}^M b_j(k) - 1 \bigg)<br/>
\]</p>

<p>对 \(b_j(k)\) 求导得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial}{\partial b_j(k)}\bigg[\sum_{j=1}^N \sum_{t=1}^T P(O,i_t=j|\overline \lambda) \log b_j(o_t) + \gamma\bigg(\sum_{k=1}^M b_j(k) - 1 \bigg)\bigg]\\<br/>
&amp;= \frac{\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k)}{b_j(k)}+ \gamma<br/>
\end{align*}<br/>
\]</p>

<p>这里只有在 \(o_t = k\) 时 \(b_j(o_t)\) 对 \(b_j(k)\) 的偏导数才不为0，以指示函数 \(\mathbf I(o_t = k)\) 表示。</p>

<p>令上式偏导结果为0得<br/>
\[<br/>
\begin{align}<br/>
\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k) = b_j(k) \gamma\label{stoto}<br/>
\end{align}<br/>
\]</p>

<p>对上式 \(k\) 求和，可得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{k=1}^N \sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k) = \sum_{k=1}^N b_j(k) \gamma\\<br/>
&amp;\Rightarrow \sum_{t=1}^T P(O,i_t=j|\overline \lambda) = \gamma<br/>
\end{align*}<br/>
\]</p>

<p>代入(\ref{stoto})式得<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k) = b_j(k) \sum_{t=1}^T P(O,i_t=j|\overline \lambda)\\ <br/>
&amp;\Rightarrow b_j(k) = \frac{\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k)}{\sum_{t=1}^T P(O,i_t=j|\overline \lambda)}<br/>
\end{align*}<br/>
\]</p>

<p>到现在我们已经推出了 \(\pi_i\)、\(a_{ij}\) 和 \(b_{j}(k)\) 的迭代公式<br/>
\[<br/>
\begin{align*}<br/>
\pi_i &amp;= \frac{P(O,i_1=i|\overline \lambda)}{P(O|I)}\\<br/>
a_{ij} &amp;= \frac{\sum_{t=1}^{T-1} P(O,i_t=i,i_{t+1}=j|\overline \lambda)}{\sum_{t=1}^{T-1} P(O,i_t=i|\overline \lambda)}\\<br/>
b_j(k) &amp;= \frac{\sum_{t=1}^T P(O,i_t=j|\overline \lambda) \mathbf I(o_t = k)}{\sum_{t=1}^T P(O,i_t=j|\overline \lambda)}\\<br/>
\end{align*}<br/>
\]</p>

<p>将式(\ref{gtf1})和式(\ref{gtf2}) 代入<br/>
\[<br/>
\begin{align*}<br/>
\pi_i &amp;= \gamma_1(i)\\<br/>
a_{ij} &amp;= \frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i) }\\<br/>
b_j(k) &amp;= \frac{\sum_{t=1}^T \gamma_t(j) \mathbf I(o_t=k)}{\sum_{t=1}^T \gamma_t(j)}\\<br/>
\end{align*}<br/>
\]</p>

<p>现在Baum-Welch算法可以描述为<br/>
<strong>输入</strong>：观测数据 \(O=(o_1,o_2,...,o_T)\)；<br/>
<strong>输出</strong>：隐马尔可夫模型参数<br/>
<strong>算法过程</strong></p>

<ul>
<li>初始化，对 \(n=0\)，选取 \({a_{ij}}^{(0)}\)，\({b_j(k)}^{(0)}\) 和 \({\pi_i}^{(0)}\)，得到模型 \(\lambda^{(0)} = (\mathbb A^{(0)},\mathbb B^{(0)},\pi^{(0)})\)</li>
<li><p>递推，对 \(n=1,2,...,\)<br/>
\[<br/>
\begin{align*}<br/>
{a_{ij}^{(n+1)}} &amp;= \frac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i) }\\<br/>
{b_j(k)}^{(n+1)} &amp;= \frac{\sum_{t=1}^T \gamma_t(j) \mathbf I(o_t=k)}{\sum_{t=1}^T \gamma_t(j)}\\<br/>
{\pi_i}^{(n+1)} &amp;= \gamma_1(i)\\<br/>
\end{align*}<br/>
\]</p>

<p>右侧各值按观测 \(O=(o_1,o_2,...,o_T)\) 和模型 \(\lambda^{(n)} = (\mathbb A^{(n)},\mathbb B^{(n)},\pi^{(n)})\) 计算。式中 \(\gamma_t(i)\) 和 \(\xi_t(i,j)\) 由式(\ref{gtf1})和式(\ref{gtf2})给出。</p></li>
<li><p>终止。得到模型 \(\lambda^{(n+1)} = (\mathbb A^{(n+1)},\mathbb B^{(n+1)},\pi^{(n+1)})\)</p></li>
</ul></li>
</ol>

<hr/>

<p>[李航 统计学习方法]<br/>
<a href="http://www.52nlp.cn/category/hidden-markov-model">HMM相关文章索引</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15195107498771.html">马尔科夫链蒙特卡罗方法 Markov Chain Monte Carlo，MCMC</a></h1>
			<p class="meta"><time datetime="2018-02-25T06:19:09+08:00" 
			pubdate data-updated="true">2018/2/25</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>对于一般的分布的采样，之前已经有一些方法可以解决，但是对于一些复杂分布的采样，却没有很好的函数实现，本文将介绍 MCMC 方法提供解决方法。</p>

<h3 id="toc_0">马尔科夫链 Markov Chain</h3>

<p>设 \(X_t\) 表示随机变量 \(X\) 在时刻 \(t\) 的取值，若该变量随时间变化的转移概率仅仅依赖于它的当前取值，与过去状态无关，所谓的“遗忘性”，即：<br/>
\[<br/>
P(X_{t+1}=s_{t+1}|X_0=s_0,X_1=s_1,...,X_t=s_t) = P(X_{t+1}=s_{t+1}|X_t=s_t)<br/>
\]</p>

<p>也就是说状态转移仅仅依赖于前一个状态，其中 \(s_0,s_1,...,s_i,...\) 表示随机变量 \(X\) 的可能状态，这个性质称为马尔科夫性质。具有马尔科夫性质的随机过程叫马尔科夫过程，其中变量称为马尔科夫变量。</p>

<p>马尔可夫链指的是在一段时间内随机变量X的取值序列 \((X_0,X_1,...,X_m)\) ，它们满足如上的马尔可夫性质。</p>

<ol>
<li>时间、状态都离散的叫做马尔可夫链。</li>
<li>时间连续、状态离散的叫做时间连续马尔可夫链。</li>
<li>时间、状态都连续的叫做马尔可夫过程。</li>
</ol>

<h4 id="toc_1">转换概率</h4>

<p>马尔可夫链是通过对应的转移概率定义的，转移概率指的是随机变量从一个时刻到下一个时刻，从状态 \(s_i\) 转移到另一个状态 \(s_j\) 的概率，即：<br/>
\[<br/>
P(i\rightarrow j):=P_{i,j} = P(X_{t+1}=s_j|X_t = s_i)<br/>
\]</p>

<p>记 \(\pi_k^{(t)}\) 表示随机变量 \(X\) 在时刻 \(t\) 的取值为 \(s_k\) 的概率，则随机变量 \(X\) 在时刻 \(t+1\) 的取值为 \(s_i\) 的概率为：<br/>
\[<br/>
\begin{align*}<br/>
\pi_i^{(t+1)} &amp;= P(X_{t+1} = s_i)\\<br/>
&amp;= \sum_{k} P(X_{t+1}=s_i|X_t = s_k)\cdot P(X_t=s_k)\\<br/>
&amp;= \sum_k P_{k,i}\cdot \pi_{k}^{(t)}<br/>
\end{align*}<br/>
\]</p>

<p>假设状态的数目为 \(n\)，则有：<br/>
\[<br/>
(\pi_1^{(t+1)},\cdots,\pi_j^{(t+1)},\cdots,\pi_n^{(t+1)}) = (\pi_1^{(t)},\cdots,\pi_i^{(t)},\cdots,\pi_1^{(t)})\left [ \begin{array}{cccccc}<br/>
P_{1,1}&amp;P_{1,2}&amp;\cdots&amp;P_{1,j}&amp;\cdots&amp;P_{1,n}\\<br/>
P_{2,1}&amp;P_{2,2}&amp;\cdots&amp;P_{2,j}&amp;\cdots&amp;P_{2,n}\\<br/>
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\cdots&amp;\vdots\\<br/>
P_{i,1}&amp;P_{i,2}&amp;\cdots&amp;P_{i,j}&amp;\cdots&amp;P_{i,n}\\<br/>
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\cdots&amp;\vdots\\<br/>
P_{n,1}&amp;P_{n,2}&amp;\cdots&amp;P_{n,j}&amp;\cdots&amp;P_{n,n}\\<br/>
\end{array} \right]<br/>
\]</p>

<p>对于任意的 \(i\) 都有 \(\sum_{j=1}^n P_{i,j} = 1\)。若设 \(\Pi=[\pi_1^{(0)},\pi_2^{(0)},\cdots,\pi_n^{(0)}]\) 是系统的初始概率分布，\(\pi_i^{(0)}\) 是系统在初始时刻处于状态 \(i\) 的概率，满足 \(\sum_{i=1}^n \pi_i^{(0)}=1\) 。</p>

<h4 id="toc_2">平稳分布</h4>

<p>对于马尔可夫链，需要注意以下的两点：</p>

<ol>
<li>周期性：即经过有限次的状态转移，又回到了自身；</li>
<li>不可约：即两个状态之间相互转移；</li>
</ol>

<p><strong>马氏定理：</strong>如果一个非周期不可约马尔可夫链的转移矩阵为 \(P\)，无论初始值 \(\pi^{(0)}\) 的取值，都有 \(\lim_{t\rightarrow \infty} \pi^{(0)} P^t\) 存在且初始值无关，记 \(\lim_{t\rightarrow \infty} \pi^{(0)} P^t = \pi^*\)，我们有：<br/>
\[<br/>
\pi^* P = \pi^*<br/>
\]</p>

<p>\(pi\) 是方程唯一非负解。其中：<br/>
\[<br/>
\pi^* =[\pi(1),\pi(2),\cdots,\pi(j),\cdots],\quad \sum_{i=0}^n \pi(i)=1<br/>
\]</p>

<p>则称 \(\pi^*\) 为马尔可夫链的平稳分布。存在稳态分布要求马尔可夫链是连通的（没有孤立点），同时不存在一个连通子图是没有对外的出边的。</p>

<p><strong>细致平稳条件：</strong>如果非周期马尔可夫链的转移矩阵 \(P\) 和分布 \(\pi\) 满足 <br/>
\[<br/>
\pi(i) P_{i,j} = \pi(j) P_{j,i},\quad \forall i,j<br/>
\]</p>

<p>则 \(\pi^*=(\pi(1),\pi(2),\cdots,\pi(j),\cdots)\) 是马尔可夫链的平稳分布。</p>

<p>这个定理是显而易见的，因为细致平稳条件的物理含义就是对于任何两个状态 \(i,j\) ，从 \(i\) 转移出去到 \(j\) 而丢失的概率质量，恰好会被从 \(j\) 转移回来到 \(i\) 的概率质量补充，所以状态 \(i\) 上的概率质量 \(\pi(i)\) 是稳定的，从而 \(\pi^*\) 是马尔可夫链的平稳分布。数学上的证明也很简单，由细致平稳条件可得：<br/>
\[<br/>
\sum_{i=1}^n \pi(i)P_{i,j}=\sum_{i=1}^n \pi(j)P_{j,i}= \pi(j)\sum_{i=1}^n P_{j,i} =\pi(j)\\<br/>
\Rightarrow \pi P=\pi<br/>
\]</p>

<p>由于 \(\pi^*\) 是方程 \(\pi P=\pi\) 的解，所以 \(\pi^*\) 是平稳分布。</p>

<p>马氏定理和细致平稳条件非常重要，是MCMC(Markov Chain Monte Carlo) 方法的基础。</p>

<h3 id="toc_3">Metropolis 采样</h3>

<p>对于给定的概率分布 \(p(x)\)，我们希望能有便捷的方式生成它对应的样本。由于马氏链能收敛到平稳分布，于是一个很的漂亮想法是：如果我们能构造一个转移矩阵为 \(P\) 的马氏链，使得该马氏链的平稳分布恰好是 \(p(x)\)，那么我们从任何一个初始状态 \(x_0\) 出发沿着马氏链转移, 得到一个转移序列 \(x_0,x_1,x_2,\cdots,x_n,x_{n+1},\cdots\)， 如果马氏链在第 \(n\) 步已经收敛了，于是我们就得到了 \(\pi(x)\) 的样本 \(x_n,x_{n+1},\cdots\)。</p>

<p>这个绝妙的想法在 1953 年被 Metropolis 想到了，为了研究粒子系统的平稳性质， Metropolis 考虑了物理学中常见的波尔兹曼分布的采样问题，首次提出了基于马氏链的蒙特卡罗方法，即 Metropolis 算法，并在最早的计算机上编程实现。Metropolis 算法是首个普适的采样方法，并启发了一系列 MCMC 方法，所以人们把它视为随机模拟技术腾飞的起点。 Metropolis 的这篇论文被收录在《统计学中的重大突破》中， Metropolis 算法也被遴选为二十世纪的十个最重要的算法之一。</p>

<p>假设现在有个转移矩阵为 \(Q\) 的马氏链，其中 \(q(j|i)\)，表示马尔可夫链在第 \(t\) 代时的状态为 \(i\) ，下一时刻转移到状态为 \(j\) 的概率。此时不满足细致平稳性：<br/>
\[<br/>
\pi(i) q(j|i) \neq \pi(j) q(i|j),\quad \forall i,j<br/>
\]</p>

<p>为了满足细致平稳性，在左边乘上右边，在右边乘上左边，也就是：<br/>
\[<br/>
\pi(i) q(j|i)\pi(j) q(i|j) = \pi(j) q(i|j)\pi(i) q(j|i),\quad \forall i,j<br/>
\]</p>

<p>令 \(\alpha(j|i) = \pi(j) q(i|j)\)，则上式可以写成：<br/>
\[<br/>
\pi(i) q(j|i) \alpha(j|i) = \pi(j) q(i|j) \alpha(i|j),\quad \forall i,j<br/>
\]</p>

<p>假设 \(Q&#39;(j|i) = q_(j|i) \alpha(j|i)\) ，所以有：<br/>
\[<br/>
\begin{align}<br/>
\pi(i)\underbrace{q(j|i) \alpha(j|i)}_{Q&#39;(j|i)} = \pi(j) \underbrace{ q(i|j) \alpha(i|j)}_{Q&#39;(i|j)}\label{puaq}\\<br/>
\end{align}<br/>
\]</p>

<p>将 \(Q&#39;(j|i)\) 视为新的转移概率，这样便把原先具有转移矩阵 \(Q\) 的普通马氏链，改造为具有转移矩阵 \(Q&#39;\) 的马氏链，而 \(Q&#39;\) 是满足细致平稳条件的，平稳分布是 \(\pi^*\)，在改造过程中引入了接受概率 \(\alpha(i,j)\)，物理意义可以理解为在原来的马氏链上，从状态 \(i\) 以 \(q(j|i)\) 跳转到状态 \(j\) 的时候，我们以 \(\alpha(i|j)\) 的概率接受这个转移，于是得到新的马氏链 \(Q&#39;\) 的转移概率为 \(q(j|i) \alpha(j|i)\) 。</p>

<p>得到接受概率 \(\alpha\) 之后，就可以随机从均匀分布中得到 \(u\) 值，如果 \(u \le \alpha(j|i) = \pi(j) q(i|j)\) 则接受状态 \(i\) 转移 到 \(j\)，否则不接受转移。</p>

<p>具体的算法流程如下：</p>

<ol>
<li>初始化马氏链初始状态 \(X_0 = x_0\)</li>
<li><p>对 \(t=0,1,2,...\)，循环以下过程进行采样</p>

<ul>
<li>第 \(t\) 个时刻马氏链的状态 \(X_t = x_t\)，采样 \(y\sim q(x|x_t)\)</li>
<li>从均匀分布采样 \(u\sim U(0,1)\)</li>
<li>如果 \(u\le \alpha(y|x_t) =  \pi(y) q(x_t|y)\)，则接受转移 \(x_t\rightarrow y\)，即\(X_{t+1} = y\)</li>
<li>否则不接收转移，即 \(X_{t+1} = x_t\)</li>
</ul></li>
</ol>

<p>上面过程中 \(p(x)\)，\(q(x|y)\) 说的是离散的情形，事实上即便这两个分布是连续的，以上算法仍然是有效的，于是就得到更一般的连续概率分布 \(p(x)\) 的采样算法，而 \(q(x|y)\) 就是一个任意一个连续二元概率分布对应的条件分布。</p>

<h5 id="toc_4">Metropolis-Hastings 算法</h5>

<p>但是Metropolis算法构造出的接受概率可能会很小，这样造成算法要经过很多的迭代才能到达平稳分布。为了加快收敛效果，我们需要在 \ref{puaq} 两边同比例增加 \(\alpha(i|j)\) 和 \(\alpha(j|i)\) ,假设要将左边的 \(\alpha(i|j)\) 增加到 1 ，需要两边同乘上 \(\frac{1}{\alpha(i|j)}\) 倍，则右边接受概率变为 \(\frac{\alpha(j|i)}{\alpha(i|j)}\)：<br/>
\[<br/>
\pi(i) q(j|i) = \pi(j) q(i|j) \frac{\alpha(i|j)}{\alpha(j|i)} = \frac{\pi(i) q(j|i)}{\pi(j) q(i|j)},\quad \forall i,j<br/>
\]</p>

<p>这样接受概率就可以写成：<br/>
\[<br/>
\begin{align*}<br/>
\alpha(j|i) &amp;= 1\\<br/>
\alpha(i|j) &amp;= \frac{\pi(i) q(j|i)}{\pi(j) q(i|j)}\\<br/>
\end{align*}<br/>
\]</p>

<p>因为在 Metropolis 采样算法过程中，生成 \([0,1]\) 均匀分布随机值 \(u\) 必定不大于1，可以将 \(\alpha(i|j)\) 缩小范围：<br/>
\[<br/>
\alpha(i|j) = \frac{\pi(i) q(j|i)}{\pi(j) q(i|j)}\quad\Leftrightarrow\quad \alpha(i|j) = \min\bigg({1,\frac{\pi(i) q(j|i)}{\pi(j) q(i|j)}}\bigg)<br/>
\]</p>

<p>这样改造后接受概率对后续过程并没有影响。</p>

<p>具体的算法流程如下：</p>

<ol>
<li>初始化马氏链初始状态 \(X_0 = x_0\)</li>
<li><p>对 \(t=0,1,2,...\)，循环以下过程进行采样</p>

<ul>
<li>第 \(t\) 个时刻马氏链的状态 \(X_t = x_t\)，采样 \(y\sim q(x|x_t)\)</li>
<li>从均匀分布采样 \(u\sim U(0,1)\)</li>
<li>如果 \(u\le \alpha(y|x_t) =  \min\bigg({1,\frac{\pi(y) q(x_t|y)}{\pi(x_t) q(y|x_t)}}\bigg)\)，则接受转移 \(x_t\rightarrow y\)，即\(X_{t+1} = y\)</li>
<li>否则不接收转移，即 \(X_{t+1} = x_t\)</li>
</ul></li>
</ol>

<p>对于分布 \(\pi(x)\)，我们构造转移矩阵 \(Q&#39;\) 使其满足细致平稳条件<br/>
\[<br/>
p(x)Q&#39;(x\rightarrow y) = p(y)Q&#39;(y\rightarrow x)<br/>
\]</p>

<p>此处 \(x\) 并不要求是一维的，对于高维空间的 \(p(\mathbf x)\)，如果满足细致平稳条件：<br/>
\[<br/>
p(\mathbf x)Q&#39;(\mathbf x\rightarrow \mathbf y) = p(\mathbf y)Q&#39;(\mathbf y\rightarrow \mathbf x)<br/>
\]</p>

<p>那么以上的 Metropolis-Hastings 算法一样有效。</p>

<h3 id="toc_5">MCMC-Gibbs Sampling算法</h3>

<p>设想 \(p(x,y)\) 是 p.d.f. 或 p.m.f. ，如果直接对他们进行采样会比较困难。不过，我们假设我们可以很容易地从条件分布 \(p(x|y)\) 和 \(p(y|x)\) 中进行采样。假设有两个 \(x\) 轴坐标相同的点 \(A(x_1,y_1)\) 和 \(B(x_1,y_2)\)。<br/>
易得：<br/>
\[<br/>
p(x_1,y_1) p(y_2|x_1) = p(x_1)p(y_1|x_1)p(y_2|x_1)\\<br/>
p(x_1,y_2) p(y_1|x_1) = p(x_1)p(y_2|x_1)p(y_1|x_1)\\<br/>
\]</p>

<p>比较上述两个等式右边得：<br/>
\[<br/>
\begin{align}<br/>
p(x_1,y_1) p(y_2|x_1) = p(x_1,y_2) p(y_1|x_1)\label{pxyp}\\<br/>
\end{align}<br/>
\]</p>

<p>即<br/>
\[<br/>
\begin{align}<br/>
p(A) p(y_2|x_1) = p(B) p(y_1|x_1)\label{papy}\\<br/>
\end{align}<br/>
\]</p>

<p>同理，如果现在有个点 \(C(x_3,y_1)\)，和点 \(A\) 在同一个 \(y\) 轴上，有如下等式：<br/>
\[<br/>
\begin{align}<br/>
p(A) p(x_3,y_1) = p(C) p(x_1|y_1)\label{papx}\\<br/>
\end{align}<br/>
\]</p>

<p>令<br/>
\[<br/>
\begin{align*}<br/>
&amp;Q(A\rightarrow B) = p(y_B|x_1) &amp;\quad \text{if }x_A = x_B = x_1\\<br/>
&amp;Q(A\rightarrow C) = p(x_C|y_1) &amp;\quad \text{if }y_A = y_C = y_1\\<br/>
&amp;Q(A\rightarrow D) = 0 &amp;\quad \text{otherwise} \\<br/>
\end{align*}<br/>
\]</p>

<p>代入(\ref{papy})和(\ref{papx})得：<br/>
\[<br/>
p(A) Q(A\rightarrow B) = p(B) Q(B\rightarrow A)\\<br/>
p(A) Q(A\rightarrow C) = p(C) Q(C\rightarrow A)\\<br/>
\]</p>

<p>有了如上的转移矩阵 Q，我们很容易知道对平面上任意两点 \(X\)、\(Y\)，满足细致平稳条件<br/>
\[<br/>
\begin{align}<br/>
p(X)Q(X\rightarrow Y)=p(Y)Q(Y\rightarrow X)\label{pxqx}\\<br/>
\end{align}<br/>
\]</p>

<p>于是这个二维空间上的马氏链将收敛到平稳分布 \(p(x,y)p(x,y)\)。而这个算法就称为 Gibbs Sampling 算法。</p>

<h5 id="toc_6">算法步骤</h5>

<ol>
<li>随机初始化 \(x_0,y_0\)</li>
<li><p>对于 \(t=0,1,2,\cdots\)，循环采样</p>

<ul>
<li>从条件分布 \(p(Y|X=x_t)\) 中采样 \(y_{t+1}\) 得到点 \((x_t,y_{t+1})\)。</li>
<li>从条件分布 \(p(X|Y=y_{t+1})\) 中采样 \(x_{t+1}\) 得到点 \((x_{t+1},y_{t+1})\)。</li>
</ul></li>
</ol>

<h5 id="toc_7">Gibbs sampling 中的马氏转移链</h5>

<p>以上采样过程中，如图所示，马氏链的转移只是轮换的沿着坐标轴 \(x\) 轴和 \(y\) 轴做转移，于是得到样本 \((x_0,y_0),(x_0,y_1),(x_1,y_1),(x_1,y_2),(x_2,y_2),\cdots\) 马氏链收敛后，最终得到的样本就是 \(p(x,y)p(x,y)\) 的样本，而收敛之前的阶段称为 burn-in period。</p>

<p>Gibbs Sampling 算法大都是坐标轴轮换采样的，但是这其实是不强制要求的。最一般的情形可以是，在 \(t\) 时刻，可以在 \(x\) 轴和 \(y\) 轴之间随机的选一个坐标轴，然后按条件概率做转移，马氏链也是一样收敛的。轮换两个坐标轴只是一种方便的形式。</p>

<p>以上的过程我们很容易推广到高维的情形，对于(\ref{papx})式，如果 \(x_1\) 变为多维情形 \(\mathbf x_1\)，可以看出推导过程不变，所以细致平稳条件同样是成立的<br/>
\[<br/>
p(\mathbf x_1,y_1)p(y_2|\mathbf x_1)=p(\mathbf x_1,y_2)p(y_1|\mathbf x_1)<br/>
\]</p>

<p>此时转移矩阵 \(Q\) 由条件分布 \(p(y|\mathbf x_1)\) 定义。上式只是说明了一根坐标轴的情形，和二维情形类似，很容易验证对所有坐标轴都有类似的结论。所以 \(n\) 维空间中对于概率分布 \(p(x_1,x_2,\cdots,x_n)\) 可以如下定义转移矩阵：马氏链转移的过程中，只能沿着坐标轴做转移，每次只转移一根坐标轴，沿着 \(x_i\) 这根坐标轴做转移的时候，转移概率由条件概率 \(p(x_i|x_1,x_2,\cdots,x_{i-1},x_{i+1},\cdots,x_n)\) 定义；其他的轴转移概率都设置为 0。</p>

<p>于是我们可以把 Gibbs Smapling 算法从采样二维的 \(p(x,y)\) 推广到采样 \(n\) 维的 \(p(x_1,x_2,...,x_n)\)。</p>

<h5 id="toc_8">n 维 Gibbs Sampling 算法步骤</h5>

<ol>
<li>随机初始化 \(\{x_i:i=1,2,\cdots,n \}\)</li>
<li>对 \(t=0,1,\cdots\) 循环采样

<ul>
<li>\(x_1^{(t+1)} = p(x_1|x_2^{(t)},x_3^{(t)},\cdots,x_n^{(t)})\)</li>
<li>\(x_2^{(t+1)} = p(x_2|x_1^{(t)},x_3^{(t)},\cdots,x_n^{(t)})\)</li>
<li>\(\cdots\)</li>
<li>\(x_j^{(t+1)} = p(x_1|x_2^{(t)},x_3^{(t)},\cdots,x_{j-1}^{(t)},x_{j+1}^{(t)},\cdots,x_n^{(t)})\)</li>
<li>\(\cdots\)</li>
<li>\(x_n^{(t+1)} = p(x_n|x_2^{(t)},x_3^{(t)},\cdots,x_{n-1}^{(t)})\)</li>
</ul></li>
</ol>

<p>以上算法收敛后，得到的就是概率分布 \(p(x_1,x_2,\cdots,x_n)\) 的样本，当然这些样本并不独立，但是我们此处要求的是采样得到的样本符合给定的概率分布，并不要求独立。同样的，在以上算法中，坐标轴轮换采样不是必须的，可以在坐标轴轮换中引入随机性，这时候转移矩阵 \(Q\) 中任何两个点的转移概率中就会包含坐标轴选择的概率，而在通常的 Gibbs Sampling 算法中，坐标轴轮换是一个确定性的过程，也就是在给定时刻 \(t\)，在一根固定的坐标轴上转移的概率是 1。</p>

<h3 id="toc_9">总结</h3>

<p>无论 metropolis-hasting 算法还是 gibbs 算法，都需要一个 burn in 过程，只有在达到平衡状态时候得到的样本才能是平衡状态时候的目标分布的样本，因此，在 burn in 过程中产生的样本都需要被舍弃。如何判断一个过程是否达到了平衡状态还没有一个成熟的方法来解决，目前常见的方法是看是否状态已经平稳。</p>

<p>关于链的收敛有这样一些检验方法</p>

<ol>
<li><strong>图形方法</strong>：这是简单直观的方法。我们可以利用这样一些图形：

<ul>
<li>迹图（trace plot）：将所产生的样本对迭代次数作图，生成马氏链的一条样本路径。如果当 \(t\) 足够大时，路径表现出稳定性没有明显的周期和趋势，就可以认为是收敛了。</li>
<li>自相关图（Autocorrelation plot）：如果产生的样本序列自相关程度很高，用迹图检验的效果会比较差。一般自相关随迭代步长的增加而减小，如果没有表现出这种现象，说明链的收敛性有问题。</li>
<li>遍历均值图（ergodic mean plot）：MCMC的理论基础是马尔科夫链的遍历定理。因此可以用累积均值对迭代步骤作图，观察遍历均值是否收敛。</li>
</ul></li>
<li><strong>蒙特卡洛误差</strong></li>
<li><strong>Gelman-Rubin方法</strong></li>
</ol>

<hr/>

<p><a href="https://www.cnblogs.com/xbinworld/p/4266146.html">随机采样方法整理与讲解</a><br/>
<a href="https://www.jianshu.com/p/1511c94b2ac3">LDA漫游系列(四)-Gibbs Sampling</a><br/>
<a href="https://cosx.org/2013/01/lda-math-mcmc-and-gibbs-sampling/">靳志辉 LDA-math-MCMC 和 Gibbs Sampling</a><br/>
<a href="https://www.zybuluo.com/evilking/note/753058">自相关</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15189654050126.html">蒙特卡罗方法 Monte Carlo Simulation</a></h1>
			<p class="meta"><time datetime="2018-02-18T22:50:05+08:00" 
			pubdate data-updated="true">2018/2/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>蒙特卡罗方法（也常称之为 MC）也叫统计模拟方法，它使用随机数（或伪随机数）来解决问题，是一类重要的数值计算方法。该方法的名字来源于世界著名的赌城蒙特卡罗，而蒙特卡罗方法正是以概率为基础的方法。</p>

<p>由概率定义知，某事件的概率可以用大量试验中该事件发生的频率来估算，当样本容量足够大时，可以认为该事件的发生频率即为其概率。蒙特卡罗方法正是基于这个思想。一个简单的例子可以解释蒙特卡罗方法，假设我们需要计算一个不规则图形的面积，那么图形的不规则程度和分析性计算（比如积分）的复杂程度是成正比的。而采用蒙特卡罗方法是怎么计算的呢？首先你把图形放到一个已知面积的方框内，然后假想你有一些豆子，把豆子均匀地朝这个方框内撒，散好后数这个图形之中有多少颗豆子，再根据图形内外豆子的比例来计算面积。当你的豆子越小，撒的越多的时候，结果就越精确。</p>

<p>蒙特卡罗方法出现后很长一段时间都不太受到关注，直到计算机的出现，使大量模拟变得简单，这种方法才重新被关注起来。</p>

<p>下面我们使用模特卡罗方法解决几个有趣的问题：</p>

<h4 id="toc_0">圆周率 \(\pi\) 的计算</h4>

<p>圆周率的计算常用的方法是割圆法，这里我们使用蒙特卡罗方法很容易得出，这也是蒙特卡罗算法最经典的应用。假设我们有一个半径为 \(r\) 的圆形，很容找到它外切的边长为 \(2r\) 的正方形：</p>

<div align="center">
    <img src="media/15189654050126/15348520595458.jpg" width="250" />
</div>

<p>我们知道正方形的面积为 \(2r\times 2r=4r^2\) ，圆的面积为 \(\pi r^2\)，面积之比为：<br/>
\[<br/>
p = \frac{s(\text{circle})}{s(\text{square})} = \frac{\pi r^2}{4r^2} = \frac{\pi}{4}<br/>
\]</p>

<p>现在使用蒙特卡罗方法生成 \(n\) 对 \([-r,+r]\) 内的随机数（包含x、y两个坐标），计算是否在圆内（与圆心的距离与 \(r\) 比较），若有 \(m\) 个点落到圆内，我们可以认为落到圆内的概率与圆与正方形面积之比相等，即：<br/>
\[<br/>
\frac{m}{n} = \frac{\pi}{4} \quad\Rightarrow\quad \pi = \frac{4m}{n}<br/>
\]</p>

<p>通过这种方法，随着 \(n\) 的增大，\(\pi\) 会越来越精确。</p>

<h4 id="toc_1">自然对数 \(\mathbf e\) 的计算</h4>

<p>使用蒙特卡罗方法计算自然对数便不那么直观了，我们来考虑一下如下的定积分：<br/>
\[<br/>
S = \int_1^2 \frac 1 x dx<br/>
\]</p>

<p>我们将这个函数画出<br/>
<div align="center"><br/>
    <img src="media/15189654050126/15348619268478.jpg" width="250" /><br/>
</div></p>

<p>如上图所示上述定积分的值即是绿色曲线与正方形围成的面积。我们通过牛顿莱布尼兹公式求定积分为：<br/>
\[<br/>
S = \ln(x)\Big|_1^2 = \ln(2) - \ln(1) = \ln(2)<br/>
\]</p>

<p>使用蒙特卡罗方法求解这个面积，先在所标矩形内取 \(n\) 对随机点 \((x_1,y_1),(x_2,y_2),...,(x_n,y_n)\)，即 \(x_i\) 取值范围为 \([1,2]\)，\(y_i\) 取值范围为 \([0,1]\)。满足<br/>
\[<br/>
y_i &lt; \frac 1 {x_i}<br/>
\]</p>

<p>的点将在所要求的面积之内，所以正方形内曲线下面的面积与正方形面积之比为落在曲线下方区域与全部随机点个数之比。假设有 \(m\) 个点满足条件，即：<br/>
\[<br/>
\frac{m}{n} = \frac{\ln(2)}{1}\quad\Rightarrow\quad \log_e 2 = \frac m n \quad\Rightarrow\quad e = 2^{m/n}<br/>
\]</p>

<h4 id="toc_2">定积分的计算</h4>

<p>使用蒙特卡罗计算定积分有两种方法：一种就是上面的那种方法“面积法”，定积分的值便是阴影部分的面积，这里不再叙述。另一种方法是“期望法”现在来介绍这种方法：</p>

<p>看如下的积分：<br/>
\[<br/>
\theta = \int_a^b f(x)dx<br/>
\]</p>

<p>如果我们很难求出 \(f(x)\) 的原函数，那么这个积分比较难求解。当然我们可以通过蒙特卡罗方法来求解近似值。假设我们函数图像如下图：</p>

<div align="center">
    <img width="230" src="media/15189654050126/15348644591195.jpg" />
</div>

<p>原函数的积分是函数 \(f(x)\) 下方与绿色区域的面积。一个简单的近似求解方法是在 \([a,b]\) 之间随机采样一个点。比如 \(x_1\)，然后用 \(x_1\) 代表 \([a,b]\) 内所有的 \(f(x)\) 的值。那么上面的定积分的近似求解为：<br/>
\[<br/>
(b-a)f(x_1)<br/>
\]</p>

<div align="center">
    <img width="230" src="media/15189654050126/15348651594504.jpg" />
</div>

<p>也就是图中阴影的面积。显然，用一个值代表 \([a,b]\) 区间上所有的 \(f(x)\) 的值，这个假设太粗糙。那么我们可以采样 \([a,b]\) 区间的 \(n\) 个值：\(x_1,x_2,...x_{n}\) ,用它们的均值来代表 \([a,b]\) 区间上所有的 \(f(x)\) 的值：<br/>
\[<br/>
\overline f(x) = \frac 1 n \sum_{i=1}^{n} f(x_i)<br/>
\]</p>

<p>这样我们上面的定积分的近似求解为:<br/>
\[<br/>
(b-a)\overline f(x) = \frac{b-a}{n} \sum_{i=1}^{n} f(x_i)<br/>
\]</p>

<div align="center">
    <img width="250" src="media/15189654050126/15348661212745.jpg" />
</div>

<p>如图中矩形所示，这个假设比之前的稍好一些，但是它隐含了一个假定，即 \(x\) 在 \([a,b]\) 之间是均匀分布的，而绝大部分情况，\(x\) 在 \([a,b]\) 之间不是均匀分布的。如果我们用上面的方法，则模拟求出的结果很可能和真实值相差甚远。而如果我们找到一个分布，使得它能在值较大的地方采集到更多的样本，则能更好地逼近结果。所以我们要对采样进行加权，这个权重就是重要性权重。</p>

<h4 id="toc_3">重要性采样 Importance Sampling</h4>

<p>假设原函数 \(f(x)\) 也许本身就是定义在一个分布之上的，我们定义这个分布为 \(p(x)\)，我们无法直接从 \(p(x)\) 上进行采样，所以另辟蹊径重新找到一个更加简明的分布 \(q(x)\) ，从它进行取样，希望间接地求出 \(f(x)\) 在分布 \(p(x) \) 下的期望。</p>

<p>首先我们知道函数 \(f(x)\) 在概率分布 \(p(x)\) 下的期望为： <br/>
\[<br/>
\begin{align*}<br/>
\mathbb E_p[f(x)] &amp;= \int_{x}^{}f(x) p(x) dx = \int_{x}^{}f(x) \frac{p(x)}{q(x)}q(x)dx\\<br/>
&amp;= \int_{x}^{} f(x) w(x) q(x) dx\\<br/>
&amp;= \mathbb E_q[f(x) w(x)]<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(w(x) = \frac{p(x)}{q(x)}\) ，被称为重要性权重。</p>

<p><strong>重要性采样</strong>是通过引入重要性权重，将分布 \(p(x)\) 下 \(f(x)\) 的期望变为分布在 \(q(x)\)  下 \(f(x)w(x)\) 的期望，从而可以近似为<br/>
\[<br/>
\hat f(N) = \frac 1 N \Big( f(x^{(1)}) w(x^{(1)}) + ... + f(x^{(N)})w(x^{(N)}) \Big)<br/>
\]</p>

<p>其中 \(x^{(i)},i=1,2,...,N\) 是独立从 \(q(x)\) 中随机抽取的点。</p>

<p>重要性采样也可以在只知道为未归一化的分布 \(\hat p(x)\) 的情况下计算函数 \(f(x)\) 的期望。</p>

<p>\[<br/>
\begin{align*}<br/>
\mathbb E_p(f(x)) &amp;= \int_x f(x) \frac{\hat p(x)}{Z} dx\\<br/>
&amp;= \frac{\int_x f(x) p(x) dx}{\int_x \hat p(x) dx}\\<br/>
&amp;\approx \frac{\sum_{i=1}^N f(x^{(i)}) \hat w(x^{(i)})}{\sum_{i=1}^N \hat w(x^{(i)}) }\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(Z\) 为配分函数，\(p(x) = \frac{\hat p(x)}{Z}\)；\(\hat w(x) = \frac{\hat p(x)}{q(x)}\)，\(x^{(i)}\) 为独立从 \(q(x)\) 中随机抽取的点。</p>

<h3 id="toc_4">概率分布采样</h3>

<p>蒙特卡罗方法关键是获得 \(x\) 的概率分布，基于概率分布去采样 \(n\) 个 \(x\) 的样本集代入蒙特卡罗式子中求解。对于常见均匀分布 \(\mathbf U(0,1)\) 是最容易采样的，一般可以通过各种伪随机数发生器可以产生指定范围内的均匀分布。而其他常见的概率分布，无论是离散的分布还是连续的分布，它们的样本都可以通过均匀分布 \(\mathbf U(0,1)\) 的样本转换而得。比如二维正态分布的样本 \((Z_1,Z_2)\) 可以通过对独立采样 \(\mathbf U(0,1)\) 得到的样本 \((X_1,X_2)\) 通过如下的式子转换而得：<br/>
\[<br/>
Z_1=\sqrt{-2\ln(X_1)} \cos(2\pi X_2)\\<br/>
Z_2=\sqrt{-2\ln(X_1)} \sin(2\pi X_2)\\<br/>
\]</p>

<p>其他一些常见的连续分布，比如t分布，F分布，Beta分布，Gamma分布等，都可以通过类似的方式从 \(\mathbf U(0,1)\) 转化得到。</p>

<p>这里介绍几个将均匀分布 \(\mathbf U(0,1)\) 转换其他分布的常见方法，并运用于各种分布的采样：</p>

<h4 id="toc_5">连续型变量的逆变换法 Inverse Transform Method For Continuous Variable</h4>

<p>先来看看 CDF 和 PDF 的定义：对于随机变量 \(X\)，如下定义的函数 \(F_X(x)\)：<br/>
\[<br/>
F_X(x) = P\{X \le x\},\quad -\infty \lt x \lt \infty<br/>
\]</p>

<p>称为 \(X\) 的累积分布函数（CDF，Cumulative Distribution Function）。已知累积分布函数满足三个性质：</p>

<ol>
<li><p><strong>有界性</strong>：<br/>
\[<br/>
\begin{align*}<br/>
\lim_{x\rightarrow -\infty} F_X(x) &amp;= 0\\<br/>
\lim_{x\rightarrow \infty} F_X(x) &amp;= 1\\<br/>
\end{align*}<br/>
\]</p></li>
<li><p><strong>单调性</strong>：<br/>
\[<br/>
F_X(x_1)\le F_X(x_2) \quad \text{if }x_1 \le x_2<br/>
\]</p></li>
<li><p><strong>右连续性</strong>：<br/>
\[<br/>
\lim_{x\rightarrow x_0^+} F_X(x) = F_X(x_0)<br/>
\]</p></li>
</ol>

<p>对于连续型随机变量 \(X\) 的累积分布函数 \(F_X(x)\)，如果存在一个定义在实数轴非负函数 \(f(x)\)，使得对于任意实数 \(x\)，有下式成立：<br/>
\[<br/>
F_X(x) = \int_{-\infty}^{x} f(t) dt<br/>
\]</p>

<p>则称 \(f(t)\) 为 \(X\) 的概率密度函数（PDF，Probability Density Function）。显然，当概率密度函数存在的时候，累积分布函数是概率密度函数的积分。</p>

<p>由累积分布积分性质我们可以知道：<br/>
\[<br/>
\begin{equation}<br/>
\lim_{x\rightarrow \infty} F(x) = 1\quad\Rightarrow\quad \int_{-\infty}^{\infty} f(t) dt = 1\label{lxri}<br/>
\end{equation}<br/>
\]</p>

<p>假设我们想生成一个随机变量 \(X\) 具有累积分布函数（CDF）\(F_X(x)\)，我们希望找到一个映射能将均匀分布 \(\mathbf u\sim \text{Uniform}(0,1)\) 转换成服从 \(X\) 分布，即 \(X=T(u)\)，所以有：</p>

<p>\[<br/>
F_X(u) = P(X\le u) = P(T(u) \le u) = P(u \le T^{-1}(u)) = T^{-1}(u)<br/>
\]</p>

<p>通过这个现象，我们能很容易获得变换函数 \(T(u) = F_X^{-1}(u)\) ，这也就意味着 \(X=T(u) = F_X^{-1}(u)\) 都服从 \(F_X(x)\) 的 CDF 分布。</p>

<p>举例说明一下：假设我们有均匀分布随机函数 \(U(0,1)\) 和累积分布函数：<br/>
\[<br/>
F(x) = 1-\exp(-\sqrt{x})<br/>
\]</p>

<p>为了去求反函数，考虑到 \(F(F^{-1}(u)) = u\)，所以有：<br/>
\[<br/>
\begin{align*}<br/>
F(F^{-1}(u)) = 1-\exp(-\sqrt{F^{-1}(u)}) &amp;= u\\<br/>
\exp(-\sqrt{F^{-1}(u)}) &amp;= 1-u\\<br/>
\sqrt{F^{-1}(u)} &amp;=-\log(1-u)\\<br/>
F^{-1}(u) &amp;= (\log(1-u))^2<br/>
\end{align*}<br/>
\]</p>

<p>再给另一个例子，我们累积分布函数在 \(x\ge 0\) 时使用指数分布 \(F_X(x) = 1-\exp(-\lambda x)\) ，其他情况为0。我们可以得到反函数通过：<br/>
\[<br/>
1-\exp(-\lambda x) = y \quad\Rightarrow\quad x = F^{-1}(y) = -\frac{1}{\lambda} \ln(1-y)<br/>
\]</p>

<p>注意这里如果我们用 \(y\) 代替 \(1-y\) 并不会对分布产生影响。</p>

<h4 id="toc_6">离散型变量的逆变换法 Inverse Transform Method For Discrete Variable</h4>

<p>考虑到在区间 \([0,1]\) 间的均匀分布 \(U\) ，它的累积分布函数为<br/>
\[<br/>
F_U(x) = P(U\le x) = \left \{\begin{array}\\0 &amp;\text{if  }x\lt 0\\x&amp;\text{if  }x=0\\1&amp;\text{if }x\gt 1\\\end{array}\right .<br/>
\]</p>

<p>假设 \(X\) 是离散变量，\(p_i = P(X=x_i)，i=1,2,...,i\)。如果 \(U\) 是一个均匀分布的随机变量，若 \(0\le a \le b\)，有<br/>
\[<br/>
P(a\le U\le b) = P(U\le b) - P(U \le a) = F_U(b) - F_U(a) = b - a<br/>
\]</p>

<p>因此对每个 \(n\) 有<br/>
\[<br/>
P(p_1+p_2+...+p_{n-1} \le U \le p_1 + p_2 + ... + p_{n-1} + p_n) = p_n<br/>
\]</p>

<p>现在令 \(Y=\Phi(U)\) 是关于随机变量 \(U\) 的方程，定义为：<br/>
\[<br/>
Y = \Phi(U) = \left \{\begin{array}\\ x_1 &amp; \text{if }U\le p_1\\ x_2 &amp; \text{if }p_1 \le U\le p_2 \\\vdots&amp;\vdots\\x_n &amp; \text{if }p_1+p_2+...+p_{n-1}\le U\le p_1 + p_2 + ... + p_{n-1}+ p_n\\\end{array}\right .<br/>
\]</p>

<p>这样 \(Y\) 有和 \(X\) 同样的分布，因此，如果 \(u_1,...,u_k\) 是从均匀分布中取样而得，\(\Phi(u_1),...,\Phi(u_k)\) 就是从 \(X\) 的分布中取样。</p>

<h4 id="toc_7">逆变换法采样</h4>

<p>在计算机模拟时，我们所说的抽样，其实是指从一个概率分布中生成观察值（observations）的方法。而这个分布通常是由其概率密度函数（PDF）来表示的。而且，即使在已知PDF的情况下，让计算机自动生成观测值也不是一件容易的事情，我们可以用上面逆变换法的方式通过 PDF 进行积分来得到概率分布的 CDF，然后再得到 CDF 的反函数 \(F_X^{-1}(x)\)，如果你想得到 \(m\) 个观察值，则重复下面的步骤 \(m\) 次：</p>

<ol>
<li>从 \(\mathbf U(0,1)\) 中随机生成一个值（前面已经说过，计算机可以实现从均匀分布中采样），用 \(u\) 表示。</li>
<li>计算 \(F^{−1}(u)\) 的值 \(x\)，则 \(x\) 就是从 \(f(x)\) 中得出的一个采样点。</li>
</ol>

<p>假设我们希望在下面的 PDF 中抽样：<br/>
\[<br/>
f(x) = \left \{ \begin{array}\\<br/>
8x\quad &amp;\text{if }\quad 0\le x\lt 0.25\\<br/>
\frac 8 3 - \frac 8 3 x\quad &amp;\text{if }\quad 0.25\le x\le 1\\<br/>
0\quad &amp;\text{otherwise}\\<br/>
\end{array} \right .<br/>
\]</p>

<p>可以算得相应的 CDF 为：<br/>
\[<br/>
F(x) = \int^x_{-\infty} f(x) \mathbf dx=  \left \{ \begin{array}\\<br/>
0,\quad &amp; \text{if }\quad  x\lt 0\\<br/>
4x^2,\quad &amp;\text{if }\quad 0\le x\lt 0.25\\<br/>
\frac 8 3 x - \frac 4 3 x^2 - \frac 1 3\quad &amp;\text{if }\quad 0.25\le x\le 1\\<br/>
1\quad &amp;\text{if }\quad x\gt 1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>在通过 PDF 计算相应CDF 时，为了点的连续加入了常量值。对于 \(u\in [0,1]\)，它的反函数为：<br/>
\[<br/>
F^{-1}(u) = \left \{ \begin{array}\\<br/>
\frac{\sqrt{u}}{2}\quad &amp;\text{if }\quad 0\le u\lt 0.25\\<br/>
1 - \frac{\sqrt{3(1-u)}}{2}\quad &amp;\text{if }\quad 0.25\le u\le 1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>从下图中你可以发现 <font color="red"><strong>采样点</strong></font> 与 <font color="blue"><strong>原始分布</strong></font> 非常吻合：</p>

<div align="center">
    <img src="media/15189654050126/15351195909818.jpg" width="250" />
</div>

<h4 id="toc_8">接受拒绝法 Acceptance-Rejection Method</h4>

<p>一般来说逆转换法是第一选择，但是逆转换法有自身的局限性，必须能给出累积分布函数 \(F_X(x)\) 反函数的表达式，这限制了逆变换法的使用范围。当没法给出累积分布函数 \(F_X(x)\) 的逆函数的表达式时，接受拒绝法是另一种选择。它的适用范围比逆变换法要大，只要给出概率密度函数的解析表达式即可，而大多数常用分布的概率密度函数是可以查到的。</p>

<p>假设我们想对 PDF 为 \(p(x)\) 的函数进行采样，但是由于种种原因（例如这个函数很复杂），对其进行采样是相对困难的。另外有一个 PDF 为 \(q(x)\) 的函数则相对容易采样，例如采用 Inverse CDF 方法可以很容易对对它进行采样，甚至 \(q(x)\) 就是一个均匀分布，\(q(x)\) 称之为提议分布（Proposal distribution）。那么，当我们将 \(q(x)\) 与一个常数 \(M\) 相乘之后，可以实现下图所示之关系，即 \(q(x)\) 将 \(p(x)\) 完全“罩住”。</p>

<div align="center">
    <img src="media/15189654050126/15351230469930.jpg" width="250" />
</div>

<p>然后重复如下步骤，直到获得 \(m\) 个被接受的采样点：</p>

<ol>
<li>从 \(q(x)\) 中获得一个随机采样点 \(x_i\)</li>
<li><p>对于 \(x_i\) 计算接受概率（acceptance probability）：<br/>
\[<br/>
\alpha = \frac{p(x_i)}{Mq(x_i)}<br/>
\]</p></li>
<li><p>从 \(U(0,1)\) 中随机生成一个值，用 \(u\) 表示</p></li>
<li><p>如果 \(u \le \alpha\)，则接受 \(x_i\) 作为一个来自 \(p(x)\) 的采样值，否则就拒绝 \(x_i\) 并回到第一步。</p></li>
</ol>

<p>我们还是以之前的例子为例，使用接受决绝进行采样，使用 \(Mq(x)=3 - 2x\) 函数作为提议分布，即 \(q(x) = \frac 1 M (3-2x)\)，如下图：</p>

<div align="center">
    <img width="230" src="media/15189654050126/15351726022817.jpg" />
</div>

<p>对 \(q(x)\) 函数下面的面积进行归一化求一下 \(M\) 的大小，由 \ref{lxri} 式：<br/>
\[<br/>
\begin{align*}<br/>
\int_{-\infty}^{\infty} f(x) = 1\quad&amp;\Rightarrow\quad \int_{-\infty}^{\infty} \frac 1 M f(x) = 1\\<br/>
&amp;\Rightarrow\quad \int_{-\infty}^{0} f(x) + \int_{0}^{1} f(x) + \int_{1}^{\infty} f(x) = 1\\<br/>
&amp;\Rightarrow\quad \int_{-\infty}^{0} 0 \mathbf dx + \int_{0}^{1} \frac 1 M (3-2x) \mathbf dx + \int_{1}^{\infty} 1 \mathbf dx = 1\\<br/>
&amp;\Rightarrow\quad 0 + \int_{0}^{1} \frac 1 M (3-2x) \mathbf dx + 0 = 1\\<br/>
&amp;\Rightarrow\quad \frac 1 M (3x - x^2) \bigg |_0^1 = 1\\<br/>
&amp;\Rightarrow\quad \frac 2 M = 1\\<br/>
&amp;\Rightarrow\quad M = 2<br/>
\end{align*}<br/>
\]</p>

<p>所以 \(q(x) = \frac 3 2 - x^2\) ，现在来求 \(q(x)\) 的累积分布函数：<br/>
\[<br/>
F_X(x) = \left \{ \begin{array} \\<br/>
0\quad &amp; x \lt 0\\<br/>
-\frac 1 2 x^2 + \frac 3 2 x\quad &amp;\text{if }\quad 0\le x\le 1\\<br/>
1\quad &amp; x \gt 1\\<br/>
\end{array}\right .<br/>
\]</p>

<p>所以 \(q(x)\) 的分布函数可以由均匀分布通过反函数求得：<br/>
\[<br/>
F^{-1}_X(u) = \frac 3 2 - \sqrt{\frac{9}{4} - 2u}  \quad u\in[0,1]<br/>
\]</p>

<p>现在能通过 Inverse Transform 方法对 \(q(x)\) 进行取样，取样后计算 \(\alpha\)，再取随机数 \(u\) 与 \(\alpha\) 比较决定接受拒绝，代码如下：</p>

<pre><code class="language-python">import numpy as np
from matplotlib import pyplot as plt
import math
# 均匀取样 10000 个数据点
uniform_sample = np.random.rand(30000)
# 利用Inverse Transform 将 10000 个样本转换成满足 q 分布样本
q_sample = [3.0/2 - math.sqrt(9.0/4 - 2*x) for x in uniform_sample]
# 计算样本 p 的值
p = [8*x if x &gt;=0 and x &lt;0.25 else 8.0/3 - 8.0/3 * x for x in q_sample]
# 计算样本 q 的值
q = [3.0/2 - x for x in q_sample]
# 计算样本 a 的值
a = np.array(p)/(3*np.array(q))
# 接受拒绝样本
accept_sample = [x  for i,x in enumerate(q_sample) if np.random.rand() &lt;= a[i]]
# 画图，原始分布
x_d = np.linspace(0,1,5000)
plt.plot(x_d,[8*x if x &gt;=0 and x &lt;0.25 else 8.0/3 - 8.0/3 * x for x in x_d],color=&quot;r&quot;,linewidth=3)
# 画图，拒绝采样后的分布
cnts, bins = np.histogram(accept_sample,bins=np.linspace(0,1,21),density=True)
bins = (bins[:-1] + bins[1:]) / 2
plt.plot(bins, cnts,color=&quot;g&quot;,linewidth=3)
plt.show()
</code></pre>

<p>如下图，采样效果还是挺好的：</p>

<div align="center">
    <img src="media/15189654050126/15351958248333.jpg" width="250" />
</div>

<p>这里还有个更简单的做法，提议分布选最简单的均匀分布，如 \(q(x) = 1，M=3\) 。</p>

<h4 id="toc_9">自适应的拒绝采样 Adapter Reject Sample</h4>

<p>前面介绍的拒绝采样中，如果 \(p(x)\) 与 \(q(x)\) 不是很接近会使 \(\alpha\) 很小，大多数的采样都会被拒绝掉，会影响采样效率。我们需要找到一个与 \(p(x)\) 很接近的 \(q(x)\) ，如果函数是 log 式凹函数（log-concave，我们通常理解的凸函数，或下凹函数）的话，那么我们就可以采样自适应的拒绝采样方法。</p>

<p>有一个的漂亮的思路是用分段的直线将分布包络起来进行采样.用分段直线进行包络时,如果分布曲线是凹的（开口向下,concave）,那么该曲线上的点的切线都将在该曲线的上方.于是在该曲线上找若干个点,并用这些点的切线,就可以将该曲线包络住。</p>

<div align="center">
    <img src="media/15189654050126/15352107929781.jpg" width="250" />
</div>

<p>大多数分布都具有指数的形式,不一定是凹函数,取对数后分布形式会变的简洁易于找切线.此时对分布的要求就转为取对数后是凹函数即可。</p>

<p>总体步骤如下：</p>

<ol>
<li><p><strong>给出分布函数 PDF 的对数函数 \(f(x)=\log(p(x))\),及其对应的一阶导数函数 \(f’(x)\)；</strong></p>

<div align="center">
    <img src="media/15189654050126/15352593502795.jpg" width="300" />
</div></li>
<li><p><strong>给定几个初始点，求出这几个初始点的切线，并计算切线与切线的交点。如果有边界，边界一般为垂直于横轴的直线，要计算切线与边界的交点；</strong></p>

<div align="center">
    <img src="media/15189654050126/15352615796344.jpg" width="300" />
</div>

<p><font color="#666"><br/>
我们来看看交点的求法，假设初始点开始有 \(n\) 个为 \((x_0,x_1,...x_i,...,x_{n-1})\) ，我们知道曲线在 \(x_i\) 处的一阶导数值为该点切线的斜率，用 \(\text{fprima}_{x_i}\) 表示。假设现在需要计算曲线在初始点 \(x_i\) 与相邻初始点 \(x_{i+1}\) 的切线的交点，首先设过 \(x_i\) 和 \(x_{i+1}\) 点的切线方程为：<br/>
\[<br/>
\begin{align}<br/>
y &amp;= \text{fprima}_{x_i} x + b_i\label{yt1}\\<br/>
y &amp;= \text{fprima}_{x_{i+1}} x + b_{i+1} \label{yt2}\\<br/>
\end{align}<br/>
\]</p>

<p>将 \(x_i\) 代入 \(f(x)\) 得到该点纵坐标的值，设为 \(f_{x_i}\)。将点 \((x_i,\text{f}_{x_i})\) 和 \((x_{i+1},\text{f}_{x_{i+1}})\) 分别代入两条切线方程求出常数项 \(b_i\) 和 \(b_{i+1}\) ：<br/>
\[<br/>
\begin{align*}<br/>
\left \{ \begin{array}\\<br/>
\text{f}_{x_i} = \text{fprima}_{x_i} x_i + b_i\\<br/>
\text{f}_{x_{i+1}} = \text{fprima}_{x_{i+1}} x_{i+1} + b_{i+1} \\<br/>
\end{array} \right .&amp;\Rightarrow \left \{ \begin{array}\\<br/>
b_i = \text{f}_{x_i} - \text{fprima}_{x_i} x_i\\<br/>
b_{i+1} = \text{f}_{x_{i+1}} - \text{fprima}_{x_{i+1}} x_{i+1}<br/>
\end{array} \right.<br/>
\end{align*}<br/>
\]</p>

<p>已知 \ref{yt1} 与 \ref{yt2} 两条切线方程的解即为交点的坐标，所以：<br/>
\[<br/>
\begin{align}<br/>
\hat x_i &amp;= \frac{b_{i+1}-b_i}{\text{fprima}_{x_i} - \text{fprima}_{x_{i+1}}} = \frac{{\text{f}_{x_{i+1}} - \text{f}_{x_i}} + \text{fprima}_{x_i} x_i- {\text{fprima}_{x_{i+1}} x_{i+1}}}{\text{fprima}_{x_i} - \text{fprima}_{x_{i+1}}} \label{xf}\\<br/>
\hat y_i &amp;= \text{fprima}_{x_i} \hat x_i + b = \text{fprima}_{x_i} \hat x_i + \text{f}_{x_i} - \text{fprima}_{x_i} x_i = \text{fprima}_{x_i} (\hat x_i - x_i) + \text{f}_{x_i} \label{yf}\\<br/>
\end{align}<br/>
\]</p>

<p>通过式 \ref{xf} 我们可以求出相邻切线之间的切点的横坐标 \((\hat x_0,\hat x_1,...,\hat x_{n-2})\) （ \(n\) 个切线相邻切线直接交点最多为 \(n-1\) 个），再加上前后两个边界线的横坐标，便得到了所有交点的横坐标：x<br/>
\[<br/>
\hat x^*=(\hat x^*_0,\hat x^*_1,...,\hat x^*_{n})=(0,\hat x_0,\hat x_1,...,\hat x_{n-2},1)<br/>
\]</p>

<p>现在再来看所有交点的纵坐标，除与边界的交点外，相邻切线的交点可以由 \ref{yf} 式得到。切线与边界 \(x=0\) 的交点的纵坐标，也就是第一条切线方程与 \(x=0\) 的解：<br/>
\[<br/>
\begin{equation}<br/>
\hat y^*_0 = b_0 = \text{f}_{x_0} - \text{fprima}_{x_0} x_0 =  \text{fprima}_{x_0} (0- x_0) + \text{f}_{x_0} \label{yf_1}<br/>
\end{equation}<br/>
\]</p>

<p>切线与边界 \(x=1\) 的交点的纵坐标，也就是第 \(n-1\) 条（最后一条）切线方程与 \(x=1\) 的解：<br/>
\[<br/>
\begin{equation}<br/>
\hat y^*_{n} = \text{fprima}_{x_{n-1}} + b_{n-1} = \text{fprima}_{x_{n-1}} + \text{f}_{x_{n-1}} - \text{fprima}_{x_{n-1}} x_{n-1} = \text{fprima}_{x_{n-1}}(1-x_{n-1}) + \text{f} _{x_{n-1}} \label{yf_2}<br/>
\end{equation}<br/>
\]</p>

<p>结合 \ref{yf}、\ref{yf_1} 和 \ref{yf_2} 式：<br/>
\[<br/>
\hat y^*_j = \left \{ \begin{array}\\<br/>
\text{fprima}_{x_0} (0- x_0) + \text{f}_{x_0} \quad &amp;\text{if}\quad j=0\\<br/>
\text{fprima}_{x_i} (\hat x_i - x_i) + \text{f}_{x_i} \quad &amp;\text{if}\quad 1\le j \le n-1;i=j-1\\<br/>
\text{fprima}_{x_{n-1}}(1-x_{n-1}) + \text{f} _{x_{n-1}} \quad &amp;\text{if}\quad j = n<br/>
\end{array}\right .<br/>
\]</p>

<p>很容易统一纵坐标的求法 <br/>
\[<br/>
\hat y^*_j = \text{fprima}^* (\hat x^* - x^*) + \text{f}_{x^*}\\<br/>
\]</p>

<p>其中：<br/>
\[<br/>
\begin{align*}<br/>
\text{fprima}^* &amp;= (\text{fprima}_{x_{0}}，\text{fprima}_{x_{0}}，\text{fprima}_{x_{1}},...,\text{fprima}_{x_{n-1}})\\<br/>
x^* &amp;=(x_0,x_0,x_1,...,x_{n-1})<br/>
\end{align*}<br/>
\]</p>

<p></font></p></li>
<li><p><strong>将分段直线取指数转换为对应的指数曲线，分别计算各段指数曲线的定积分。也就是计算各段曲线下覆盖的面积。累积且归一化后得到一个分段 CDF</strong>；</p>

<div align="center">
    <img width="300" src="media/15189654050126/15352636080572.jpg" />
</div>

<p><font color="#666"><br/>
上面已经求出每一条切线方程，设初始点 \(x_i\) 对应的切线方程为：<br/>
\[<br/>
\begin{align}<br/>
y &amp;= \text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i} \label{ytx1}\\<br/>
\end{align}<br/>
\]</p>

<p>指数曲线为：<br/>
\[<br/>
\begin{align}<br/>
f_{x_i}(x) = \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\label{eye}\\<br/>
\end{align}<br/>
\]</p>

<p>计算指数曲线的定积分：     \[<br/>
\begin{align*}<br/>
S_i &amp;= \int_{x^*_i}^{x^*_{i+1}} f_{x_i}(x) = \int_{x^*_i}^{x^*_{i+1}} \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
&amp;= \frac 1 {\text{fprima}_{x_i}}\exp\Big[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}\Big]\bigg|_{x^*_i}^{x^*_{i+1}}\\<br/>
&amp;= \frac 1 {\text{fprima}_{x_i}}\bigg(\exp\Big[\text{fprima}_{x_i} (x^*_{i+1} - x_i)+ \text{f}_{x_i}\Big] - \exp\Big[\text{fprima}_{x_i} (x^*_i - x_i)+ \text{f}_{x_i}\Big] \bigg)<br/>
\end{align*}<br/>
\]</p>

<p>之后对所有曲线计算出的 \(S\) 进行归一化，得到归一化参数 \(M\)，即：<br/>
\[<br/>
M \sum_{i=0}^{n-1} S_i = 1 \quad \Rightarrow \quad M = \frac 1 {\sum_{i=0}^{n-1} S_i}<br/>
\]</p>

<p>那初始点 \(x_i\) 对应的曲线的 CDF 函数为：<br/>
\[<br/>
\begin{align*}<br/>
F_{x_i}(x) &amp;= M \int_{-\infty}^x f_{x_i}(x) \\<br/>
&amp;= M \int_{-\infty}^x \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
&amp;= M \int_{-\infty}^{x_i} \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}] + M \int_{x_i}^x \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
&amp;= M \sum_{j=0}^{i} S_j + M \int_{x_i}^x \exp[\text{fprima}_{x_i} (x - x_i) + \text{f}_{x_i}]\\<br/>
\end{align*}<br/>
\]</p>

<p></font></p></li>
<li><p><strong>从均匀分布中得到一个样本，记为 \(a\)，找到属于分段 CDF 中的哪一段；</strong></p></li>
<li><p><strong>再用该段对应的指数函数的 CDF，再次使用 \(y\)，用 Inverse Transform 找到对应的 \(y\) 的值；</strong></p></li>
<li><p><strong>再次用均匀分布 \((0,1)\) 中产生一个随机值，若该随机值小于等于 \(p(x)/e(x)\) 则接受该样本 \(x\) ， \(e(x)\) 为该段对应的指数函数；</strong></p></li>
<li><p><strong>若第6步中样本 \(x\) 被拒，则将 \(x\) 点加入到初始点集合中，重复2、3步，也就是多加一段以形成更好的包络；</strong></p></li>
</ol>

<p>在采样过程中用到两次 Inverse Transform 和一个拒绝采样；</p>

<p>我们举个简单的例子说明这个过程，首先看一下 \(\text{Beta}(2,5)\) 分布：</p>

<div align="center">
    <img src="media/15189654050126/15352090709370.jpg" width="250" />
</div>

<p>第一步：Beta 分布函数对应的对数函数 \(f(x)=\log(p(x))\)，及其对应的对数函数一阶导数函数 \(f’(x)\)。<br/>
\[<br/>
\begin{align*}<br/>
f(x) &amp;= \log(\text{Beta}(\alpha,\beta)) = \log\bigg(\frac 1 {\text{B}(\alpha,\beta)} x^{\alpha-1}(1-x)^{\beta-1}\bigg)\\<br/>
&amp;= \frac 1 {\text{B}(\alpha,\beta)}\bigg[(\alpha-1)\log x + (\beta - 1)\log(1-x)\bigg]\\<br/>
f&#39;(x) &amp;= \frac 1 {\text{B}(\alpha,\beta)}\bigg[\frac{\alpha-1}{x} + \frac{\beta - 1}{1-x}\bigg]\\<br/>
\end{align*}<br/>
\]</p>

<p>将常数项 \(\frac 1{\text{B}(\alpha,\beta)}\) 用 \(B\) 表示，代码如下：</p>

<pre><code class="language-python">import numpy as np
from matplotlib import pyplot as plt

# beta原函数
def beta_pdf(x,a=2,b=5):
    return B*np.power(x,(a-1))*np.power((1-x),(b-1))

# beta对数函数
def f(x, a=2, b=5):
    return B*((a-1)*np.log(x)+(b-1)*np.log(1-x))

# beta对数函数的一阶导数函数
def fprima(x, a=2, b=5):
    return B*((a-1)/x-(b-1)/(1-x))
</code></pre>

<p>第二步：给定几个初始点，求出这几个初始点的切线，并计算切线与切线的交点。如果有边界，边界一般为垂直于横轴的直线，要计算切线与边界的交点；</p>

<p>Beta 分布有边界 \(x=0\) 和 \(x=1\) 。在示例中再给出3个初始点，那么一共有3个切线，两个边界，我们关心的交点就有4个（三条切线有两个交点，切线与两个边界有两个交点）。</p>

<pre><code class="language-python"># 初始点
x = np.array([0.1,0.4,0.8])

# 初始化交点的横轴对应的值
z = np.zeros(len(x)+1)
z[0] = 0.0  # 第一个边界
z[-1] = 1.0 # 第二个边界

# 计算切线交点对应的横轴的值
for j in range(len(x)-1):
  z[j+1] = (f(x[j+1])-f(x[j]) - x[j+1]*fprima(x[j+1]) + x[j]*fprima(x[j])) / (fprima(x[j]) - fprima(x[j+1]))

# 计算切线交点对应的纵轴的值
h = f(x)
hprime = fprima(x)
u = hprime[[0]+range(len(x))]*(z-x[[0]+range(len(x))]) + h[[0]+range(len(x))]

# 画出对应的 PDF 的对数曲线,切线,并标注交点
fig, ax = plt.subplots()
log_x = np.linspace(0.0,1.0,1000)
ax.plot(log_x,f(log_x),linewidth=3)

# 画切线
for i in range(len(x)):
    log_line_x = np.linspace(z[i],z[i+1],30)
    log_line_y = h[i] + hprime[i]*(log_line_x-x[i])
    ax.plot(log_line_x,log_line_y,color=&#39;green&#39;,linewidth=3)

# 绘制辅助线
xticks = []
xticklabels = []

# 初始点横坐标
for i in range(len(x)):    
    ax.plot([x[i]]*30,np.linspace(-35,0,30),ls=&#39;dotted&#39;,color=&#39;red&#39;,linewidth=2)
    xticks += [x[i]]
    xticklabels += [&quot;x[%d]&quot;%i]

# 交点横坐标
for i in range(len(z)):
    ax.plot([z[i]]*30,np.linspace(-35,0,30),ls=&#39;dotted&#39;,color=&#39;red&#39;,linewidth=2)
    xticks += [z[i]]
    xticklabels += [&quot;z[%d]&quot;%i]

ax.set_xticks(xticks)
ax.set_xticklabels(xticklabels)

# 绘制交点
ax.scatter(z,u,color=&#39;blue&#39;)
fig.show()
</code></pre>

<p>效果图：</p>

<div align="center">
    <img src="media/15189654050126/15352544615332.jpg" width="300" />
</div>

<p>第三步：将分段直线取指数转换为对应的指数曲线，分别计算各段指数曲线的定积分。也就是计算各段曲线下覆盖的面积。累积且归一化后得到一个分段 CDF。</p>

<h4 id="toc_10">组合法</h4>

<p>当目标分布可以用其它分布经过四则运算表示时，可以使用组合算法生成对应随机数。此部分仅以几个例子简要介绍。</p>

<ol>
<li><p><strong>正态分布（Box Muller方法）</strong></p>

<p>在上文中，我们直接给出了二维正态分布由均匀分布变换的方法：二维正态分布的样本 \((Z_1,Z_2)\) 可以通过对独立采样 \(\mathbf U(0,1)\) 得到的样本 \((X_1,X_2)\) 通过如下的式子转换而得：<br/>
\[<br/>
Z_1=\sqrt{-2\ln(X_1)} \cos(2\pi X_2)\\<br/>
Z_2=\sqrt{-2\ln(X_1)} \sin(2\pi X_2)\\<br/>
\]</p>

<p>证明：假设现在有两个独立的标准正态分布 \(X\sim \mathcal N(0,1)\) 和 \(Y\sim \mathcal N(0,1)\)，由于二者相互独立，则联合概率密度函数为<br/>
\[<br/>
\begin{align*}<br/>
p(x,y) = p(x)p(y) &amp;= \frac{1}{\sqrt{2\pi}}\exp(-\frac{x^2}{2})\cdot \frac{1}{\sqrt{2\pi}}\exp(-\frac{y^2}{2})\\<br/>
&amp;= \frac{1}{2\pi}\exp(-\frac{x^2+y^2}{2})<br/>
\end{align*}<br/>
\]</p>

<p>由逆转换法我们知道直接对 \(p(x,y)\) 求积分比较难，由此我们想到可以先将平面坐标转化为极坐标，令 <br/>
\[<br/>
\begin{align}<br/>
x=\rho\cos(\theta)\label{xrc}\\<br/>
y=\rho\sin(\theta)\label{xrs}\\<br/>
\end{align}<br/>
\]</p>

<p>我们知道二重积分转化为极坐标下二重积分如下<br/>
\[<br/>
\iint\limits_D p(x,y) \mathbf dx\mathbf dy = \int_{\alpha}^{\beta} \mathbf d\theta\int_{\rho_1(\theta)}^{\rho_2(\theta)} p(\rho\cos\theta,\rho\sin\theta)\rho \mathbf d\rho<br/>
\]</p>

<p>现在我们分别对 \(\theta\) 和 \(\rho\) 来求累计分布概率<br/>
\[<br/>
\begin{align*}<br/>
F_\theta(x) &amp;= \int_{0}^{x} \mathbf d\theta \int_{-\infty}^{\infty} \frac{1}{2\pi}\exp(-\frac{\rho^2}{2})\rho\mathbf d\rho\\<br/>
&amp;= \frac{x}{2\pi} \bigg[-\exp(-\frac{\rho^2}{2})\bigg]_{-\infty}^{\infty}\\<br/>
&amp;= \frac{x}{2\pi}\\<br/>
F_\rho(x) &amp; = \int_{0}^{2\pi}\mathbf d\theta \int_{0}^{x} \frac{1}{2\pi}\exp(-\frac{\rho^2}{2})\rho\mathbf d\rho\\<br/>
&amp;= \int_{0}^{x} \exp(-\frac{\rho^2}{2})\rho\mathbf d\rho\\<br/>
&amp;= \bigg[-\exp(-\frac{\rho^2}{2}) \bigg]_{0}^{x}\\<br/>
&amp;= 1 -\exp(-\frac{x^2}{2}) <br/>
\end{align*}<br/>
\]</p>

<p>对 CDF 求逆函数即可得 \(\theta\) 和 \(\rho\) 的分布，即<br/>
\[<br/>
\theta = {F_{\theta}}^{-1}(u) = 2\pi u\\<br/>
\rho = {F_{\rho}}^{-1}(u) = \sqrt{-2\ln(1-u)}\\<br/>
\]</p>

<p>而如果 \(u\) 是均匀分布的，那么 \(u = 1-u\) 也将是均匀分布的，于是可以用 \(u\) 替换 \(1-u\)，当我们得到均匀分布 \(U_1、U_2\) 后，可以通过下式得到二维正太分布采样：<br/>
\[<br/>
X = \rho\cos(\theta) = \cos(2\pi U_1)\sqrt{-2\ln U_2}\\<br/>
Y = \rho\sin(\theta) = \sin(2\pi U_1)\sqrt{-2\ln U_2}\\<br/>
\]</p></li>
<li><p><strong>泊松分布（Poisson distribution）</strong></p>

<p>泊松分布是一种统计与概率学里常见到的离散机率分布，概率函数为：<br/>
\[<br/>
p(N(t) = k) = \frac{\lambda^k}{k!} e^{-\lambda t},\quad k=1,2,...<br/>
\]</p>

<p>其中 \(N\) 表示某种函数关系，\(t\) 表示事件，\(n\) 表示发生的次数。如1小时内出生3个婴儿的概率，就表示为 \(P(N(1)= 3)\)，等号右边 \(\lambda\) 是单位时间(或单位面积)内随机事件的平均发生率。泊松分布适合于描述单位时间内随机事件发生的次数。通俗讲就是观察事物平均发生 \(\lambda\) 次的条件下，实际发生 \(k\) 次的概率。关于泊松分布<a href="https://www.face2ai.com/Math-Probability-5-4-The-Poisson-Distribution/">看这里</a></p>

<p>再来看指数分布，指数分布（也称为负指数分布）是描述泊松过程中的事件之间的时间的概率分布，即事件以恒定平均速率连续且独立地发生的过程。 这是伽马分布的一个特殊情况。关于指数分布的文章<a href="http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html">看这里</a></p>

<p>指数分布由泊松分布推出：设相邻两次事件间隔为 \(T\)，起始时刻为 \(T_{start}\)，则终止时间为 \(T_{start} + T\)，\(P\{T\ge t\}\) 表示 \([T_{start},T_{start} + t]\) 时间内没有事件发生，即：<br/>
\[<br/>
P\{T\ge t\} = P(N(t)=0) = e^{-\lambda t}<br/>
\]</p>

<p>从而可知事件发生的概率为：<br/>
\[<br/>
F_T(t) = 1 - P\{T\ge t\} = P\{T\lt t\} = 1 - e^{-\lambda t}<br/>
\]</p>

<p>也就是 CDF 函数为 \(F_T(t)\)，对应的概率质量函数 PMF 为：<br/>
\[<br/>
f_T(t) = \lambda e^{-\lambda t},\quad t\ge 0<br/>
\]</p>

<p>也就是有<br/>
\[<br/>
p(t=0) = \lambda<br/>
\]</p>

<p><strong>算法思想</strong>：根据分析可知，泊松分布对应的是一段时间内 （记为\(t_{max}\)）时间发生的次数，而指数分布对应的是事件发生时间间隔的概率分布；</p>

<p>反过来，<strong>已知两两相邻的时间变量，该变量服从指数分布且相互独立，所有时间变量相加，并让其不超过一段时间的总量 \(t_{max}\)，则累加数的分布对应泊松（Poisson）分布</strong>。</p>

<p><strong>算法步骤</strong>：</p>

<p>a. 生成一组均匀分布随机数：\(U\sim U(0,1)\)；<br/>
b. 利用逆变换法生成一系列独立的指数分布 \(X_i\)<br/>
c. 记<br/>
\[<br/>
Y = X_1 + X_2 + ... + X_k<br/>
\]</p>

<p>如果 \(Y&gt;t_{max}\)，则停止，并输出 \(k−1\);否则，继续生成 \(X_{k+1}\)，直到 \(Y&gt;t_{max}\) 为止；<br/>
d. 循环操作过程3；</p>

<p>输出的一系列整数（值为 \(k−1\)）服从参数为 \(\mu=\lambda t_{max}\) 的泊松分布。</p>

<p>这里我们不失一般性的令 \(t_max = 1\)，这样便需要找到最小的 \(t\) 使<br/>
\[<br/>
X_1 + X_2 + ... + X_k \gt 1 \quad\Rightarrow\quad \sum_{i=1}^k X_i \gt 1<br/>
\]</p>

<p>又因为 \(X_i\) 是指数分布，即<br/>
\[<br/>
X_i = F_T^{-1}(u_i) = \frac{\ln(1-u_i)}{-\lambda} \Leftrightarrow X_i = -\frac{\ln(u_i)}{\lambda}<br/>
\]</p>

<p>所以<br/>
\[<br/>
X_1 + X_2 + ... + X_k = \sum_{i=1}^k -\frac{\ln(u_i)}{\lambda} = -\frac{1}{\lambda} \ln \Big(\prod_{i=1}^k u_i\Big) \gt 1\\<br/>
\Rightarrow \prod_{i=1}^k u_i \lt e^{-\lambda}<br/>
\]</p>

<p>所以我们算法可以变成：生成一组均匀分布随机数 \(U_1,U_2,...,U_n\)，找到最小的 \(j\) 使<br/>
\[<br/>
\prod_{i=1}^k U_i \lt e^{-\lambda}<br/>
\]</p>

<p>输出一系列的 \(j-1\) 满足泊松分布。</p>

<p>代码如下：</p>

<pre><code class="language-python">import math
import random

def poisson(Lambda):
    j=0
    p = 1.0
    l = math.exp(-Lambda)
    while p &gt;= l:
        U = random.random()
        p = p * U
        j = j + 1
    return j-1

for i in range(100):
    x = poisson(5)
    print(x)
</code></pre>

<p>上面使用指数分布来生成泊松分布，其实泊松分布也可以通过离散型变换法得到，由于这过程中有阶乘的计算，为提升效率，这里使用一个方法简介计算，在 \(N(t)=K+1\) 时<br/>
\[<br/>
\begin{align}<br/>
P(N(t) = k+1) &amp;= \frac{\lambda^{k+1}}{(k+1)!} e^{-\lambda t}\\<br/>
&amp;= \frac{\lambda^k}{k!} e^{-\lambda t} \frac{\lambda}{k+1}\\<br/>
&amp;= \frac{\lambda}{k+1} P(N(t)=k)<br/>
\end{align}<br/>
\]</p>

<p>这样可以使用前一步的结果乘上 \(\frac{\lambda}{k+1}\) 得到下一个概率提升效率。</p>

<p>代码如下：</p>

<pre><code class="language-python">import math
import random

def poisson(Lambda):
    k=0
    p = math.exp(-Lambda)
    s = p
    U = random.random()
    if U &lt;= math.exp(-Lambda):
        return 0
    else:
        while U &gt; s:
            p = Lambda * p / (k+1)
            s = s + p
            k += 1
        return k-1

for i in range(100):
    x = poisson(5)
    print(x)
</code></pre></li>
</ol>

<hr/>

<p><a href="http://www.cnblogs.com/pinard/p/6625739.html">刘建平Pinard-蒙特卡罗方法</a><br/>
<a href="https://blog.csdn.net/ACdreamers/article/details/44978591">蒙特卡罗算法</a><br/>
<a href="https://www.cnblogs.com/xingshansi/p/6539319.html">信号处理-生成给定分布</a><br/>
<a href="https://blog.csdn.net/baimafujinji/article/details/51407703">蒙特卡罗采样-拒绝采样</a><br/>
<a href="https://blog.csdn.net/lin360580306/article/details/51240398">随机过程-Metropolis-Hastings算法</a><br/>
<a href="https://wenku.baidu.com/view/d2c27c0510661ed9ac51f325.html">极坐标计算二重积分</a><br/>
<a href="https://lucius-yu.github.io/docs/probability/BasicMCSamplingMethod/">基本的蒙特卡罗采样方法</a><br/>
<a href="http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html">泊松分布与指数分布</a><br/>
<a href="http://www3.eng.cam.ac.uk/%7Ess248/G12-M01/Week1/ITM.pdf">Inverse Transform Method</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15181958451732.html">随机森林 Random Forest</a></h1>
			<p class="meta"><time datetime="2018-02-10T01:04:05+08:00" 
			pubdate data-updated="true">2018/2/10</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>随机森林，英文名为 Random Forest，后面简称 RF，它是 Bagging 算法的进化版，它在 Bagging 的基础上改进了一些内容：</p>

<ol>
<li>随机森林就是由多棵 CART 树构成的。</li>
<li>对于普通的决策树，我们会在节点上所有的 \(n\) 个样本特征中选择一个最优的特征来做决策树的左右子树划分，但是 RF 通过随机选择节点上的一部分样本特征。假设特征总数目为 \(n\) ，每次随机选择 \(n_{sub}\) 个样本特征，在其中选择一个最优的特征来做决策树的左右子树划分。这样进一步增强了模型的泛化能力。如果 \(n_{sub}=n\) ，则此时 RF 的 CART 决策树和普通的 CART 决策树没有区别。\(n_{sub}\) 越小，则模型越健壮，当然此时对于训练集的拟合程度会变差。在实际案例中，一般会通过交叉验证调参获取一个合适的 \(n_{sub}\) 的值。</li>
</ol>

<h3 id="toc_0">随机森林算法步骤</h3>

<p><b>输入</b>：样本集 \(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)，弱分类器迭代次数 \(T\)<br/>
<b>输出</b>：最终的强分类器 \(f(x)\)<br/>
<b>算法过程</b>：</p>

<ul>
<li><p>对于\(t=1,2,...,T\)：</p>

<ul>
<li>对训练集进行第 \(t\) 次随机采样，共采集 \(m\) 次，得到包含 \(m\) 个样本的采样集 \(D_t\)；</li>
<li>用采样集 \(D_t\) 训练第 \(t\) 个决策树模型 \(G_t(x)\) ，在训练决策树模型的节点的时候，在节点上所有的样本特征中选择一部分样本特征， 在这些随机选择的部分样本特征中选择一个最优的特征来做决策树的左右子树划分；</li>
</ul></li>
<li><p>如果是分类算法预测，则 \(T\) 个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，\(T\) 个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。</p></li>
</ul>

<h3 id="toc_1">随机森林扩展</h3>

<p>由于 RF 在实际应用中的良好特性，基于 RF ，有很多变种算法，应用也很广泛，不光可以用于分类回归，还可以用于特征转换，异常点检测等。下面对于这些RF家族的算法中有代表性的做一个总结。</p>

<h5 id="toc_2">Extra-Trees 极端随机树</h5>

<p>ET 或 Extra-Trees（Extremely randomized trees，极端随机树）是由PierreGeurts等人于2006年提出。该算法与随机森林算法十分相似，都是由许多决策树构成。但该算法与随机森林有两点主要的区别：</p>

<ol>
<li><p>随机森林应用的是 Bagging 模型，而 ET 是使用所有的训练样本得到每棵决策树，也就是每棵决策树应用的是相同的全部训练样本；</p></li>
<li><p>随机森林是在一个随机子集内得到最佳分叉属性，而 ET 是完全随机的得到分叉值，从而实现对决策树进行分叉的。</p></li>
</ol>

<p>从第二点可以看出，由于随机选择了特征值的划分点位，而不是最优点位，这样会导致生成的决策树的规模一般会大于 RF 所生成的决策树。也就是说，模型的方差相对于RF进一步减少，但是偏倚相对于 RF 进一步增大。在某些时候，Extra-Trees 的泛化能力比 RF 更好。</p>

<h5 id="toc_3">Totally Random Trees Embedding</h5>

<p>Totally Random Trees Embedding(以下简称 TRTE)是一种非监督学习的数据转化方法。它将低维的数据集映射到高维，从而让映射到高维的数据更好的运用于分类回归模型。我们知道，在支持向量机中运用了核方法来将低维的数据集映射到高维，此处TRTE提供了另外一种方法。</p>

<p>TRTE 在数据转化的过程也使用了类似于 RF 的方法，建立 \(T\) 个决策树来拟合数据。当决策树建立完毕以后，数据集里的每个数据在T个决策树中叶子节点的位置也定下来了。比如我们有3颗决策树，每个决策树有5个叶子节点，某个数据特征 \(x\) 划分到第一个决策树的第2个叶子节点，第二个决策树的第3个叶子节点，第三个决策树的第5个叶子节点。则 \(x\) 映射后的特征编码为 \((0,1,0,0,0,\qquad 0,0,1,0,0,\qquad 0,0,0,0,1)\)，有15维的高维特征。这里特征维度之间加上空格是为了强调三颗决策树各自的子编码。</p>

<p>映射到高维特征后，可以继续使用监督学习的各种分类回归算法了。　　　　</p>

<h5 id="toc_4">Isolation Forest　　　　</h5>

<p>Isolation Forest（以下简称IForest）是一种异常点检测的方法。它也使用了类似于RF的方法来检测异常点。</p>

<p>对于在 \(T\) 个决策树的样本集，IForest 也会对训练集进行随机采样,但是采样个数不需要和 RF 一样，对于 RF，需要采样到采样集样本个数等于训练集个数。但是 IForest 不需要采样这么多，一般来说，采样个数要远远小于训练集个数？为什么呢？因为我们的目的是异常点检测，只需要部分的样本我们一般就可以将异常点区别出来了。</p>

<p>对于每一个决策树的建立， IForest 采用随机选择一个划分特征，对划分特征随机选择一个划分阈值。这点也和 RF 不同。</p>

<p>外，IForest 一般会选择一个比较小的最大决策树深度 max_depth ,原因同样本采集，用少量的异常点检测一般不需要这么大规模的决策树。</p>

<p>对于异常点的判断，则是将测试样本点 \(x\) 拟合到 \(T\) 颗决策树。计算在每颗决策树上该样本的叶子节点的深度 \(h_t(x)\) ，从而可以计算出平均高度 \(h(x)\)。此时我们用下面的公式计算样本点 \(x\) 的异常概率:<br/>
\[<br/>
s(x,m)=2^{−\frac{h(x)}{c(m)}}<br/>
\]</p>

<p>其中，\(m\) 为样本个数。\(c(m)\) 的表达式为：<br/>
\[<br/>
c(m)=2\ln(m−1)+\xi−2\frac{m−1}{m},\quad \xi\text{ 为欧拉常数}<br/>
\]</p>

<p>\(s(x,m)\) 的取值范围是 \([0,1]\) ,取值越接近于1，则是异常点的概率也越大。</p>

<h5 id="toc_5">优缺点</h5>

<p>RF的主要优点有：</p>

<ol>
<li>训练可以高度并行化，对于大数据时代的大样本训练速度有优势。个人觉得这是的最主要的优点。</li>
<li>由于可以随机选择决策树节点划分特征，这样在样本特征维度很高的时候，仍然能高效的训练模型。</li>
<li>在训练后，可以给出各个特征对于输出的重要性</li>
<li>由于采用了随机采样，训练出的模型的方差小，泛化能力强。</li>
<li>相对于Boosting系列的Adaboost和GBDT， RF实现比较简单。</li>
<li>对部分特征缺失不敏感。</li>
</ol>

<p>RF的主要缺点有：</p>

<ol>
<li>在某些噪音比较大的样本集上，RF模型容易陷入过拟合。</li>
<li>取值划分比较多的特征容易对RF的决策产生更大的影响，从而影响拟合的模型的效果。</li>
</ol>

<hr/>

<p><a href="https://www.cnblogs.com/pinard/p/6156009.html">Bagging与随机森林算法原理小结</a><br/>
<a href="https://blog.csdn.net/xbmatrix/article/details/69488867?locationNum=10&amp;fps=1">Extra-Trees原理</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15175826339606.html">Bagging 方法</a></h1>
			<p class="meta"><time datetime="2018-02-02T22:43:53+08:00" 
			pubdate data-updated="true">2018/2/2</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在集成学习中，除了 Boosting 方法，各个弱学习器中有依赖关系。另一个就是 Bagging 方法，各个弱学习器中间没有依赖关系，可以并行拟合。同一个学习算法在来自同一分布的多个不同的训练数据集上训练得到的模型偏差可能较大，即模型的方差（variance）较大，为了解决这个问题，可以综合多个模型的输出结果，对于回归问题可以取平均值，对于分类问题可以采取多数投票的方法。这就是Bagging的核心思想。</p>

<p>Bagging 需要同一分布的多个不同的训练集，关键之处在于“随机取样“。固定从训练集中采集固定个数的样本，但是这种采集是一种有放回的采集，对于每一次采集，我们都将这一次采集到的样本放回，也就是说我们可能采集到重复的样本，对于这个算法我们一般会随机采集与样本训练样本数目相同的样本，这样得到的采样集和训练集合样本数目相同，但是内容不同，对于数据集m个样本的进行T次随机采样，得到训练T个训练器的训练集。 </p>

<p>注意到这和GBDT的子采样是不同的。GBDT的子采样是无放回采样，而Bagging的子采样是放回采样。</p>

<p>对于一个样本，它在某一次含m个样本的训练集的随机采样中，每次被采集到的概率是 \(1/m\) 。不被采集到的概率为 \(1−1/m\) 。如果 \(m\) 次采样都没有被采集中的概率是 \((1−1/m)^m\) 。当m→∞时，\((1−1/m)^m \rightarrow \frac 1 e \approx 0.368\) 。也就是说，在 Bagging 的 \(m\) 轮随机采样中，训练集中大约有 36.8% 的数据没有被采样集采集中。</p>

<blockquote>
<p>高等数学中两个重要的极限性质：<br/>
\[<br/>
\lim_{x\rightarrow 0} \frac{\sin x}{x} = 1\\<br/>
\lim_{x\rightarrow +\infty} (1+\frac r x)^x = e^r\\<br/>
\]</p>
</blockquote>

<p>对于这部分大约36.8%的没有被采样到的数据，我们常常称之为袋外数据(Out Of Bag, 简称OOB)。这些数据没有参与训练集模型的拟合，因此可以用来检测模型的泛化能力。</p>

<p>与 Adaboost 算法一样，一般 Bagging 算法的基础学习器是神经网络或者决策树。</p>

<p>Bagging 的集合策略也比较简单，对于分类问题，通常使用简单投票法，得到最多票数的类别或者类别之一为最终的模型输出。对于回归问题，通常使用简单平均法，对T个弱学习器得到的回归结果进行算术平均得到最终的模型输出。</p>

<p>由于 Bagging 算法每次都进行采样来训练模型，因此泛化能力很强，对于降低模型的方差很有作用。当然对于训练集的拟合程度就会差一些，也就是模型的偏倚会大一些。</p>

<h3 id="toc_0">Bagging 算法步骤</h3>

<p><b>输入</b>：样本集 \(D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}\)，弱学习器算法, 弱分类器迭代次数 \(T\) <br/>
<b>输出</b>：最终的强分类器 \(f(x)\)<br/>
<b>算法过程</b>：</p>

<ul>
<li><p>对于 \(t=1,2...,T\) :</p>

<ul>
<li>对训练集进行第 \(t\) 次随机采样，共采集 \(m\) 次，得到包含 \(m\) 个样本的采样集 \(D_t\)</li>
<li>用采样集 \(D_t\) 训练第 \(t\) 个弱学习器 \(G_t(x)\)</li>
</ul></li>
<li><p>如果是分类算法预测，则 \(T\) 个弱学习器投出最多票数的类别或者类别之一为最终类别。如果是回归算法，\( T\) 个弱学习器得到的回归结果进行算术平均得到的值为最终的模型输出。</p></li>
</ul>

<hr/>

<p><a href="https://www.cnblogs.com/pinard/p/6156009.html">Bagging与随机森林算法原理小结</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15170125982743.html">XgBoost 算法</a></h1>
			<p class="meta"><time datetime="2018-01-27T08:23:18+08:00" 
			pubdate data-updated="true">2018/1/27</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	

		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15167212454767.html">提升树与GBDT</a></h1>
			<p class="meta"><time datetime="2018-01-23T23:27:25+08:00" 
			pubdate data-updated="true">2018/1/23</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>从提升方法学习中可以知道提升方法是采用加法模型和前向分布算法，提升树是以决策树为基函数的提升方法。对于分类问题决策树是二叉分类树，对于回归问题决策树是二叉回归树。提升树可以表示为决策树的加法模型：<br/>
\[<br/>
f_M(x) = \sum_{m=1}^M T(x;\Theta_m)<br/>
\]</p>

<p>其中 \(T(x;\Theta_m)\) 表示决策树；\(\Theta_m\) 表示决策树的参数；M 为树的个数。</p>

<h4 id="toc_0">前向分布算法</h4>

<p>由前向分布算法，可知第 \(m\) 轮模型 \(f_m(x)\) 为：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + T(x;\Theta_m)<br/>
\]</p>

<p>其中 \(f_{m-1}(x)\) 为当前模型，可以通过经验风险最小化来确定下一棵决策树参数 \(\Theta_m\) ，即：<br/>
\[<br/>
\hat \Theta_m = arg \min_{\Theta_m} \sum_{i=1}^N L(y_i, f_{m-1}(x_i) + T(x_i;\Theta_m))<br/>
\]</p>

<p>不同问题的提升树学习算法的主要区别是使用的损失函数不同，包括用平方误差损失函数的回归问题，用指数损失函数的分类问题，以及使用一般损失函数的一般决策问题。</p>

<p>对于二类分类问题，提升树算法可以算是 AdaBoost 算法的特殊情况，下面主要叙述回归问题的提升树：</p>

<p>已知一个训练数据集 \(T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，\(x_i\in \mathcal X\subseteq R^n\)，\(\mathcal X\) 为输入空间，\(y_i\in \mathcal Y\subseteq R\)，\(\mathcal Y\) 为输出空间。如果将输入空间 \(\mathcal X\) 划分为 \(J\) 个互不相交的区域 \(R_1,R_2,...,R_J\)，并且在每一个区域上确定输出常量 \(c_j\) ，那么树可以表示为：<br/>
\[<br/>
T(x;\Theta) = \sum_{j=1}^J c_j I(x\in R_j)<br/>
\]</p>

<p>其中，参数 \(\Theta = \{(R_1,C_1),(R_2,c_2),...,(R_J,c_J)\}\) 表示树的区域划分和各区域上的常数。\(J\) 是回归树的复杂度即叶节点的个数。回归树使用以下的前向分步算法：<br/>
\[<br/>
\begin{align*}<br/>
&amp;f_0(x) = 0\\<br/>
&amp;f_m(x) = f_{m-1}(x) + T(x;\Theta_m), \quad m = 1,2,...,M\\<br/>
&amp;f_M(x) = \sum_{m=1}^M T(x;\Theta_m)<br/>
\end{align*}<br/>
\]</p>

<p>在前向分布算法的第 \(m\) 步，给定当前模型 \(f_{m-1}(x)\) ，需求解：<br/>
\[<br/>
\hat\Theta_m = arg \min_{\Theta_m} \sum_{i=1}^N L(y_i,f_{m-1}(x_i) + T(x_i;\Theta_m))<br/>
\]</p>

<p>得到 \(\hat\Theta_m\) ，即第 \(m\) 棵树的参数。</p>

<p>当采用平方误差损失函数时：<br/>
\[<br/>
L(y,f(x)) = (y-f(x))^2<br/>
\]</p>

<p>其损失变为：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f_{m-1}(x) + T(x;\Theta_m)) &amp;= [y-f_{m-1}(x) - T(x;\Theta_m)]^2\\<br/>
&amp;= [r-T(x;\Theta_m)]^2<br/>
\end{align*}<br/>
\]</p>

<p>这里：<br/>
\[<br/>
r = y - f_{m-1}(x)<br/>
\]</p>

<p>是当前模型拟合数据的残差（residual）。所以，对回归问题的提升树来说，只需简单的拟合当前模型的残差。这样，算法是相当简单的。</p>

<h4 id="toc_1">算法过程</h4>

<p><b>输入</b>：训练数据集 \(T=\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}\)，其中 \(x_i\in \mathcal X\subseteq R^n\)，\(y_i \in\mathcal Y \subseteq R\)；<br/>
<b>输出</b>：提升树 \(f_M(x)\)<br/>
<b>算法过程</b>：</p>

<ul>
<li>初始化 \(f_0(x) = 0\)</li>
<li><p>对 \(m=1,2,...,M\)</p>

<ul>
<li><p>计算当前残差<br/>
\[<br/>
r_{mi} = y_i - f_{m-1}(x_i), \quad i=1,2,...,N<br/>
\]</p></li>
<li><p>拟合残差 \(r_{mi}\) 学习回归树，得到 \(T(x;\Theta_m)\) </p></li>
<li><p>更新 \(f_m(x) = f_{m-1}(x) + T(x, \Theta_m)\)</p></li>
</ul></li>
<li><p>得到回归问题提升树<br/>
\[<br/>
f_M(x) = \sum_{m=1}^M T(x,\Theta_m)<br/>
\]</p></li>
</ul>

<p>接下来先介绍一下决策树桩，然后举例说明提升树实例。</p>

<h4 id="toc_2">决策树桩 decision stump</h4>

<p>决策树桩，也可以称之为单层决策树，只对一列属性做一次判断决定最终的分类结果，比如只根据瓜的根蒂是否蜷缩来判断是否是好瓜，这提现的是单一特征起作用。显然 decision stump 仅可作为一个弱基本分类器，它的结果仅会比瞎猜 \(1/2\) 稍好一点点，在集成学习中，常可以作为基本分类器。</p>

<p>决策树桩仅可以对一个属性的一次判断获取结果，我们需要找到最低错误率的决策树桩，即优化目标函数：<br/>
\[<br/>
arg \min_{1\le c\le \text{d}} \frac 1 N \sum_{i=1}^N I(y_i \neq T_c(x_i))<br/>
\] </p>

<p>其中 \(c\) 表示属性值，\(d\) 表示属性列个数，\(N\) 表示样本数量。</p>

<h4 id="toc_3">提升树实例</h4>

<p>如下图的训练数据， \(x\) 的取值范围是区间 [0.5,10.5]，\(y\) 的取值范围是区间 [5.0,10.0]，学习这个回归问题的提升树模型，考虑只用决策树桩作为基函数<br/>
\[<br/>
\begin{array}{ccccccccccc}\\\hline<br/>
x_i &amp; 1 &amp;  2 &amp;  3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10\\\hline<br/>
y_i &amp; 5.56 &amp; 5.70 &amp; 5.91 &amp; 6.40 &amp; 6.80 &amp; 7.05 &amp; 8.90 &amp; 8.70 &amp; 9.00 &amp; 9.05 \\\hline<br/>
\end{array}<br/>
\]</p>

<p>按照算法，第一步要求 \(f_1(x)\) 即第一个树桩 \(T_1(x)\)：<br/>
在本例中只有一个属性 \(x\) ，我们只需要找到在属性 \(x\) 上找到为最佳切分点 \(s\) ，切分点将样本分成了 \(R_1\) 和 \(R_2\) 两部分，两部分的属性值为 \(c_1\) 和 \(c_2\) ：<br/>
\[<br/>
\min m(s) = \min_s\bigg[ \min_{c_1} \sum_{x_i \in R_1}(y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2}(y_i - c_2)^2 \bigg]<br/>
\]</p>

<p>求解最佳切分点 \(s\) ：<br/>
\[<br/>
R_1 = {x|x\le s} ,\quad R_2 = {x|x \gt s}<br/>
\]</p>

<p>容易求得在 \(R_1\) 和 \(R_2\) 两区域使平方误差最小的 \(c_1\) 和 \(c_2\) 为：<br/>
\[<br/>
c_1 = \frac 1 {|R_1|} \sum_{x_i \in R_1}y_i , \quad c_2 = \frac 1 {|R_2|} \sum_{x_i \in R_2} y_i<br/>
\]</p>

<p>当 \(s=1.5\) 时，\(R_1=\{1\}\)，\(R_2 = \{2,3,4,5,6,7,8,9,10\}\)，此时：<br/>
\[<br/>
c_1 = 5.56,\quad c_2 = 67.51/9 = 7.50\\<br/>
m(s) = \min_{c_1} \sum_{x_i \in R_1}(y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2}(y_i - c_2)^2 = 15.72<br/>
\]</p>

<p>当 \(s=2.5\)，\(s=3.5\)，...，\(s=9.5\)，会求出不同的 \(m(s)\) ，找到令 \(m(s)\) 最小的切分点 \(s\)，本例中 \(s=6.5\) 时，\(m(s)\) 达到最小值。此时 \(R_1(x) = \{1,2,3,4,5,6\}\)，\(R_2(x) = \{7,8,9,10\}\)，\(c_1=6.24\)，\(c_2=8.91\)。所以回归树为：<br/>
\[<br/>
T_1(x) = \left \{ \begin{array}\\<br/>
6.24&amp;\quad x \le 6.5\\<br/>
8.91&amp;\quad x \gt 6.5\\<br/>
\end{array} \right .\\<br/>
f_1(x) = T_1(x)<br/>
\]</p>

<p>计算残差 \(r_{2i} = y_i - f_1(x_i),\quad i=1,2,...,10\)，可得:<br/>
\[<br/>
\begin{array}{ccccccccccc}\\\hline<br/>
 x_i  &amp; 1 &amp;  2 &amp;  3 &amp;  4 &amp;  5 &amp;  6 &amp;  7 &amp;  8 &amp;  9 &amp;  10 \\\hline<br/>
 y_i &amp;  -0.68 &amp;  -0.54 &amp;  -0.33 &amp;  0.16 &amp;  0.56 &amp; 0.81 &amp;  -0.01 &amp;  -0.21 &amp;  0.09 &amp;  0.14 &amp; \\\hline<br/>
\end{array}<br/>
\]</p>

<p>用 \(f_1(x)\) 拟合训练集平方损失误差为：<br/>
\[<br/>
L(y,f_1(x)) = \sum_{i=1}^10 (y_i - f_1(x_i))^2 = \sum_{i=1}^10 r_{1i}^2 = 1.93<br/>
\]</p>

<p>建立第二棵树拟合残差，可以得到：<br/>
\[<br/>
T_2(x) = \left \{ \begin{array}\\<br/>
-0.52&amp;\quad x\le 3.5\\<br/>
0.22 &amp;\quad x \gt 3.5\\<br/>
\end{array} \right .<br/>
\]</p>

<p>所以回归树：<br/>
\[<br/>
f_2(x) = f_1(x) + T_2(x) = \left \{ \begin{array}\\<br/>
6.24-0.52=5.72 &amp; \quad x \le 3.5\\<br/>
6.24+0.22=6.46 &amp; \quad 3.5 \lt x \le 6.5\\<br/>
8.91+0.22=9.13 &amp; \quad x \gt 6.5\\<br/>
\end{array} \right .<br/>
\]</p>

<p>如果用 \(f_2(x)\) 拟合训练数据，平方损失误差为：<br/>
\[<br/>
L(y,f_2(x)) = \sum_{i=1}^10 (y_i - f_2(x_i))^2 = 0.79\\<br/>
\]</p>

<p>继续前向分步算法直到平方损失误差满足条件结束。</p>

<h3 id="toc_4">梯度提升树 GBDT</h3>

<p>提升树使用加法模型和前向分步算法，当损失函数是平方损失和指数损失函数时，很容易求解。但当损失函数是一般损失函数而言，往往每一步优化都不容易。针对这一问题，Freidman 提出了梯度提升技术，所以有了梯度提升树 GBDT。</p>

<p>GBDT (Gradient Boosting Decision Tree) 又叫 MART(Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力较强的算法。</p>

<p>GBDT 的树是回归树，不是分类树，GBDT用来做回归预测，调整后也可以用于分类。</p>

<p>它利用最速下降的近似方法，其关键是利用损失函数的负梯度在当前模型的值：<br/>
\[<br/>
-\bigg[\frac{\partial L(y,f(x_i))}{\partial f(x_i)} \bigg]_{f(x) = f_{m-1}(x)}<br/>
\]</p>

<p>作为回归问题提升树算法中的残差的近似值，拟合一个回归树。</p>

<h4 id="toc_5">梯度提升算法</h4>

<p><b>输入</b>：训练数据集 \(T = \{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)，\(x_i \in \mathcal X \subseteq R^n\)，\(y_i\in \mathcal Y\subseteq R\)；损失函数 \(L(y,f(x))\)；<br/>
<b>输出</b>：回归树 \(\hat{f(x)}\)<br/>
<b>算法过程</b>：</p>

<ul>
<li>初始化
\[
f_0(x) = arg \min_c \sum_{i=1}^N L(y_i,c)
\]</li>
</ul>

<blockquote>
<p>当损失函数为平方损失函数时，平方损失函数是一个下凸函数，可以直接求导获得：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial L(y_i,c)}{\partial c} = \frac{\partial \sum_{i=1}^N \frac 1 2 (y_i-c)^2}{\partial c} = \sum_{i=1}^N -(y_i-c) = 0\\<br/>
&amp;c = \frac 1 N \sum_{i=1}^N y_i<br/>
\end{align*}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
f_0(x) = c = \frac 1 N \sum_{i=1}^N y_i<br/>
\]</p>
</blockquote>

<ul>
<li><p>对 \(m=1,2,...,M\) </p>

<ul>
<li><p>对 \(i=1,2,...,N\)，计算<br/>
\[<br/>
r_{mi} = -\bigg[ \frac{\partial L(y_i,f(x_i))}{\partial f(x_i)} \bigg ]_{f(x) = f_{m-1}(x)}<br/>
\]</p></li>
<li><p>对 \(r_{mi}\) 拟合一个回归树，得到第 \(m\) 棵树的叶节点区域 \(R_{mj}\)，\(j=1,2,...,J\)</p></li>
<li><p>对 \(j=1,2,...,J\) 计算<br/>
\[<br/>
c_{mj} = arg \min_c \sum_{x_i\in R_{mj}} L(y_i,f_{m-1}(x_i) + c)<br/>
\]</p></li>
</ul>

<blockquote>
<p>当损失函数为平方损失函数时，计算 \(r_{mj}\) ：<br/>
\[<br/>
\begin{align*}<br/>
r_{mi} = -\frac{\partial L(y_i,f_0(x_i))}{\partial f_{m-1}(x_i)} = -\frac{\partial \frac 1 2 (y_i - f_{m-1}(x_i))^2}{\partial f_{m-1}(x_i)} = y_i - f_{m-1}(x_i) <br/>
\end{align*}<br/>
\]</p>

<p>计算 \(c_{mj}\)：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial \sum_{x_i\in R_{mj}} L(y_i,f_{m-1}(x_i) + c)}{\partial c} &amp;= \frac{\partial \sum_{x_i\in R_{mj}} \frac 1 2 (y_i - f_{m-1}(x_i) -c)^2}{\partial c}\\<br/>
&amp;= \sum_{x_i\in R_{mj}} (y_i - f_{m-1}(x_i) -c)\\<br/>
&amp;= \sum_{x_i\in R_{mj}} (y_i - f_{m-1}(x_i)) - |R_{mj}|c = 0\\<br/>
\therefore \quad c &amp;= \frac 1 {|R_{mj}|} \sum_{x_i\in R_{mj}} (y_i - f_{m-1}(x_i))\\<br/>
&amp;= \frac 1 {|R_{mj}|} \sum_{x_i \in R_{mj}} r_{mi}<br/>
\end{align*}<br/>
\]</p>
</blockquote>

<ul>
<li>更新 \(f_m(x) = f_{m-1}(x) + \sum_{j=1}^J c_{mj}I(x\in R_{mj})\)</li>
</ul></li>
<li><p>得到回归树<br/>
\[<br/>
\hat{f(x)} = f_M(x) = \sum_{m=1}^M \sum_{j=1}^J c_{mj} I(x\in R_{mj})<br/>
\]</p></li>
</ul>

<h4 id="toc_6">梯度提升树实例</h4>

<p>还是以前面的训练数据集为例，损失函数设为平方损失函数。</p>

<ol>
<li><p>首先初始学习器为：<br/>
\[<br/>
f_0(x) = c = \frac 1 N \sum_{i=1}^N y_i = 7.307<br/>
\]</p></li>
<li><p>当迭代轮数 \(m=1\) : <br/>
计算所有样本的残差：<br/>
\[<br/>
r_{1i} = -\frac{\partial L(y_i,f_0(x_i))}{\partial f_0(x_i)} = -\frac{\partial \frac 1 2 (y_i - f_0(x_i))^2}{\partial f_0(x_i)} = y_i - f_0(x_i)<br/>
\]</p>

<p>第一个样本的残差为 \(5.56 - 7.307 = -1.747\)<br/>
同理可以求得第 \(i=2,3,...,m\) 个样本的残差，然后使用残差作为样本的真实值训练 \(f_1(x)\)，残差如下：<br/>
\[<br/>
\begin{array}{ccccccccccc}\\\hline<br/>
x_i &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp;  6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 \\\hline<br/>
y_i &amp; -1.747 &amp; -1.607 &amp; -1.397 &amp; -0.907 &amp; -0.507 &amp; -0.257 &amp; 1.593 &amp; 1.393 &amp; 1.693 &amp; 1.743 \\\hline<br/>
\end{array}<br/>
\]</p>

<p>当切分点 \(s = -1.677\)，此时 \(R_1 = \{1\}\)，\(R_2 = \{2,3,4,5,6,7,8,9,10\}\)，此时：<br/>
\[<br/>
c_1 = -1.747,\quad c_2 = 0.194\\<br/>
m(s) = \min_{c_1} \sum_{x_i \in R_1}(y_i - c_1)^2 + \min_{c_2} \sum_{x_i \in R_2}(y_i - c_2)^2 = 15.72<br/>
\]</p>

<p>同理可以再算出其他切分点 \(s\) 对应的 \(m(s)\) ，找到令 \(m(s)\) 最小的切分点 \(s\)，此时划分的区域为 \(c_{1j}\)，\(j=1,2,...,J\)，回归树表示为：<br/>
\[<br/>
f_1(x) = f_0(x) + \sum_{j=1}^J c_{1j}I(x\in R_{1j})<br/>
\]</p></li>
<li><p>继续迭代 \(m=2,3,...,M\) 。</p></li>
</ol>

<h3 id="toc_7">GBDT 分类问题</h3>

<p>GBDT的分类算法从思想上和GBDT的回归算法没有区别，但是由于样本输出不是连续的值，而是离散的类别，导致我们无法直接从输出类别去拟合类别输出的误差。为了解决这个问题，主要有两个方法，一个是用指数损失函数，此时GBDT退化为Adaboost算法。另一种方法是用类似于逻辑回归的对数似然损失函数的方法。也就是说，我们用的是类别的预测概率值和真实概率值的差来拟合损失。</p>

<h4 id="toc_8">GBDT 二分类问题</h4>

<p>对于二分类，将真实值 \(y\) 和预测值 \(f(x)\) 的乘积，通过sigmoid处理成概率，再使用对数似然损失函数，损失函数为：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f(x)) = -\log P(y|x) = -\log[\text{sigmod}(yf(x))] = -\log(\frac{1}{1 + \exp(-yf(x))}) = \log(1+\exp(-yf(x)))<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(y\in \mathcal Y = \{-1,1\}\)</p>

<p>此时负梯度误差为：<br/>
\[<br/>
\begin{align*}<br/>
r_{mi} &amp;= -\bigg[\frac{\partial L(y,f(x_i))}{\partial f(x_i)} \bigg]_{f(x) = f_{m-1}(x)}\\<br/>
&amp;=-\frac{\partial L(y_i,f_{m-1}(x_i))}{\partial f_{m-1}(x_i)} \\<br/>
&amp;= -\frac{\partial \log(1+\exp(-yf_{m-1}(x_i)))}{\partial f_{m-1}(x_i)}\\<br/>
&amp;= \frac{y\exp(-yf_{m-1}(x_i))}{1+\exp(-yf_{m-1}(x_i))} \\<br/>
&amp;= \frac{y\exp(-yf_{m-1}(x_i)) \exp(yf_m(x_i))}{(1+\exp(-yf_{m-1}(x_i))) \exp(yf_{m-1}(x_i))} \\<br/>
&amp;= \frac{y}{\exp(yf_{m-1}(x_i))+1} \\<br/>
\end{align*}<br/>
\]</p>

<p>用 \(r_{mi}\) 拟合一个回归树，得到第 \(m\) 棵树的叶节点区域 \(R_{mj}\)，\(j=1,2,...,J\)，各个叶子节点的最佳残差拟合值为：<br/>
\[<br/>
\begin{align*}<br/>
c_{mj} &amp;= arg \min_c \sum_{x_i\in R_{mj}} L(y_i,f_{m-1}(x_i) + c) = arg \min_c \sum_{x_i \in R_{mj}} \log(1+\exp(-y_i(f(x_i) + c)))<br/>
\end{align*}<br/>
\]</p>

<p>由于上式比较难优化，我们一般使用近似值代替：<br/>
\[<br/>
c_{mj} = \sum_{x_i \in R_{mj}} r_{mi} / \sum_{x_i\in R_{mj}} |r_{mi}|(1−|r_{mi}|)<br/>
\]</p>

<p>除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，二元GBDT分类和GBDT回归算法过程相同。</p>

<h4 id="toc_9">GBDT 多分类问题</h4>

<p>多分类 GBDT 要比二分类更复杂一下，对应的是多元逻辑回归和二元逻辑回归的复杂度差别。假设类别数为 \(K\)，则此时我们的对数似然损失函数为：<br/>
\[<br/>
L(y,f(x)) = -\sum_{k=1}^K y_k \log p_k(x)<br/>
\]</p>

<p>如果输出样本为 \(k\) ，则 \(y_k=1\) ，第 \(k\) 类的概率 \(p_k(x)\) 的表达式为：<br/>
\[<br/>
p_k(x) = \frac{\exp(f_k(x))}{\sum_{l=1}^K \exp(f_l(x))} <br/>
\]</p>

<p>集合上面两式可以计算第 \(m\) 轮的第 \(i\) 个样本对应类别 \(k\) 的负梯度误差为：<br/>
\[<br/>
\begin{align*}<br/>
r_{mik} &amp;= -\bigg[\frac{\partial L(y_i,f(x_i))}{\partial f_k(x_i)}\bigg]_{f_l(x) = f_{l,m-1}(x)}\\<br/>
&amp;= -\bigg[\frac{\partial -\sum_{k=1}^K y_{ik} \log \big[{\exp(f_k(x_i))}/{\sum_{l=1}^K \exp(f_l(x_i))}\big]}{\partial f_k(x_i)} \bigg]_{f_l(x) = f_{l,m-1}(x)}\\<br/>
&amp;= -\bigg[\frac{\partial -\sum_{k=1}^K y_{ik} \log \big[{\exp(f_{k,m-1}(x_i))}/{\sum_{l=1}^K \exp(f_{l,m-1}(x_i))}\big]}{\partial f_{k,m-1}(x_i)} \bigg]\\<br/>
&amp;= \frac{y_{ik} \frac{\exp(f_{k,m-1}(x_i))}{{\sum_{l=1}^K \exp(f_{l,m-1}(x_i))}}- \frac{\exp(f_{k,m-1}(x_i))\exp(f_{k,m-1}(x_i))}{({\sum_{l=1}^K \exp(f_{l,m-1}(x_i))})^2}}{{\exp(f_{k,m-1}(x_i))}/{\sum_{l=1}^K \exp(f_{l,m-1}(x_i))}}\\<br/>
&amp;= \frac{y_{ik} p_{k,m-1}(x_i)- (p_{k,m-1})^2}{p_{k,m-1}(x_i)}\\<br/>
&amp;= y_{ik} - p_{k,m-1}(x_i)<br/>
\end{align*}<br/>
\]</p>

<p>观察上式可以看出，其实这里的误差就是样本 \(i\) 对应类别 \(k\) 的真实概率和 \(m−1\) 轮预测概率的差值。用 \(r_{mi}\) 拟合一个回归树，得到第 \(m\) 棵树的叶节点区域 \(R_{mj}\)，\(j=1,2,...,J\)，各个叶子节点的最佳残差拟合值为：<br/>
\[<br/>
\begin{align*}<br/>
c_{mjk} = arg \min_{c_{jk}} \sum_{x_i\in R_{mj}} \sum_{k=1}^K L(y_k,f_{m-1,k}(x_i)+\sum_{j=1}^J c_{jk}) \\<br/>
\end{align*}<br/>
\]</p>

<p>由于上式比较难优化，我们一般使用近似值代替：<br/>
\[<br/>
c_{mjk} = \frac{K-1}{K} \frac{\sum_{x_i \in R_{mj}} r_{mil}}{\sum_{x_i\in R_{mj}} |r_{mik}|(1-|r_{mik}|)}<br/>
\]</p>

<p>除了负梯度计算和叶子节点的最佳残差拟合的线性搜索，多元GBDT分类和二元GBDT分类以及GBDT回归算法过程相同。</p>

<h3 id="toc_10">GBDT常见损失函数</h3>

<p>对于分类算法，其损失函数一般有对数损失函数和指数损失函数两种:</p>

<ol>
<li><p>如果是指数损失函数，则损失函数表达式为<br/>
\[<br/>
L(y,f(x))=\exp(−yf(x))<br/>
\]</p>

<p>其负梯度计算和叶子节点的最佳残差拟合可以参考Adaboost自适应提升方法。</p></li>
<li><p>如果是对数损失函数，分为二元分类和多元分类两种，参加上面的讲解。</p></li>
</ol>

<p>对于回归算法，常用损失函数有如下4种:</p>

<ol>
<li><p>均方差，这个是最常见的回归损失函数了<br/>
\[<br/>
L(y,f(x))=\frac 1 2 (y−f(x))^2<br/>
\]</p></li>
<li><p>绝对损失，这个损失函数也很常见：</p>

<p>\[<br/>
L(y,f(x) = |y-f(x)|<br/>
\]</p>

<p>对于负梯度误差为：<br/>
\[<br/>
\mathrm {sign}(y_i-f(x_i))<br/>
\]</p></li>
<li><p>Huber损失，它是均方差和绝对损失的折衷产物，对于远离中心的异常点，采用绝对损失，而中心附近的点采用均方差。这个界限一般用分位数点度量。损失函数如下：<br/>
\[<br/>
L(y,f(x))=\left \{\begin{array}\\<br/>
\frac 1 2 (y−f(x))^2\quad &amp;|y−f(x)|\le \delta\\<br/>
\delta (|y−f(x)|− \frac \delta 2)\quad &amp;|y−f(x)|&gt;\delta\\<br/>
\end{array} \right .<br/>
\]</p>

<p>对应的负梯度为：<br/>
\[<br/>
r(y_i,f(x_i))=\left \{\begin{array}\\<br/>
y_i−f(x_i)\quad &amp; |y_i−f(x_i)|\le\delta\\<br/>
\delta\text{ sign}(y_i−f(x_i))\quad &amp; |yi−f(xi)|&gt;\delta\\<br/>
\end{array} \right .<br/>
\]</p></li>
<li><p>分位数损失。它对应的是分位数回归的损失函数，表达式为<br/>
\[<br/>
L(y,f(x))= \sum_{y\ge f(x)}\theta|y−f(x)|+\sum_{y&lt;f(x)}(1−\theta)|y−f(x)|<br/>
\]</p>

<p>其中 \(\theta\) 为分位数，需要我们在回归前指定。对应的负梯度误差为：<br/>
\[<br/>
r(y_i,f(x_i))=\left \{\begin{array}\\<br/>
\theta\quad&amp; y_i\ge f(x_i)\\<br/>
\theta-1\quad &amp;y_i&lt;f(x_i)\\<br/>
\end{array}\right .<br/>
\]</p></li>
</ol>

<p>对于Huber损失和分位数损失，主要用于健壮回归，也就是减少异常点对损失函数的影响。</p>

<h3 id="toc_11">GBDT 的正则化</h3>

<p>和 Adaboost 一样，我们也需要对 GBDT 进行正则化，防止过拟合。GBDT的正则化主要有三种方式。</p>

<ol>
<li><p>和Adaboost类似的正则化项，即步长(learning rate)。定义为 \(v\)，对于前面的弱学习器的迭代<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + G_m(x)<br/>
\]</p>

<p>如果我们加上了正则化项，则有：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + v\text{ }G_m(x)<br/>
\]</p>

<p>\(v\) 的取值范围为 \(0&lt;v\le 1\)。对于同样的训练集学习效果，较小的 \(v\) 意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p></li>
<li><p>通过子采样比例（subsample）。取值为 \((0,1]\) 。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于 1 ，则只有一部分样本会去做GBDT的决策树拟合。选择小于 1 的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在 \([0.5, 0.8]\) 之间。</p>

<p>使用了子采样的GBDT有时也称作随机梯度提升树(Stochastic Gradient Boosting Tree, SGBT)。由于使用了子采样，程序可以通过采样分发到不同的任务去做boosting的迭代过程，最后形成新树，从而减少弱学习器难以并行学习的弱点。</p></li>
<li><p>对于弱学习器即CART回归树进行正则化剪枝。</p></li>
</ol>

<h3 id="toc_12">GBDT 优缺点</h3>

<p>GBDT主要的优点有：</p>

<ol>
<li>可以灵活处理各种类型的数据，包括连续值和离散值。</li>
<li>在相对少的调参时间情况下，预测的准备率也可以比较高。这个是相对SVM来说的。</li>
<li>使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数。</li>
</ol>

<p>GBDT的主要缺点有：</p>

<ol>
<li>由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。</li>
</ol>

<hr/>

<p>李航【统计学习方法】<br/>
<a href="https://blog.csdn.net/lanchunhui/article/details/50980635">决策树桩</a><br/>
<a href="https://www.cnblogs.com/pinard/p/6140514.html">梯度提升树 GBDT</a><br/>
<a href="https://statweb.stanford.edu/%7Ejhf/ftp/trebst.pdf">Greedy Function Approximation:A Gradient Booting Machine</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15158019416874.html">自适应提升方法 Adaboost</a></h1>
			<p class="meta"><time datetime="2018-01-13T08:05:41+08:00" 
			pubdate data-updated="true">2018/1/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>Adaboost，英文全称是 Adapter Boosting（自适应增强）的缩写，由 Yoav Freund 和 Robert Schapire 在1995年提出。Adaboost 是属于 Boosting （提升）方法中具有代表性的一种。Boosting 方法是一种常见的统计学习方法，一种能提高任意给定学习算法准确率的方法。在分类问题上，它通过改变训练样本的权重，学习多个分类器，并将这些分类器进行线性组合，来提高分类的性能。历史上，首先 Valiant 和 Kearns 提出了“弱可学习”和“强可学习”的概念：</p>

<blockquote>
<h5 id="toc_0">强可学习</h5>

<p>在概率近似正确（Probably approximate correct，PAC）学习的框架中，一个概念（一个类），如果存在一个多项式的学习算法可以学习它，并且正确率很高，那么就称这个概念是强可学习的。</p>

<h5 id="toc_1">弱可学习</h5>

<p>而一个概念存在一个多项式的学习算法可以学习它，但是正确率仅比随机猜测略好，那么称这个概念是弱可学习的。</p>
</blockquote>

<p>同时，Valiant 和 Kearns 首次提出了PAC学习模型中弱可学习和强可学习等价性的问题，即任意弱可学习问题都可以提升为强可学习问题。后来 Schapire 最先对这个问题作出了肯定的证明，也就是最初的 Boosting 方法，也就是如果已经学习了“弱可学习算法”，便可以通过这个方法将其提升为“强可学习算法”，而显然，学习一个“弱可学习算法”比“强可学习算法”要容易很多。</p>

<p>在1995年 Freund 对Schapire 提出的最初的 Boosting 算法做出了改进，提高了算法的效率，但是这两个算法都有一个天生的缺陷，都是需要知道“弱学习算法”学习正确率的下界，这在实际问题中难以做到；在1996年，Freund 和 Schapire 提出了 Adaboost 算法，效率与 Freund 之前的算法效率接近，却没有了事先知道“弱学习算法”正确率下界的限制条件，容易运用到实际问题中，因此该算法得到普遍应用。</p>

<h3 id="toc_2">Boosting 算法</h3>

<p>Boosting 算法是将”弱学习算法“提升到”强学习算法“的过程，主要是涉及两个部分：加法模型和前向分布算法。加法模型是指针对训练数据集学习一系列弱分类器，再将其线性相加的过程。</p>

<h4 id="toc_3">加法模型</h4>

<p>考虑加法模型(additive model)：<br/>
\[<br/>
f(x) = \sum_{m=1}^M \beta_m b(x;\gamma_m)<br/>
\]</p>

<p>其中 \(b(x;\gamma_m)\) 为基函数，\(\gamma_m\) 为基函数的参数，\(\beta_m\) 为基函数的系数。显然这是一个加法模型。</p>

<p>在给定训练数据及损失函数 \(L(y,f(x))\) 的条件下，学习加法模型 \(f(x)\) 成为经验风险极小化即损失函数极小化问题：<br/>
\[<br/>
\min_{\beta_m,\gamma_m} \sum_i^N L(y_i,\sum_{m=1}^M \beta_m b(x_i;\gamma_m))<br/>
\]</p>

<h4 id="toc_4">前向分布算法</h4>

<p>极小化上面的损失函数这是一个复杂的优化问题，前向分布算法（Forward stagewise Algorithm）解决这类问题的一个思路是：因为学习的是加法模型，如果能从前往后，每一步只学习一个基函数及其系数，逐步极小化损失函数，那么就可以简化优化的复杂度，每步只需优化如下损失函数：<br/>
\[<br/>
\min_{\beta,\gamma} \sum_{i=1}^N L(y_i,\beta b(x_i;\gamma))<br/>
\]</p>

<p>给定训练数据集 \(T = {(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}\)，\(x_i\in \mathcal X \subseteq R^n\) ，\(y_i \in mathcal Y = \{-1,1\}\)，损失函数为 \(L(y,f(x))\)，基函数的集合 \(\{b(x;\gamma)\}，学习加法模型 \)f(x)\( 的前向分布算法如下：<br/>
(1) 初始化 \)f_0(x)=0\(<br/>
(2) 对 \)m=1,2,...,M<br/>
　　(a) 极小化损失函数：<br/>
\[<br/>
(\beta_m,\gamma_m) = \arg \min_{\beta,\gamma} \sum_{i=1}^N L(y_i,f_{m-1}(x_i) + \beta f(x_i;\gamma))<br/>
\]</p>

<p>　　得到参数 \(\beta_m\)，\(\gamma_m\)<br/>
　　(b) 更新：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + \beta_m b(x;\gamma_m)<br/>
\]</p>

<p>(3) 得到加法模型：<br/>
\[<br/>
f(x) = f_M(x) = \sum_{m=1}^M \beta_m b(x;\gamma_m)<br/>
\]</p>

<p>这样前向分布算法将同时求解从 \(m=1\) 到 \(M\) 所有参数 \(\beta_m\)、\(\gamma_m\) 的问题化为逐次求解各个 \(\beta_m\) 、\(\gamma_m\) 的优化问题。</p>

<p>Boosting 算法采用不同的损失函数会得到不同的模型，AdaBoost 是损失函数为指数函数的 Boosting 算法。</p>

<h3 id="toc_5">AdaBoost算法</h3>

<p>AdaBoost是一种迭代算法，它通过提高前一轮被错误分类的样本的权值，降低被正确分类样本的权值，这样没有被正确分类的样本由于权值的增大，会得到下一轮弱分类器的更大关注。它能在学习的过程中不断减少训练误差，即在训练数据集上的分类误差率。假设给定一个二类分类的训练数据集：<br/>
\[<br/>
T = {(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}<br/>
\]</p>

<p>其中，每一个样本都是由实例和标签组成，实例 \(x_i\in \mathcal X \subseteq R^n\) ，标记 \(y_i \in \mathcal Y = \{-1,1\}\)，\(\mathcal X\) 是实例空间，\(\mathcal Y\) 是标记空间。</p>

<p>前面说到 AdaBoost 是损失函数为指数函数的 Boosting 算法，定义最终分类器的训练误差为指数形式：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f(x)) &amp;= \sum_{i=1}^N \exp(-y_i f(x_i))\\<br/>
\end{align*}<br/>
\]</p>

<p>假设前 \(m-1\) 轮迭代前向分步算法以及得到 \(f_{m-1}(x)\)，在第 \(m\) 轮迭代要得到 \(\alpha_m\)，\(G_m(x)\) 和 \(f_m(x)\)<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + \alpha_m G_m(x)<br/>
\]</p>

<p>目标是使前向分步算法得到的 \(\alpha_m\) 和 \(G_m(x)\) 使 \(f_m(x)\) 在训练数据上的误差最小，即：<br/>
\[<br/>
\begin{align*}<br/>
(\alpha_m,G_m(x)) &amp;= \arg \min_{\alpha,G} L(y,f_m(x))\\<br/>
&amp;= \arg\min_{\alpha,G} \sum_{i=1}^N \exp(-y_i f_m(x_i))\\<br/>
&amp;= \arg\min_{\alpha,G} \sum_{i=1}^N \exp[-y_i (f_{m-1}(x_i) + \alpha G(x_i))]\\<br/>
&amp;= \arg\min_{\alpha,G} \sum_{i=1}^N \exp[f_{m-1}(x_i)] \exp[-y_i \alpha G(x_i)]\\<br/>
\end{align*}<br/>
\]</p>

<p>令 \(w_{mi} = \exp[-y_i f_{m-1}(x_i)]\). 上式可以表示为：<br/>
\[<br/>
\begin{equation}<br/>
(\alpha_m,G_m(x)) = \arg \min_{\alpha,G} \sum_{i=1} w_{mi} \exp[-y_i \alpha G(x_i)] \\\label{ag}<br/>
\end{equation}<br/>
\]</p>

<p>容易看出 \(w_{mi}\) 与 \(\alpha\)，\(G(x)\) 无关，只依赖于 \(f_{m-1}(x)\)，随着每一轮的迭代而发生变化。\(w_{mi}\) 可以表示每一个样本的权值。初始时设样本的权值都设为 \(1/N\)，即：<br/>
\[<br/>
w_{1i} = \frac 1 N, \quad i=1,2,...,N<br/>
\]</p>

<p>定义第 \(m\) 轮基本分类器 \(G_m(x)\) 在训练数据集上加权分类误差率 \(e_m\) 等于样本权重乘上错误分类：<br/>
\[<br/>
e_m = \sum_{i=1}^N P(G_m(x_i) \neq y_i) = \sum_{i=1}^N w_{mi} I(G_m(x_i) \neq y_i)<br/>
\]</p>

<p>对于式 \ref{ag} ，我们来求解 \(G(x)\) 和 \(\alpha\) ，设最优解为 \(G(x)^*\)，\(\alpha^*\)。先求 \(G(x)^*\)，由前向分布算法可知，每一轮只需要求解令当前分类误差率最小的 \(G_(x)\) ：<br/>
\[<br/>
G(x)^* = \arg\min e_m = \arg\min \sum_{i=1}^N w_{mi} I(G_m(x_i) \neq y_i)<br/>
\]</p>

<p>再求 \(\alpha*\) ，先化简一下式 \ref{ag} ：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1} w_{mi} \exp[-y_i \alpha G(x)] &amp;= \sum_{y_i=G_m(x_i)} w_{mi} e^{-\alpha} + \sum_{y_i\neq G_m(x_i)} w_{mi} e^{\alpha} \\<br/>
&amp;= \sum_{y_i=G_m(x_i)} w_{mi} e^{-\alpha} + \sum_{y_i\neq G_m(x_i)} w_{mi} e^{-\alpha} + \sum_{y_i\neq G_m(x_i)} w_{mi} e^{\alpha} - \sum_{y_i\neq G_m(x_i)} w_{mi} e^{-\alpha}\\<br/>
&amp;= \sum_{i=1}^N w_{mi} e^{-\alpha} + (e^{\alpha} - e^{-\alpha}) \sum_{i=1}^N w_{mi} I(y_i\neq G_m(x_i))\\<br/>
&amp;= e^{-\alpha}\sum_{i=1}^N w_{mi} + (e^{\alpha} - e^{-\alpha}) e_m\\<br/>
&amp;= e^{-\alpha} + (e^{\alpha} - e^{-\alpha}) e_m\\<br/>
\end{align*}<br/>
\]</p>

<p>对 \(\alpha\) 求导可得：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial e^{-\alpha} + (e^{\alpha} - e^{-\alpha}) e_m}{\partial \alpha} &amp;= -e^{-\alpha} + (e^{\alpha} + e^{-\alpha}) e_m \\<br/>
&amp;= -e^{-\alpha} (1+e_m) + e^{\alpha} e_m \\<br/>
\end{align*}<br/>
\]</p>

<p>令求导结果为 0，得：<br/>
\[<br/>
\alpha^* = \frac 1 2 log \frac {1-e_m}{e_m}<br/>
\]</p>

<p>现在再来看看每一轮分类器的迭代：<br/>
\[<br/>
f_m(x) = f_{m-1}(x) + \alpha_m G_m(x)<br/>
\]</p>

<p>以及 \(w_{mi} = \exp[-y_i f_{m-1}(x_i)]\)，所以对于任何样本 \(x_i\) 都有：<br/>
\[<br/>
\begin{align*}<br/>
&amp;f_m(x_i) = f_{m-1}(x_i) + \alpha_m G_m(x_i)\\<br/>
\Rightarrow \quad &amp; -y_i f_m(x_i) = -y_i f_{m-1}(x_i) - y_i \alpha_m G_m(x_i)\\<br/>
\Rightarrow \quad &amp; \exp[-y_i f_m(x_i)] = \exp[-y_i f_{m-1}(x_i) - y_i \alpha_m G_m(x_i)]\\<br/>
\Rightarrow \quad &amp; \exp[-y_i f_m(x_i)] = \exp[-y_i f_{m-1}(x_i)] \exp[-y_i \alpha_m G_m(x_i)]\\<br/>
\Rightarrow \quad &amp; w_{m+1,i} = w_{mi} \exp[-y_i \alpha_m G_m(x_i)]\\<br/>
\end{align*}<br/>
\]</p>

<p>这样就得到了每一轮权值的更新，为了使权值和等于1，需要进行归一化处理。定义归一化因子 \(Z_m\)： <br/>
\[<br/>
Z_m = \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i))<br/>
\]</p>

<p>权值更新函数为：<br/>
\[<br/>
w_{m+1,i} = \frac{w_{mi}}{Z_m} \exp[-y_i \alpha_m G_m(x_i)]<br/>
\]</p>

<h3 id="toc_6">训练误差分析</h3>

<p>最终分类器在训练数据上的训练误差为：<br/>
\[<br/>
L(y,f_M(x)) = \sum_{i=1}^N \exp(-y_i f_M(x_i))\\<br/>
\]</p>

<p>样本在最终分类器上的样本分类误差定义为：<br/>
\[<br/>
err = \sum_{i=1}^N I(G_M(x_i) \neq y_i)<br/>
\]</p>

<p>现在证明可以通过减少训练误差的方式减小分类误差率。考虑到：<br/>
\[<br/>
I(G(x_i) \neq y_i) \le \exp(-y_i f(x_i)), \quad i = 1,2,...,N <br/>
\]</p>

<p>当 \(G(x_i) = y_i\) 时，\(I(G(x_i) \neq y_i) = 0\)，\(\exp(-y_i f(x_i)) &gt; 0\)，上式成立。<br/>
当 \(G(x_i) \neq y_i\) 时，\(I(G(x_i) \neq y_i) = 1\)，而 \(- y_i f(x_i) &gt; 0\)，所以 \(\exp(-y_i f(x_i)) &gt; e^0 = 1\) ，上式成立。</p>

<p>得证。</p>

<p>现在继续来化简一下最终分类器的训练误差：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f_M(x_i)) &amp;= \sum_{i=1}^N \exp(-y_i f_M(x_i)) \\<br/>
&amp;= \sum_{i=1}^N \exp(-y_i \sum_{m=1}^M \alpha_m G_m(x_i)) \\<br/>
&amp;= \sum_{i=1}^N \prod_{m=1}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N \frac 1 N \prod_{m=1}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N \frac 1 N \exp(-y_i \alpha_1 G_1(x_i)) \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N w_{1i} \exp(-y_i \alpha_1 G_1(x_i)) \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N \sum_{i=1}^N Z_1 w_{2,i} \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N Z_1 \sum_{i=1}^N w_{2,i} \prod_{m=2}^M \exp(-y_i \alpha_m G_m(x_i))\\<br/>
&amp;= N Z_1 Z_2 ... Z_{m-1} \sum_{i=1}^N w_{Mi} \exp(-y_i \alpha_M G_M(x_i)) \\<br/>
&amp;= N Z_1 Z_2 ... Z_{m-1} Z_M \sum_{i=1}^N w_{m+1,i}\\<br/>
&amp;= N \prod_{m=1}^M Z_m<br/>
\end{align*}<br/>
\]</p>

<p>这一定理说明，可以在每一轮选择适当的 \(G_m(x)\) 使 \(Z_m\) 最小，从而使训练误差减小最快。而实际 \(Z_m\) 还依赖 \(\alpha_m\) 的选择，实际并不可操作。</p>

<p>再来看一下 \(Z_m\) 的表达式：<br/>
\[<br/>
\begin{align}<br/>
Z_m &amp;= \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i)) \nonumber\\<br/>
&amp;= \sum_{G_m(x_i) = y_i} w_{mi} \exp(-\alpha_m) + \sum_{G_m(x_i) \neq y_i} w_{mi} \exp(\alpha_m)  \nonumber\\<br/>
&amp;= \sum_{G_m(x_i) = y_i} w_{mi} e^{-\alpha_m} + \sum_{G_m(x_i) \neq y_i} w_{mi} e^{-\alpha_m} + \sum_{G_m(x_i) \neq y_i} w_{mi}  e^{\alpha_m} - \sum_{G_m(x_i) \neq y_i} w_{mi} e^{-\alpha_m} \nonumber\\<br/>
&amp;= e^{-\alpha_m} \sum_{i=1} ^N w_{mi} + e^{\alpha_m} e_m - e^{-\alpha_m} e_m \nonumber\\<br/>
&amp;= e^{-\alpha_m} + e^{\alpha_m} e_m - e^{-\alpha_m}e_m  \nonumber\\<br/>
&amp;= (1-e_m) e^{-\alpha_m} + e_m e^{\alpha_m} \label{zm}<br/>
\end{align}<br/>
\]</p>

<p>由 \(\alpha=\frac 1 2 log \frac {1-e_m}{e_m}\) 可得 ：<br/>
\[<br/>
e^{\alpha} = \sqrt{\frac{1-e_m}{e_m}}\\<br/>
e^{-\alpha} = \sqrt{\frac{e_m}{1-e_m}}<br/>
\]</p>

<p>将上式代入 \ref{zm} 中得：<br/>
\[<br/>
\begin{align*}<br/>
Z_m &amp;= 2\sqrt{e_m(1-e_m)}<br/>
\end{align*}<br/>
\]</p>

<p>令 \(\gamma_m = \frac 1 2 - e_m\)：<br/>
\[<br/>
Z_m = \sqrt{1-4\gamma_m^2}<br/>
\]</p>

<p>比较 \(\sqrt{1-4\gamma_m^2}\) 与 \(\exp(-2\gamma_m^2)\) 的大小：<br/>
\(e^x\) 在 \(x_0=0\) 处泰勒展开：<br/>
\[<br/>
\begin{align*}<br/>
e^x &amp;= {e^{x_0}}+\frac{e^{x_0}}{1!}(x-x_0) + \frac{e^{x_0}}{2!}(x-x_0)^2\\<br/>
&amp;= 1 + x + \frac{x^2}{2}<br/>
\end{align*}<br/>
\]</p>

<p>令 \(x=-2\gamma_m^2\)，所以：\(\exp(-2\gamma_m^2) = 1 - 2\gamma^2 + 2\gamma_m^4\)</p>

<p>\(\sqrt{1-x}\) 在 \(x_0=0\) 处泰勒展开：<br/>
\[<br/>
\begin{align*}<br/>
\sqrt{1-x} &amp;= {(1-{x_0})^{1/2}} - \frac 1 2 \frac{(1-{x_0})^{-1/2}}{1!} (x-x_0) - \frac{1}{2*2} \frac{(1-{x_0})^{-3/2}}{2!}(x-x_0)^2\\<br/>
&amp;= 1 - \frac{x}{2} - \frac{x^2}{8}<br/>
\end{align*}<br/>
\]</p>

<p>令 \(x=4\gamma_m^2\)，所以：\(\sqrt{1-4\gamma_m^2} = 1 - 2\gamma^2 - 2\gamma^4\)</p>

<p>显然 \(\sqrt{1-4\gamma_m^2} \le \exp(-2\gamma_m^2)\)</p>

<p>所以最终分类其的训练误差：<br/>
\[<br/>
\begin{align*}<br/>
L(y,f_M(x_i)) &amp;= \sum_{i=1}^N \exp(-y_i f_M(x_i) \\<br/>
&amp;= N\prod_{m=1}^M Z_m \\<br/>
&amp;= N\prod_{m=1}^M \sqrt{1-4\gamma_m^2} \\<br/>
&amp;\le \prod_{m=1}^M \exp(-2\gamma_m^2)\\<br/>
&amp;= \exp\big (-2\sum_{m=1}^M \gamma_m^2\big )\\<br/>
\end{align*}<br/>
\]</p>

<p>这表明当 \(\gamma_m &gt; 0\) 时， AdaBoost 的训练误差是以指数速率下降的。</p>

<h3 id="toc_7">算法步骤</h3>

<p><b>输入</b>：训练数据集 \(T = {(x_1,y_1),(x_2,y_2),...,(x_N,y_N)}\)， \(x_i\in \mathcal X \subseteq R^n\)，\(y_i \in mathcal Y = \{-1,1\}\)。<br/>
<b>输出</b>：最终分类器 \(G(x)\)。<br/>
<b>算法过程</b>：<br/>
(1) 初始化训练数据的权值初始值：<br/>
\[<br/>
D_1 = (w_{11},...,w_{1i},...,w_{1N})<br/>
\]</p>

<p>(2) 对 \(m=1,2,...,M\)，迭代次数为 \(M\)：<br/>
(a) 在具有权值分布 \(D_m\) 的训练数据集上学习，得到基本分类器：<br/>
\[<br/>
G_m(x):\mathcal X \rightarrow \{-1,1\}<br/>
\]</p>

<p>(b) 计算 \(G_m(x)\) 在训练数据集上的分类误差率：<br/>
\[<br/>
e_m = P(G_m(x_i) \neq y_i) = \sum_{i=1}^N w_{mi} I(G_m(x_i)\neq y_i)<br/>
\]</p>

<p>(c) 计算 \(G_m(x)\) 的系数，也就是在最终分类器中的重要程度（对数为自然对数）：<br/>
\[<br/>
\alpha_m = \frac 1 2 \log \frac{1-e_m}{e_m}<br/>
\]</p>

<p>(d) 更新训练数据的权值分布：<br/>
\[<br/>
D_{m+1} = {w_{m+1,1},w_{m+1,2},...,w_{m+1,i},...,w_{m+1,N}}\\<br/>
w_{m+1,i} = \frac{w_{mi}}{Z_m} \exp(-\alpha_m y_i G_m(x_i)),\quad i=1,2,...,N<br/>
\]</p>

<p>这里的 \(Z_m\) 是规范因子，为了是样本概率分布和为1：<br/>
\[<br/>
Z_m = \sum_{i=1}^N w_{mi} \exp(-\alpha_m y_i G_m(x_i))<br/>
\]</p>

<p>它使 \(D_{m+1}\) 成为一个概率分布。<br/>
(3) 构建基本分类器的线性组合<br/>
\[<br/>
F_M(x) = \sum_{m=1}^M \alpha_m G_m(x)<br/>
\]</p>

<p>得到最终分类器<br/>
\[<br/>
G(x) = sign(F_M(x)) = sign(\sum_{m=1}^M \alpha_m G_m(x))<br/>
\]</p>

<h3 id="toc_8">AdaBoost举例</h3>

<p>如下图的数据：<br/>
\[<br/>
\begin{array}{ccccccccccc}\hline<br/>
\text{No}&amp;1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 \\\hline<br/>
\text{x} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9  \\\hline<br/>
\text{y} &amp; 1 &amp; 1 &amp; 1 &amp; -1&amp; -1&amp; -1&amp; 1 &amp; 1 &amp; 1 &amp; -1 \\\hline<br/>
\end{array}<br/>
\]</p>

<p>首先初始化样本权重 \(D_1 = (w_{11},...,w_{1i},...,w_{1N})\)，其中<br/>
\[<br/>
w_{1i} = 0.1, \quad i=1,2,...,10<br/>
\]</p>

<p>在具有权值分布 \(D_1\) 的训练数据集上学习，当阈值取 2.5 时样本误差率最小：<br/>
\[<br/>
G_1(x) = \left \{ \begin{array}\\ 1 &amp;\quad x \le 2.5 \\ 0 &amp;\quad x \gt 2.5 \\\end{array}\right .<br/>
\]</p>

<p>计算 \(G_1(x)\) 在训练集上的分类误差率为：<br/>
\[<br/>
e_1 = \sum_{i=1}^N w_{1i} I(G_1(x_i) \neq y_i) = 0.3<br/>
\]</p>

<p>计算 \(G_1(x)\) 的系数为：<br/>
\[<br/>
\alpha_1 = \frac 1 2 \log \frac{1-e_1}{e_1} = 0.4236<br/>
\]</p>

<p>更新数据集的权值分布：<br/>
\[<br/>
D_2 = (w_{21},w_{22},...,w_{2i},...,w_{2N})\\<br/>
Z_1 = \sum_{i=1}^N w_{1i} \exp(-\alpha_1 y_i G_1(x_i))\\<br/>
w_{2i} = \frac{w_{1i}}{Z_1} \exp[-y_i \alpha_1 G_1(x_i)]\\<br/>
\]</p>

<p>得 \(D_2 = (0.0715,0.0715,0.0715,0.0715,0.0715,0.0715,0.1666,0.1666,0.166,0.0715)\)，\(f_1(x) = sign(0.4236 G_1(x))\)。分类器 \(sign(f_1(x))\) 在训练集上有三个误分点。</p>

<p>继续 \(m=2,...,M\) ，这里不再叙述。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15151569041850.html">概率近似正确学习 PAC Learning</a></h1>
			<p class="meta"><time datetime="2018-01-05T20:55:04+08:00" 
			pubdate data-updated="true">2018/1/5</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在计算机学习理论中，PAC 是英文 probably approximately correct 的缩写，是机器学习数学分析的框架，它由 Leslie Valiant 在 1994 年提出。</p>

<h3 id="toc_0">前置知识</h3>

<p>在学习 PAC 之前先看一下相关的概念：假设空间、版本空间、泛化误差和经验误差。</p>

<h5 id="toc_1">假设空间 hypothesis space</h5>

<p>所有属性可能取值组成的假设的集合称为假设空间，学习的过程可以看作是在假设空间中进行搜索的过程，搜索目标是找到与训练集“匹配”的假设，即能够将训练集中数据正确表示的假设。假设的表示一旦确定，假设空间规模大小就确定了。如以下的例子：<br/>
\[<br/>
\begin{array}{ccccc}\\\hline<br/>
\text{编号}\quad&amp;\quad\text{色泽}\quad&amp;\text{根蒂}\quad&amp;\quad\text{敲声}\quad&amp;\quad\text{好瓜}\quad\\\hline<br/>
\text{1}\quad&amp;\quad\text{青绿}\quad&amp;\text{蜷缩}\quad&amp;\quad\text{浊响}\quad&amp;\quad\text{是}\quad\\<br/>
\text{2}\quad&amp;\quad\text{乌黑}\quad&amp;\text{蜷缩}\quad&amp;\quad\text{浊响}\quad&amp;\quad\text{是}\quad\\<br/>
\text{3}\quad&amp;\quad\text{青绿}\quad&amp;\text{硬挺}\quad&amp;\quad\text{清脆}\quad&amp;\quad\text{否}\quad\\<br/>
\text{4}\quad&amp;\quad\text{乌黑}\quad&amp;\text{稍蜷}\quad&amp;\quad\text{沉闷}\quad&amp;\quad\text{否}\quad\\\hline<br/>
\end{array}<br/>
\]</p>

<p>这里我们的假设空间由“色泽=？”、“根蒂=”、“敲声=？”三个属性的所有可能取值所形成的假设组成。例如，色泽的三个可能取值是“青绿”、“乌黑”、“浅白”，根蒂的三个可能取值是“蜷缩”、“稍蜷”、“硬挺”，敲声的三个取值是“浊响”，“清脆”，“沉闷”。还有可能不论色泽和根蒂是什么，只要是敲声是浊响的都是好瓜，即“色泽=* ” \(\land\) “根蒂=* ” \(\land\) “敲声=浊响” \(\leftrightarrow\) “好瓜”，所以每一种属性都要加上通配符 * ，所以每种属性都有4种可能，总共是 \(4^3=64\) 种可能。还有可能好瓜根本不存在，所以总共假设空间的规模大小是65。有了假设空间之后，要根据已获取的信息（数据集）来对假设空间进行剪枝。即要找到一个与训练集匹配的假设空间子集。</p>

<h5 id="toc_2">版本空间 version space</h5>

<p>在现实问题中我们常面临很大的假设空间，但学习的过程是给予有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与训练集一致的“假设集合”，我们称之为“版本空间”。如上面的例子中，假设空间的规模大小是65，删除与正例不一致的假设和与反例一致的假设即可得到版本空间。假设空间里如果有“色泽=青绿，根蒂=*，敲声=* ”的瓜是好瓜的假设，由编号3的训练集可知假设是不正确的，需要从假设空间里删除，最终留下来的就是版本空间。版本空间<font color=red><strong>不一定</strong></font>是正确的，也可能只是在训练集上是正确的，因此，要想判断的正确，就要全面、大量的训练，以排除更多假设空间中的错误假设。错误假设越少，剩下的假设越少，就越有可能是正确假设，我们判断的结果的正确概率越大。因为最终的假设会随着版本（数据集）变化而变化，所以叫做版本空间。</p>

<h5 id="toc_3">经验误差</h5>

<p>学习器在训练集上产生的误差叫做经验误差，由于这个误差是针对训练集的，因此又叫训练误差。训练数据也可以称之为经验，这就是经验误差的由来。</p>

<h5 id="toc_4">泛化误差</h5>

<p>机器学习的目标是使学得的模型能很好地适用于“新样本”，而不仅仅是在训练样本上工作很好，学得模型适用于新样本的能力我们称为“泛化（generalization）“能力，具有强泛化能力的模型能更好的适应于整个样本空间。这里泛化能力的度量便是泛化误差，泛化误差越小，也就是越能适用于新样本。一般来说，训练样本越多，经验误差可以越小，但是泛化误差不一定，可能会出现过拟合的情况。</p>

<h3 id="toc_5">PAC 学习理论 PAC learning theory</h3>

<p>计算学习理论中最基本的是概率近似正确学习理论，来研究什么时候一个问题是可以被学习的。</p>

<p>首先我们来考虑一下机器学习算法的目的，机器学习算法是通过希望学习一个模型能很好地完成从样本空间 \(\mathcal X\) 到标记空间 \(\mathcal Y\) 的映射。这样的每一个映射，我们称之为概念 concept ，用 \(c\) 表示。若对于样例 \((x,y)\) 有 \(c(x)=y\) 成立，则称 \(c\) 为目标概念。所有我们希望学得的目标概念所构成的集合称为“概念类（concept class）”，用符号 \(\mathcal C\) 表示。</p>

<p>对于给定的算法 \(\Phi\) ，它所考虑的所有可能概念的集合被称为“假设空间”，用符号 \(\mathcal H\) 表示，其中单个的概念称之为假设。</p>

<p>若目标概念 \(c \in \mathcal H\)，则 \(\mathcal H\) 中存在假设能将所有示例按与真实标记一致的方式完全分开，我们称该问题对学习算法 \(\mathcal L\) 是“可分的（separable）”，亦称“一致的（consistent）”。 反之，若算法的假设空间中不包含目标概念，则称该数据集对算法是“不可分的”或称“不一致的”。</p>

<p>举个简单的例子：对于非线性分布的数据集，若使用一个线性分类器，则该线性分类器对应的假设空间就是空间中所有可能的超平面，显然假设空间不包含该数据集的目标概念，所以称数据集对该学习器是不可分的。给定一个数据集D，我们希望模型学得的假设 \(h\) 尽可能地与目标概念一致，这便是概率近似正确 (Probably Approximately Correct，简称PAC)的来源，即以较大的概率学得误差满足预设上限的模型。这就是“概率”“近似正确”的含义，形式化地说，令 \(\delta\) 表示置信度，可定义：</p>

<p><b>PAC辨识（PAC Identify）</b>：对 \(\epsilon &gt; 0\)，\(\delta &lt; 1\)，所有 \(c\in \mathcal C\) 和分布 \(\mathcal D\)，若存在学习算法 \(\mathcal L\) ，其输出假设 \(h \in \mathcal H\) 满足：<br/>
\[<br/>
P(\mathrm{E}(h) \le \epsilon) \ge 1 - \delta<br/>
\]</p>

<p>其中\(\mathrm{E}(h)\) 表示泛化误差，则称学习算法 \(\mathcal L\) 能从假设空间 \(\mathcal H\) 中PAC辨识出概念类 \(\mathcal C\)，这样的学习算法 \(\mathcal L\) 能以较大的概率（至少 \(1-\delta\)）学得学习目标概念 \(c\) 的近似（误差最多为 \(\epsilon\)）。</p>

<p>PAC 辨识也可以写成如下形式：<br/>
\[<br/>
\begin{align*}<br/>
P(\mathrm{E}(h) \gt \epsilon) &amp;= 1 - P(\mathrm{E}(h) \le \epsilon) \\<br/>
&amp;\le 1 - (1-\delta) \\<br/>
&amp;= \delta\\<br/>
\end{align*}<br/>
\]</p>

<p>表示泛化误差大于 \(\epsilon\) 的概率不大于 \(\delta\)。在此基础上可以定义：</p>

<p><b>PAC可学习性（PAC Learnable）</b>：令 \(m\) 表示从分布 \(\mathcal D\) 中独立同分布采样得到的样本数目，\(\epsilon &gt; 0\)，\(\delta &lt; 1\)，对所有分布 \(\mathcal D\)，若存在学习算法 \(\mathcal L\) 和多项式函数 \(\text{poly}(\cdot,\cdot,\cdot,\cdot)\) ，使得对于任何 \(m\ge \text{poly}(1/\epsilon,1/\delta,\text{size(}\mathbf x\text{),size(c)})\)，\(\mathcal L\) 能从假设空间 \(\mathcal H\) 中PAC 辨识概念类 \(\mathcal C\)，则称概念类 \(\mathcal C\) 对假设空间 \(\mathcal H\) 而言是 PAC 可学习的，有时候也称概念类 \(\mathcal C\) 是 PAC 可学习的。其中 \(\text{size(}x)\) 数据本身的复杂度，\(\text{size}(c)\) 为目标概念的复杂度。</p>

<p>对于计算机而言，必然要考虑时间复杂性，于是：</p>

<p><b>PAC学习算法（PAC Learning Algorithm）</b>：若学习算法 \(\mathcal L\) 使概念类 \(\mathcal C\) 可学习的，且 \(\mathcal L\) 的运行时间也是多项式函数 \(\text{poly(}1/\epsilon,1/\delta,\text{size(}\mathbf x\text{),size(c)})\)，则称概念类 \(\mathcal C\) 是高效PAC可学习的（efficiently PAC learnable）的，称 \(\mathcal L\) 为概念类 \(\mathcal C\) 的 PAC 学习算法。</p>

<p>假设学习算法 \(\mathcal L\) 处理每一个样本的时间为常数，则 \(\mathcal L\) 的时间复杂度等价于样本的时间复杂度。于是，我们对算法时间复杂度的关心就转变为对样本复杂度的关系：</p>

<p><b>样本复杂度（Sample Complexity）</b>：满足 PAC 学习算法 \(\mathcal L\) 所需要的 \(m \ge \text{poly(}1/\epsilon,1/\delta,\text{size(}\mathbf x),\text{size(c))}\) 中的最小的 \(m\)，称之为学习算法 \(\mathcal L\) 的样本复杂度。</p>

<p>PAC 学习中一个关键因素是假设空间 \(\mathcal H\) 的复杂度。\(\mathcal H\) 包含了学习算法 \(\mathcal L\) 所有可能输出的假设，若在 PAC 学习中假设空间与概念类完全相同，即 \(\mathcal H=\mathcal C\)，这称为 “恰 PAC 可学习”；直观上看，这意味着学习算法的能力与学习任务 ”恰好匹配“ 。然而，通常我们目标概念 \(\mathcal C\) 一无所知，显然，更重要的是研究假设空间和目标概念不一样的情况，即 \(\mathcal H \ne C\) 。一般而言，\(\mathcal H\) 越大，其包含任意目标概念的可能性越大，但从中找到某个具体目标概念的难度也越大。 \(\mathcal H\) 有限时，我们称 \(\mathcal  H\) 为“有限假设空间”，否则称为“无限假设空间”。</p>

<h3 id="toc_6">有限假设空间</h3>

<h5 id="toc_7">可分情形</h5>

<p>可分情形意味着目标概念 \(c\) 属于假设空间 \(\mathcal H\)，即 \(c\in \mathcal H\)，若给定包含 \(m\) 个数据集的训练样本 \(D\)，如何找出满足误差参数的假设呢？既然 \(D\) 中样例标记都是有目标概念 \(c\) 赋予的，并且 \(c\) 存在于假设空间 \(\mathcal H\) 中，那么，任何在训练集 \(D\) 上出现的标记错误的假设肯定不是目标概念 \(c\) 。于是，我们只需要保留与 \(D\) 一致的假设，剔除与 \(D\) 不一致的假设即可，若训练集 \(D\) 足够大，则可不断借助 \(D\) 中样例剔除不一致的假设，直到 \(\mathcal H\) 中仅剩下一个假设为止，这个假设就是目标概念 \(c\) 。通常情况下，由于训练集规模有限，假设空间 \(\mathcal H\) 中可能存在不止一个与 \(D\) 一致的“等效”假设，对于这些等效假设，无法根据 \(D\) 来对它们做进一步的区分。</p>

<p>到底需要多少样例才能学得目标概念 \(c\) 得有效近似呢？对 PAC 学习而言，只要训练集 \(D\) 的规模能使学习算法 \(\mathcal L\) 以概率 \(1-\delta\) 找到目标假设的 \(\epsilon\) 近似即可。</p>

<p>我们先估计泛化误差大于 \(\epsilon\) 但在训练集上仍表现完美的假设出现的概率。假定 \(h\) 的泛化误差大于 \(\epsilon\) ，即\(\mathrm{E}(h) \gt \epsilon\)，对分布 \(D\) 上随机采样而得的任何样例 \((x,y)\)，有：<br/>
\[<br/>
\begin{align*}<br/>
P(h(x) = y) &amp;= 1-P(h(x) \neq y)\\<br/>
&amp;= 1- \mathrm{E}(h)\\<br/>
&amp;\lt 1 - \epsilon<br/>
\end{align*}<br/>
\] </p>

<p>由于 \(D\) 包含 \(m\) 个从 \(\mathcal D\) 中独立同分布采样而得的样例，因此，\(h\) 与 \(D\) 表现一致的概率为：<br/>
\[<br/>
P(h(x_1) = y_1) \land P(h(x_2) = y_2) \land ... \land P(h(x_m) = y_m) = (1-P(h(x)\neq y)^m \lt (1-\epsilon)^m<br/>
\]</p>

<p>我们事先并不知道学习算法 \(\mathcal L\) 会输出 \(\mathcal H\) 中的那个假设，但仅需保证泛化误差大于 \(\epsilon\) ，且在训练集上表现完美的所有假设出现概率之和不大于 \(\delta\) 即可：<br/>
\[<br/>
\begin{equation}<br/>
P(h\in \mathcal H:\mathrm{E}(h) &gt; \epsilon \land \hat {\mathrm{E}}(h) = 0) \lt \sum_{i=1}^{|\mathcal H|}  (1-\epsilon)^m \lt |\mathcal H|(1-\epsilon)^m\\\label{hiH}<br/>
\end{equation}<br/>
\]</p>

<p>考虑到 \(1-x &lt; e^{-x}\) ，证明：<br/>
令 \(F(x) = e^{-x} - 1 + x\)，当 \(x \ge 0\) 时有： <br/>
\[<br/>
F&#39;(x) = -e^{-x} + 1 \ge 0<br/>
\]</p>

<p>所以 \(F(x)\) 在 \(x \ge 0\) 时单调递增，\(F(x) \ge F(0) = 0 \)，所以得证。</p>

<p>所以式(\ref{hiH})可以写为：<br/>
\[<br/>
P(h\in \mathcal H:\mathrm{E}(h) &gt; \epsilon \land \hat {\mathrm{E}}(h) = 0) \lt |\mathcal H|(1-\epsilon)^m\lt |\mathcal H|e^{-m\epsilon}<br/>
\]</p>

<p>令上式不大于 \(\delta\) ，即：<br/>
\[<br/>
|\mathcal H|e^{-m\epsilon} \le \delta<br/>
\]</p>

<p>可得：<br/>
\[<br/>
\begin{equation}<br/>
m \ge \frac 1 \epsilon (\ln{|\mathcal H| + \ln{\frac 1 \delta}}) \label{yxm}<br/>
\end{equation}<br/>
\]</p>

<p>由此可知，有限假设空间 \(\mathcal H\) 都是 PAC 可学习的，所需的样例数目如(\ref{yxm})所示，输出假设 \(h\) 的泛化误差随样本数目的增多而收敛到 0，收敛速度为 \(O(\frac 1 m)\) 。</p>

<h5 id="toc_8">不可分情形</h5>

<p>对于目标概念不存在于假设空间中 \(\mathcal H\) 中，假定对于任何的 \(h\in\mathcal H\)，\(\mathrm{\hat E(h)}\ne 0\)，也就是 \(\mathcal H\) 中的任意一个假设都会在训练集上产生或多或少的错误。由泛化误差 \(\mathrm{E}(h)\) 与经验误差 \(\mathrm{\hat E(h)}\) 的定义易知 \(\mathbb E(\mathrm{\hat E(h)})=\mathrm{E(h)}\) ，因此由霍夫丁不等式理论一可得出定义。</p>

<p><b>若训练集 \(D\) 中包含 \(m\) 个从分布 \(\mathcal D\) 上独立同分布采样而得的样例，\(0\lt \epsilon\lt 1\)，则对任意 \(h\in\mathcal H\)，有：</b></p>

<p>\[<br/>
\begin{align}<br/>
&amp;P\big(\mathrm{\hat E(h)- E(h)}\ge \epsilon\big)\leq e^{-2m\epsilon^{2}}\label{dbo1}\\<br/>
&amp;P\big(\mathrm{E(h)-\hat E(h)}\ge \epsilon\big)\leq e^{-2m\epsilon^{2}}\label{dbo2}\\<br/>
&amp;P\big(\big|\mathrm{\hat E(h)- E(h)}\big|\ge \epsilon\big)\leq 2e^{-2m\epsilon^{2}}\label{dbo3}\\<br/>
\end{align}<br/>
\]</p>

<p>上面各式可以用霍夫丁不等式定理一得到，等式中 \(\mathrm{E}(h)\) 可以看成 \(\mathbb E\big[\mathrm{\hat E}(h)\big]\)，所以 \(\mathrm{\hat E}(h) - \mathrm{E}(h)\) 可以写成 \(\mathrm{\hat E}(h) - \mathbb E\big[\mathrm{\hat E}(h)\big]\)，再运用霍夫丁不等式即可。</p>

<p><strong>推论：若训练集 \(D\) 包含 \(m\) 个从 \(\mathcal D\) 中 i.i.d 采样而得的样本，\(0\lt \epsilon \lt 1\)，则对 \(h\in \mathcal H\) ，式(\ref{tl})以至少 \(1-\delta\) 的概率成立：</strong><br/>
\[<br/>
\begin{equation}<br/>
\mathrm{\hat E}(h) - \sqrt{\frac{\ln(2/\delta)}{2m}} \lt \mathrm{E}(h) \lt \mathrm{\hat E}(h) + \sqrt{\frac{\ln(2/\delta)}{2m}} \label{tl}\\<br/>
\end{equation}<br/>
\]</p>

<blockquote>
<p>下面简单证明一下这个推论：由(\ref{dbo3})式可知 \(P\big(\big|\mathrm{\hat E(h)- E(h)}\big|\gt \epsilon\big)\leq 2e^{-2m\epsilon^{2}}\)，该式子可以写成：<br/>
\[<br/>
\begin{align}<br/>
P \big(\big|\mathrm{\hat E(h)- E(h)}\big|\le \epsilon\big)\ge 1-2e^{-2m\epsilon^{2}}\label{dbo4}\\<br/>
\end{align}<br/>
\]</p>

<p>令 \(\delta = 2\exp({-2m\epsilon^2})\)，所以：<br/>
\[<br/>
\epsilon = \sqrt{\frac{\ln(2/\delta)}{2m}}<br/>
\]</p>

<p>所以由(\ref{dbo4})式可知 \(\big|\mathrm{\hat E(h)- E(h)}\big|\le\sqrt{\frac{\ln(2/\delta)}{2m}}\) 的概率不小于 \(1-\delta\)，整理可得推论。</p>
</blockquote>

<p>推论说明样本数目 \(m\) 较大时，\(h\) 的经验误差是其泛化误差很好的近似。对于有限假设空间我们有：<br/>
\[<br/>
P\Bigg( \Big| \mathrm{E}(h) - \mathrm{\hat E}(h)\Big| \le \sqrt{\frac{\ln|\mathcal H| + \ln(2/\delta)}{2m}}  \Bigg) \ge 1 - \delta<br/>
\]</p>

<blockquote>
<p>证明：令 \(h_1,h_2,...,h_{|\mathcal H}\) 是假设空间 \(\mathcal H\) 中的假设，有：<br/>
\[<br/>
\begin{align}<br/>
P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big) &amp;= P \big(\exists h \in \mathcal H:\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big)\nonumber\\<br/>
&amp;= P\Big(\big(\big| \mathrm{E(h_1)- \hat E(h_1)} \big| \gt \epsilon \big) \vee \cdots \vee \big(\big| \mathrm{E(h_{|\mathcal H|}) -\hat E(h_{|\mathcal H|})} \big| \gt \epsilon \big) \Big )\nonumber\\<br/>
&amp;\le \sum_{i=1}^{|\mathcal H|} \sup_{h\in \mathcal H}P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big)\nonumber\\<br/>
&amp;= |\mathcal H| \sup_{h\in \mathcal H}P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big)\label{mshp}\\<br/>
\end{align}<br/>
\]</p>

<p>由式(\ref{dbo3})可得：<br/>
\[<br/>
\sup_{h\in \mathcal H}P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big) = 2e^{-2m\epsilon^{2}}<br/>
\]</p>

<p>上式代入(\ref{mshp})可得：<br/>
\[<br/>
P \big(\big|\mathrm{E(h)- \hat E(h)}\big|\gt \epsilon\big) \le 2|\mathcal H|e^{-2m\epsilon^{2}}<br/>
\]</p>

<p>令 \(\delta = 2|\mathcal H|e^{-2m\epsilon^{2}} \) 求出 \(\epsilon\) 得表达式，便能很容易证明。</p>
</blockquote>

<p>而显然当 \(c\notin \mathcal H\) 时学习算法 \(\mathcal L\) 无法学得目标概率的 \(\mathcal c\) 的 \(\epsilon\) 近似。当时当假设空间 \(\mathcal H\) 给定时，必定存在一个泛化误差最好的假设，找到此假设的 \(\epsilon\) 近似也不失为一个较好的目标。\(\mathcal H\) 中训泛化差最好的假设是 \(\min_{h\in\mathcal H} \mathrm{E}(h)\)，于是以此目标可以将 PAC 学习推广到 \(\mathcal c \notin \mathcal H\) 的情况，这称为不可知学习（agnostic learning）。相应的，我们有：</p>

<p><strong>不可知 PAC 可学习（agnostic PAC learnable）</strong>：令 \(m\) 表示从 \(\mathcal H\) 中独立同分布（i.i.d.） 采样的样本个数，\(0\lt \epsilon\)，\(\delta \lt 1\)，对于所有分布 \(\mathcal H\) ，若存在学习算法 \(\mathcal L\) 和多项式 \(poly(\cdot,\cdot,\cdot,\cdot)\)，使得对于任意的 \(m\ge poly(1/\epsilon,1/\delta,\text{size}(\mathbf x),\text{size}(c))\)，\(\mathcal L\) 能从假设空间 \(\mathcal H\) 输出满足下式的假设 \(h\)：<br/>
\[<br/>
P\Big(\mathrm{E(h) - \min_{h&#39;\in\mathcal H}\hat E(h&#39;)} \le \epsilon\Big) \ge 1 - \delta<br/>
\]</p>

<p>则称假设空间 \(\mathcal H\) 是不可知 PAC 可学习的。</p>

<blockquote>
<p>对 \(\mathcal c \in \mathcal H\) 的情况称为<strong>可实现学习 realization learning</strong></p>
</blockquote>

<p>与 PAC 可学习类似，若学习算法的 \(\mathcal L\) 的运行时间也是多项式函数 \(poly(1/\epsilon,1/\delta,\text{size}(\mathbf x),\text{size}(c))\)，则称 \(\mathcal H\) 是高效不可知 PAC 可学习的，学习算法 \(\mathcal L\) 则称假设空间 \(\mathcal H\) 的不可知 PAC 学习算法，满足上述条件的最小的 \(m\) 称为学习算法 \(\mathcal L\) 的样本复杂度。</p>

<h3 id="toc_9">VC 维 Vapnik-Chervonenkis dimension</h3>

<p>现实学习任务所面临的通常是无限假设空间，例如实数域中的所有区间、\(\mathcal R^d\) 空间中的所有线性超平面。欲对此种情形的可学习性进行研究，需度量假设空间的复杂度。最常见的办法是考虑假设空间的“VC维”。</p>

<p>介绍 VC 维之前，我们先引入几个概念：增长函数（growth function）、对分（dichotomy）和打散（shattering）。</p>

<h4 id="toc_10">增长函数 growth function</h4>

<p>有些文献中将增长函数称为打散系数（shatter coefficient），其实是一样的。给定假设空间 \(\mathcal H\) 和示例集 \(D=\{x_1,x_2,...,x_m\}\)，\(\mathcal H\) 中每个假设 \(h\) 都能对 \(D\) 中示例赋予标记，标记结果可表示为：<br/>
\[<br/>
h|_D = \{(h(x_1),h(x_2),...,h(x_m))\}<br/>
\]</p>

<p>随着 \(m\) 的增大，\(\mathcal H\) 中所有假设对 \(D\) 中的示例所能赋予标记的可能结果数也会增大。</p>

<p><b>所有的 \(m \in \mathbf N\)，假设空间 \(\mathcal H\) 的增长函数 \(\Pi_{\mathcal H}(m)\) 为：<br/>
\[<br/>
\Pi_{\mathcal H}(m) = \max_{\{x_1,...,x_m\}\subseteq \mathcal X}\big|\{(h(x_1),...,h(x_m))\}|h\in \mathcal H\big|<br/>
\]<br/>
</b></p>

<p>增长函数 \(\Pi_{\mathcal H}(m)\) 表示假设空间 \(\mathcal H\) 对 \(m\) 个示例所能赋予标记的最大可能结果数。例如一个二分类问题，当 \(D\) 中只有两个示例 \(\{a,b\}\) ，\(h\) 对 \(D\) 中的示例所能赋予标记的可能为 \(\{(a=0,b=0),(a=0,b=1),(a=1,b=0),(a=1,b=1)\}\) ，当有三个示例时，赋予的标记有 8 种可能，对于 \(m\) 个示例最多有 \(2^m\) 种可能，即：<br/>
\[<br/>
\Pi_{\mathcal H}(m) \le 2^m<br/>
\]</p>

<p>显然，\(\mathcal H\) 对示例所能赋予标记的可能结果数越大，\(\mathcal H\) 的表示能力越强，对学习任务的适应能力也越强。因此，增长函数描述了假设空间 \(\mathcal H\) 的表示能力，由此反应出假设空间的复杂度。</p>

<h5 id="toc_11">对分 dichotomy</h5>

<p>假设空间 \(\mathcal H\) 中不同的假设对于 \(D\) 中示例赋予标记的结果可能相同，也可能不同；尽管 \(\mathcal H\) 中可能包含无穷多个假设，单其对 \(D\) 中示例赋予标记的可能结果数是有限的。对于二分类问题来说，\(\mathcal H\) 中假设对 \(D\) 中示例赋予标记的每种可能称为对 \(D\) 的一次“对分”。</p>

<h5 id="toc_12">打散 shatter</h5>

<p>对于二分类而言，若假设空间 \(\mathcal H\) 能实现示例集 \(D\) 的所有对分，即存在：<br/>
\[<br/>
\Pi_{\mathcal H}(m) = 2^m<br/>
\]</p>

<p>称示例集 \(D\) 能被假设空间“打散”，这也就是“打散系数”的由来。</p>

<h3 id="toc_13">VC 维</h3>

<p><b><br/>
假设空间 \(\mathcal H\) 的 VC 维定义为：<br/>
\[<br/>
V_{\mathcal H} = \max\{m|\Pi_{\mathcal H}(m) = 2^m\}<br/>
\]</p>

<p></b></p>

<p>\(V_{\mathcal H} = d\) 表明存在大小为 \(d\) 的示例集能被假设空间 \(\mathcal H\) 打散，这并不意味着所有大小为 \(d\) 的示例都能被假设空间 \(\mathcal H\) 打散。VC 维的定义与数据分布 \(D\) 无关，这意味着在数据分布未知的情况下仍能计算假设空间 \(\mathcal H\) 的VC维。</p>

<p>若存在大小为 \(d\) 的示例集能被 \(\mathcal H\) 打散，但是不存在 \(d+1\) 的示例集能被 \(\mathcal H\) 打散，则 \(\mathcal H\) 的 VC 维是 \(d\) 。如果对于所有的 \(m\) 有 \(\Pi_{\mathcal H} = 2^m\) ，那么有 \(V_{\mathcal H} = \infty\)。</p>

<p>我们可利用增长函数来估计经验误差与泛化误差之间的关系：</p>

<p><b>VC 不等式：对假设空间 \(\mathcal H\)，\(m\in \mathcal N\)，\(0\lt \epsilon \lt 1\) 和任意 \(h\in \mathcal H\) 有：<br/>
\[<br/>
P\bigg(\sup_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg) \le 4\Pi_{\mathcal H}(2m)\exp(-\frac{m\epsilon^2}{8})<br/>
\]</p>

<p></b></p>

<p>我们现在来尝试证明这个公式，为了证明这个定理，我们需要引入一个 “ghost sample” ，它是一个和训练数据 \(D\) 相同的数据，它只是为了帮我们证明结论，并不会在最后的结果中出现。设 \(D&#39; = \{(X&#39;_1,Y&#39;_1),..., (X&#39;_n , Y&#39;_n )\}\)，是独立于 \(D\) 外的以 i.i.d 形式从 \(\mathcal D\) 中采样出来的随机变量。定义这个样本上的经验损失为：<br/>
\[<br/>
\mathrm {\hat E&#39;(h)} = \frac 1 m \sum_{i=1}^m \mathbf{I}(h(x&#39;_i) \neq y&#39;_i)<br/>
\]</p>

<p>其中 \(\mathbf{I}\)是指示函数。</p>

<p>在下面的证明中，我们不失一般性地假设 \(m\epsilon^2\ge 2\)，否则定理中的边界会小。首先我们看 <b>Symmetrization 引理</b>：</p>

<p>对于任意的 \(\epsilon\)，且 \(m\epsilon^2 \ge 2\)，有：<br/>
\[<br/>
\begin{equation}<br/>
P\bigg(\sup_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg) \le 2P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}|\gt \frac \epsilon 2 \bigg) \label{psmm}<br/>
\end{equation}<br/>
\]</p>

<p>注意右边涉及两个不同的经验误差（empirical risk）的绝对值项是对称的，且这两个经验误差都是建立在有限的数据集合上，这样我们就避开了无限集的问题。现在我们假设不等式左边的上确界可以达到，并在 \(\widetilde{h}(D)\equiv \widetilde{h} \in \mathcal H\) 时达到。尽管因为 \(\mathcal H\) 是无限空间，不太容易定义出 \(\mathcal H\) 中达到最大值的元素，我们还是可以定义 \(\widetilde{h}\) 为：<br/>
\[<br/>
\widetilde{h} \approx \arg \max_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|<br/>
\]</p>

<p>现在我们来看一下(\ref{psmm})式的右边：<br/>
\[<br/>
\begin{align}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;\ge P\bigg( |\mathrm{\hat E(\widetilde h) - \hat E&#39;(\widetilde h)} | \gt \frac \epsilon 2\bigg)\label{pbs1}\\<br/>
&amp;\ge P\bigg( \Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) \Big| &gt; \epsilon \text{ and } \Big|\hat E&#39;(\widetilde h) - E(\widetilde h)} \Big| \lt \frac \epsilon 2\bigg)\label{pbs2}\\<br/>
&amp;= \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) \Big| &gt; \epsilon\Big\} \mathbf{I}\Big\{\Big|\hat E&#39;(\widetilde h) - E(\widetilde h)} \Big| \lt \frac \epsilon 2\Big\} \bigg]\label{pbs3}\\<br/>
&amp;= \mathbb E\bigg\{\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\} \mathbb E\Big[\mathbf{I}\Big\{\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)} \Big| \lt \frac \epsilon 2\Big\}\Big| D&#39;\Big] \bigg\}\label{pbs4}\\<br/>
&amp;= \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\} P\Big[\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2 \Big | D&#39;\Big]\bigg]\label{pbs5}\\<br/>
\end{align}<br/>
\]</p>

<p>式子从(\ref{pbs1})到式子(\ref{pbs2})是因为对于任意实数 \(x\)，\(y\) 和 \(z\)，有：<br/>
\[<br/>
|x-z|\gt \epsilon\text{ and }|y-z| \gt \frac \epsilon 2 \Rightarrow |x-y| \gt \frac \epsilon 2<br/>
\]</p>

<p>在 \(D&#39;\) 的条件下：<br/>
\[<br/>
\mathrm{\hat E&#39;(\widetilde h)} - \mathrm{E(\widetilde h)} = \frac 1 m \sum_{i=1}^m U_i(\widetilde h)<br/>
\]</p>

<p>其中 \(U_i(\widetilde h) = \mathbf{I}(\widetilde h(x&#39;_i) \neq y&#39;_i) - \mathbb E\big[\mathbf{I}(\widetilde h(x&#39;_i) \neq y&#39;_i)|D&#39;\big]\)，它是一个平均值为 0 的独立同分布的随机变量。使用切比雪夫不等式：<br/>
\[<br/>
\begin{align*}<br/>
P\Big[\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big] &amp;= P\Big[\Big|\frac 1 m \sum_{i=1}^m U_i(\widetilde h)\Big| \lt \frac \epsilon 2 \bigg| D&#39;\Big]\\<br/>
&amp;= P\Big[\Big|\sum_{i=1}^m U_i(\widetilde h)\Big| \lt \frac{m\epsilon}{2} \bigg| D&#39;\Big]\\<br/>
&amp;\ge 1 - \frac {\text{var}\Big[|\sum_{i=1}^m U_i(\widetilde h)|\Big|D&#39;\Big]}{(m\epsilon/2)^2}\\<br/>
&amp;= 1 - \frac{4}{m^2\epsilon^2} \text{var}\Big[|\sum_{i=1}^m U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
&amp;= 1 - \frac{4m}{m^2\epsilon^2}\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
&amp;= 1 - \frac{4}{m\epsilon^2}\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>若随机变量 \(X\) 的范围为 \([a,b]\)，则：<br/>
\[<br/>
\mathbb{D}(X) \le \frac{(b-a)^2}{4}<br/>
\]</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb{D}(X) &amp;= \mathbb{E}\{[X-\mathbb{E}(X)]^2\} \\<br/>
&amp;= \mathbb E\{X^2 - 2X\mathbb{E}(X) + [\mathbb{E}(X)]^2\} \\<br/>
&amp;= \mathbb{E}(X^2) - 2[\mathbb{E}(X)]^2 + [\mathbb{E}(X)]^2 \\<br/>
&amp;= \mathbb{E}(X^2) - [\mathbb{E}(X)]^2<br/>
\end{align*}<br/>
\]</p>

<p>考虑到 \(a \le X \le b\)，即 \(\mathbb{E}(a) \le \mathbb{E}(X) \le \mathbb{E}(b)\)，也就是 \(a\le \mathbb{E}(X) \le b\)，令 \(Y=\frac{X-a}{b-a}\)，可知 \(0\le Y \le 1\)，<br/>
\[<br/>
\begin{align*}<br/>
&amp;\mathbb{D}(Y) = \mathbb{D}(\frac{X-a}{b-a}) = \frac{\mathbb{D}(X)}{b-a}\\<br/>
&amp;\Rightarrow \quad \mathbb{D}(X) = \mathbb{D}(Y)\cdot (b-a) = \{\mathbb{E}(Y^2) - [\mathbb{E}(Y)]^2\}\cdot (b-a)\\<br/>
&amp;\because \quad Y \le 1 \\<br/>
&amp;\therefore \quad Y^2 \le Y \\<br/>
&amp;\therefore \quad \mathbb{D}(Y^2) &lt; \mathbb{D}(Y)\\<br/>
&amp;\Rightarrow \quad \mathbb{D}(X) = \{\mathbb{E}(Y^2) - [\mathbb{E}(Y)]^2\}\cdot (b-a) \le \{\mathbb{E}(Y) - [\mathbb{E}(Y)]^2\}\cdot (b-a)\\<br/>
\end{align*}<br/>
\]</p>

<p>由均值不等式可知：<br/>
\[<br/>
\mathbb{E}(Y) - [\mathbb{E}(Y)]^2 = \mathbb{E}(Y)[1-\mathbb{E}(Y)] \le \frac{\big\{\mathbb{E}(Y)+[1-\mathbb{E}(Y)] \big\}^2}{4}= \frac 1 4<br/>
\]</p>

<p>所以：\(\mathbb{D}(X) \le {(b-a)^2}/{4}\)，得证</p>
</blockquote>

<p>由 \(U_i(\widetilde h)\) 的定义知 \(|U_i(\widetilde h)|\) 的区间为 \([0,1]\)，所以 \(\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big] \le \frac 1 4\)，所以：<br/>
\[<br/>
\begin{align*}<br/>
P\Big(\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big) &amp;\ge 1 - \frac{4}{m\epsilon^2}\text{var}\Big[|U_i(\widetilde h)|\Big|D&#39;\Big]\\<br/>
&amp;\ge 1- \frac{4}{m\epsilon^2}\cdot \frac 1 4 = 1- \frac{1}{m\epsilon^2}\\<br/>
\because\quad &amp; m\epsilon^2 &gt; 2\\<br/>
\therefore \quad &amp; -\frac{1}{m\epsilon^2} &gt; -\frac 1 2\\<br/>
\Rightarrow \quad P\Big(\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big) &amp;\ge 1- \frac{1}{m\epsilon^2} \ge \frac 1 2<br/>
\end{align*}<br/>
\]</p>

<p>现在再看式(\ref{pbs5})，可以知道：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;\ge \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\} P\Big[\Big|\mathrm{\hat E&#39;(\widetilde h) - E(\widetilde h)}\Big| \lt \frac \epsilon 2\bigg | D&#39;\Big]\bigg]\\<br/>
&amp;\ge \frac 1 2 \mathbb E\bigg[\mathbf{I}\Big\{\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big\}\bigg]\\<br/>
&amp;= \frac 1 2 P\Big[\Big|\mathrm{\hat E(\widetilde h) - E(\widetilde h) }\Big| &gt; \epsilon\Big]\\<br/>
&amp;= \frac 1 2 P\Big[\sup_{h\in \mathcal H}\Big|\mathrm{\hat E(h) - E(h) }\Big| &gt; \epsilon \Big]\\<br/>
\end{align*}<br/>
\]</p>

<p>上面推导过程中最后一个不等式，是由于 \(\widetilde h\) 的定义是此时 \(\mathrm{\hat E(\widetilde h) - E(\widetilde h)}\) 能得到最大值，此时也就等价于 \(\mathrm{\hat E(h) - E(h) }\) 达到上确界。所以引理得证。</p>

<p>Symmetrization 引理一个很大的好处是我们将无限假设空间的问题边界问题转换成有限假设空间边界问题，现在我们来考虑有限假设空间上的<br/>
\[<br/>
\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)} = \frac 1 m \sum_{i=1}^m \mathbf{I}[h(x_i) \neq y_i]-\frac 1 m \sum_{i=1}^m \mathbf{I}[h(x&#39;_i) \neq y&#39;_i] = \frac 1 m \sum_{i=1}^m \{\mathbf{I}[h(x_i) \neq y_i]-\mathbf{I}[h(x&#39;_i) \neq y&#39;_i]\}<br/>
\]</p>

<p>注意上面的等式，令 \(\mathbf h=(h_1,h_2,...,h_m,h&#39;_1,h&#39;_2,...,h&#39;_m)\)，这里 \(h_1\) 表示 \(h(x_1)\) ，\(h&#39;_1\) 表示 \(h(x&#39;_1)\) ，\(\mathbf h\) 只取决于训练样本和 “ghost sample”，因此考虑 \(\mathcal H\) 在两个样本 \(DD&#39;\) 的投影 \(\mathcal H_{D\cup D&#39;}\)，便有：<br/>
\[<br/>
\begin{eqnarray}<br/>
\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| = \sup_{\mathbf h \in \mathcal H_{D\cup D&#39;}}\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\label{hmc}\\<br/>
\end{eqnarray}<br/>
\]</p>

<blockquote>
<p>现在我们仅考虑经验损失边界 ，如果很多假设有着相同的经验损失（也就是在各数据点上都产生相同的 labels/values 对），我们可以取出一个作为代表，称之为“有效假设”，将其他的都去除。在数据集 \(D\) 上仅选择那些不同的有效假设，我们可以将假设空间限制到一个更小的子集 \(\mathcal H_D\)。 同理，如果考虑 \(\mathcal H\) 在训练样本和 ”ghost sample“ 的限制，即 \(\mathcal H_{D\cup D&#39;}\)。</p>
</blockquote>

<p>因为上限值很大，所以至少存在一个 \(\mathbf h\) 能使  \(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\) 很大：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;= P\bigg(\sup_{\mathbf h \in \mathcal H_{D\cup D&#39;}}\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;= P\bigg(\exists \mathbf h \in \mathcal H_{D\cup D&#39;}:\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>由于 \(\mathcal H_{DD&#39;}\) 是可数的，我们可以对这个特殊 \(\mathbf h\) 的概率用联合概率的一致性：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\exists \mathbf h \in \mathcal H_{D\cup D&#39;}:\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)&amp;\le \sum_{ \mathbf h \in \mathcal H_{D\cup D&#39;}}P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;\le |\mathcal H_{D\cup D&#39;}| P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>一致限（union bound）：若 \(A_1,A_2,...,A_k\) 为k个不同的事件（不一定相互独立），那么有：<br/>
\[<br/>
P(A_1\cup A_2 \cup ... \cup A_k) = P(A_1) + P(A_2) + ... + P(A_n)<br/>
\]</p>

<p>一致限说明：k个事件中任一个事件发生的概率小于等于这k个事件发生的概率和（等号成立的条件为这k个事件相两两互斥）</p>
</blockquote>

<p>用增长函数的定义我们知道 \(|\mathcal H_{D\cup D&#39;}| \le \Pi_\mathcal H(2m)\)，代入得：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\exists \mathbf h \in \mathcal H_{D\cup D&#39;}:\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg) &amp;\le |\mathcal H_{D\cup D&#39;}| P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;\le \Pi_\mathcal H(2m) P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
\end{align*}<br/>
\]</p>

<p>这里我们令 \(L_i = \mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\)，它的期望值为：<br/>
\[<br/>
\begin{align*}<br/>
\mathbb E(L_i) &amp;= \mathbb E\big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i) \big]\\<br/>
&amp;= \mathbb E\big[\mathbf{I}(h_i \neq y_i)\big]-\mathbb E\big[\mathbf{I}(h&#39;_i \neq y&#39;_i) \big]\\<br/>
&amp;= \mathrm{E}(h) - \mathrm{E}(h) = 0<br/>
\end{align*}<br/>
\]</p>

<p>我们允许我们表示 \(\hat {\mathrm{E}}(h) - \mathrm{E&#39;}(h)\)：<br/>
\[<br/>
\begin{align*}<br/>
\hat {\mathrm{E}}(h) - \mathrm{E&#39;}(h) &amp;= \frac 1 m \sum_{i=1}^m \big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\big]\\<br/>
&amp;= \frac 1 m \sum_{i=1}^m L_i\\<br/>
&amp;= \frac 1 m \sum_{i=1}^m \big [L_i-\mathbb{E}(L_i)\big]\\<br/>
\end{align*}<br/>
\]</p>

<p>除此之外我们注意到 \(L_i\) 的取值范围是 \([-1,1]\) ，我们可以运用霍夫丁不等式理论二：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \big [L_i - \mathbb{E}(L_i)\big ]\bigg|\gt t\bigg) \le 2\exp(-\frac{2t^2m^2}{\sum_{i=1}^{m}(1+1)^2}) = 2\exp(-\frac{2t^2m^2}{4m}) = 2\exp(-\frac{mt^2}{2})<br/>
\end{align*}<br/>
\]</p>

<p>令 \(t=\frac \epsilon 2\) ，得：<br/>
\[<br/>
P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg) \le 2\exp(-\frac{m\epsilon^2}{8})<br/>
\]</p>

<p>最终结果可得：<br/>
\[<br/>
\begin{align*}<br/>
P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}| \gt \frac\epsilon 2\bigg) &amp;\le \Pi_\mathcal H(2m) \sup_{\mathbf h \in \mathcal H_{D,D&#39;}} P\bigg(\bigg|\frac 1 m \sum_{i=1}^m \Big[\mathbf{I}(h_i \neq y_i)-\mathbf{I}(h&#39;_i \neq y&#39;_i)\Big]\bigg|\gt \frac\epsilon 2\bigg)\\<br/>
&amp;= 2\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})\\<br/>
\end{align*}<br/>
\]</p>

<p>结合 Symmetrization 引理可以得到：<br/>
\[<br/>
P\bigg(\sup_{h\in \mathcal H}|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg) \le 2P\bigg(\sup_{h\in\mathcal H}|\mathrm {\hat E(h)} - \mathrm{\hat E&#39;(h)}|\gt \frac \epsilon 2 \bigg) \le 4\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})<br/>
\]</p>

<p>所以 VC 不等式可证。</p>

<h4 id="toc_14">VC 维举例</h4>

<p><b>实数域举例</b>：实数域的区间 \([a,b]\) ，令 \(\mathcal H\) 表示实数域中的所有闭区间构成的集合 \(\{h_{[a,b]}:a,b\in \mathbb R,a\le b\}\)，\(\mathcal X = \mathbb R\)，对 \(x \in \mathcal X\)，若 \(x \in [a,b]\)，则 \(h_{[a,b]}(x) = +1\)，否则 \(h_{[a,b]}(x) = -1\)。若 \(D=\{x_1,x_2\} = \{0.5,1.5\}\)，则假设空间中 \(\mathcal H\) 中存在假设 \(\{h_{[0,1]},h_{[0,2]},h_{[1,2]},h_{[2,3]}\}\) 将 \(\{x_1,x_2\}\) 打散，所以假设空间 \(\mathcal H\) 的 VC 维至少为2；对任意大小为 3 的示例集 \(\{x_3,x_4,x_5\}\)，不妨设 \(x_3\lt x_4 \lt x_5\)，则 \(\mathcal H\) 中不存在任意假设 \(h_{[a,b]}\) 能实现对分结果 \(\{(x_3,+1),(x_4,-1),(x_5,+1)\}\) ，于是 VC 维为2.</p>

<p><b>二维平面举例</b>：令 \(\mathcal H\) 表示二维实平面上所有线性划分构成的集合，\(\mathcal X=\mathbb R^2\)。</p>

<div align="center">
    <img width="600" src="media/15151569041850/15338602041302.jpg" />
</div>

<p>如上图所示，存在大小为 3 的示例集可被 \(\mathcal H\) 打散，但不存在大小为 4 的示例集可被 \(\mathcal H\) 打散。于是，二维平面上所有线性划分构成的假设空间 \(\mathcal H\) 的 VC 维为 3 。</p>

<h4 id="toc_15">Sauer 引理</h4>

<p>Sauer 引理基于 VC 维提供一类二分类增长函数的多项式约束。若假设空间 \(\mathcal H\) 的 VC 维为 \(d\)，则对任意的 \(m\in \mathbb N\) 有：<br/>
\[<br/>
\Pi_\mathcal H(m) \le \sum_{i=0}^d\bigg(\begin{array}{c}m\\i\\\end{array}\bigg) <br/>
\]</p>

<blockquote>
<p>其中<br/>
\[<br/>
\bigg( \begin{array}{c}m\\n\\\end{array} \bigg) = \frac{m!}{n!(n-m)!} <br/>
\]</p>

<p>表示组合数，又可以简写为 \(C_n^m\) ，物理意义表示为从 \(m\) 个不同元素中取出 \(n\) 个元素的组合数。规定 \(C_0^m = 1\)、\(C_m^m = 1\) 和 \(C_0^0 = 1\)。</p>
</blockquote>

<p>证明：由数学归纳法证明。当 \(m=1\)，\(d=0\) 或 \(d=1\) 时：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\Pi_\mathcal H(m) = \left \{ \begin{array}{c}<br/>
2^0 = 1\quad&amp;m=1,d=0\\<br/>
2^1 = 2\quad&amp;m=1,d=1\\<br/>
\end{array} \right .\\<br/>
&amp;\sum_{i=0}^d \left(\begin{array}{c}m\\i\\\end{array}\right ) = \left \{ \begin{array}\\ \left (\begin{array}{c}1\\0\\\end{array}\right ) = 1;\quad &amp;m=1,d=0\\<br/>
\left (\begin{array}{c}1\\0\\\end{array}\right ) + \left ( \begin{array}{c}1\\1\\\end{array}\right ) = 2;\quad &amp;m=1,d=1\\<br/>
\end{array}\right .<br/>
\end{align*}<br/>
\]</p>

<p>定理成立。</p>

<p>假设定理对 \((m-1,d-1)\) 和 \((m-1,d)\) 成立。令 \(D=\{x_1,x_2,...,x_m\}\)，\(D&#39;=\{x_1,x_2,...,x_{m-1}\}\)，<br/>
\[<br/>
\begin{align*}<br/>
\mathcal H_{|D}  &amp;= \{(h(x_1),h(x_2),...,h(x_m))|h\in\mathcal H\},\\<br/>
\mathcal H_{|D&#39;} &amp;= \{(h(x_1),h(x_2),...,h(x_{m-1}))|h\in\mathcal H\}.\\<br/>
\end{align*}<br/>
\]</p>

<p>任何假设 \(h\in \mathcal H\) 对 \(x_m\) 的分类结果或为 \(+1\) 或为 \(-1\)，因此任何出现 \(\mathcal H_{|D&#39;}\) 中的串都会在 \(\mathcal H_{|D}\) 中出现一次或两次，令 \(\mathcal H_{D&#39;|D}\) 表示在 \(\mathcal H_{|D}\) 中出现两次的 \(\mathcal H_{|D&#39;}\) 中串组成的集合，即：<br/>
\[<br/>
\mathcal H_{D&#39;|D} = \{(y_1,y_2,...,y_{m-1})\in \mathcal H_{|D&#39;} | \exists h,h&#39;\in \mathcal H,(h(x_i)=h&#39;(x_i) = y_i)\land(h(x_m)\neq h&#39;(x_m)),1\le i\le m-1\}<br/>
\]</p>

<p>考虑到 \(\mathcal H_{D&#39;|D}\) 中的串在 \(\mathcal H_{|D}\) 中出现了两次，但在 \(\mathcal H_{|D&#39;}\) 中仅出现了一次，有：<br/>
\[<br/>
\begin{align}<br/>
|\mathcal H_{|D}| = |\mathcal H_{|D&#39;}| + |\mathcal H_{D&#39;|D}|\label{mmm}<br/>
\end{align}<br/>
\]</p>

<p>\(D&#39;\) 的大小为 \(m-1\) ，由假设可得：<br/>
\[<br/>
\begin{align}<br/>
|\mathcal H_{|D&#39;}| \le \Pi_{\mathcal H}(m-1) \le \sum_{i=0}^d \bigg( \begin{array}{c}m-1\\i\\\end{array}\bigg )\label{mlp}\\<br/>
\end{align}<br/>
\]</p>

<p>令 \(Q\) 表示能被 \(\mathcal H_{D|D&#39;}\) 打散的集合，由 \(\mathcal H_{D&#39;|D}\) 定义可知 \(Q\cup\{x_m\}\) 必能被 \(\mathcal H_{|D}\) 打散。由于 \(\mathcal H\) 的 VC 维为 \(d\)，因此 \(\mathcal H_{D&#39;|D}\) 的 VC 维最小为 \(d-1\)，于是有：<br/>
\[<br/>
\begin{align}<br/>
|H_{D&#39;|D}| \le \Pi(m-1) \le \sum_{i=0}^{d-1}\bigg(\begin{array}{c}m-1\\i\\\end{array}\bigg )\label{hll}<br/>
\end{align}<br/>
\]</p>

<p>由式(\ref{mmm})、(\ref{mlp})和(\ref{hll})可得：<br/>
\[<br/>
\begin{align*}<br/>
|\mathcal H_{|D}| &amp;\le \sum_{i=0}^d \left(\begin{array}{c}m-1\\i\\\end{array}\right ) + \sum_{i=0}^{d-1} \left(\begin{array}{c} m-1\\i\\\end{array}\right)\\<br/>
&amp;= \sum_{i=0}^d \left(\begin{array}{c}m-1\\i\\\end{array}\right ) + \sum_{i=0}^{d} \left(\begin{array}{c} m-1\\i-1\\\end{array}\right)\\<br/>
&amp;= \sum_{i=0}^d \bigg(\left(\begin{array}{c}m-1\\i\\\end{array}\right)+\left(\begin{array}{c}m-1\\i-1\\\end{array}\right )\bigg)\\<br/>
&amp;= \sum_{i=0}^d \left (\begin{array}{c}m\\i\\\end{array} \right )<br/>
\end{align*}<br/>
\]</p>

<p>由集合 \(D\) 的任意性，引理得证。</p>

<p><strong>Sauer推论1：如果 \(d &lt; \infty\) ，对于所有的 \(m \ge 1\) ：<br/>
\[<br/>
\Pi_\mathcal H(m) \le \sum_{i=0}^d\bigg(\begin{array}{c}m\\i\\\end{array}\bigg)  \le (m+1)^d<br/>
\]</strong></p>

<p>推论证明：通过二项式定理：<br/>
\[<br/>
\begin{align*}<br/>
(m+1)^d &amp;= \sum_{i=0}^d m^i \left( \begin{array}\\d\\i\\\end{array}\right ) = \sum_{i=0}^d m^i \frac{d!}{(d-i)!i!}\\<br/>
&amp;\ge \sum_{i=1}^d \frac{m!}{i!} \ge \sum_{i=1}^d \frac{m!}{(m-i)!i!} = \sum_{i=1}^d \left (\begin{array}{cc}m\\i\\\end{array}\right )<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>二项式定理：可以将 \(x+y\) 的任意次幂展开成和的形式<br/>
\[<br/>
(x+y)^n = \left(\begin{array}\\ n\\0\\\end{array} \right)x^n y^0 + \left(\begin{array}\\ {n}\\1\\\end{array}\right) x^{n-1} y^1 + \cdots + \left(\begin{array}{cc} n\\{n-1}\\\end{array} \right )x^1 y^{n-1} + \left(\begin{array}\\ n\\n\\\end{array} \right )x^0 y^n\\<br/>
\]</p>
</blockquote>

<p><strong>Sauer推论2：对于所有的 \(m\le d\) ，有：<br/>
\[<br/>
\Pi_\mathcal H(m) \le \sum_{i=0}^d\bigg(\begin{array}{c}m\\i\\\end{array}\bigg) \le\bigg(\frac{me}{d}\bigg)^d<br/>
\]</strong></p>

<p>推论证明：如果 \(\frac d m \le 1\) 然后<br/>
\[<br/>
\begin{align*}<br/>
\bigg(\frac d m \bigg)^d \sum_{i=0}^d \left (\begin{array}{cc}m\\i\\\end{array}\right ) &amp;\le \sum_{i=0}^d \bigg(\frac d m \bigg)^i \left (\begin{array}{cc}m\\i\\\end{array}\right ) \le \sum_{i=0}^m \bigg(\frac d m \bigg)^i \left (\begin{array}{cc}m\\i\\\end{array}\right ) \\<br/>
&amp;= \bigg(1+\frac d m\bigg)^m \le (e^{d/m})^m \le e^d<br/>
\end{align*}<br/>
\]</p>

<blockquote>
<p>上面的推理使用了\[<br/>
(1+x)&lt;e^x<br/>
\]</p>

<p>这个不等式在上面已经有证明。</p>
</blockquote>

<p>因此<br/>
\[<br/>
\sum_{i=0}^d \left (\begin{array}{cc}m\\i\\\end{array}\right )  \le e^d \bigg(\frac m d \bigg )^d = \bigg (\frac {me}{d}\bigg)^d<br/>
\]</p>

<p><strong>Sauer推论3：如果 \(d\gt 2\) ，那么对于所有 \(m \ge d\)：<br/>
\[<br/>
\Pi_\mathcal H(m) \le m^d<br/>
\]</strong></p>

<p>推论证明：如果 \(d \gt 2\)，且 \(d\in \mathcal N\) ，则\(\frac e d \lt 1\)，由上个推论自然可证。</p>

<p>我们现在来根据<strong>VC不等式定理</strong>和推论可得基于 VC 维的泛化误差界</p>

<p><strong>定理1</strong>：若假设空间 \(\mathcal H\) 的VC维为 \(d\)，则对任意 \(m\gt d\)，\(0\lt \delta\lt 1\) 和 \(h\in \mathcal H\) 有<br/>
\[<br/>
\begin{align}<br/>
P\bigg(\Big|\mathrm E(h) - \mathrm{\hat E}(h)\Big|\le \sqrt{\frac{8d\ln\frac{2em}{d} + 8\ln\frac{4}{\delta}}{m}}\bigg) \ge 1 - \delta\label{pbhb}\\<br/>
\end{align}<br/>
\]</p>

<p>证明：由VC不等式可知：<br/>
\[<br/>
P\bigg(|\mathrm E(h) - \mathrm{\hat E(h)}|\gt \epsilon\bigg)\le 4\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})\\<br/>
\Rightarrow P\bigg(|\mathrm E(h) - \mathrm{\hat E(h)}|\le \epsilon\bigg)\ge 1 - 4\Pi_\mathcal H(2m) \exp(-\frac{m\epsilon^2}{8})\ge 1 - 4\bigg(\frac{2me}{d}\bigg)^d \exp(-\frac{m\epsilon^2}{8})\\<br/>
\]</p>

<p>令 \(\delta = 4\Big(\frac{2me}{d}\Big)^d \exp\Big(-\frac{m\epsilon^2}{8}\Big)\) 得<br/>
\[<br/>
\epsilon = \sqrt{\frac{8\ln(4/\delta) + 8d\ln(2em/d)}{m}}<br/>
\]</p>

<p>得证。</p>

<p>由该定理可知(\ref{pbhb})得泛化误差界只与样例数目 \(m\) 有关，收敛速率为 \(\mathbb O(1/m\) ，与数据分布 \(\mathcal D\) 和样例集 \(D\) 无关。因此基于 VC 维的泛化误差界是分布无关（distribution-free）、数据独立（data-independent）的。</p>

<p>令 \(h\) 表示学习算法 \(\mathcal L\) 输出的假设，若 \(h\) 满足：<br/>
\[<br/>
h = \min_{h&#39;\in\mathcal H} \mathrm{\hat E}(h&#39;)<br/>
\]</p>

<p>则称学习算法 \(\mathcal L\) 满足经验风险最小化（ERM，Empirical Risk Minimization）原则的算法，有下面的定理：</p>

<p><strong>定理2</strong>：任何VC维有限的假设空间 \(\mathcal H\) 都是（不可知）PAC可学习的。</p>

<p>证明：假设 \(\mathcal L\) 是满足经验风险最小化的算法，\(h\) 是算法输出的假设。令 \(g\) 表示 \(\mathcal H\) 中最小泛化误差的假设，即：<br/>
\[<br/>
\mathrm{E}(g) = \min_{h\in\mathcal H}\mathrm{E}(h)<br/>
\]</p>

<p>令 <br/>
\[<br/>
\begin{align}<br/>
\delta&#39;/2 = \delta，\nonumber\\<br/>
\sqrt{\frac{\ln(\delta&#39;/2)}{2m}} = \frac \epsilon 2\label{sfl}<br/>
\end{align}<br/>
\]</p>

<p>由<strong>推论</strong>公式(\ref{tl})可知<br/>
\[<br/>
\begin{align}<br/>
\mathrm{\hat E}(g) - \frac \epsilon 2 \le \mathrm{E}(g) \le \mathrm{\hat E}(g) + \frac \epsilon 2\label{mheg}<br/>
\end{align}<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。令<br/>
\[<br/>
\begin{align}<br/>
\sqrt{\frac{8\ln(4/\delta&#39;) + 8d\ln(2em/d)}{m}} = \frac \epsilon 2\label{sf8}\\<br/>
\end{align}<br/>
\]</p>

<p>由<strong>定理1</strong>公式(\ref{pbhb}) 可知<br/>
\[<br/>
\begin{align}<br/>
P\bigg(\Big|\mathrm E(h) - \mathrm{\hat E}(h)\Big|\le \frac \epsilon 2\bigg) \ge 1 - \delta\label{pbbme}<br/>
\end{align}<br/>
\]</p>

<p>由(\ref{mheg})知<br/>
\[<br/>
\mathrm{E}(g) - \mathrm{\hat E}(g) + \frac \epsilon 2 \ge 0<br/>
\]</p>

<p>结合(\ref{pbbme})知<br/>
\[<br/>
\mathrm E(h) - \mathrm{\hat E}(h) \le \frac \epsilon 2 + \mathrm{E}(g) - \mathrm{\hat E}(g) + \frac \epsilon 2<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。</p>

<p>所以<br/>
\[<br/>
\mathrm{E}(h) - \mathrm{E}(g) \le \mathrm{\hat E}(h) - \mathrm{\hat E}(g) + \epsilon \le \epsilon<br/>
\]</p>

<p>以至少 \(1-\delta/2\) 的概率成立。由(\ref{sfl})和(\ref{sf8})可以解出 \(m\)，再由 \(\mathcal H\) 的任意性可知定理成立，得证。</p>

<hr/>

<p>周志华 机器学习<br/>
<a href="https://web.eecs.umich.edu/%7Ecscott/past_courses/eecs598w14/notes/05_vc_theory.pdf">VC Theory</a><br/>
<a href="http://freemind.pluskid.org/pdf/slt/vc-theory-symmetrization.pdf">VC Symmetrization</a><br/>
<a href="https://mostafa-samir.github.io/ml-theory-pt2/">ml-theory-pt2</a><br/>
<a href="https://blog.csdn.net/wangjianguobj/article/details/57413819">30分钟了解PAC学习理论</a><br/>
<a href="https://blog.csdn.net/icefire_tyh/article/details/52064910">机器学习(周志华西瓜书)参考答案总目录</a><br/>
<a href="http://mlweb.loria.fr/book/en/SauerShelah.html">Sauer&#39;s Lemma</a><br/>
<a href="http://mlweb.loria.fr/book/en/VCbound.html">My first VC bound</a><br/>
<a href="http://mlweb.loria.fr/book/en/symmetrization.html">Symmetrization (where we start seeing ghost samples)</a><br/>
<a href="https://people.cs.umass.edu/%7Eakshay/courses/cs690m/files/lec4.pdf">Lecture 4: The Vapnik-Chervonenkis Dimension</a><br/>
<a href="http://nowak.ece.wisc.edu/SLT09/lecture19.pdf">The Proof of the Vapnik-Chervonenkis (VC) Inequality</a><br/>
<a href="http://www.cs.cmu.edu/%7Ehanxiaol/slides/rademacher_vc_hanxiaol.pdf">Rademacher Complexity and VC Dimension</a><br/>
<a href="https://web.eecs.umich.edu/%7Ecscott/past_courses/eecs598w14/notes/05_vc_theory.pdf">Vapnik-Chevronenkis Theory</a><br/>
<a href="https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec14.pdf">Introduction to Statistical Learning Theory</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15145527362267.html">回归分类树-CART算法</a></h1>
			<p class="meta"><time datetime="2017-12-29T21:05:36+08:00" 
			pubdate data-updated="true">2017/12/29</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>CART算法的英文名称是 Classfication And Regression Tree，即可以用来创建分类树也可以用来创建回归树。通过 ID3 和 C4.5 算法得到的决策树不一定是二叉树，但是通过 CART 得到的决策树肯定是二叉树。CART 算法的生成也是分为三个部分：特征选择、决策树生成、决策树剪枝：</p>

<ol>
<li>特征选择：当 CART 是分类树的时候，以基尼指数选择最优特征，同时决定该特征的最优二值切分点。</li>
<li>决策树生成：基于训练数据生成决策树，生成的树要求尽可能大</li>
<li>决策树剪枝：用合适的方法对已经生成的树进行剪枝选择最优子树。</li>
</ol>

<p>首先我们来分别了解一下 CART 的分类树和回归树。</p>

<h3 id="toc_0">特征选择</h3>

<p>首先来了解一下特征选择所需要的基尼指数知识。</p>

<h5 id="toc_1">基尼指数 Gini</h5>

<p>基尼指数（基尼不纯度）表示在样本集合中一个随机选中的样本被分错的概率。Gini指数越小表示集合中被选中的样本被分错的概率越小，也就是说集合的纯度越高，反之，集合越不纯。所以基尼指数（基尼不纯度）= 样本被选中的概率 * 样本被分错的概率，定义 \(p_k\) 表示选中的样本属于k类别的概率，则这个样本被分错的概率是 \((1-p_k)\)：<br/>
\[<br/>
Gini(k) = \sum_{k=1}^K p_k (1-p_k) = \sum_{k=1}^K p_k - \sum_{k=1}^K p_k^2 = 1 - \sum_{k=1}^K p_k^2<br/>
\]</p>

<p>当二分类时，\(Gini(k) = 2p(1-p)\)。</p>

<p>假设样本集合 D 有 K 个类别，类别 \(C_k\) 包含 \(|C_k|\) 个样本，他们被正确选中为类别 \(C_k\) 的概率为：<br/>
\[<br/>
p(k) = \frac{|C_k|}{|D|}<br/>
\]</p>

<p>所以基尼指数：<br/>
\[<br/>
Gini(k) = 1 - \sum_{k=1}^K p_k^2 = 1 - \sum_{k=1}^K (\frac{|C_k|}{|D|})^2<br/>
\]</p>

<p>基于特征 A 划分样本集合 D 后，集合被分为 \(D_1,D_2,...D_n\)，在 CART 算法中 \(n=2\)，此时基尼指数：<br/>
\[<br/>
Gini(D,A) = \sum_{D_i} \frac{|D_i|}{|D|} Gini(D_i)<br/>
\]</p>

<p>当拥有多个特征时，需要计算以每一个取值作为划分点，对样本D划分之后子集的纯度 \(Gini(D,Ai)\)，(其中Ai 表示特征A的可能取值)。然后从所有的可能划分的 \(Gini(D,Ai)\) 中找出Gini指数最小的划分，这个划分的划分点，便是使用特征 A 对样本集合 D 进行划分的最佳划分点。</p>

<h3 id="toc_2">CART生成树</h3>

<p>决策树的生成是递归生成二叉决策树的过程，对分类树用基尼指数最小化准则，对回归树采用平方误差最小化准则进行特征选择，生成二叉树。</p>

<h4 id="toc_3">分类树生成算法</h4>

<p><b>输入</b>：训练数据集离散数据集 D，停止计算的条件；<br/>
<b>输出</b>：CART 决策树<br/>
<b>算法过程</b>：<br/>
（1）设结点的训练数据集为 D ，计算现有特征对该数据基的基尼指数。此时，对每一个特征 A，对其可能取的每个值 a，根据样本点对 A=a 的测试为“是”或“否” 将 D 分割成 \(D_1\) 和 \(D_2\) 两部分，利用 \(A=a\) 的基尼指数；<br/>
（2）在所有可能的特征 A 以及它们所有可能的切分点 a 中，选择基尼指数最小的特征及其对应的切分点作为最优特征和最优切分点，依最优特征与最优切分点，从现结点生成两个子结点，将训练数据集依特征分配到两个子结点中去。<br/>
（3）对两个子结点递归地调用（1）、（2），直至满足停止条件；<br/>
（4）生成 CART 决策树；</p>

<p>算法停止计算的条件是结点中的样本个数小于预定阈值，或样本集的基尼指数小于阈值阈值（样本基本属于同一类），活着没有更多特征。</p>

<h5 id="toc_4">举例说明</h5>

<p>比如在之前决策树的14天数据中，当 \(A_1\) = 天气特征时，有三种取值，分别是晴天、阴天、下雨，可能的划分情况有{{晴天}{阴天、下雨}}、{{晴天、阴天}{下雨}}、{{阴天}{晴天、下雨}}，分别计算每一种情况的基尼指数。<br/>
\[<br/>
Gini(D,A_1=阴天) = \frac 4 {14}* 2*1*0 + \frac{10}{14} *2 * \frac 5 {10} * \frac 5 {10} = 0.3571 \\<br/>
Gini(D,A_1=下雨) = \frac 5 {14}* 2*\frac 3 5 * \frac 2 5 + \frac {9}{14} * 2* \frac{6}{9} *\frac{3}{9} = 0.4571 \\<br/>
Gini(D,A_1=晴天) = \frac 5 {14}* 2*\frac 2 5 * \frac 3 5 + \frac 9 {14} * 2 * \frac 7 9  *\frac 2 9 = 0.3937<br/>
\]</p>

<p>再计算 \(A_2\) = 湿度特征时，有三种取值，求得每一种取值的基尼指数。。。依次类推，选择所有可能特征及其所有可能的切分点种，基尼指数最小的特征和切分点。将训练数据分到两个子结点中，再对子结点按照同样的方式选择最优特征和最优切分点。CART算法每次都是生成二叉树，在这个例子中某属性特征值为3个时，有3个可能的切分点。当特征值为4个时，如a、b、c、d，可能有{{a}{b,c,d}}、{{b}{a,c,d}}、{{c}{a,b,d}}、{{d}{a,b,c}}、{{a,b}{c,d}}、{{a,c}{b,d}}、{{a,d}{b,c}}这7种。同时，如果没有把特征 \(A\) 的取值完全分开，后面我们还有机会在子节点继续选择到特征 \(A\) 来划分子结点。这和ID3或者C4.5不同，在ID3或者C4.5的一棵子树中，离散特征只会参与一次节点的建立。</p>

<h4 id="toc_5">回归树的生成</h4>

<p><b>输入</b>：数据集 \(D={(x_1,y_1),(x_2,y_2),...(x_n,y_n)}\)<br/>
<b>输出</b>：CART决策树<br/>
<b>算法过程</b>：<br/>
一个回归树对应着输入空间的（特征空间）一个划分以及在划分的单元的输出值。假设已将输入空间划分为M个单元 \(R_1,R_2,...,R_M\)，并且在每一个单元 \(R_M\) 上有一个固定的输出值 \(c_m\)，于是回归树模型可表示为：<br/>
\[<br/>
f(x) = \sum_{i=1}^M c_m I(x\in R_m)<br/>
\]</p>

<p>当输入空间的划分确定时，可以用平方误差 \(\sum_{x_i\in R_m}(y_i-f(x_i))^2\) 来表示回归树对于训练数据的预测误差，用平方误差最小的准则求解每一个单元上的最优输出值。易知，单元 \(R_m\) 上的 \(c_m\) 的最优值 \(\hat c_m\) 是 \(R_m\) 上所有的输入实例 \(x_i\) 对应的输出 \(y_i\) 的均值，即：<br/>
\[<br/>
\hat c_m = ave(y_i|x_i \in R_m)<br/>
\]</p>

<p>特征选择时选择第 \(j\) 个变量 \(x^{j}\) 和它的取值 \(s\) ，作为切分变量和切分点，并定义两个区域：<br/>
\[<br/>
R_1(j,s) = \{x|x^j \le s\} \quad\quad R_2(j,s) = \{x|x^j \gt s\}<br/>
\]</p>

<p>其中定义两个区域的 \(y_i\) 均值：<br/>
\[<br/>
c_1 = ave(y_i|x\in R_1(j,s) \qquad c_2 = ave(y_i|x\in R_2(j,s))<br/>
\]</p>

<p>然后在所有可能特征的最优切分点上寻找最优切分变量和最优切分点，具体地，求解：<br/>
\[<br/>
\min_{j,s} [\min_{c_1} \sum_{x_i\in R_1(j,s)} (y_i-c_1)^2 + \min_{c_2}\sum_{x_i \in R_2(j,s)}(y_i-c2)^2]<br/>
\]</p>

<p>遍历所有输入变量，找到最优的切分变量 \(j\)，构成一个对\((j,s)\)，依次将输入空间划分为两个区域，接着对每一个区域重复上述过程生成一棵回归树，这样的回归树通常被称为最小二乘回归树。</p>

<h5 id="toc_6">举例说明</h5>

<p>假设考虑如下只有一个属性 \(x\) 的数据集 D：</p>

<table>
<thead>
<tr>
<th>x</th>
<th>1</th>
<th style="text-align: left">2</th>
<th style="text-align: left">3</th>
<th style="text-align: left">4</th>
<th style="text-align: left">5</th>
<th style="text-align: left">6</th>
<th style="text-align: left">7</th>
<th style="text-align: left">8</th>
<th style="text-align: left">9</th>
<th style="text-align: left">10</th>
</tr>
</thead>

<tbody>
<tr>
<td>y</td>
<td>5.56</td>
<td style="text-align: left">5.75</td>
<td style="text-align: left">5.91</td>
<td style="text-align: left">6.4</td>
<td style="text-align: left">6.8</td>
<td style="text-align: left">7.05</td>
<td style="text-align: left">8.9</td>
<td style="text-align: left">8.7</td>
<td style="text-align: left">9</td>
<td style="text-align: left">9.05</td>
</tr>
</tbody>
</table>

<p>这里我们不失一般性的考虑9个切分点：1.5 , 2.5 , 3.5 , 4.5 , 5.5 , 6.5 , 7.5 , 8.5 , 9.5 。因为数据集中只有一个属性 \(x\) ，选择属性 \(x\) 所有可能的切分点将数据集分成两部份。当 \(s=1.5\) 时：<br/>
\[<br/>
\begin{align*}<br/>
R_1(j=x,s=1.5) &amp;= \{x|x \le 1.5\} = \{1\}\\<br/>
R_2(j=x,s=1.5) &amp;= \{x|x \gt 1.5\} = \{2,3,4,5,6,7,8,9,10\} <br/>
\end{align*}<br/>
\]</p>

<p>这个区域的输出值为对应区域所有对象 \(y\) 的均值：<br/>
\[<br/>
\begin{align*}<br/>
c_1 &amp;= 5.56\\<br/>
c_2 &amp;= ave(y_i|x \in R_2(j=x,s=1.5) = \frac 1 9(5.75 + 5.91 + 6.4 + 6.8 + 7.05 + 8.9 + 8.7 + 9 + 9.05 ) = 7.50<br/>
\end{align*}<br/>
\]</p>

<p>在两个区域上分别用  \(\sum_{x_i\in R_m}(y_i-f(x_i))^2\) 计算平方误差：<br/>
\[<br/>
\begin{align*}<br/>
\text{Loss}(R_1) &amp;= 0\\<br/>
\text{Loss}(R_2) &amp;= \sum_{x_i\in R_2}(y_i-f(x_i)) = (5.75-7.5)^2+(5.91-7.5)^2+(6.4-7.5)^2+(6.8-7.5)^2+(7.05-7.5)^2\\<br/>
&amp;+(8.9-7.5)^2+(8.7-7.5)^2+(9-7.5)^2+(9.05-7.5)^2 = 15.545\\<br/>
\text{Loss}(s=1.5) &amp;= \text{Loss}(R_1) + \text{Loss}(R_2) = 15.545<br/>
\end{align*}<br/>
\]</p>

<p>同理可以计算出 \(x\) 的其他分割点 \(s\) 的均方误差：\(\text{Loss}(s=2.5)=12.07\)...，如果有多个属性值，用同样的方式再求出其他属性值不同切分点的均方误差。从中选出最小的均方误差对应的属性值和切分点就是最优切分变量和最优切分点。</p>

<h3 id="toc_7">CART剪枝</h3>

<p>CART剪枝算法就是在完整的决策树上，剪掉一些子树，使决策树变小。对CART的剪枝可以通过代价复杂度算法（Cost-Complexity Pruning，CCP）来进行：</p>

<p>在剪枝过程中，计算子树的损失函数：<br/>
\[<br/>
C_\alpha (T) = C(T) + \alpha|T|<br/>
\]</p>

<p>其中，\(T\) 为任意子树，\(C(T)\) 为训练数据的预测误差（后面讲具体计算过程），\(|T|\) 为子树的叶节点个数，\(\alpha \ge 0\) 为参数，正则化项。\(C_\alpha (T)\) 为参数是 \(\alpha\) 是子树 T 的整体损失，参数 \(\alpha\) 用来平衡训练数据的拟合程度和模型的复杂度。</p>

<p>对于固定的 \(\alpha\) ，一定存在使损失函数 \(C_\alpha(T)\) 最小的子树，将其表示为 \(T_\alpha\)，当 \(|T|\) 越大时，模型复杂度越高，对训练数据的拟合越好，反之 \(|T|\) 越小时，模型复杂度越小，但是对训练数据的拟合也不好。当 \(\alpha\) 越大，越倾向于一个复杂度较小的树。当 \(\alpha=0\) 时，不考虑模型复杂度，未剪枝的决策树对训练数据效果最好。</p>

<p>Breiman 等人证明：可以用递归的方法对树进行剪枝，将 \(\alpha\) 从小增大，\(0=\alpha_0&lt;\alpha_1&lt;\alpha_2&lt;...&lt;\alpha_n&lt;+\infty\)，产生一系列的区间 \([\alpha_i,\alpha_{i+1}]，i=0,1,...,n\)；剪枝得到的子树序列对应着区间 \(\alpha\in[\alpha_i,\alpha_{i+1}]，i=0,1,...,n\) 的最优子树序列 \(\{T_0,T_1,...,T_n]\)，序列中的子树是嵌套的。</p>

<p>从整体树 \(T_0\) 开始剪枝，对 \(T_0\) 的任意内部结点 \(t\)，以 \(t\) 为单结点树的损失函数是：<br/>
\[<br/>
C_\alpha(t) = C(t) + \alpha<br/>
\]</p>

<blockquote>
<p>其中：<br/>
\[<br/>
C(t) = p(t) r(t)<br/>
\]</p>

<p>这里 \(p(t)\) 表示结点在总样本中所占的比例，\(r(t)\) 表示该结点的误差代价（分错的结点的比例，结点中类比较多的实例为正确实例）。</p>
</blockquote>

<p>以 \(t\) 为根结点的子树 \(T_t\) 的损失函数为：<br/>
\[<br/>
C_\alpha(T_t) = C(T_t) + \alpha|T_t|<br/>
\]</p>

<blockquote>
<p>其中：<br/>
\[<br/>
C(T_t) = \sum_i^m p(t_i)r(t_i) <br/>
\]</p>

<p>这里 \(p(t_i)\) 表示每一个叶结点在总样本中所占的比例，\(r(t)\) 表示该叶结点的误差代价。</p>
</blockquote>

<p>当 \(\alpha=0\) 及 \(\alpha\) 足够小时，有不等式<br/>
\[<br/>
\begin{equation}<br/>
C_\alpha(T_t) &lt; C_\alpha(t) \label{ca}<br/>
\end{equation}<br/>
\]</p>

<p>当 \(\alpha\) 增大时，在某一 \(\alpha\) 有：<br/>
\[<br/>
\begin{align*}<br/>
&amp;C_\alpha(T_t) = C_\alpha(t)\\<br/>
&amp;\Rightarrow C(T_t) + \alpha|T_t| = C_\alpha(t)\\<br/>
&amp;\Rightarrow \alpha = \frac{C_\alpha(t) - C_\alpha(T_t)}{|T_t|-1}<br/>
\end{align*}<br/>
\]</p>

<p>当 \(\alpha\) 再增大时，不等式 \ref{ca} 反向。只要 \(\alpha=\frac{C(t)-C(T_t)}{|T_t|-1}\) ，\(T_t\) 与 \(t\) 有相同的损失函数值，而 \(t\) 的结点少，因此 \(t\) 比 \(T_t\) 更可取，对 \(T_t\) 进行剪枝。</p>

<p>为此，对 \(T_0\) 中每一内部结点 \(t\)，计算：<br/>
\[<br/>
g(t) = \frac{C(t) - C(T_t)}{|T_t|-1}<br/>
\]</p>

<p>它表示剪枝后整体损失函数减少的程度。在 \(T_0\) 中剪去 \(g(t)\) 最小的 \(T_t\)，将得到的子树称为 \(T_1\)，同时将最小的 \(g(t)\) 设为 \(\alpha_i\)，\(T_i\) 为区间\([\alpha_i,\alpha_2)\) 的最优子树。</p>

<p>如此剪枝下去，自下而上直至得到根结点。在这一过程中，不断地增加 \(\alpha\) 的值，产生新的区间。在剪枝得到的子树序列 \(T_0\),\(T_1\),...,\(T_n\) 中通过交叉验证选取最优子树 \(T_\alpha\)。在子树序列中，每棵子树 \(T_1\),\(T_2\),...,\(T_n\) 都对应于一个参数 \(\alpha_1\),\(\alpha_2\),...,\(\alpha_n\)。所以当最优子树 \(T_k\) 确定时，对应的 \(\alpha_k\) 也确定了，即得到最优决策树 \(T_\alpha\)。</p>

<h5 id="toc_8">举例说明</h5>

<p>如下这棵树：</p>

<div align="center">
    <img width="400" src="media/15145527362267/15325307805907.jpg" />
</div>

<p>一开始时 \(\alpha_0=0\) ，以结点 Node1 的损失函数为：<br/>
\[<br/>
C(t) = p(t)r(t) = \frac{18}{40}*\frac{8}{18} = \frac 1 5\\<br/>
C(T_t) = \frac 3 {40} *\frac 1 3 +\frac 9 {40}*\frac 4 9  + \frac 6 {40} *\frac 1 6= \frac{6}{40}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
g(t)=\frac{C(t)-C(T_t)}{|T_t|-1} = \frac{1}{2}*(\frac 1 5-\frac 6 {40}) = \frac{1}{40}<br/>
\]</p>

<p>以结点 Node2 的损失函数为：<br/>
\[<br/>
C(t) = p(t)r(t) = \frac{15}{40}*\frac{6}{15} = \frac 6 {40}\\<br/>
C(T_t) = \frac 9 {40}*\frac 4 9  + \frac 6 {40} *\frac 1 6= \frac{5}{40}<br/>
\]</p>

<p>计算：<br/>
\[<br/>
g(t) =\frac{C(t)-C(T_t)}{|T_t|-1} = \frac 6 {40}-\frac 5 {40} = \frac{1}{40}<br/>
\]</p>

<p>所以这个g(t)相同，选择 \(|T_t|\) 最大的进行剪枝（在和训练集误差相等的情况下选择模型复杂度较低的决策树，所以剪掉 \(|T_t|\) 较大的枝。这里也就是选择 Node1 进行剪枝得到子树 \(T_1\)，同时将最小的 g(t) 设为 \(\alpha_1\) ，\(T_1\)  为区间 \([\alpha_1,\alpha_2)\) 的最优子树。</p>

<p>继续剪枝，直到得到根结点为止，这个过程中不断增加 \(\alpha\) 的值产生新的区间。 </p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15109408623126.html">GMM与最大期望算法</a></h1>
			<p class="meta"><time datetime="2017-11-18T01:47:42+08:00" 
			pubdate data-updated="true">2017/11/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>EM算法的一个重要应用时高斯混合模型的参数估计，高斯混合模型应用广泛，在许多情况下，EM算法时学习高斯混合分布的有效方法。先来介绍一下高斯混合分布 GMM 和相关的几个概念：</p>

<h4 id="toc_0">高斯分布</h4>

<p>高斯分布（Gaussian Distribution），有时也被称为正太分布，在自然界中最常见的存在。假设对我国成年男人的身高作出统计，如下图：</p>

<div align="center">
    <img width='300' src='media/15109408623126/15326117493088.jpg'/>
</div>

<p>这个图形非常直观的展现了高斯分布的形状，高斯函数的数学定位为 \(N(\mu,\sigma^2)\)，其中 \(\mu\) 为分布的平均值，\(\sigma\) 为分布的标准差：<br/>
\[<br/>
\mathcal N(y|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})<br/>
\]</p>

<p>上面身高的高斯分布便是在 \(N(172,36)\) 下绘制的分布图。期望值决定了分布的位置，标准差决定分布的振幅。</p>

<h4 id="toc_1">混合高斯分布</h4>

<p>高斯混合分布（Gaussian Mixture Model）是指多个高斯分布的线性分布，理论上高斯混合分布能模拟出任何分布形状。高斯混合模型的数学定义如下：<br/>
\[<br/>
\begin{align*}<br/>
P(y|\theta) &amp;=\sum_{k=1}^K P(\text{第}k\text{个高斯分布}|\theta)  P(y|\text{第}k\text{个高斯分布},\theta)\\<br/>
&amp;= \sum_{k=1}^K \alpha_k \mathcal N(y|\theta_k)\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\alpha_k\) 是系数，\(\alpha_k \ge 0\)，\(\sum_{k=1}^K \alpha_k = 1\)，\(\mathcal N(y|\theta_k)\) 是高斯分布密度，\(\theta_k=(\mu_k,\sigma_k^2)\)：<br/>
\[<br/>
\mathcal N(y|\theta_k) = \frac{1}{\sqrt{2\pi}\sigma_k} exp(-\frac{(y-\mu_k)^2}{2\sigma_k^2})<br/>
\]</p>

<p>称为第 \(k\) 个分模型。</p>

<p>如下图是分别是我国成年男女的身高分布：</p>

<div align="center">
    <img width='360' src="media/15109408623126/15326156226146.jpg" />
</div>

<p>假设成年男人的身高满足高斯分布 \(N(\mu_1,\sigma_1)\)，成年女人身高满足高斯分布 \(N(\mu_2,\sigma_2)\)，我国男女的比例分别是 \(\alpha_1\) 和 \(\alpha_2\) ，混合高斯分布模型如下：<br/>
\[<br/>
P(y|\theta) = \alpha_1 \mathcal N(y|\mu_1,\sigma_1) + \alpha_2 \mathcal N(y|\mu_2,\sigma_2)<br/>
\]</p>

<p>上式中未知的参数有六个，\(\theta=(\alpha_1,\mu_1,\sigma_2,\alpha_2,\mu_2,\sigma_2)\)。如果要从 GMM 的分布中随机地取一个点的话，实际上可以分为两步：首先随机地在这 \(K\) 个分布之中选一个，每个分布被选中的概率实际上就是它的系数 \(\alpha_k\) ，选中单个分布之后，比如上图蓝色的分布，这里已经回到了普通的 Gaussian 分布，转化为已知的问题。</p>

<h5 id="toc_2">高斯混合模型参数估计的 EM 算法</h5>

<p>假设观察数据 \(y_1,y_2,...y_n\) 由高斯混合模型生成：<br/>
\[<br/>
P(y|\theta) =  \sum_{k=1}^K \alpha_k \mathcal N(y|\theta_k)<br/>
\]</p>

<p>其中 \(\theta=(\alpha_1,\alpha_2,...,\alpha_k;\theta_1,\theta_2,...,\theta_k)\) 。显然我们已经知道观察数据 \(y_1,y_2,...,y_n\) 的生成步骤：首先根据概率 \(\alpha_k\) 选择第 \(k\) 个高斯分布模型 \(\mathcal N(y,\theta_k)\) ，然后根据模型生成观察数据 \(y_j\) 。使用 \(\gamma_j\) 表示第 \(j\) 个观察数据来自的高斯分布 ，\(\gamma_{jk}\) 表示第 \(j\) 个观察数据来源于第 \(k\) 个高斯分布的概率，其定义如下：<br/>
\[<br/>
\begin{align*}<br/>
\gamma_{jk} = \left \{ \begin{array}\\<br/>
1\qquad &amp;\gamma_j = k\\<br/>
0\qquad &amp;\gamma_j \neq k\\<br/>
\end{array}\right .<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(j=1,2,...,N\)，\(k=1,2,...,K\)，\(\gamma_{jk}\) 是 \(0-1\) 随机变量，容易看出：<br/>
\[<br/>
\sum_{k=1}^K \hat\gamma_{jk} = 1<br/>
\]</p>

<p>有了观察数据 \(y_j\) 以及未观察数据 \(\gamma_{jk}\)，那么完全数据是：<br/>
\[<br/>
(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}),\quad j=1,2,...,N<br/>
\]</p>

<p>先来看对于单样本 \(y_j\) 的概率：<br/>
\[<br/>
\begin{align*}<br/>
p(y_j|\gamma_{j1},\gamma_{j2},...,\gamma_{jK},\theta) &amp;= \prod_{k=1}^K [p(y_j|\gamma_{jk} ,\theta)]^{\gamma_{jk}}=\prod_{k=1}^K [\mathcal N(y_j|\theta_k)]^{\gamma_{jk}}\\<br/>
\end{align*}<br/>
\]</p>

<p>隐变量的先验概率为：<br/>
\[<br/>
p(\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta) = \prod_{k=1}^K \alpha_k^{\gamma_{jk}}<br/>
\]</p>

<p>所以单样本 \(y_j\) 的似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
p(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta) &amp;= p(y_j|\gamma_{j1},\gamma_{j2},...,\gamma_{jK},\theta) p(\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta)\\<br/>
&amp;= \prod_{k=1}^K [\mathcal N(y_j|\theta_k)]^{\gamma_{jk}} \prod_{k=1}^K \alpha_k^{\gamma_{jk}}\\<br/>
&amp;= \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}<br/>
\end{align*} <br/>
\]</p>

<p>于是，可以写出完整数据的似然函数：<br/>
\[<br/>
\begin{align*}<br/>
P(y,\gamma|\theta) &amp;= \prod_{j=1}^N p(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta)\\<br/>
&amp;= \prod_{j=1}^N \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>所以完整数据的对数似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta) &amp;= \log p(y,\gamma|\theta) = \log \prod_{j=1}^N \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K [\gamma_{jk} \log\alpha_k+\gamma_{jk}\log\mathcal N(y_j|\theta_k)]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K [\gamma_{jk} \log\alpha_k+\gamma_{jk}\log \frac 1 {\sqrt{2\pi}\sigma_k} \exp(-\frac{(y_j-\mu_k)^2}{2\sigma_k^2})]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
\end{align*}<br/>
\]</p>

<p>EM算法的E步骤，确定Q函数：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_\gamma[\log p(y,\gamma|\theta)|y,\theta^{i}] \\<br/>
&amp;= \sum_\gamma p(\gamma|y,\theta^{(i)}) \log p(y,\gamma|\theta)\\<br/>
&amp;= \sum_\gamma p(\gamma|y,\theta^{(i)}) \sum_{j=1}^N \sum_{k=1}^K \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} \\<br/>
\end{align*}<br/>
\]</p>

<p>现在计算 \(\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk}\)，因为只有当 \(\gamma_{j}=k\) 时 \(\gamma_{jk} = 1\) ，否则 \(\gamma_{jk}=0\)。所以：<br/>
\[<br/>
\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} = \sum_\gamma \gamma_{jk} \sum_{j=1}^N \sum_{k=1}^K p(\gamma_{jk}|y_j,\theta^{(i)}_k) = p(\gamma_{jk}=1|y_j,\theta^{(i)}_k)<br/>
\]</p>

<p>令\(\hat\gamma_{jk} = \sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk}\)：</p>

<p>\[<br/>
\begin{align*}<br/>
\hat\gamma_{jk} &amp;= P(\gamma_{jk}=1|y_j,\theta_k^{(i)})\\<br/>
&amp;= \frac{P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}{P(y_j|\theta^{(i)}_k)}\\<br/>
&amp;= \frac{P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}{\sum_{k=1}^K P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}\\<br/>
&amp;= \frac{P(y_j|\gamma_{jk}=1,\theta_k^{(i)})P(\gamma_{jk}=1|\theta_k^{(i)})}{\sum_{k=1}^K P(y_j|\gamma_{jk}=1,\theta_k^{(i)})P(\gamma_{jk}=1|\theta_k^{(i)})}\\<br/>
&amp;= \frac{\alpha^{(i)}_k \mathcal N(y_j|\theta_k^{(i)})}{\sum_{k=1}^K \alpha^{(i)}_k \mathcal N(y_j|\theta_k^{(i)}) },\quad j=1,2,...,N;k=1,2,...,K<br/>
\end{align*}<br/>
\]</p>

<p>代入 Q 函数中：<br/>
\[<br/>
Q(\theta,\theta^{(i)}) = \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} \\<br/>
\]</p>

<p>EM 算法的M步骤，求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \mu_k} &amp;= \frac{\partial \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \mu_k} \\<br/>
&amp;= \sum_{j=1}^N \frac{[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \mu_k}\\<br/>
&amp;= \sum_{j=1}^N \frac{(y_j-\mu_k)}{\sigma_k^2}\hat\gamma_{jk}\\<br/>
\because &amp;\sum_{j=1}^N \frac{(y_j-\mu_k)}{\sigma_k^2}\hat\gamma_{jk} = 0\\<br/>
\therefore &amp; \sum_{j=1}^N y_j \hat\gamma_{jk}-\sum_{j=1}^N \gamma_{jk}\mu_k = 0\quad \Rightarrow\quad \mu_k = \frac{\sum_{j=1}^N y_j \hat\gamma_{jk}}{\sum_{j=1}^N\hat\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \sigma_k^2} <br/>
&amp;= \frac{\partial \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \sigma_k^2} \\<br/>
&amp;= \sum_{j=1}^N \frac{[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \frac 1 2\log\sigma_k^2  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \sigma_k^2}\\<br/>
&amp;= \sum_{j=1}^N[\frac{1}{2\sigma_k^2} + (\mu_j-y_j)^2 \frac 1 {2\sigma_k^4}]\hat\gamma_{jk}\\<br/>
&amp;= \sum_{j=1}^N \frac{\sigma_k^2+(\mu_j-y_j)^2}{2\sigma_k^4}\hat\gamma_{jk}\\<br/>
\because &amp;\sum_{j=1}^N \frac{\sigma_k^2+(\mu_j-y_j)^2}{2\sigma_k^4}\hat\gamma_{jk} = 0\\<br/>
\therefore &amp; \sum_{j=1}^N [\sigma_k^2+(\mu_j-y_j)^2]\hat\gamma_{jk} = 0\\<br/>
\Rightarrow &amp; \sigma_k^2 = \frac{\sum_{j=1}^N (\mu_j-y_j)^2\hat\gamma_{jk}}{\sum_{j=1}^N \hat\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>现在还剩下一个 \(\alpha_k\) 没有求出，这里用拉格朗日乘子法求解，原问题为：<br/>
\[<br/>
\begin{align*}<br/>
\min \quad&amp;-Q(\theta,\theta^{(i)})\\<br/>
e.t. \quad&amp;\sum_{k=1}^K \alpha_k = 1<br/>
\end{align*}<br/>
\]</p>

<p>定义拉格朗日函数：<br/>
\[<br/>
L(\alpha,\beta) = -\sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \alpha_k -1)\\<br/>
\]</p>

<p>原问题的极小问题可以表示为拉格朗日方程的极大极小问题，先求 \(L(\alpha,\beta)\) 对 \(\alpha\) 的极小值：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial L(\alpha,\beta)}{\partial \alpha_k} &amp;= \frac{\partial \{-\sum_{j=1}^N [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \alpha_k -1)\}}{\partial \alpha_k}\\<br/>
&amp;= -\sum_{j=1}^N \frac 1 \alpha_k \hat\gamma_{jk} + \beta<br/>
\end{align*}<br/>
\]</p>

<p>令导数为0，可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta}<br/>
\]</p>

<p>将 \(\alpha_k\) 代入 \(L(\alpha,\beta)\) 中，得到关于 \(\beta\) 的函数 \(\min_{\alpha_k}L(\alpha,\beta)\)：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\alpha_k} L(\alpha,\beta) &amp;= -\sum_{j=1}^N \sum_{k=1}^K[\log (\frac{\sum_{i=1}^N \hat\gamma_{ik}}{\beta})+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \frac{\sum_{i=1}^N \hat\gamma_{ik}}{\beta} -1)\\<br/>
&amp;=  -\sum_{j=1}^N \sum_{k=1}^K[\log \sum_{i=1}^N \hat\gamma_{ik} - \log\beta+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} +\sum_{i=1}^N \sum_{k=1}^K\hat\gamma_{ik}-\beta\\<br/>
\end{align*}<br/>
\]</p>

<p>拉格朗日乘子法可知需对 \(\min_{\alpha_k} L(\alpha,\beta)\) 求 \(\beta\) 的最大值，对 \(\beta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\min_{\alpha_k} L(\alpha,\beta)}{\partial \beta} = \frac{\sum_{j=1}^N\sum_{k=1}^K \hat\gamma_{jk}}{\beta} - 1 = \frac{N}{\beta} -1 <br/>
\end{align*}<br/>
\]</p>

<p>令导数为0，可得 \(\beta=N\)，代入可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{N}<br/>
\]</p>

<blockquote>
<p>其实不用拉格朗日求出 \(\beta\) 也可以，在求出 \(\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta}\) 后，直接考虑到：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{k=1}^K \alpha_k = 1 \quad &amp;\Rightarrow \quad \sum_{k=1}^K \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta} = 1\\<br/>
&amp;\Rightarrow \quad \frac{\sum_{j=1}^N \sum_{k=1}^K \hat\gamma_{jk}}{\beta} = 1\\<br/>
&amp;\Rightarrow \quad \frac{N}{\beta} = 1 \\<br/>
&amp;\Rightarrow \quad \beta = N<br/>
\end{align*}<br/>
\]</p>

<p>代入可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{N}<br/>
\]</p>
</blockquote>

<p>至此，我们在隐变量已知的情况下得到了GMM的三种类型参数的求解公式。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15092133657181.html">决策树 Decision Tree</a></h1>
			<p class="meta"><time datetime="2017-10-29T01:56:05+08:00" 
			pubdate data-updated="true">2017/10/29</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>决策树，英文名称是Decision Tree（简称DT）。DT是一种树形结构，它的每一个内部节点表示属性上的一次判断，每一个分支代表一种结果的输出，最后的每一个叶节点代表一种结果。决策树的决策过程需要从决策树的根节点开始，待测数据与决策树中的特征节点进行比较，并按照比较结果选择选择下一比较分支，直到叶子节点作为最终的决策结果。决策树在分类问题上可以看做if-then的集合，主要优点是模型具有很高的可读性和执行速度快。</p>

<h3 id="toc_0">决策树学习</h3>

<p>决策树学习是指利用训练数据通过最小化损失函数找到最佳分类特性和阈值，进而建立决策树。决策树的生成包括特征选择、决策树生成和决策树修剪这三个流程，后面会重点介绍这三个流程。决策树通常使用的损失函数是正则化的极大似然函数，当损失函数确定后，学习问题就变成在损失函数意义下选择最优决策树的问题。决策树的算法通常是一个递归选择最优特征，然后根据特征对数据集进行分类，得到子集，使各个子集在当前特征条件下是最好的分类。如果这个子集已经被正确分类，则停止。否则继续对这个子集选择新的最优特征，继续对其进行分割，如此递归下去直到所有的子集都被正确分类。决策树的剪枝是为了使树更加简单，减少对训练数据的拟合，使决策树能够适应更多未知问题。决策树可以认为是一种贪心算法，得到的解可能并不是最优解。</p>

<h4 id="toc_1">特征选择</h4>

<p>特征选择是决策树学习中最重要的步骤，直接决定着决策树的好坏。当一个特征进行分类的结果与随机分类的结果没有较大差别，那么我们认为这个特征是没有分类能力的，经验上来说可以扔掉这样的特征。特征选择是用来确定通过哪个特征来划分特征空间，特征选择的目的：使用某特征对数据集划分之后，各数据子集的纯度要比划分前的数据集的纯度高，这里划分后的纯度表示为各子集的纯度的带权和。通常有几个常见的评判标准：</p>

<h5 id="toc_2">信息熵 Entropy</h5>

<p>首先看一下信息熵的定义，信息熵表示一个信息所含有的信息量的大小，同时也说明一个信息的不确定度的大小。如果我们有一个六面都是1的骰子，不论怎么掷它，我们知道结果肯定是1，没有任何不确定度，所以信息熵为0。</p>

<p>接下来从数学的角度，描述熵的定义：假设随机变量X的可能取值有\(x_1\)，\(x_2\)， ... , \(x_n\)，对于每一个可能的取值 \(x_i\)，其概率 \(P(X=x_i) = p_i , ( i = 1,2, ... , n)\)。随机变量X的信息熵：<br/>
\[<br/>
H(X) = -\sum_{i=1}^N p_i \log p_i<br/>
\]</p>

<p>这里的信息熵通常是以2为底数，具体计算中以什么为底数并没有什么影响，当以2为底数时，信息熵的单位为比特。底数不同时，单位不同，意义相同。在以下计算中，以e为底数来方便计算。而信息熵前面的负号是因为概率通常小于等于1，取对数后小于等于0，为使结果为非负数，所以加上负号。</p>

<p>而对于一个数据集D，有 k 个类别，每一个类别用 \(\text{C}_k\) 表示，数量为 \(|\text{C}_k|\) ，则每一个类别的概率为 \(\frac{|\text{C}_k|}{|\text{D}|}\) ，样本集合D的经验熵：<br/>
\[<br/>
H(D) = -\sum_{k=1}^N \frac{|\text{C}_K|}{|D|} \log \frac{|\text{C}_K|}{|D|}<br/>
\]</p>

<p>这里举个例子：假设训练样本记录了一个人14天的天气、温度、湿度、风四个特征和是否出去玩的情况：<br/>
\[<br/>
\begin{array}{|c|c|c|c|c|}<br/>
\hline<br/>
日期&amp;天气&amp;温度&amp;湿度&amp;风&amp;是否出去玩\\\hline<br/>
01  &amp;晴天&amp;高温&amp;高  &amp;弱&amp;否\\\hline<br/>
02  &amp;晴天&amp;高温&amp;高  &amp;强&amp;否\\\hline<br/>
03  &amp;阴天&amp;高温&amp;高  &amp;弱&amp;是\\\hline<br/>
04  &amp;下雨&amp;中温&amp;高  &amp;弱&amp;是\\\hline<br/>
05  &amp;下雨&amp;凉爽&amp;中  &amp;弱&amp;是\\\hline<br/>
06  &amp;下雨&amp;凉爽&amp;中  &amp;强&amp;否\\\hline<br/>
07  &amp;阴天&amp;凉爽&amp;中  &amp;强&amp;是\\\hline<br/>
08  &amp;晴天&amp;中温&amp;高  &amp;弱&amp;否\\\hline<br/>
09  &amp;晴天&amp;凉爽&amp;中  &amp;弱&amp;是\\\hline<br/>
10  &amp;下雨&amp;中温&amp;中  &amp;弱&amp;是\\\hline<br/>
11  &amp;晴天&amp;中温&amp;中  &amp;强&amp;是\\\hline<br/>
12  &amp;阴天&amp;中温&amp;高  &amp;强&amp;是\\\hline<br/>
13  &amp;阴天&amp;高温&amp;中  &amp;弱&amp;是\\\hline<br/>
14  &amp;下雨&amp;中温&amp;高  &amp;强&amp;否\\<br/>
\end{array}<br/>
\]</p>

<p>设是否出去玩为随机变量Y，则：<br/>
\[<br/>
P(Y=\text{是}) = \frac{9}{14}\\<br/>
P(Y=\text{否}) = \frac{5}{14}\\<br/>
\]</p>

<p>所以：<br/>
\[<br/>
H(Y) = - P(Y=\text{是})\log P(Y=\text{是}) - P(Y=\text{否})\log P(Y=\text{否}) = -\frac{9}{14}\log \frac{9}{14} - \frac{5}{14}\log\frac{5}{14} = 0.6518<br/>
\]</p>

<h5 id="toc_3">代码示例</h5>

<pre><code class="language-python">## 最后一行是标签
def calculateEntropy(data):
    count = len(data)
    labelCounts = np.unique(data[:,-1],return_counts=True)[1]
    entropy = 0
    for labelCount in labelCounts:
        entropy -= labelCount/count * math.log(labelCount/count)
    return entropy
</code></pre>

<h5 id="toc_4">条件熵 Condition Entropy</h5>

<p>条件熵表示在某个条件下的信息熵， \(P(Y|X)\) 则表示在 \(X\) 的条件下 \(Y\) 的信息熵：<br/>
\[<br/>
H(Y|X) = \sum_{x\in X} P(x) H(Y|X=x)<br/>
\]</p>

<p>在上个例子中若 \(X\) 表示湿度，使用 \(Y\) 表示是否出去玩，则：<br/>
\[<br/>
P(x=\text{高}) = \frac{7}{14} = \frac 1 2\\<br/>
P(\text{Y=是}|x=\text{高}) = \frac{3}{7}\\<br/>
P(\text{Y=否}|x=\text{高}) = \frac{4}{7}\\<br/>
P(x=\text{中}) = \frac{7}{14} = \frac 1 2\\<br/>
P(\text{Y=是}|x=\text{中}) = \frac 6 7\\<br/>
P(\text{Y=否}|x=\text{中}) = \frac 1 7<br/>
\]</p>

<p>所以信息熵：<br/>
\[<br/>
\begin{align*}<br/>
H(Y|x=\text{高}) &amp;= -P(\text{是}|x=\text{高}) \log P(\text{是}|x=\text{高}) - P(\text{否}|x=\text{高})\log P(\text{否}|x=\text{高}) \\<br/>
&amp;= -\frac 3 7 \log(\frac 3 7) - \frac 4 7 \log(\frac 4 7) = 0.6829\\<br/>
H(Y|x=\text{中}) &amp;= -P(\text{是}|x=\text{中}) \log P(\text{是}|x=\text{中}) - P(\text{否}|x=\text{中})\log P(\text{否}|x=\text{中}) \\<br/>
&amp;= -\frac 6 7 \log(\frac 6 7) - \frac 1 7 \log(\frac 1 7) = 0.41<br/>
\end{align*}<br/>
\]</p>

<p>条件熵为：<br/>
\[<br/>
\begin{align*}<br/>
H(Y|X) &amp;= P(x=\text{高})H(Y|x=\text{高})+P(x=\text{中})H(Y|x=\text{中})\\<br/>
&amp;= \frac 1 2 \times 0.6829 + \frac 1 2 \times 0.41 = 0.5465<br/>
\end{align*}<br/>
\]</p>

<h5 id="toc_5">代码示例</h5>

<pre><code class="language-python"># 以data的第i行为条件，data的最后一行为标签
def calculateConditionEntropy(data,k):
    entropy = 0
    count = len(data)
    labelLabels, labelCounts = np.unique(data[:,k],return_counts=True)
    for i in range(len(labelLabels)):
        entropy += labelCounts[i]/count * calculateEntropy(data[data[:,k] == labelLabels[i]])
    return entropy
</code></pre>

<h5 id="toc_6">信息增益 Information Gain</h5>

<p>信息增益是指以某特征划分数据集前后熵的差值，我们认为在数据集划分前熵的值已经是确定的，而划分后，如果得到的熵越小，也就是各子集的混乱度越小，纯度越高。因此在选择特征的时候，选择使划分后熵最小的特征，这一点有点类似于梯度下降法，通常会选择梯度最大的方向。定义信息增益为Y的信息熵减去在特征X下的条件熵，即：<br/>
\[<br/>
IG(X) = H(Y) - H(Y|X)<br/>
\]</p>

<p>所以上例子中，\(IG(X) = 0.6518-0.5465 = 0.1053\) ，用相同的方式我们可以求出其他特征的信息增益。</p>

<p>优点：容易理解，计算简单。<br/>
缺点： <br/>
1.信息增益考察的是特征对整个系统的贡献（所有类别使用相同的特征集合），没有到具体的类别上，所以一般只能用来做全局的特征选择，而没法针对单个类别做特征选择（每一个类别有自己的特征集合）。 <br/>
2.只能处理连续型的属性值，没法处理连续值的特征。 <br/>
3.算法天生偏向选择分支多的属性，容易导致overfitting。</p>

<h5 id="toc_7">信息增益比 Infomation Gain Ratio</h5>

<p>在上面提到信息增益天生偏向选择分支多的属性，举个极端的例子：刚才的例子中，如果选择的特征是第一列日期，那么每一天都会被分到一个单独的类中，此时一个类也只有一条记录，此时子集信息熵会变成0，但是这并不是我们希望得到的。为了解决这个问题，自然想到的就是给分支多的特征加以惩罚，定义惩罚系数 \(\text{pub}\) 。于是便有了信息增益比：<br/>
\[<br/>
IGR(X) = \text{pub}\cdot IG(X)<br/>
\]</p>

<p>其中惩罚系数定义为 \(\text{pub}\)：<br/>
\[<br/>
\text{pub} = \frac{1}{\text{IntI}(X)}<br/>
\]</p>

<p>这里的 \(\text{IntI}(X)\) 定义为属性 X 的固有信息（Intrinsic Information of an Attribute），还记得我们在前面信息熵小节里说过数据集D有k个类别 \(C_1,C_2,...,C_k\)，样本集合D的经验熵的计算，这个固有信息便可以理解为这里的经验熵：<br/>
\[<br/>
H(D) = -\sum_{k=1}^N \frac{|\text{C}_K|}{|D|} \log \frac{|\text{C}_K|}{|D|}<br/>
\]</p>

<p>所以代入这里，便是：<br/>
\[<br/>
\text{pub} = \frac{1}{H(X)} = \frac{1}{-\sum_{k=1}^N \frac{|\text{C}_K|}{|X|} \log \frac{|\text{C}_K|}{|X|}}\\<br/>
\] </p>

<p>当我们使用信息增益比时会更加偏向于选择分支较少的特征，为了解决这个问题，一个做法是先通过信息增益过滤掉小于平均增益的特征，然后对剩余特征比较信息增益比，使用信息增益比最大的特征进行分类。</p>

<h4 id="toc_8">决策树的生成</h4>

<p>以下就 ID3算法、C4.5算法、CART算法了解决策树的生成：</p>

<h5 id="toc_9">ID3 算法</h5>

<p>ID3决策树的英文名称是 Iterative Dichotomiser 3，即迭代二叉树3代，它在决策树各节点特征选择上使用信息增益准则，递归选择决策树。从根结点开始，对结点计算所有可能特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征划分形成子结点；再对子结点递归地调用以上方法，构建决策树；直到所有特征的信息增益均很小或没有可以选择的特征为止，最后得到一个决策树。</p>

<p><b>输入</b>：训练数据集D，特征集A，阈值 \(\epsilon\)<br/>
<b>输出</b>：决策树T<br/>
<b>算法过程</b>：<br/>
（1）若 D 中所有实例都属于同一类别 \(C_k\)，则 T 为单结点树，并将 \(C_k\) 做为该结点的类标记，返回 T；<br/>
（2）若 A=\(\varnothing\)，则T为单结点树，将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记；<br/>
（3）计算 A 中的各特征对数据 D 的信息增益，选择信息增益最大的特征 \(A_z\)；<br/>
（4）如果 \(A_z\) 的信息增益小于阈值 \(\epsilon\) ，则置 T 为单结点树，并将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记，返回 T；<br/>
（5）否则，对 \(A_z\) 的每一个可能去值 \(a_i\) ，将 D 分给成若干个非空子集 \(D_i\)，将 \(D_i\) 中实例树最大的类作为标记，构建子节点，由结点及其子结点构成树 T，返回 T；<br/>
（6）对第 i 个子结点，以 \(D_i\) 为训练集，以 \(A-A_z\) 为特征集，递归地调用（1）～（5）步，得到子树 \(T_i\)，返回 \(T_i\)。</p>

<h5 id="toc_10">代码示例</h5>

<p>代码每次创建子树都会删除已经划分的特征，可以优化一下。</p>

<pre><code class="language-python">import os
import numpy as np
import math

class Cluster():
    def __init__(self, label=&quot;&quot;, feature=&quot;&quot;):
        self.label = label
        self.feature= feature
        self.children = []
        self.data = []

    def addData(self, data):
        self.data.extend(data)

def loadData():
    fileName = &quot;14day.txt&quot;
    if not os.path.exists(fileName):
        print(&quot;Data File Not Exists&quot;)
        return
    feature = []
    data  = []
    with open(fileName) as fOpen:
        for index,line in enumerate(fOpen.readlines()):
            if index == 0:
                feature = line.strip().split(&quot; &quot;)
            else:
                data.append(line.strip().split(&quot; &quot;))
    return feature,data

def calculateEntropy(data):
    count = len(data)
    labelCounts = np.unique(data[:,-1],return_counts=True)[1]
    entropy = 0
    for labelCount in labelCounts:
        entropy -= labelCount/count * math.log(labelCount/count)
    return entropy

def calculateConditionEntropy(data,k):
    entropy = 0
    count = len(data)
    labelLabels, labelCounts = np.unique(data[:,k],return_counts=True)
    for i in range(len(labelLabels)):
        entropy += labelCounts[i]/count * calculateEntropy(data[data[:,k] == labelLabels[i]])
    return entropy

def createTree(feature, data):
    data = np.array(data)
    if len(set(data[:,-1])) == 1:
        cluster = Cluster(data[-1,-1])
        cluster.addData(data)
        return cluster
    if len(feature) == 0:
        tempLabel,tempCount = np.unique(data[:,-1],return_counts=True)
        maxLabel = tempLabel[np.argmax(tempCount)]
        cluster = Cluster(maxLabel)
        cluster.addData(data)
        return cluster

    # 计算当前信息熵
    # entropyBefore = calculateEntropy(data)
    minEntropy = math.inf
    minIdex = -1
    for i in range(len(feature)-1):
        entropy = calculateConditionEntropy(data,i)
        if entropy &lt; minEntropy:
            minEntropy = entropy
            minIdex = i
    print(&quot;划分:&quot;+feature[minIdex])
    cluster = Cluster(feature=feature[minIdex])
    newFeature = list(np.delete(feature,minIdex))
    newLabel = set(data[:,minIdex])
    for label in newLabel:
        newData = np.delete(data[data[:,minIdex]==label],minIdex,axis=1)
        newCluster = createTree(newFeature,newData)
        cluster.children.append(newCluster)
    return cluster

if __name__ == &quot;__main__&quot;:
    feature, data = loadData()
    root = createTree(feature, data)
    print(feature)
</code></pre>

<h4 id="toc_11">C4.5算法</h4>

<p>C4.5算法与ID3算法类似，不同的是在树的生成过程中，使用信息增益率来进行选择特征。</p>

<p><b>输入</b>：训练数据集 D，特征集 A ，阈值 \(\epsilon\)<br/>
<b>输出</b>：决策树 T<br/>
<b>算法过程</b>：<br/>
（1）若 D 中所有实例都属于同一类别 \(C_k\)，则 T 为单结点树，并将 \(C_k\) 做为该结点的类标记，返回T；<br/>
（2）若 A=\(\varnothing\) ，则 T 为单结点树，将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记；<br/>
（3）计算 A 中的各特征对数据D的信息增益率，选择信息增益率最大的特征 \(A_z\)；<br/>
（4）如果 \(A_z\) 的信息增益率小于阈值 \(\epsilon\) ，则置T为单结点树，并将 D 中数量最大的类别 \(C_k\) 作为该结点的类标记，返回 T；<br/>
（5）否则，对 \(A_z\) 的每一个可能去值 \(a_i\) ，将 D 分给成若干个非空子集 \(D_i\)，将 \(D_i\) 中实例树最大的类作为标记，构建子节点，由结点及其子结点构成树 T，返回 T；<br/>
（6）对第 i 个子结点，以 \(D_i\)为训练集，以 \(A-A_z\) 为特征集，递归地调用（1）～（5）步，得到子树 \(T_i\)，返回 \(T_i\)。</p>

<h4 id="toc_12">决策树剪枝</h4>

<p>在决策树的学习中，我们知道层数越多，叶结点越复杂，分类效果越好，越容易产生过拟合，对测试集的效果也会受影响。在决策树学习中将已生成的树进行简化的过程称为剪枝，具体地，剪枝从已生成的树上裁掉一些子树或叶节点，并将其根结点和父结点作为新的叶结点，从而简化分类树模型。</p>

<p>通常有两个剪枝方法，预剪枝和后剪枝：</p>

<h5 id="toc_13">预剪枝</h5>

<p>在决策树的生成过程中进行剪枝，常见的有以下几种方式：</p>

<ol>
<li>设置树的高度阈值，当树的高度超过阈值时停止生长。</li>
<li>设置叶结点的最小实例个数，当叶节点的实例树小于阈值时停止生长，不足之处是不能处理那些数据量比较小的特殊情况。</li>
<li>设置经验熵阈值，当叶节点的经验熵小于阈值时停止生长。</li>
<li>设置性能增益阈值，当每次扩展对系统性能的增益小于阈值就可以让它停止生长。</li>
</ol>

<h5 id="toc_14">后剪枝</h5>

<p>设树的叶节点的数量为 \(|T|\)，叶节点 \(t\) 有 \(N_t\) 个样本点，其中 k 类样本点有 \(N_{tk}\) 个，\(k=1,2,...,K\)，定义 \(H(t)\) 为叶节点 \(t\) 的经验熵：<br/>
\[<br/>
H_t(T) = \sum_k^K \frac{N_{tk}}{N_t} \log \frac{N_{tk}}{N_t}<br/>
\]</p>

<p>经验熵反应一个叶结点的分类的混乱程度，经验熵越大，说明该叶结点所对应的分类结果越混乱，也就是说分类结果中包含了较多的类别，表明该分支的分类效果较差。</p>

<p>定义该决策树的损失函数 \(C_\alpha(T)\)为：<br/>
\[<br/>
C_\alpha(T) = \sum_t^{|T|} N_t H_t(T)<br/>
\]</p>

<p>损失函数实际熵是求经验熵的权重，给每一个经验熵一个权重 \(N_t\)。</p>

<p>为了防止过拟合添加 L1 正则化项，修正后的损失函数为：<br/>
\[<br/>
C_\alpha(T) = \sum_t^{|T|} N_t H_t(T) + \alpha |T|<br/>
\]</p>

<p>添加L1正则化项是为了防止过度拟合，在决策树中要追求损失函数和模型复杂度的平衡。当 \(|T|\) 越大时，模型复杂度越高，对训练数据的拟合越好，反之 \(|T|\) 越小时，模型复杂度越小，但是对训练数据的拟合也不好。当 \(\alpha\) 越大，越倾向于一个复杂度较小的树。当 \(\alpha=0\) 时，不考虑模型复杂度，未剪枝的决策树对训练数据效果最好。</p>

<ol>
<li>计算每一个结点的经验熵</li>
<li>递归地从树的叶节点向子结点收缩，设一组叶节点回缩到其父结点之前和之后的整体树为 \(T_{b}\) 和 \(T_{a}\) ，计算损失函数得 \(C_\alpha(T_{b})\) 和 \(C_\alpha(T_{a})\)，当 \(C_\alpha(T_a) \le C_\alpha(T_b)\) 时则进行剪枝，将父结点变成新的叶结点。</li>
<li>重复2，直到不能剪枝为止。</li>
</ol>

<p>决策树的剪枝算法可以由一种动态规划的算法实现。</p>

<hr/>

<p><a href="https://blog.csdn.net/bird_fly_i/article/details/72824639">决策树剪枝算法原理</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15089443346795.html">期望最大化算法 EM</a></h1>
			<p class="meta"><time datetime="2017-10-25T23:12:14+08:00" 
			pubdate data-updated="true">2017/10/25</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>期望最大化算法的英文名称是 Expectation Maximization Algorithm，被称为机器学习十大算法之一。它是一种启发式迭代算法，是一种从不完全数据中求极大似然的算法。算法的每次迭代由两部组成：E步，求期望（Expectation）；M步，求最大值。</p>

<p>看到某篇文章中有个生动的例子阐述EM算法的核心思想：食堂大师傅炒了一盘菜，要等分给俩个人吃，显然没有必要拿天平去称分量，而是可以先随意的将菜倒入两个碗中，然后对比两个碗，从多的里面拿出少量放入少的碗里，再进行比较，再从多的里面拿出少量放入少的碗中，这个过程一直迭代下去，直到看不出哪个多一点少一点为止。</p>

<p>而EM算法便是这样，假设我们不知道A和B两个参数的值，并且如果知道了A的值，就能很容易求出B的值，知道B的值，也能很容易求出A的值。可以考虑先赋予A一个初值，通过这个值求出B的值，再反过来通过B的值求得A的值，反复迭代直到A、B收敛。</p>

<h3 id="toc_0">二硬币问题</h3>

<p>考虑一个掷硬币的例子：假设有A和B两个密度不相等硬币，它们掷出来的正面和反面的概率不相等，我们将 A 和 B 投掷出来的正面的概率设为 \(\theta_A\) 和 \(\theta_B\) ，现在独立的进行5次实验，每次实验选取 A 或 B 中一枚硬币投掷10次，统计出正面的概率。</p>

<p>在这个实验中，我们记录两组向量 \(x=(x_1,x_2,x_3,x_4,x_5)\) 和 \(z=(z_1,z_2,z_3,z_4,z_5)\) ，其中 \(x_i\in(0,1,2,3,4,5,6,7,8,9,10)\) 代表第 \(i\) 次实验中出现正面朝上的次数，\(z_i\in(A,B)\) 表示第 \(i\) 次实验投掷的是硬币A还是硬币B。这次设置的参数估计是完整数据情况，因为我们模型里关联的随机变量（每次实验的结果和投掷硬币的类型）的值都是已知的。</p>

<p>这里一个简单的估计 \(\theta_A\) 和 \(\theta_B\) 的方法是返回每一个硬币观察到的正面的比例。<br/>
\[<br/>
\begin{equation}<br/>
\hat\theta_A = \frac{\text{用 A 硬币投掷出来的正面的次数}}{\text{用 A 硬币投掷的总的次数}} \label{ybzm}\\<br/>
\hat\theta_B = \frac{\text{用 B 硬币投掷出来的正面的次数}}{\text{用 B 硬币投掷的总的次数}} \\<br/>
\end{equation}<br/>
\]</p>

<p>实际上，在统计学上这种直观的猜测被称为极大似然估计。如果用 \(\log P(x;z;\theta)\)表示得到的观察到的正面次数 \(x\) 和 使用硬币的类型 \(z\) 的联合概率的对数形式（对数似然），那么\ref{ybzm}中的公式就是求解使 \(\log P(x;z;\theta)\) 最大的 \(\hat\theta=(\theta_A,\theta_B)\) 。</p>

<div align=center>
    <img width=500 src="media/15089443346795/15308145217430.jpg">
</div>

<p>现在考虑挑战一个参数估计问题中更大的变体，我们给出正面次数的记录但不给出每一组投掷的硬币的类型。我们将 z 称为隐藏变量或潜在因子。这种新设置中的参数估计被称为不完整数据情况。这次对每一种硬币计算正面出现的比例将不再可行，因为我们将不知道每一次实验中所使用的硬币类型。然而，我们有一些方法来使数据完整（在我们的例子中，正确猜测5次实验中使用的是哪个金币），然后我们就能将不完整数据的参数估计简化到完整数据的极大似然估计。</p>

<p>可以通过一个迭代的方法得到完整数据通过下列步骤：开始时给定一个初始值 \(\hat \theta^{(t)}=(\hat\theta^{(t)}_A,\hat\theta^{(t)}_B)\)，我们通过这个初始值来估计5次实验中每一次最有可能使用的硬币是 A 还是 B。然后我们假设这些结论（即猜测指定的硬币）是正确的，然后再使用常规的最大似然估计处理来获得 \(\hat\theta^{(t+1)}\)。最后，重复这两个过程直到收敛。随着参数模型的改进，最终完成的质量也会提高。</p>

<p>如下图所示：先初始化 \(\hat\theta_A^{(0)}=0.6\) 和 \(\hat\theta_B^{(0)}=0.5\) ，我们第一轮实验掷的 5H 和 5T ，正面出现的概率是0.5，更有可能是用硬币 B 投掷，同理第二轮实验正面的概率为0.9，更有可能是硬币 A 投掷......全部猜测完之后，便可以根据我们猜测计算出投掷硬币 A 正面出现的次数是24，反面出现的次数是6，那么可以计算出硬币 A 正面出现的概率 \(\hat\theta_A^{(1)}=0.8\)，同理计算出硬币 B 正面出现的概率 \(\hat\theta_B^{(1)}=0.45\)。重复这个过程，得出最终过程。</p>

<div align=center>
    <img width=520 src="media/15089443346795/15308182178307.jpg">
</div>

<p>期望最大化算法就是对这个基本思想的改进。期望最大化算法并不需要在每一次迭代中选出一个最有可能的硬币（ A 还是 B ），而是用当前参数 \(\hat\theta^{(t)}\) 计算出投掷硬币是 A 或 B 的概率，在此基础上建立一个所有可能完成数据的加权训练数据集。最后，通过改进版本的极大似然估计处理这些加权训练数据集得出一个新的估计参数 \(\hat\theta^{(t+1)}\) 。通过使用加权训练集而不是单个的最有可能的完整数据的好处是EM算法考虑了模型在每一个完整数据的置信度。</p>

<p>如下图所示：先初始化 \(\hat\theta_A^{(0)}=0.6\) 和 \(\hat\theta_B^{(0)}=0.5\) ，我们第一轮实验掷的 5H 和 5T ，所以是用硬币 A 投掷的，正面出现的概率为 \(P_A=\text{C}_{10}^5 (\hat\theta_A^{(0)})^5 (1-\theta_A^{(0)})^5\)，如果是硬币 B 投掷的，正面出现的概率为 \(P_B=\text{C}_{10}^5 (\hat\theta_B^{(0)})^5 (1-\theta_B^{(0)})^5\)，所以投掷的是硬币 A 的概率为：\(\frac{P_A}{P_A+P_B}\thickapprox 0.45\)，同理可求的投掷的是硬币 B 的概率为：\(\frac{P_B}{P_A+P_B}\thickapprox 0.55\)。实际发生正面向上的次数是5，所以这次硬币 A 正面向上的期望为 \(5\times 0.45=2.2\)，硬币 B 正面向上的期望是 \(5\times 0.55\thickapprox 2.8\)，同理求出其他实验结果，这时候再按照完整数据求的硬币 A 正面向上的概率：<br/>
\[<br/>
\hat\theta_A^{(1)} = \frac{21.3}{21.3+8.6} = 0.71<br/>
\]<br/>
同理可求得硬币 B 正面向上的概率。重复这两个流程，便可得最终结果。</p>

<div align=center>
    <img width=520 src="media/15089443346795/15308183981554.jpg">
</div>

<p>总的来说，通过这个EM算法例子，可知EM算法包括两个步骤：E步骤求期望的过程；M步骤，求极大的过程。</p>

<h3 id="toc_1">琴生不等式 Jensen inequality</h3>

<p>1）若 \(f(x)\) 是区间 \((a,b)\) 上的凸函数，有：<br/>
\[<br/>
f[E(x)] \ge E[f(x)]<br/>
\]</p>

<p>2) 若 \(f(x)\) 是区间 \((a,b)\) 上的凹函数（下凸函数），有：<br/>
\[<br/>
f[E(x)] \le E[f(x)]<br/>
\]</p>

<p>3）加权形式凸函数，有：<br/>
\[<br/>
f(a_1x_1+a_2x_2+...+a_nx_n) \ge a_1f(x_1) + a_2f(x_2) + ... + a_nf(x_n),\sum_{i=1} a_i = 1<br/>
\]</p>

<p>4）加权形式凹函数（下凸函数），有：<br/>
\[<br/>
f(a_1x_1+a_2x_2+...+a_nx_n) \le a_1f(x_1) + a_2f(x_2) + ... + a_nf(x_n),\sum_{i=1} a_i = 1<br/>
\]</p>

<p>在本文中，使用加权形式凸函数，令 \(f(x) = \log(x)\) ，\(f(x)&#39;&#39; = (1/x)&#39; = -x^{-2} &lt; 0\)，所以 \(f(x)\) 是凸函数，则：<br/>
\[<br/>
\begin{equation}<br/>
\log[\sum_{i=1} a_i x_i] \ge \sum_{i=1} a_i f(x_i) \label{jensen0}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_2">EM算法推导</h3>

<p>现在通过一个经典的三硬币模型，来看一下EM算法的算法步骤以及推导过程。</p>

<h5 id="toc_3">三硬币模型</h5>

<p>假设有三枚硬币，记为 A，B，C。这些硬币都是密度不均匀的，投掷正面向上的概率分别为 \(\pi\)，\(p\)，\(q\)。现在进行实验：每轮实验先投掷 A 硬币，如果正面朝上，则投掷 B 硬币，如果反面朝上，则投掷 C 硬币；然后投掷选出的硬币，记录正面向上为1，反面向上为0。独立重复进行 n 次实验，假设只能观察到最终记录的结果，不能观察到掷硬币的过程，现在要估计 \(\theta=(\pi,p,q)\) 的概率参数。</p>

<p>将问题抽象出来：</p>

<ul>
<li><strong>输入</strong>：观察数据 \(Y\)</li>
<li><p><strong>输出</strong>：模型参数 \(\theta\)</p></li>
<li><p><strong>方法</strong>：定义隐变量为 \(Z\) ，则观察数据的对数似然函数 <br/>
\[<br/>
L(\theta|Y) = \log P(Y|\theta) = \log \sum_Z P(Y,Z|\theta) = \log \sum_Z P(Y|Z,\theta) P(Z|\theta)<br/>
\]</p>

<p>最大化观测数据的对数似然函数<br/>
\[<br/>
\theta^* = arg \max_\theta L(\theta|Y)<br/>
\]</p></li>
</ul>

<p>对于这个问题不能直接求解，只能通过迭代的方式求解。EM算法便是用来求解此类问题的一种迭代算法。EM算法首先选取参数的初值 \(\theta^{(0)} = (\pi^{(0)},p^{(0)},q^{(0)})\)，然后通过迭代，第 \(i\) 次迭代参数的估计值记为 \(\theta^{(i)} = (\pi^{(i)},p^{(i)},q^{(i)})\)，在第 \(i+1\) 次迭代的E步迭代参数的估计值记为 \(\theta\)。</p>

<h5 id="toc_4">E 步骤：</h5>

<p>定义完全数据 \(Y\), \(Z\) 的对数似然函数 \(\log P(Y,Z|\theta)\)，关于未观测数据 \(Z\) 在给定观测数据 \(Y\) 和当前参数估计 \(\theta_i\) 的情况下的后验概率分布 \(P(Z|Y,\theta_i)\) 的条件期望称为 \(Q\)函数：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
&amp;= \sum_Z \log P(Y,Z|\theta) P(Z|Y,\theta^{(i)}) <br/>
\end{align*}<br/>
\]</p>

<p>\(Q\) 函数中的两个概率分布：</p>

<ul>
<li><p>完全数据 \(Y\), \(Z\) 的对数似然函数 \(\log P(Y,Z|\theta)\)：<br/>
\[<br/>
\log P(Y,Z|\theta) = \log P(Y|Z,\theta)P(Z|\theta)<br/>
\]</p></li>
<li><p>未观测数据 \(Z\) 的后验概率分布 \(P(Z|Y,\theta^{(i)})\)：<br/>
\[ <br/>
\begin{equation}<br/>
P(Z|Y,\theta^{(i)})=\frac{P(Y,Z|\theta^{(i)})}{P(Y|\theta^{(i)})}=\frac{P(Y,Z|\theta^{(i)})}{\sum_{Z′}P(Y,Z′|\theta^{(i)})}=\frac{P(Y|Z,\theta^{(i)})P(Z|\theta^{(i)})}{\sum_{Z′}P(Y|Z′,\theta^{(i)})P(Z′|\theta^{(i)})}\label{zhy}<br/>
\end{equation}<br/>
\]</p></li>
</ul>

<h5 id="toc_5">M步骤：</h5>

<p>求解使 \(Q(\theta,\theta^{(i)})\) 最大的 \(\theta\) ，确定第 \(i+1\) 次迭代的参数估计值 \(\theta^{(i+1)}\) ：<br/>
\[<br/>
\theta^{(i+1)} = arg \max_\theta Q(\theta,\theta^{(i)})<br/>
\]</p>

<h5 id="toc_6">证明：</h5>

<p>在迭代过程中，我们希望新估计值 \(\theta\) 能使 \(L(\theta)\) 增加，即 \(L(\theta) &gt; L(\theta^{(i)})\)，并逐步成为最大值，所以：<br/>
\[<br/>
\begin{align}<br/>
L(\theta) - L(\theta^{(i)}) &amp;= \log P(Y|\theta) - \log P(Y|\theta^{(i)}) \nonumber\\<br/>
&amp;= \log [\sum_Z P(Z,\theta) P(Y|Z,\theta)] - \log P(Y|\theta^{(i)}) \nonumber\\<br/>
&amp;= \log [\sum_Z P(Y|Z,\theta^{(i)}) \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}] - \log P(Y|\theta^{(i)}) \label{ptl}<br/>
\end{align}<br/>
\]</p>

<p>使用式 \ref{jensen0} 得：<br/>
\[<br/>
\log [\sum_Z P(Y|Z,\theta^{(i)}) \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}] \ge \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}<br/>
\]</p>

<p>将上式带入式 \ref{ptl} 得：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta) - L(\theta^{(i)}) &amp;\ge  \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})} - \log P(Y|\theta^{(i)})\\<br/>
&amp;= \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})}\\<br/>
\end{align*}<br/>
\] </p>

<p>令 <br/>
\[<br/>
\begin{equation}<br/>
B(\theta,\theta^{(i)}) = L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})} \label{BTT}\\<br/>
\end{equation}<br/>
\]</p>

<p>则：<br/>
\[<br/>
L(\theta) \ge B(\theta,\theta^{(i)})<br/>
\]</p>

<p>那么，\(B(\theta,\theta^{(i)})\) 是 \(L(\theta)\) 的下限。并从式 \ref{BTT} 可知：<br/>
\[<br/>
 L(\theta^{(i)}) = B(\theta^{(i)},\theta^{(i)})<br/>
\] </p>

<p>任何能使 \(B(\theta,\theta^{(i)})\) 变大的 \(\theta\) 都能使 \(L(\theta)\) 增大，选择 \(\theta^{(i+1)}\) 使 \(B(\theta,\theta^{(i)})\) 达到极大。即：<br/>
\[<br/>
\theta^{(i+1)} = arg \max_\theta B(\theta,\theta^{(i)})<br/>
\]</p>

<p>现在对 \(B(\theta,\theta^{(i)})\) 求 \(\theta^{(i+1)}\) ：<br/>
\[<br/>
\begin{align*}<br/>
\theta^{(i+1)} &amp;= arg \max_\theta B(\theta,\theta^{(i)}) = arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})} ] \\<br/>
&amp;= arg \max_\theta \{L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) [\log P(Z,\theta) P(Y|Z,\theta) - \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})]\} \\<br/>
&amp;= arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta) - \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})] \\<br/>
\end{align*}<br/>
\]</p>

<p>省去其中含有 \(\theta^{(i)}\) 的常数项：<br/>
\[<br/>
\begin{align*}<br/>
\theta^{(i+1)} &amp;= arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta) - \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})] \\<br/>
&amp;= arg \max_\theta [\sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta)]\\<br/>
&amp;= arg \max_\theta [\sum_Z P(Y|Z,\theta^{(i)}) \log P(Y,Z|\theta)]\\<br/>
\end{align*}<br/>
\]</p>

<p>令<br/>
\[<br/>
Q(\theta,\theta^{(i)}) = \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y,Z|\theta)<br/>
\]</p>

<p>所以这就像相当于 EM 算法的一次迭代，即求 \(Q\)函数及求其极大化的过程。</p>

<h5 id="toc_7">EM算法的收敛性</h5>

<p>要证明EM 算法的收敛性，也就是每一次迭代都比以前的结果更优，也就是证明：<br/>
\[<br/>
\begin{equation}<br/>
L(\theta^{(i+1)}) \ge  L(\theta^{(i)}) \quad\Leftrightarrow\quad \log P(Y|\theta^{(i+1)}) \ge \log P(Y|\theta^{(i)})\label{LTLL}<br/>
\end{equation}<br/>
\]</p>

<p>也就是证明 \(\log P(Y|\theta)\) 单调递增，考虑到：</p>

<p>\[<br/>
\begin{align}<br/>
\because \quad &amp; \sum_Z P(Z|Y,\theta^{(i)})=1\nonumber\\<br/>
\therefore \quad &amp; \log P(Y|\theta)= [\log P(Y|\theta)]\sum_Z P(Z|Y,\theta^{(i)})\nonumber\\<br/>
&amp;\qquad\qquad = \sum_Z P(Z|Y,\theta^{(i)})\log P(Y|\theta)\nonumber\\<br/>
\because \quad &amp;P(Y|\theta) = \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)}\nonumber\\<br/>
\therefore \quad &amp; \log P(Y|\theta) = \sum_Z P(Z|Y,\theta^{(i)})\log \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)}\nonumber\\<br/>
&amp;\qquad\qquad = \sum_Z P(Z|Y,\theta^{(i)}) \log P(Y,Z|\theta) - \sum_Z P(Z|Y,\theta^{(i)}) \log P(Z|Y,\theta) \nonumber\\<br/>
&amp;\qquad\qquad = E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] - E_Z[\log P(Z|Y,\theta)|Y,\theta^{(i)}]\label{slxzm}<br/>
\end{align}<br/>
\]</p>

<p>令</p>

<p>\[<br/>
\begin{align*}<br/>
H(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Z|Y,\theta)|Y,\theta^{(i)}]= \sum_Z P(Z|Y,\theta^{(i)}) \log(Z|Y,\theta)<br/>
\end{align*}<br/>
\]</p>

<p>所以式 \ref{slxzm} 可以写成 \(\log P(Y|\theta) = Q(\theta,\theta^{(i)}) - H(\theta,\theta^{(i)})\)，则：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta^{(i+1)}) - L(\theta^{(i)}) &amp;= \log P(Y|\theta^{(i+1)}) - \log P(Y|\theta^{(i)}) \\<br/>
&amp;= [Q(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i+1)},\theta^{(i)})] - [Q(\theta^{(i)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)})] \\<br/>
&amp;= [Q(\theta^{(i+1)},\theta^{(i)})- Q(\theta^{(i)},\theta^{(i)})] - [H(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)})] \\<br/>
\end{align*}<br/>
\]</p>

<p>因为EM算法是求 \(\theta^{(i+1)}\) 使 \(Q(\theta,\theta^{(i)})\) 增大，所以第一项不用证明，必大于0，现证明第二项：<br/>
\[<br/>
\begin{align*}<br/>
H(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)}) &amp;= \sum_Z  P(Z|Y,\theta^{(i)}) \log P(Z|Y,\theta^{(i+1)})  - \sum_Z P(Z|Y,\theta^{(i)})\log(Z|Y,\theta^{(i)}) \\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \log \frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})} \\<br/>
&amp;\le \log [\sum_Z \log P(Z|Y,\theta^{(i)}) \frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})} ]\\<br/>
&amp;= \log [\sum_Z P(Z|Y,\theta^{(i+1)})]\\<br/>
&amp;= 0<br/>
\end{align*}<br/>
\]  </p>

<p>所以\(L(\theta^{(i+1)}) - L(\theta^{(i)}) \ge 0\)，得证。从上面的推导可以看出，EM算法可以保证收敛到一个稳定点，但是却不能保证收敛到全局的极大值点，因此它是局部最优的算法，当然，如果我们的优化目标 \(Q(θ,θ^{(i)})\) 是凸的，则EM算法可以保证收敛到全局最大值，这点和梯度下降法这样的迭代算法相同。</p>

<h4 id="toc_8">三硬币求解</h4>

<p>我们用 \(y\) 表示观察变量，表示一次实验观察的结果是 1（正面） 或 0（反面）；使用 \(z\) 表示隐变量，表示未观察到的投掷 A 硬币的结果。一次实验观察数据 \(Y_i\) 的概率：<br/>
\[<br/>
\begin{align*}<br/>
P(Y_i=y|\theta) &amp;= \sum_z P(y,z|\theta) = \sum_z P(z|\theta)P(y|z,\theta) \\<br/>
&amp;= \pi p^y (1-p)^{1-y} + (1-\pi) q^y (1-q)^{1-y}<br/>
\end{align*}<br/>
\]</p>

<p>将观察数据表示为 \(Y=(Y_1,Y_2,...,Y_n)^T\)，不可观察数据表示为 \(Z=(Z_1,Z_2,...,Z_n)^T\)，观察数据的似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
P(Y|\theta) &amp;= P(Y_1,Y_2,...,Y_n|\theta) = \prod_{i=1}^n P(Y_i|\theta) \\<br/>
&amp;= \prod_{i=1}^n [\pi p^{y_i} (1-p)^{1-{y_i}} + (1-\pi) q^{y_i} (1-q)^{1-y_{i}}]<br/>
\end{align*}<br/>
\]</p>

<h6 id="toc_9">E步骤：</h6>

<p>先定义Q函数为：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
\end{align*}<br/>
\]</p>

<p>现在来化简 Q函数，先看：<br/>
\[<br/>
P(Y,Z|\theta) = \prod_j P(Y_j,Z_j|\theta) = \prod_j \prod_k P(Y_j,Z_j=k|\theta)^{Z_{jk}}<br/>
\]</p>

<p>这里使用 \(Z_{jk}\) 表示观察数据 \(Y_j\) 对应的隐藏数据，也就是硬币 A 的结果，在这个例子中 \(k=\{0,1\}\)：<br/>
\[<br/>
Z_{jk} = \left \{ \begin{array}\\ 1 \quad &amp; Z_j = k\\ 0 \quad &amp; Z_j \neq k\\\end{array}\right .<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\log P(Y,Z|\theta) &amp;= \log \prod_j \sum_k P(Y_j,Z_j=k|\theta)^{Z_{jk}} = \sum_j \sum_k Z_{jk} \log P(Y_j,Z_j=k|\theta) <br/>
\end{align*}<br/>
\]</p>

<p>上式代入 Q函数得：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \log P(Y,Z|\theta)\\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \sum_j \sum_k Z_{jk} \log P(Y_j,Z_j=k|\theta)\\<br/>
&amp;= \sum_j \sum_k \sum_Z P(Z|Y,\theta^{(i)}) (Z_{jk})\log P(Y_j,Z_j=k|\theta)\\<br/>
&amp;= \sum_j \sum_k \log P(Y_j,Z_j=k|\theta) \sum_Z P(Z|Y,\theta^{(i)}) Z_{jk}\\<br/>
\end{align*}<br/>
\]</p>

<p>现在来计算 \(\sum_Z P(Z|Y,\theta^{(i)}) Z_{jk}\)，因为只有 \(Z_j=k\) 时 \(Z_{jk}=1\) ，其他都等于0，所以：<br/>
\[<br/>
\sum_Z P(Z|Y,\theta^{(i)}) Z_{jk} = \sum_Z Z_{jk} \sum_j\sum_k P(Z_j=k|Y_j,\theta^{(i)}) = P(Z_j=k|Y_j,\theta^{(i)})<br/>
\]</p>

<p>分别代入 \(k=0\) 或 \(k=1\)，得：<br/>
\[<br/>
\begin{align*}<br/>
P(Z_j=0|Y_j,\theta^{(i)}) &amp;= \frac{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}} \\<br/>
P(Z_j=1|Y_j,\theta^{(i)}) &amp;= \frac{(1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}} \\<br/>
\end{align*}<br/>
\]</p>

<p>令：</p>

<p>\[<br/>
\begin{equation}<br/>
\mu_{i,j} = \frac{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}}\label{muij}<br/>
\end{equation}<br/>
\]</p>

<p>则：</p>

<p>\[<br/>
\sum_Z P(Z_j=k|Y_j,\theta^{(i)}) Z_{jk} = \left \{ \begin{array}\\<br/>
\mu_{i,j} &amp; \quad if\quad k=0\\<br/>
1-\mu_{i,j} &amp; \quad if\quad k=1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>再求 \(\sum_j \sum_k \log P(Y_j,Z_j=k|\theta)\)，分别代入 \(k=0\) 或 \(k=1\) 得：</p>

<p>\[<br/>
P(Y_j,Z_j|\theta) = \left \{ \begin{array}\\<br/>
\pi p^{y_j}(1-p)^{1-y_j}&amp; \quad if \quad k = 0\\<br/>
(1-\pi) q^{y_j}(1-q)^{1-y_j}&amp;\quad if \quad k = 1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>所以Q函数可以改写为：</p>

<p>\[<br/>
Q(\theta,\theta^{(i)}) = \sum_j \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}<br/>
\]</p>

<h6 id="toc_10">M步骤</h6>

<p>Q函数对参数 \(\pi\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \pi} &amp;= \sum_j \frac{\partial \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}}{\partial \pi}\\<br/>
&amp;= \sum_j [\mu^{i,j} \frac{p^{y_j}(1-p)^{1-y_j}}{\pi p^{y_j}(1-p)^(1-y_j)} - (1-\mu_{i,j})\frac{q^{y_j}(1-q)^{1-y_j}}{(1-\pi)q^{y_j}(1-q){1-y_j}}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}}{\pi} - \frac{1-\mu_{i,j}}{1-\pi}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}(1-\pi) - (1-\mu_{i,j})\pi}{\pi(1-\pi)}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j} - \pi}{\pi(1-\pi)}]\\<br/>
&amp;= \frac{\sum_j \mu_{i,j} - n\pi}{\pi(1-\pi)}] = 0\\<br/>
\Rightarrow \quad &amp; \pi = \frac 1 n \sum_j \mu_{i,j}<br/>
\end{align*}<br/>
\]</p>

<p>Q函数对参数 \(p\) 求导：</p>

<p>\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial p} &amp;= \sum_j \frac{\partial \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}}{\partial p}\\<br/>
&amp;= \sum_j [\mu_{i,j}\frac{\pi y_j p^{y_j-1}(1-p)^{1-y_j}-\pi p^{y_j}(1-y_j)(1-p)^{-y_j}}{\pi p^{y_j}(1-p)^{1-y_j}}]\\<br/>
&amp;= \sum_j [\mu_{i,j}\frac{y_j(1-p)-p(1-y_j)}{p(1-p)}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}(y_j-p)}{p(1-p)}]\\<br/>
&amp;= \frac{\sum_j \mu_{i,j} y_j - \sum_j \mu_{i,j}p}{p(1-p)} = 0\\<br/>
\Rightarrow \quad &amp; p = \frac{\sum_j \mu_{i,j}y_j}{\sum_j \mu_{i,j}}<br/>
\end{align*}<br/>
\]</p>

<p>Q函数对参数 \(q\)求导，同上，直接写出结果：</p>

<p>\[<br/>
q = \frac{\sum_j (1-\mu_{i,j})y_j}{\sum_j (1-\mu_{i,j})}<br/>
\]</p>

<p>综合三式得：</p>

<p>\[<br/>
\begin{align}<br/>
\pi^{(i+1)} &amp;= \frac 1 n \sum_j \mu_{i,j}\label{pii1}\\<br/>
p^{(i+1)} &amp;= \frac{\sum_j \mu_{i,j}y_j}{\sum_j \mu_{i,j}}\label{pi1}\\<br/>
q^{(i+1)} &amp;= \frac{\sum_j (1-\mu_{i,j})y_j}{\sum_j (1-\mu_{i,j})}\label{qi1}<br/>
\end{align}<br/>
\]</p>

<p>当给定初值便可以进行迭代求解了。</p>

<p>假设三硬币模型的结果如下：</p>

<p>\[<br/>
1,1,0,1,0,0,1,0,1,1<br/>
\]</p>

<p>假定一开始我们设初始值 \(\pi^{(0)}=0.5,p^{(0)} = 0.5,q^{(0)} = 0.5\)，由式 \ref{muij} 对 \(y_j=0\) 或 \(y_j=1\) ，都有：<br/>
\[<br/>
\mu_{0,0} = \frac{\pi^{(0)} (p^{(0)})^{y_0}(1-p^{(0)})^{1-y_0}}{\pi^{(0)} (p^{(0)})^{y_0}(1-p^{(0)})^{1-y_0} + (1-\pi^{(0)}) (q^{(0)})^{y_0}(1-q^{(0)})^{1-y_0}} = 0.5\\<br/>
\mu_{0,1} = \frac{\pi^{(0)} (p^{(0)})^{y_1}(1-p^{(0)})^{1-y_1}}{\pi^{(0)} (p^{(0)})^{y_1}(1-p^{(0)})^{1-y_1} + (1-\pi^{(0)}) (q^{(0)})^{y_1}(1-q^{(0)})^{1-y_1}} = 0.5\\<br/>
\]</p>

<p>利用式 \ref{pii1}、式\ref{pi1}、式 \ref{qi1} 迭代可得：<br/>
\[<br/>
\pi^{(1)} = 0.5,\quad p^{(1)} = 0.6,\quad q^{(1)} = 0.6<br/>
\]</p>

<p>由 \ref{muij} 得：</p>

<p>\[<br/>
\mu_{1,0} = 0.5,\quad \mu_{1,1} = 0.5<br/>
\]</p>

<p>继续迭代得：<br/>
\[<br/>
\pi^{(2)} = 0.5,\quad p^{(2)} = 0.6,\quad q^{(2)} = 0.6<br/>
\]</p>

<p>于是得到 \(\theta\) 的极大似然估计为：<br/>
\[<br/>
\hat \pi = 0.5,\quad \hat p = 0.6,\quad \hat q = 0.6<br/>
\]</p>

<p>另外我们可以试一下，设置不同的初值，最终结果可能不同，也就是说EM算法与初值的选取有关，选择不同的初值可能会得到不同的结果。</p>

<hr/>

<p><a href="http://www.cs.tau.ac.il/%7Ershamir/algmb/archive/EM-BW.pdf">Introduction to Expectation Maximization</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15061862782517.html">最大后验概率估计 MAP</a></h1>
			<p class="meta"><time datetime="2017-09-24T01:04:38+08:00" 
			pubdate data-updated="true">2017/9/24</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>最大后验概率估计的全称是 Maximum a posteriori estimation，简称MAP。极大似然估计是通过求参数 \(\theta\) ，使似然函数估计 \(P(x_0|\theta)\)最大。最大后验概率估计顾名思义就是最大化后验概率，看一下后验概率的定义：<br/>
\[<br/>
p(\theta|x) = \frac{\pi(\theta)\prod_{i=1}^N p(x_i|\theta)}{\prod_{i=1}^N p(x_i)}<br/>
\]</p>

<p>因为样本是固定的，所以认为分母是固定的，所以最大后验概率与使 \(\pi(\theta)\prod_{i=1}^N p(x_i|\theta)\) 最大的 \(\theta\) 值同解：<br/>
\[<br/>
\hat \theta = \arg\max_\theta p(\theta|x) = \arg\max_\theta \pi(\theta)\prod_{i=1}^N p(x_i|\theta)<br/>
\]</p>

<p>其中 \(p(x|\theta)=\prod_{i=1}^N p(x_i|\theta)\) 就是似然函数，\(\pi(\theta)\) 是参数的先验知识，所以我们可以认为最大后验估计就是规则化的极大似然估计，对上式加上对数处理后：<br/>
\[<br/>
\begin{align}<br/>
\arg\max_\theta p(\theta|x) &amp;= \arg\max_\theta [\ln \prod_{i=1}^N p(x_i|\theta) + \ln\pi(\theta)]\nonumber\\<br/>
&amp;= \arg\max_\theta[\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta)] \label{hygl}<br/>
\end{align}<br/>
\]</p>

<h4 id="toc_0">二项分布</h4>

<p>在二项分布中，假设参数的先验分布满足贝塔分布 \(Be(\alpha,\beta)，\)即：<br/>
\[<br/>
\pi(\theta) = \frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}<br/>
\]</p>

<p>而二项分布中每次的结果都用 \(\theta\) 表示为：<br/>
\[<br/>
p(x_i|\theta) = \theta^{x_i}(1-\theta)^{1-x_i}<br/>
\]<br/>
将上两式带入式\ref{hygl}中，很容易得到对数后验概率为：<br/>
\[<br/>
\begin{align}<br/>
\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta) &amp;= \sum_{i=1}^N \ln [\theta^{x_i}(1-\theta)^{1-x_i}] + \ln[\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}]\label{dshy}\\<br/>
\end{align}<br/>
\]</p>

<p>要想求出对数后验概率的最大值，需要对其求导。可以分成两部分对 \(\theta\) 求导，前面一项在极大似然估计已经求出，直接给出结果：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\{\sum_{i=1}^N[ \ln[\theta^{x_i}(1-\theta)^{1-x_i}]\} = \frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i)<br/>
\end{align*}<br/>
\]</p>

<p>我们来看式\ref{dshy}的后一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\{\ln[\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}]\} &amp;= \frac{\partial}{\partial \theta}[-\lnB(\alpha,\beta)+(\alpha-1)\ln\theta+(\beta-1)\ln(1-\theta)]\\<br/>
&amp;=\frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta}<br/>
\end{align*}<br/>
\]</p>

<p>所以对数后验概率对 \(\theta\) 求导结果为上面两项之和，即：<br/>
\[<br/>
\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) + \frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta}<br/>
\]</p>

<p>为求得最大值，令上式为0：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) + \frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta} = 0\\<br/>
\Rightarrow &amp;(1-\theta)\sum_{i=1}^N x_i-\theta\sum_{i=1}^N(1-x_i)+(\alpha-1)(1-\theta) - (\beta-1)\theta = 0\\<br/>
\Rightarrow &amp;\sum_{i=1}^N x_i - \theta\sum_{i=1}^N x_i-n\theta+\theta\sum_{i=1}^N x_i + \alpha - 1 -\alpha\theta + \theta - \beta\theta + \theta = 0\\<br/>
\Rightarrow &amp; \sum_{i=1}^N x_i -n\theta + \alpha - 1 -\alpha\theta - \beta\theta +2\theta= 0\\<br/>
\Rightarrow &amp; \frac{\sum_{i=1}^N x_i + \alpha -1}{n+\alpha+\beta-2}<br/>
\end{align*}<br/>
\]</p>

<p>所以先验概率满足 \(Be(\alpha,\beta)\) 的二项分布的最大后验估计：<br/>
\[<br/>
\hat\theta = \frac{\sum_{i=1}^N x_i + \alpha -1}{n+\alpha+\beta-2}<br/>
\]</p>

<p>在投硬币的例子中这里的 \(\sum_{i=1}^N x_i\) 即为硬币正面朝上的次数， \(\sum_{i=1}^N x_i=7\) 。与MLE不同的是我们由经验一般会认为硬币的正面出现的概率为0.5，即先验概率 \(\pi(\theta) \sim Be(1,1)\)，所以由最大后验概率求得 \(\theta\) 的值为：<br/>
\[<br/>
\theta = \frac{7+1-1}{10+1+1-2} = 0.7<br/>
\]</p>

<p>有人可能会说，MLE和MAP不就是一样的吗？不是的，可以说这里只是一个偶然，如果说先验知识是硬币是均匀的，也就是这里的 \(\alpha=\beta\) ，但是他们的大小可以表示先验概率的确信度。当我们取\(\alpha=200,\beta=200\)时，在MLE中，没有考虑先验仍旧是0.7。但是在MAP中，\(\theta=\frac{7+200-1}{10+200+200-2} =0.5049\)，也就是说10次实验中7次正面朝上并不能动摇我们对先验概率的坚持。要想改变我们的看法，需要做更多的实验才可以，从这一点上来MAP比MLE有更多的可信性。</p>

<h4 id="toc_1">正太分布</h4>

<p>设 \(x_1\) , \(x_2\) , …, \(x_n\)是来自正态分布 \(N(\theta,\sigma^2)\)的一个样本，其中 \(\sigma^2\) 已知， \(\theta\)未知，假设 \(\theta\) 的先验分布亦为正态分布 \(N(\mu,\tau^2)\)，其中先验均值 \(\mu\) 和先验方差 \(\tau^2\) 均已知。</p>

<p>\[<br/>
\pi(\theta) = \frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\\<br/>
p(x_i|\theta) = \frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\\<br/>
\]</p>

<p>所以对数后验概率为：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta)] = \sum_{i=1}^N \ln\{\frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\}+\ln\{\frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\}\\<br/>
\end{align*}<br/>
\]</p>

<p>将等式对 \(\theta\) 求导分成两部分，前面一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\sum_{i=1}^N \ln\{\frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\} &amp;= \frac{\partial}{\partial \theta}\sum_{i=1}^N [\ln\frac{1}{\sqrt{2\pi}\sigma} -\frac{(x_i-\theta)^2}{2\sigma^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta}\frac{\sum_{i=1}^N(x_i-\theta)^2}{2\sigma^2}\\<br/>
&amp;= -\frac{\partial}{\partial \theta}\frac{\sum_{i=1}^N x_i^2-2\sum_{i=1}^N \theta x_i + \sum_{i=1}^N\theta^2}{2\sigma^2}\\<br/>
&amp;= \frac{n\theta-\sum_{i=1}^N x_i}{\sigma^2}<br/>
\end{align*}<br/>
\]</p>

<p>后面一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta} \{\ln\{\frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\} &amp;= \frac{\partial}{\partial \theta} [\ln\frac{1}{\sqrt{2\pi}\tau} - \frac{(\theta-\mu)^2}{2\tau^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta} [\frac{(\theta-\mu)^2}{2\tau^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta} (\frac{\theta^2-2\mu\theta+\mu^2}{2\tau^2}) \\<br/>
&amp;= \frac{\theta-\mu}{\tau^2}<br/>
\end{align*}<br/>
\]</p>

<p>前后两项的和相加，再令其等于0：<br/>
\[<br/>
\begin{align*}<br/>
&amp; \frac{n\theta-\sum_{i=1}^N x_i}{\sigma^2} + \frac{\theta-\mu}{\tau^2} = 0\\<br/>
\Rightarrow &amp;n\tau^2\theta-\tau^2\sum_{i=1}^N x_i + \theta\sigma^2 - \mu\sigma^2 = 0\\<br/>
\Rightarrow &amp; \hat\theta = \frac{\tau^2\sum_{i=1}^N x_i + \mu\sigma^2}{n\tau^2+\sigma^2}<br/>
\end{align*} <br/>
\]</p>

<p>这里的结果和贝叶斯参数估计的结果表现形式一模一样。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15058431971790.html">极大似然估计 MLE</a></h1>
			<p class="meta"><time datetime="2017-09-20T01:46:37+08:00" 
			pubdate data-updated="true">2017/9/20</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>极大似然估计的英文全称是Maximum -likelihood Estimate，是指利用现有样本，反推能导致这样结果的最大可能的参数值（模型已定参数未知）。在一篇文章看到这样的比喻：某位同学和一个猎人出去打猎，他们同时看到了一个兔子，同时开枪，兔子应声而倒，如果要你猜测兔子是谁打死的？你可能很容易想到是猎人打死的，因为猎人命中的概率很大。这就是极大似然的思路，反推能导致这样结果的的最大可能参数。</p>

<h4 id="toc_0">算法步骤</h4>

<p>当从总体模型中选取n组观察样本后，可以这样认为，我们一次就选取到这n组观察样本，那么这n组样本的组合在总体模型中的联合概率密度最大。所以一般算法步骤如下：</p>

<p>记样本集 \(D = \{x_1,x_2,...,x_n\}\)，参数估计为 \(\theta\) ，最优参数为 \(\theta^*\)。</p>

<p>1）写出似然函数。联合概率密度 \(p(D|\theta)\) 称为相对于 \(D\) 的 \(\theta\) 的似然函数：<br/>
\[<br/>
L(\theta) = p(D|\theta) = p(x_1,x_2,...,x_n|\theta) = \prod_{i=1}^N p(x_i|\theta)<br/>
\] </p>

<p>2) 在实际分析中，累乘会不太好计算，通常作为是取对数，这里也不例外，定义对数似然函数：<br/>
\[<br/>
H(\theta) = \text{In} L(\theta) = \sum_{i=1}^N \text{In} p(x_i|\theta)<br/>
\]</p>

<p>2）对对数似然函数求导，求出令对数似然函数最大的参数值。<br/>
\[<br/>
\theta^* = arg\max_\theta L(\theta) = arg\max_\theta H(\theta) = arg\max \limits_\theta \sum_{i=1}^N \text{In} p(x_i|\theta)<br/>
\]</p>

<h4 id="toc_1">二项分布</h4>

<p>先以简单的抛硬币的例子来讲解，假设我们有一个质量不均匀的硬币，我们想知道这个硬币抛出去正面出现的概率 \(\theta\)，于是做了一个实验，抛了10次，得到的结果是（正面是1，反面是0）：<br/>
\[<br/>
\text{1}\quad\text{1}\quad\text{0}\quad\text{1}\quad\text{0}\quad\text{1}\quad\text{1}\quad\text{1}\quad\text{1}\quad\text{0}\quad<br/>
\]<br/>
如果我们抛开算法，会很容易得出 \(\theta=\frac{\text{正面次数}}{\text{正面次数}+\text{反面次数}}=0.7\)，现在通过MLE来求解一下。</p>

<p>通过上述的算法步骤先写出似然函数，假设正面出现的次数时，\(x_i=1\)：<br/>
\[<br/>
L(\theta) = \prod_{i=1}^N p(x_i|\theta) = \prod_{i=1}^N \theta^{x_i}(1-\theta)^{1-x_i}<br/>
\]<br/>
所以对数似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
H(\theta) &amp;= \text{In}L(\theta) = \sum_{i=1}^N \text{In} \theta^{x_i}(1-\theta)^{1-x_i} \\<br/>
&amp;= \sum_{i=1}^N[ \text{In} \theta^{x_i}+\text{In}(1-\theta)^{1-x_i} ]\\<br/>
&amp;= \sum_{i=1}^N[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ]<br/>
\end{align*}<br/>
\]</p>

<p>对对数似然函数求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial H(\theta)}{\partial \theta} &amp;= \frac{\partial \sum_{i=1}^N[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ]}{\partial \theta}\\<br/>
&amp;= \sum_{i=1}^N \frac{\partial}{\partial \theta}[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ] \\<br/>
&amp;= \sum_{i=1}^N (\frac{x_i}{\theta} - \frac{1-x_i}{1-\theta}) = \frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i)<br/>
\end{align*}<br/>
\]</p>

<p>令求导结果为0，来求得令 \(l(\theta)\)最大值的 \(\theta^*\)：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) = 0\\<br/>
&amp;\Rightarrow (1-\theta) \sum_{i=1} x_i = \theta (n-\sum_{i=1} x_i)\\<br/>
&amp;\Rightarrow \sum_{i=1} x_i - \theta\sum_{i=1} x_i = \theta (n-\sum_{i=1} x_i)\\<br/>
&amp;\Rightarrow \sum_{i=1} x_i = n\theta\\<br/>
&amp;\Rightarrow \theta = \frac 1 n \sum_{i=1} x_i<br/>
\end{align*}<br/>
\]</p>

<p>所以 \(\theta=0.7\) ，与我们用常识估计的相同。</p>

<h4 id="toc_2">正态分布</h4>

<p>假设样本X服从正态分布：<br/>
\[<br/>
x \sim N(\mu,\sigma^2)<br/>
\]</p>

<p>则似然函数为：<br/>
\[<br/>
L(\mu,\sigma^2) = \prod_{i=1}^N \frac 1{\sqrt{2\pi}\sigma}exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) = (2\pi\sigma^2)^{-n/2} exp(-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2})<br/>
\]</p>

<p>则对数似然函数为：<br/>
\[<br/>
H(\mu,\sigma^2) = \text{In}L(\mu,\sigma^2) = -\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}+\text{In}[(2\pi\sigma^2)^{-n/2}] = -\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)<br/>
\]</p>

<p>分别用对数似然函数对 \(\mu\) 和 \(\sigma^2\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial H(\mu,\sigma^2)}{\partial \mu} &amp;= \frac{\partial}{\partial \mu}[-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)] \\<br/>
&amp;=\frac{\partial}{\partial \mu}[-\frac{\sum_{i=1}^N (x_i^2-2x_i\mu+\mu^2)}{2\sigma^2}]\\<br/>
&amp;=\frac{-2\sum_{i=1}^N x_i + 2\sum_{i=1}^N \mu}{2\sigma^2}\\<br/>
\Rightarrow &amp; \mu^* = \frac 1 n \sum_{i=1}^N x_i\\<br/>
\frac{\partial H(\mu,\sigma^2)}{\partial \sigma^2} &amp;= \frac{\partial}{\partial \sigma^2}[-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)]\\<br/>
&amp;=\frac{\sum_{i=1}^N(x_i-\mu)^2}{2\sigma^4} - \frac{n}{2\sigma^2} \\<br/>
\Rightarrow &amp; \sigma^{2*} = \frac{1}{n}\sum_{i=1}^N (x_i-\mu)^2<br/>
\end{align*}<br/>
\]</p>

<p>所以极大似然估计为 \((\mu^*,\sigma^{2*})\)。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15055294223433.html">朴素贝叶斯 Native Bayes</a></h1>
			<p class="meta"><time datetime="2017-09-16T10:37:02+08:00" 
			pubdate data-updated="true">2017/9/16</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在概率论和统计学中，贝叶斯理论（或者贝叶斯法则、贝叶斯规则）通常是基于和事件相关的先验知识来描述概率事件。贝叶斯定理在很多地方都应用广泛，比如垃圾邮件、疾病预测等。</p>

<h3 id="toc_0">条件概率公式与贝叶斯定理</h3>

<p>设A、B是两个事件，在事件A发生的条件下，事件B发生的条件概率（conditional probability）为：<br/>
\[<br/>
P(B|A)<br/>
\]</p>

<p>同理在事件B发生的条件下，事件A发生的条件概率为\(P(A|B)\)<br/>
很容易想到事件A、事件B同时发生的概率等于事件A发生的概率乘上在事件A发生的条件下事件B发生的概率，即：<br/>
\[<br/>
P(AB) = P(A)P(B|A)<br/>
\]<br/>
同理也可得：\(P(AB) = P(B)P(A|B)\)<br/>
结合两式：<br/>
\[<br/>
\begin{eqnarray}<br/>
P(A)P(B|A) = P(B)P(A|B) \nonumber\\<br/>
\Rightarrow P(B|A) = \frac{P(B)P(A|B)}{P(A)} \label{bayes}<br/>
\end{eqnarray}<br/>
\]<br/>
上式（\ref{bayes}）就是贝叶斯定理公式，其中\(P(B)\)称之为先验概率（prior probability），是指在没有任何条件下事件B发生的概率，\(P(A|B)\)是事件B发生的条件事件A发生的条件概率，分母的\(P(A)\)被称为整体概率，因为它起到归一化的作用，所以又称为归一化常量。</p>

<h3 id="toc_1">全概率公式和贝叶斯定理</h3>

<p>如果事件组\(B_1\),\(B_2\),...,\(_n\)是样本空间\(\Omega\)的一个划分，A为任意事件，则：<br/>
\[<br/>
P(A) = P(A|B_1)+P(A|B_2)+...+P(A|B_n) = \sum_{i=1}^N P(A|B_i)P(B_i)<br/>
\]<br/>
全概率公式的意义在于，当直接计算\(P(A)\)不好计算时，而\(P(A|B_i)\)比较容易计算时，可以使用全概率公式计算\(P(A)\)。举个天气的实例，假设6月的某一天天晴的概率是0.4，多云的概率是0.4，下雨的概率是0.2。天晴的天气我出去玩的概率是0.4，多云的天气出去的概率是0.7，下雨的天气出去的概率是0.3，那么这一天我出去玩的概率设为\(P(play)\)：<br/>
\[<br/>
\begin{align*}<br/>
P(play) &amp;= P(play|sunny)P(sunny)+P(play|cloudy)P(cloudy)+P(play|rain)P(rain) \\<br/>
&amp;= 0.4\times 0.4 + 0.7\times 0.4 + 0.3\times 0.2 = 0.16+0.28+0.06=0.5<br/>
\end{align*}<br/>
\]<br/>
计算得出去玩的概率为0.5。</p>

<p>结合全概率公式和公式（\ref{bayes}）得：<br/>
\[<br/>
\begin{equation}<br/>
P(B_j|A) = \frac{P(B_j)P(A|B_j)}{\sum_{i=1}^N P(A|B_i)P(B_i)} \label{bayes_q}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_2">贝叶斯定理</h3>

<p>在上面的例子中，换一种问法，假设那一天如果在我出门的条件下，各个天气状况的概率分别是多少？那么便可以使用贝叶斯定理计算：<br/>
\[<br/>
P(sunny|play) = \frac{P(sunny)P(play|sunny)}{P(play)} = \frac{0.4\times 0.4}{0.5} = 0.32\\<br/>
P(cloudy|play) = \frac{P(cloudy)P(play|cloudy)}{P(play)} = \frac{0.4\times 0.7}{0.5} = 0.56\\<br/>
P(rain|play) = \frac{P(rain)P(play|rain)}{P(play)} = \frac{0.2\times 0.3}{0.8} = 0.12\\<br/>
P(\Omega)=P(sunny|play) + P(cloudy|play) + P(rain|play) = 0.32+0.56+0.12 = 1<br/>
\]<br/>
我觉得从这个实例中已经完全可以理解贝叶斯定理了。</p>

<h3 id="toc_3">先验概率谬误</h3>

<p>先通过一个经典的例子开始说明，假设某种疾病在所有人群中的感染率是 \(0.1\%\)，医院现有的技术对于已知患病情况下，\(99\%\)的可能性可以检查出阳性；对于正常人\(99\%\)的可能性检查为正常，如果从人群中随机抽一个人去检测，医院给出的检测结果为阳性，那么这个人实际得病的概率是多少？从直观上来看，很多人会直接说\(99\%\)，那么真实情况我们来通过贝叶斯定理计算一下:<br/>
\[<br/>
\begin{align*}<br/>
P(患病|阳性) &amp;= \frac{P(患病)P(阳性|患病)}{P(阳性)} = \frac{P(患病)P(阳性|患病)}{P(阳性|患病)P(患病)+P(阳性|正常)P(正常)} \\<br/>
&amp;= \frac{0.1\%\times 99\%}{99\%\times 0.1\%+1\%\times 99.9\%} = \frac{9.9‱}{9.9‱+99.9‱} \approx 9.02\%<br/>
\end{align*}<br/>
\]</p>

<p>可知其实被检测出来是阳性，患病机率也不高。这种情况下，先验概率的大小会严重影响检测结果，很多时候会反直觉。先验概率数据不一定在每种情况下都存在，但是假如确实有这个数据你却不用，那么，你将毁于先验概率谬误，即忽略事前数据并因此作出错误决策。</p>

<p>来一句题外话：如果这个人再去医院复检，检测结果仍为阳性，那么患病概率可以算一下：<br/>
\[<br/>
\begin{align*}<br/>
P(患病|(阳性\cap 阳性)) &amp;= \frac{P(患病)P((阳性\cap 阳性)|患病)}{P((阳性\cap 阳性)|患病)P(患病)+P((阳性\cap 阳性)|正常)P(正常)} \\<br/>
\because  P((阳性\cap 阳性)|患病) &amp;= P(阳性|患病)P(阳性|患病) = 99\% \times 99\%=98.01‱\\<br/>
P((阳性\cap 阳性)|正常) &amp;= P(阳性|正常)P(阳性|正常) = 1\%\times 1\%=0.01‱ \\<br/>
\therefore P(患病|(阳性\cap 阳性)) &amp;= \frac{0.1\%\times 98.01‱}{98.01‱\times 0.1\%+0.01‱\times 99.9\%} = 90.75\%\\ <br/>
\end{align*}<br/>
\]<br/>
可见复检后患病的可信度一下子高出了10倍，还是很有效果的。</p>

<h2 id="toc_4">贝叶斯参数估计</h2>

<p>对于参数估计，一直存在两个学派的不同解决方案。频率派把需要推断的<font color=red>参数θ看做是固定的</font>未知常数，即概率虽然是未知的，但最起码是确定的一个值，同时，<font color=red>样本X 是随机的</font>，所以频率派重点研究样本空间，大部分的概率计算都是针对样本X 的分布；；贝叶斯派的观点则截然相反，他们认为<font color=red>参数是随机变量，而样本X 是固定的</font>，由于样本是固定的，所以他们重点研究的是参数的分布。在两种学派里后面要学的极大似然估计便是频率派的代表算法。而接下来的贝叶斯参数估计和后面需要学习的最大后验概率估计毫无疑问便是贝叶斯派的代表算法。</p>

<p>贝叶斯参数估计是以贝叶斯公式为理论基础的参数估计方法。假设有一个样本集\(x=(x_1,x_2,...,x_n)\)，其中参数是\(\theta=(\theta_1,\theta_2,...,\theta_k)\)，贝叶斯估计的本质就是通过固定的样本利用贝叶斯方法得到参数\(\theta\)的分布。</p>

<p>人们根据先验信息对参数 \(\theta\) 有个基本的认识，这个认识就是先验分布。然后我们通过实验对先验分布进行调整，调整的方法就是贝叶斯方程，调整的结果就是后验分布。</p>

<h4 id="toc_5">先验分布</h4>

<p>将总体中的未知参数 \(\theta\) 看作是变量，样本 \(x\) 看作是常量，可以得到关于 \(\theta\) 的方程\(\pi(\theta)\)，\(\pi(\theta)\)认为是待估计参数\(\theta\) 的先验分布，且 \(\theta\) 的取值和样本集 \(x\) 有关（以下说明中都忽略数据集，如先验分布 \(\pi(\theta,D)\) 写成 \(\pi(\theta)\) ，样本 \(\pi(x|\theta,\text{D})\) 写成 \(\pi(x|\theta)\) ）。</p>

<h4 id="toc_6">后验分布</h4>

<p>考虑到联合概率分布：<br/>
\[<br/>
h(x_1,x_2,...,x_n,\theta)=p(x_1,x_2,...,x_n|\theta)\pi(\theta)=p(\theta|x_1,x_2,...,x_n)p(x_1,x_2,...,x_n)<br/>
\]<br/>
所以可得：<br/>
\[<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{p(x_1,x_2,...,x_n|\theta)\pi(\theta)}{p(x_1,x_2,...,x_n)} = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{p(x_1,x_2,...,x_n)}<br/>
\]<br/>
对于\(p(x_1,x_2,...,x_n)\)，我们称之为边缘分布函数，记为 \(m(x)\)，如果参数空间\(\Theta=(\theta_1,\theta_2,...,\theta_n)\)是离散的，应用全概率公式，可得离散边缘分布：<br/>
\[<br/>
\begin{align*}<br/>
m(x) &amp;= p(x_1,x_2,...,x_n) = \prod_{i=1}^n p(x_i) =\prod_{i=1}^n p(x_i|\theta_1)\pi(\theta_1)+\prod_{i=1}^n p(x_i|\theta_2)\pi(\theta_2)+...+\prod_{i=1}^n p(x_i|\theta_n)\pi(\theta_n)\\<br/>
&amp;= \sum_{j}\pi(\theta_j)\prod_{i=1}^n p(x_i,\theta_j)\\<br/>
\end{align*}<br/>
\]<br/>
如果参数空间\(\Theta\)是连续的，应用积分可得连续边缘分布：<br/>
\[<br/>
m(x) = p(x_1,x_2,...,x_n) = \prod_{i=1}^n p(x_i) = \prod_{i=1}^n [\int_\theta p(x_i,\theta)\pi(\theta)d\theta]=\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta<br/>
\]<br/>
这里我们称\(p(\theta|x_1,x_2,...,x_n)\)为后验分布，可以分情况写出后验分布的公式：<br/>
1）参数空间\(\Theta=(\theta_1,\theta_2,...,\theta_n)\)是离散<br/>
\[<br/>
\begin{align}<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\sum_{j}\pi(\theta_j)\prod_{i=1}^n p(x_i,\theta_j)} \label{ls}<br/>
\end{align}<br/>
\]<br/>
2）参数空间\(\Theta\)是连续<br/>
\[<br/>
\begin{align}<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} \label{lx}<br/>
\end{align}<br/>
\]</p>

<p>这里介绍一些常用分布的后验分布：</p>

<h4 id="toc_7">二项分布 binomial distribution</h4>

<p>在n重伯努利试验（同样的条件下重复地、相互独立地进行的一种随机试验）中，如果它分别以概率 \(\theta\) 和 \((1-\theta)\) 取1和0为值，恰好出现 k 次1的概率为 \(p(X=k|\theta)= \text{C}_n^k\theta^k(1-\theta)^{n-k}\)，这就是二项分布的分布律，记为\(\text{X}\sim B(n,\theta)\)，当 \(n=1\) 时二项分布又称为伯努利分布。</p>

<p>假设我们实现对概率\(\theta\)没有任何信息，这种情形贝叶斯本人建议使用“等同无知”的原则，使用(0,1)上的均匀分布U(0,1)作为 \(\theta\) 的先验分布，因为在(0,1)上每一点的概率都相等，这被人称为贝叶斯假设。所以 \(\theta\) 出现的概率为\(\pi(\theta)\)<br/>
\[<br/>
\pi(\theta) = \left \{ \begin{array}\\<br/>
1\qquad 0\lt \theta \lt 1\\<br/>
0\qquad \text{其他}<br/>
\end{array}\right.<br/>
\]</p>

<p>考虑上述二项分布事件与概率 \(\theta\) 的联合概率分布：<br/>
\[<br/>
h(X=k,\theta) = f(X=k|\theta)\pi(\theta) = \text{C}_n^k\theta^k(1-\theta)^{n-k},\qquad k=1,2,...,n,0\lt \theta \lt 1<br/>
\]</p>

<p>考虑到该参数空间\(\theta\)是连续的，结合（\ref{lx}）式：<br/>
\[<br/>
\begin{align}<br/>
\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta &amp;= \int_\theta f(X=k|\theta)\pi(\theta)d\theta = \int_\theta \text{C}_n^k\theta^k(1-\theta)^{n-k} d\theta = \text{C}_n^k\int_0^1 \theta^k(1-\theta)^{n-k} d\theta \label{lllx}\\<br/>
\end{align}<br/>
\]</p>

<p>为方便令 \(j=n-k\) ，设：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j) &amp;= \int_0^1 \theta^k(1-\theta)^j d\theta<br/>
\end{align*}<br/>
\]<br/>
利用分部积分法，令 \(\mu(\theta) = (1-\theta)^j\)，令 \(v(\theta) = \frac{1}{k+1}\theta^{k+1}\)，则：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j)&amp;=\int_0^1 \theta^k(1-\theta)^j d\theta = \int_0^1 \mu(\theta)\nu(\theta)&#39; = [u(\theta)v(\theta)]^1_0-\int_0^1 \nu(\theta) \mu(x)&#39;dx \\<br/>
&amp;= [u(\theta)v(\theta)]^1_0-\int_0^1 \frac{1}{k+1}\theta^{k+1}(-j)(1-\theta)^{j-1}d\theta\\<br/>
&amp;= [u(\theta)v(\theta)]^1_0 + \frac{j}{k+1}\int_0^1 \theta^{k+1}(1-\theta)^{j-1}d\theta\\<br/>
&amp;= [u(1)v(1)-u(0)v(0)] + \frac{j}{k+1} J(k+1,j-1)\\<br/>
&amp;= \frac{j}{k+1} J(k+1,j-1)\\<br/>
\end{align*}<br/>
\]<br/>
以此类推：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j) &amp;= \frac{j}{k+1} J(k+1,j-1) = \frac{j(j-1)}{(k+1)(k+2)}J(k+2,j-2) = ... = \frac{j(j-1)\cdots 2\cdot 1}{(k+1)\cdots (k+j)}J(k+j,0) \\<br/>
\end{align*}<br/>
\]<br/>
其中：<br/>
\[<br/>
J(k+j,0) = \int_0^1 \theta^{k+j}(1-\theta)^0 d\theta = \int_0^1 \theta^{k+j}d\theta = \frac{1}{k+j+1}\theta^{k+j+1}|^1_0 = \frac{1}{k+j+1}<br/>
\]<br/>
所以：<br/>
\[<br/>
J(k,j) = \frac{j(j-1)\cdots 2\cdot 1}{(k+1)\cdots (k+j)(k+j+1)} = \frac{j!}{(k+1)\cdots (k+j)(k+j+1)}<br/>
\]<br/>
考虑到伽马函数 \(\Gamma(n) = (n-1)!\)（这里不叙述伽马函数的由来，后面会有伽马函数的介绍）：<br/>
\[<br/>
J(k,j) = \frac{j!}{(k+1)\cdots (k+j)(k+j+1)} = \frac{\Gamma(j+1)\Gamma(k+1)}{\Gamma(j+k+2)}<br/>
\]<br/>
至此我们可以再看看式\ref{lllx}，代入得：<br/>
\[<br/>
\begin{align*}<br/>
\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta &amp; = \text{C}_n^k\int_0^1 \theta^k(1-\theta)^{n-k} d\theta = \text{C}_n^k \frac{\Gamma(n-k+1)\Gamma(k+1)}{\Gamma(n+2)}\\<br/>
\end{align*}<br/>
\]<br/>
将上式带入后验公式（\ref{lx}）便可得二项分布的后验概率：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta|x_1,x_2,...,x_n) &amp;= \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} = \frac{h(X=k,\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} \\<br/>
&amp;= \frac{\Gamma(n+2)}{\text{C}_n^k\Gamma(n-k+1)\Gamma(k+1)} \text{C}_n^k\theta^k(1-\theta)^{n-k} \\<br/>
&amp;= \frac{\Gamma(n+2)}{\Gamma(n-k+1)\Gamma(k+1)} \theta^k(1-\theta)^{n-k},\qquad k=1,2,...,n,0\lt \theta \lt 1<br/>
\end{align*}<br/>
\]<br/>
对比 Beta 分布的概率密度函数：<br/>
\[<br/>
f(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1−x)^{\beta−1} = \frac{1}{B(\alpha,\beta)}x^{\alpha−1}(1−x)^{\beta−1}<br/>
\]<br/>
只要令\(\alpha=k+1,\beta = n-k+1\)，就会发现这两者形式完全一致，所以我们可以说二项分布的后验分布服从 Beta 分布，即 \(\theta|X \sim \text{Be}(k+1,n-k+1)\)，由 Beta 分布的性质可知，二项分布后验分布的期望为：<br/>
\[<br/>
\theta^* = E(\theta|X) = \frac{\alpha}{\alpha+\beta} =  \frac{k+1}{n+2}<br/>
\]</p>

<p>这里举个例子：Laplace在1786年研究了巴黎的男婴出生的比率,他希望检验男婴出生的概率 \(\theta\) 是否大于0.5.为此,他收集到1745~1770年在巴黎出生的婴儿数据.其中,男婴251527个,女婴241945个,他选用U(0,1)作为 \(\theta\) 的先验分布,则 \(\theta\) 的后验分布服从 \(\beta\) 分布，即 \(\beta\sim Be(k+1,n-k+1) = Be(251528,241946)\)，所以：<br/>
\[<br/>
\begin{align*}<br/>
&amp;n = 251527 + 241945 = 493472\\<br/>
&amp;\hat\theta = \frac{k+1}{n+2} = \frac{251527+1}{493472+2} = 0.5097<br/>
\end{align*}<br/>
\]</p>

<h4 id="toc_8">高斯分布</h4>

<p>设 \(x_1\) , \(x_2\) , …, \(x_n\)是来自高斯分布 \(N(\mu,\sigma^2)\)的一个样本，其中 \(\sigma^2\) 已知， \(\mu\)未知，假设 \(\mu\) 的先验分布亦为高斯分布 \(N(\theta,\tau^2)\)，其中先验均值 \(\theta\) 和先验方差 \(\tau^2\) 均已知。</p>

<p>由高斯分布可知样本 \(\mu\) 的先验分布概率密度函数为：<br/>
\[<br/>
\pi(\mu) = \frac{1}{\sqrt{2\pi}\tau}\exp(-\frac{(\mu-\theta)^2}{2\tau^2})<br/>
\]<br/>
样本 \(x_1\), \(x_2\) , …, \(x_n\) 的条件概率密度函数为：<br/>
\[<br/>
p(x|\mu) =\prod_i^n p(x_i|\mu) = (\frac{1}{\sqrt{2\pi}\sigma})^n \exp(\sum_i^n -\frac{(x_i-\mu)^2}{2\sigma^2})\\<br/>
\]<br/>
所以联合概率密度为：<br/>
\[<br/>
\begin{align*}<br/>
h(x,\mu) &amp;= p(x|\mu)\pi(\mu) = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(\sum_i^n -\frac{(x_i-\mu)^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(-\sum_i^n \frac{x_i^2-2\mu x_i + \mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(- \frac{\sum_i^n x_i^2-2 \sum_i^n \mu x_i + \sum_i^n \mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(- \frac{\sum_i^n x_i^2-2 n \mu \overline x + n\mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp;=  (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(-(\frac{n}{2\sigma^2}+\frac{1}{2\tau^2})\mu^2  + (\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2})\mu - (\frac{\sum_i^n x_i^2}{2\sigma^2}+\frac{\theta^2}{2\tau^2}))\\<br/>
\end{align*}<br/>
\]<br/>
其中 \(\overline x = \frac{1}{n} \sum_i^n x_i\)。若令\(k = \frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau}\)，\(A = (\frac{n}{\sigma^2}+\frac{1}{\tau^2})\)，所以 \(A&gt;0\)，\(B = (\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2})\)，\(C = (\frac{\sum_i^n x_i^2}{\sigma^2}+\frac{\theta^2}{\tau^2})\)，则：<br/>
\[<br/>
\begin{align*}<br/>
h(x,\mu) &amp;= k\cdot \exp[-\frac{1}{2}(A\mu^2-2B\mu+C)] \\<br/>
&amp;= k\cdot \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})]\nonumber\\<br/>
\end{align*}<br/>
\]</p>

<p>由于参数空间 \(\mu\) 是连续的，所以边缘分布 \(m(x)\)为：<br/>
\[<br/>
\begin{align}<br/>
m(x) &amp;= \int_\mu\prod_{i=1}^n  p(x_i,\mu)\pi(\mu)d\mu = \int_\mu h(x,\mu) d\mu\nonumber\\<br/>
&amp;=k\cdot \int_\mu \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})] d\mu\nonumber\\<br/>
&amp;=k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})]\int_\mu \exp([-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu\label{mx}\\<br/>
\end{align}<br/>
\]</p>

<p>我们先来求解这个式子<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu \label{yiim}<br/>
\end{equation}<br/>
\]<br/>
用 \(\nu\) 替换其中的 \(\mu\) 得：<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\nu \label{yiin}<br/>
\end{equation}<br/>
\]<br/>
用式\ref{yiim}和式\ref{yiin}相乘得：<br/>
\[<br/>
\begin{align*}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu \int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\nu &amp;= \int\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\mu d\nu \\<br/>
&amp;= \int\int_{-\infty}^{\infty} \exp\{-\frac{A}{2} [(\mu-\frac{B}{A})^2+(\nu-\frac{B}{A})^2]\}d\mu d\nu<br/>
\end{align*}<br/>
\]<br/>
令\(\mu-\frac{B}{A} = r\cos\alpha\)，\(\nu-\frac{B}{A} = r\sin\alpha\)，其中\(\alpha\in[0,2\pi]，r\in[0,\infty]\)，为方便计算令\(f^2\)等于等式左边：<br/>
\[<br/>
\begin{align*}<br/>
f^2 &amp;= \int_{0}^{\infty}\int_{0}^{2\pi} \exp\{-\frac{A}{2} [(r\cos\alpha)^2+(r\sin\alpha)^2]\}r dr d\alpha\\<br/>
&amp;= \int_{0}^{\infty}\int_{0}^{2\pi} \exp(-\frac{A}{2}r^2)r dr d\alpha\\<br/>
&amp;= \int_{0}^{\infty}\exp(-\frac{A}{2}r^2)r\int_0^{2\pi} d\alpha\\<br/>
&amp;= 2\pi \int_0^\infty \exp(-\frac{A}{2}r^2)rdr\\<br/>
&amp;= 2\pi \cdot [-\frac{1}{A} \exp(-\frac{A}{2}r^2) ]^\infty_0\\<br/>
\end{align*}<br/>
\]<br/>
由前面定义\(A = (\frac{n}{\sigma^2}+\frac{1}{\tau^2})\)，显然 \(A&gt;0\)，所以：<br/>
\[<br/>
f^2 =2\pi \cdot [-\frac{1}{A} \exp(-\frac{A}{2}r^2) ]^\infty_0 = 2\pi \frac{1}{A} [\exp(0)-\exp(-\infty)] = \frac{2\pi}{A}\\<br/>
\Rightarrow f = (\frac{2\pi}{A})^{1/2}<br/>
\]</p>

<p>将上述结果带入式\ref{mx}，可知：<br/>
\[<br/>
\begin{align*}<br/>
m(x) &amp;= k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})]\int_\mu \exp([-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu \\<br/>
&amp;= k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})] (\frac{2\pi}{A})^{1/2}<br/>
\end{align*}<br/>
\]<br/>
由后验公式（\ref{lx}）可得：<br/>
\[<br/>
\begin{align*}<br/>
p(\mu|x) &amp;= \frac{\pi(\mu)\prod_{i=1}^n p(x_i|\mu)}{\int_\mu\prod_{i=1}^n  p(x_i,\mu)\pi(\mu)d\mu} = \frac{h(x,\mu)}{m(x)} = \frac{k\cdot \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})]}{k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})] (\frac{2\pi}{A})^{1/2}} \\<br/>
&amp;= (\frac{A}{2\pi})^{1/2} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2]\\<br/>
&amp;= \frac{1}{2\pi\sqrt{1/A}} \exp[-\frac{(\mu - \frac{B}{A})^2}{2/A}]<br/>
\end{align*}<br/>
\]<br/>
对比高斯分布可知\(p(\mu|x)\sim N(B/A,1/A)\)，即：<br/>
\[<br/>
p(\mu|x) \sim N(\frac{\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2}}{\frac{n}{\sigma^2}+\frac{1}{\tau^2}},\frac 1{\frac{n}{\sigma^2}+\frac{1}{\tau^2}}) = N(\frac{n\tau^2\overline x+\theta\sigma^2}{n\tau^2+\sigma^2},\frac{\tau^2\sigma^2}{n\tau^2+\sigma^2})<br/>
\]</p>

<p>后验均值即为贝叶斯估计：<br/>
\[<br/>
\hat u = \frac{n\tau^2\overline x+\theta\sigma^2}{n\tau^2+\sigma^2}<br/>
\]</p>

<h4 id="toc_9">共轭分布法</h4>

<p>我们前面再二项分布时说如果一个没有任何先验知识的分布可以看作为“等同无知”，采用均匀分布U(0,1)作为先验分布，这里均匀分布也可以看作是贝塔分布 \(\text{Beta}(1,1)\)，所以二项分布 \(\text{B}(n,\theta)\) 的先验分布为 \(\text{Beta}(1,1)\) 时，后验分布为 \(\text{Beta}(k+1,n-k+1)\) ，其中k表示n次独立试验中正例出现的次数。这种先验分布和后验分布属于同一个分布类型的现象并不是偶然的，在上文的高斯分布也证明了这一点，先验分布是高斯分布，后验分布也是高斯分布。</p>

<p>共轭分布法就是指<strong>先验分布和后验分布属于同一个分布类型</strong>。</p>

<h4 id="toc_10">贝叶斯估计举例</h4>

<p>这个举个例子，为了提高某产品质量，某部门经理希望引入不同厂家生产的一种设备，两厂家招标时称：<br/>
<font color='#666'>1）使用厂家一设备生产后，高质量产品将占90%；</font><br/>
<font color='#666'>2）使用厂家二设备生产后，高质量产品将占70%；</font><br/>
部门经理根据以往两厂家的用户评价，认为厂家一的可信度为40%，厂家二的可信度为60%。</p>

<p>首先来数学化这些数字，将厂家一、厂家二认为是两个不同的参数\(\theta_1\)，\(\theta_2\)，那么可知 \(p(\theta_1) = 40\%;p(\theta_2) = 60\%\)，将生产高质量产品看作概率分布 \(p(x,\theta)\)，可知\(p(x,\theta_1) = 90\%\)，\(p(x,\theta_2)=70\%\)。</p>

<p>部门经理为此做了小型试验，第一次实验分别使用两厂家的设备进行生产，生产5件产品，都是高质量产品，记第一次实验为事件A，高质量产品记为1，否则为0，则：<br/>
\[<br/>
A|\theta_1 = (1,1,1,1,1)\\<br/>
A|\theta_2 = (1,1,1,1,1)<br/>
\]<br/>
第二次实验，再生产5件产品，使用设备一都是高质量产品，使用设备二4件高质量产品，记第二次实验为事件B，则：<br/>
\[<br/>
B|\theta_1 = (1,1,1,1,1)\\<br/>
B|\theta_2 = (1,1,1,1,0)\\<br/>
\]<br/>
我们利用事件A使用离散性后验分布概率：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta_1|A) &amp;= p(\theta_1|x_1,x_2,...,x_n) = \frac{p(\theta_1)\prod_{i=1}^n p(x_i|\theta_1)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} \\<br/>
&amp;= \frac{0.9^5*0.4}{0.4*0.9^5+0.6*0.7^5} = \frac{0.236}{0.236 + 0.101} = 0.700\\<br/>
p(\theta_2|A) &amp;= p(\theta_2|x_1,x_2,...,x_n) = \frac{p(\theta_2)\prod_{i=1}^n p(x_i|\theta_2)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} =0.300<br/>
\end{align*}<br/>
\]</p>

<p>通过实验一（事件A）更新了我们对厂家的可信度，计算得厂家一的可信度为0.7，厂家二的可信度为0.3，再来看第二次实验（事件B）计算可信度：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta_1|A) &amp;= p(\theta_1|x_1,x_2,...,x_n) = \frac{p(\theta_1)\prod_{i=1}^n p(x_i|\theta_1)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} \\<br/>
&amp;= \frac{0.9^5*0.7}{0.7*0.9^5+0.3*0.7^4*0.3} = \frac{0.413}{0.413+0.022} = 0.949\\<br/>
p(\theta_2|A) &amp;= p(\theta_2|x_1,x_2,...,x_n) = \frac{p(\theta_2)\prod_{i=1}^n p(x_i|\theta_2)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} = 0.051\\<br/>
\end{align*}<br/>
\]</p>

<p>通过实验二（事件B）计算已经可以得出厂家一的可信度为0.949，所以我们很有理由可以选择采进此设备。</p>

<p><strong>关于贝叶斯的知识还有很多，以后遇见再继续讨论~</strong></p>

<p><font color="#666"></p>

<p>我们来求解这个式子的另一种方法（只解出了一半，如果有人可以继续解下去，希望能联系我）<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu<br/>
\end{equation}<br/>
\]</p>

<p>这个函数的定积分不容易直接求得，我们先看一下伽马函数 \(\Gamma(s)\) ，定义如下：<br/>
\[<br/>
\begin{equation}<br/>
\Gamma(s) = \int_0^\infty e^{-x} x^{s-1} dx\qquad (s&gt;0) \label{Gamma}<br/>
\end{equation}<br/>
\]<br/>
由余元公式可知：<br/>
\[<br/>
\Gamma(s)\Gamma(1-s) = \frac{\pi}{\sin\pi s} \qquad (0\lt s \lt 1)<br/>
\]<br/>
所以：<br/>
\[<br/>
\Gamma(\frac1 2) = \sqrt{\pi}<br/>
\]</p>

<p>对\ref{Gamma}式利用定积分换元法，\(A&gt;0\) 情况下，令 \(x = \frac{A}{2}(\mu-\frac{B}{A})^2\)，则：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad dx = A(\mu-\frac{B}{A})d\mu\\<br/>
&amp;\therefore\quad \Gamma(s) = \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] [\frac{A}{2}(\mu-\frac{B}{A})^2]^{s-1} [A (\mu-\frac{B}{A})]d\mu \\<br/>
&amp;\qquad\qquad = \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] (\frac{A}{2})^{s-1}\cdot (\mu-\frac{B}{A})^{2s-1}\cdot Ad\mu \\<br/>
\end{align*}<br/>
\]<br/>
令 \(s=\frac 1 2\)：<br/>
\[<br/>
\begin{align}<br/>
\Gamma(\frac 1 2) &amp;= \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] (\frac{A}{2})^{-1/2}\cdot (\mu-\frac{B}{A})^0\cdot Ad\mu\nonumber\\<br/>
&amp;= \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2](2A)^{1/2} d\mu = \sqrt{\pi}\nonumber\\<br/>
&amp;\Rightarrow \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu = (\frac{\pi}{2A})^{1/2}\label{G0I}<br/>
\end{align}<br/>
\]<br/>
关于<br/>
\[<br/>
\begin{align}<br/>
\int_{-\infty}^0 \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu\label{GI0}<br/>
\end{align}<br/>
\]<br/>
怎么解，还没有一个好的方法，希望以后能解决。</p>

<p></font></p>

<hr/>

<p>[1] &nbsp;&nbsp;<a href="https://cosx.org/2013/01/lda-math-gamma-function">神奇的 Gamma 函数</a><br/>
[2] &nbsp;&nbsp;<a href="https://blog.csdn.net/u010945683/article/details/48950063">贝塔与伽马分布</a><br/>
[3] &nbsp;&nbsp;<a href="https://mp.weixin.qq.com/s/ZEoxYPgenFgzHuNnI2IieQ">贝塔分布生动的棒球例子</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15042890159558.html">随机领域嵌入算法 SNE</a></h1>
			<p class="meta"><time datetime="2017-09-02T02:03:35+08:00" 
			pubdate data-updated="true">2017/9/2</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>SNE算法，英文全称是stochastic neighbor embedding，它是将高维向量或成对的不相似度描述的对象“嵌入（Embed）”到低维空间中，并保持对象邻居间的特性。SNE将高维或低维空间的点都看做高斯分布，在这个高斯分布下的密度，用来定义对象所有潜在邻居点的概率分布。SNE属于一种流行学习的降维方法，首先我们介绍一下流行学习。</p>

<h3 id="toc_0">前置知识</h3>

<h4 id="toc_1">流形学习</h4>

<p>关于“流形”两个字一直不好理解，如果按照字面意思翻译，那么“manifold”翻译成“多样体”的意思。看到一篇论文上说到，中国第一个拓扑学家江泽涵（北大老教授）把这个词翻译为 “流形”，取自文天祥《正气歌》，“天地有正气，杂然赋流形”，而其原始出处为《易经》，“大哉乾元，万物资始，乃统天。云行雨施，品物流形。” 这个翻 译比英文翻译更加符合黎曼的原意，即多样化的形体。黎曼定义的“n 维流形”大概是这个样子的：以其中一个点为基准，则周围每个点的位置都可以用 n 个实数来确定，比如圆形如果用极坐标表示以圆心作为基点，那么只需要一个实数（坐标）就可以确定，所以称圆形为一维流形，再比如如果是一个圆球，假设为地球，那么如果以某个点为基点，作经纬线，那么只需要两个个实数（经度值、纬度值）便能确定其他点，可以称圆球为二维流形。</p>

<p>在流形空间里，存在一些性质：（1）流形空间中，过任意两点都不存在平行线，即任意两线都会相交，这个性质很容易在球面上看出来，球面上任意两线都会相交。（2）流形空间里，三角形的内角和不一定等于180度，也容易在一个球面上看出来。（3）总有一点是风平浪静的，如果放到一维流形中便是极坐标远点，如果在二维流形中便是极点了。</p>

<p>那么什么样的空间是流形空间呢？一个直观的感受是在空间内任意一个足够小的区域内，可以近似为欧式空间，这样的空间就是流形空间。比如圆球上任意一个足够小的区域，都可以看做欧式空间，可以找到平行线，三角形内角和为180度，所以认为圆球是流形空间。而假设圆球上竖起了一个直杆，假设直杆可以看做一条线，那么它将不能被看做是一个流形空间了，因为考虑到这个直杆所在的微小区域无法描述为欧式空间。</p>

<p>流形学习的英文名称叫做manifold Learning，是机器学习、模式识别中的一种方法，其主要思想是把一个高维的数据非线性映射到低维，该低维数据能够反映高维数据的本质，当然有一个前提假设就是高维观察数据存在流形结构，其优点是非参数，非线性，求解过程简单。</p>

<p>总体上来说这里关于流形的介绍不够严谨科学，仅是作为我对流形的初步理解，推荐几篇比较好的文章：<a href="http://blog.pluskid.org/?p=533">浅谈流形学习</a>，<a href="http://www.cad.zju.edu.cn/reports/%C1%F7%D0%CE%D1%A7%CF%B0.pdf">浙大流形学习PPT</a></p>

<h3 id="toc_2">SNE基本原理</h3>

<p>SNE是由Geoffrey Hinton 和 Sam Roweis在2012年提出的算法，原始论文看<a href="https://www.cs.toronto.edu/%7Ehinton/absps/sne.pdf">这里</a>，论文提出了用邻居点概率分布的方式来将高维空间点映射到低维空间。</p>

<h4 id="toc_3">SNE原理推导</h4>

<p>对于每一个对象 \(i\) ，和它潜在的邻居点 \(j\) ,我们来计算它们之间的非对称概率 \(p_{j|i}\) ，即 \(i\) 选择 \(j\) 作为邻居的概率：<br/>
\[<br/>
p_{j|i} = \frac{\exp(-{d_{i|j}}^2)}{\sum_{k\neq i}\exp(-{d_{i,k}}^2)}<br/>
\]<br/>
其中不相似度\({d_{i|j}}^2\)可以是问题定义时给定的（不需要是对称的）也可以能是两个高维点 \(x_i\) 和 \(x_j\) 通过缩放的平方欧几里得距离计算得到的：<br/>
\[<br/>
{d_{j|i}}^2 = \frac{||x_i - x_j||^2}{2\sigma_i^2}<br/>
\]<br/>
这里的 \(\sigma_i\) 可以手动设置或者（在我们的经验里）通过二分搜索法找到使邻居分布的熵等于 \(\log(k)\) 的 \(\sigma_i\)值，其中这里 \(k\) 是附近有效邻居点个数或者我们手动设置的困惑度（perplexity）。原文中的这段话比较拗口，简单来说就是我们可以先手动选取一个困惑度（proplexity）通常选取的依据是点 \(i\) 附近有效邻居点的个数，SNE对困惑度的调整比较有鲁棒性，通常选择5-50之间，假设这个值为 \(k\) 。由概率分布中困惑度通常写作：<br/>
\[<br/>
\text{Perplexity}(P_i) = b^{H(P_i)}<br/>
\]<br/>
通常这里的b取2，其中\(H(P_i)\)表示 \(P_i\)的熵：<br/>
\[<br/>
H(P_i) = -\sum_j p_{j|i}\log_2(p_{j|i})<br/>
\]<br/>
所以可得\(\log_2(\text{Perplexity}(P_i))\) 等于 \(P_i\)的熵，即 \(\log_2(k) = H(P_i)\)，而我们需要做的就是通过二分法找到合适的 \(\sigma_i\) 使这个等式成立。</p>

<p>而在低维空间中我们也用高斯邻居，但是使用一个固定的方差（这里我们不失一般性的设置为 \(\sigma_i^2=\frac{1}{2}\) ），因此低维空间点 \(i\) 选择点 \(j\) 作为它的邻居的概率 \(q_{i|j}\) 是关于低维图像中对象 \(y_i\) 的函数，通过下面的表达式给出：<br/>
\[<br/>
\begin{equation}<br/>
q_{j|i} = \frac{\exp(-||y_i - y_j||^2)}{\sum_{k\neq i}\exp(-||y_i - y_k||^2)} \\\label{q_j_i}<br/>
\end{equation}<br/>
\]</p>

<p>嵌入的目的是使这两个分布尽可能的匹配。我们可以用最小化原始概率 \(p_{ij}\) 和归纳概率 \(q_{ij}\) 之间的KL散度（Kullback-Leibler divergences）之和作为损失函数，并通过最小化这个损失函数来达到目的：<br/>
\[<br/>
C = \sum_i \sum_j p_{j|i}\log\frac{p_{j|i}}{q_{j|i}} = \sum_{i} KL(P_i || Q_i)<br/>
\]</p>

<p>这里 \(y\) 空间（即降维后空间）的维度也是手动选择的（远小于对象的个数），由于KL散度具有不对称性,在低维映射中不同的距离对应的惩罚权重是不同的，直观上来看SNE强调局部距离，它的损失函数倾向使对象附近的图像靠近，使对象分离的图像相对较远。具体来说：距离较远的两个点来表达距离较近的两个点会产生更大的cost，相反，用较近的两个点来表达较远的两个点产生的cost相对较小。</p>

<p>代价函数C对 \(y_i\) 求导可得：<br/>
\[<br/>
\frac{\partial C}{\partial y_i} = \sum_j 2(y_i-y_j)(p_{i|j} - q_{i|j} + p_{j|i} -q_{j|i} )<br/>
\]<br/>
具体推导过程如下：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= \frac{\partial \sum_i \sum_j p_{j|i} \log(p_{j|i}/q_{j|i})}{\partial q_{j|i}} \cdot \frac{\partial q_{j|i}}{\partial y_i} \\<br/>
&amp;= -\sum_i\sum_j \frac{p_{j|i}}{q_{j|i}} \frac{\partial q_{j|i}}{\partial y_i}\\<br/>
&amp;= -\sum_m\sum_n \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{i|m}}{q_{i|m}} \frac{\partial q_{i|m}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{n|i}}{q_{n|i}} \frac{\partial q_{n|i}}{\partial y_i}\\<br/>
\end{align*}<br/>
\]</p>

<p>先看第一项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i} &amp;=  -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial \big[{\exp(-||y_m-y_n||^2)}/{\sum_{k\neq m} \exp(-||y_k-y_m||^2)}\big]}{\partial y_i} \\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i}\frac{\exp(-||y_m-y_n||^2)\exp(-||y_i-y_m||^2)(-2y_i+2y_m)}{(\sum_{k\neq m} \exp(-||y_k -y_m||^2))^2} \\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{n|m} \frac{\exp(-||y_i-y_m||^2)(-2y_i+2y_m)}{\sum_{k\neq m} \exp(-||y_k -y_m||^2)} \\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{n|m} q_{i|m}(2y_m-2y_i)\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第二项：</p>

<p>\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n=i}  \frac{p_{i|m}}{q_{i|m}} \frac{\partial q_{i|m}}{\partial y_i} &amp;= -\sum_{m\neq i}\frac{p_{i|m}}{q_{i|m}} \frac{\partial \big[{\exp(-||y_m-y_i||^2)}/{\sum_{k\neq m} \exp(-||y_k-y_m||^2)}\big]}{\partial y_i} \\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{i|m}}{q_{i|m}} \bigg(\frac{\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{\sum_{k\neq m} \exp(-||y_k-y_m||^2)}-\frac{\exp(-||y_m-y_i||^2)\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{(\sum_{k\neq m} \exp(-||y_k-y_m||^2))^2} \bigg)\\<br/>
&amp;= -\sum_{m\neq i} \frac{p_{i|m}}{q_{i|m}} \bigg(q_{i|m} (2y_m-2y_i)-q_{i|m}\frac{\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{\sum_{k\neq m} \exp(-||y_k-y_m||^2)} \bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{i|m}} \bigg((2y_m-2y_i)-\frac{\exp(-||y_i-y_m||^2)(2y_m-2y_i)}{\sum_{k\neq m} \exp(-||y_k-y_m||^2)} \bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{i|m}} \bigg((2y_m-2y_i)-{q_{i|m}(2y_m-2y_i)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} p_{i|m}(2y_m-2y_i) + \sum_{m\neq i}p_{i|m} q_{i|m}(2y_m-2y_i)\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第三项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{n|i}}{q_{n|i}} \frac{\partial q_{n|i}}{\partial y_i} &amp;= -\sum_{n\neq i}\frac{p_{n|i}}{q_{n|i}} \frac{\partial \big[{\exp(-||y_n-y_i||^2)}/{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}\big]}{\partial y_i} \\<br/>
&amp;= -\sum_{n\neq i}  \frac{p_{n|i}}{q_{n|i}} \bigg(\frac{\exp(-||y_n-y_i||^2)(2y_n-2y_i)}{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}-\frac{\exp(-||y_n-y_i||^2)(\sum_{k\neq i} \exp(-||y_k-y_i||^2)(2y_k-2y_i))}{(\sum_{k\neq i} \exp(-||y_k-y_i||^2))^2}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  \frac{p_{n|i}}{q_{n|i}} \bigg({q_{n|i}(2y_n-2y_i)}-\frac{q_{n|i}(\sum_{k\neq i} \exp(-||y_k-y_i||^2)(2y_k-2y_i))}{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  p_{n|i}\bigg({(2y_n-2y_i)}-\frac{\sum_{k\neq i} \exp(-||y_k-y_i||^2)(2y_k-2y_i)}{\sum_{k\neq i} \exp(-||y_k-y_i||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  p_{n|i}\bigg({(2y_n-2y_i)}-\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\bigg)\\<br/>
&amp;= -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{n\neq i}  p_{n|i}\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\\<br/>
\end{align*}<br/>
\]</p>

<p>将上面三式代入，其中\(p_{i|i} = 0\)：<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial C}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{n|m}}{q_{n|m}} \frac{\partial q_{n|m}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{i|m}}{q_{i|m}} \frac{\partial q_{i|m}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{n|i}}{q_{n|i}} \frac{\partial q_{n|i}}{\partial y_i}\nonumber\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{n|m} q_{i|m}(2y_m-2y_i) - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) + \sum_{m\neq i}p_{i|m} q_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{n\neq i}  p_{n|i}\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\nonumber\\<br/>
&amp;= \sum_{m\neq i}\sum_{n} p_{n|m} q_{i|m}(2y_m-2y_i) - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{n\neq i}  p_{n|i}\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\nonumber\\<br/>
&amp;= \sum_{m\neq i}q_{i|m}(2y_m-2y_i) \sum_{n} p_{n|m} - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\sum_{n\neq i}  p_{n|i}\label{ttd}\\<br/>
\end{align}<br/>
\]</p>

<p>考虑到：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\sum_{n\neq i} p_{n|i} = \sum_{n\neq i} \frac{\exp(-{||x_i - x_n||^2}/{2\sigma_i^2})}{\sum_{k\neq i}\exp(-{||x_i - x_k||^2}/{2\sigma_i^2})} = \frac{\sum_{n\neq i}\exp(-{||x_i - x_n||^2}/{2\sigma_i^2})}{\sum_{k\neq i}\exp(-{||x_i - x_k||^2}/{2\sigma_i^2})} = 1\\<br/>
&amp;\sum_n p_{n|i} = \sum_{n\neq i} p_{n|i}  + p_{i|i} = 1 <br/>
\end{align*}<br/>
\]</p>

<p>上结论代入 \ref{ttd} 可得：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;=\sum_{m\neq i}q_{i|m}(2y_m-2y_i) - \sum_{m\neq i}p_{i|m}(2y_m-2y_i) -\sum_{n\neq i}  p_{n|i} (2y_n-2y_i)+\sum_{k\neq i} q_{k|i}(2y_k-2y_i)\\<br/>
&amp;=\sum_{j\neq i}q_{i|j}(2y_j-2y_i) - \sum_{j\neq i}p_{i|j}(2y_j-2y_i) -\sum_{j\neq i}  p_{j|i} (2y_j-2y_i)+\sum_{j\neq i} q_{j|i}(2y_j-2y_i)\\<br/>
&amp;=\sum_{j\neq i}2(y_i-y_j)(p_{i|j} - q_{i|j} + p_{j|i} - q_{j|i})\\<br/>
&amp;=\sum_{j}2(y_i-y_j)(p_{i|j} - q_{i|j} + p_{j|i} - q_{j|i})\\<br/>
\end{align*}<br/>
\]</p>

<p>推导结束。</p>

<p>初始化时，可以以原点为中心选择较小的 \(\sigma\) 的高斯分布。为了避免陷入局部最优解，梯度中还需要一个相对较大的动量 momentum。即参数更新中除了当前梯度，还要引入之前梯度累加的指数衰减项，如下：<br/>
\[<br/>
Y^{(t)} = Y^{(t-1)} + \eta \frac{\partial C}{\partial Y} + \alpha^{(t)}(Y^{(t-1)} - Y^{(t-2)})<br/>
\]</p>

<p>这里 \(Y^{(t)}\) 表示迭代 \(t\) 次的解，\(\eta\) 表示学习速率，\(\alpha^{(t)}\) 表示迭代 \(t\) 次的动量。</p>

<p>此外，在优化的早期阶段，在每一轮迭代后向映射点中间加入一些高斯噪声，之后像模拟退火一样逐渐减小该噪声的方差，可以用来避免局部最优解。如果噪声的方差在全局结构开始形成临界点处改变非常慢，SNE 倾向于找到更好的全局结构的映射。不幸的是，这需要明智的选择一个高斯噪声的初始值和衰减速率，进一步来说，这个选择与动量大小及梯度下降中步长大小相互作用。因此通常在数据集上多次进行优化来寻找一个合适的参数。从这个角度来说，SNE 不如一些允许凸优化和不用引入模拟退火花费额外的计算时间和参数选择，就能给出很好的结果的优化方法。</p>

<h3 id="toc_4">T-SNE(t-Distributed Stochastic Neighbor Embedding)</h3>

<p>上一节介绍了 2002 年 Hinton 和 Roweis 提出的 SNE ，尽管 SNE 构造了相当好的可视化，但是它被难以优化的损失函数所束缚，我们把这个问题称为“crowding（拥挤）问题”。在这一小节中，我们将介绍一个新技术“T-SNE”来缓解这个问题。t-SNE 的损失函数和 SNE 的损失函数在两个地方有点不同：</p>

<ol>
<li>使个对称版本的 SNE ，其损失函数有着更简单的梯度。</li>
<li>使用 t 分布代替了高斯分布来计算在低维空间两个点的相似度。</li>
</ol>

<p>t-SNE 在低维空间使用一个重尾分布来避免 SNE 的拥挤问题和优化问题。在这一小节中，我们首先来介绍一下对称 SNE ，然后再来介绍拥挤问题，和使用重尾分布来处理这个问题。我们最后来介绍我们的方法来优化 t-SNE 损失函数。</p>

<h4 id="toc_5">对称 SNE（Symmetric SNE）</h4>

<p>对称 SNE 可以作为优化条件概率 \(p_{j|i}\) 和 \(p_{i|j}\) 的 KL 散度之和一个替代方案，还可以最小化高维空间中的联合概率分布 \(P\) 和低维空间的联合分布概率 \(Q\) 的单个 KL 散度：<br/>
\[<br/>
C = KL(P||Q) = \sum_{i} \sum_{j} p_{ij} \log \frac{p_{ij}}{q_{ij}}<br/>
\]</p>

<p>这里我们还是将 \(p_{ii}\) 和 \(q_{ii}\) 设为 0，我们称这种 SNE 叫做对称 SNE，因为联合概率分布有个特性 \(p_{ij} = p_{ji}\) 和 \(q_{ij} = q{ji}\)，在对称 SNE 中，低维空间映射的成对相似度 \(q_{ji}\) 可以表示为：<br/>
\[<br/>
\begin{equation}<br/>
q_{ij} = \frac{\exp(-||y_i-y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)} \label{qij}<br/>
\end{equation}<br/>
\]</p>

<p>显而易见定义在高维空间的成对相似度 \(p_{ij}\) 为：<br/>
\[<br/>
p_{ij} = \frac{\exp(-||x_i-x_j||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}<br/>
\]</p>

<p>但是考虑到高维数据点 \(x_i\) 是异常点时将产生问题（所有的点关于 \(x_i\) 的成对距离 \(||x_i-x_j||^2\) 都很大）。对于这样的异常点，\(p_{ij}\) 对于所有的 \(j\) 都非常小（之前仅是在 \(x_i\) 下很小），因此低维空间映射点 \(y_i\) 位置对损失函数的影响会很小，结果就是映射点的位置不能很好的由其他映射点的位置确定。我们可以通过定义高维空间的联合概率 \(p_{ij}\) 为对称条件概率来回避这个问题，即：<br/>
\[<br/>
p_{ij} = \frac{p_{j|i} + p_{i|j}}{2n}<br/>
\]</p>

<p>这即保证了 \(p_{ij}\) 的对称性，且对于所有的数据点 \(x_i\) 都有 \(\sum_{j} p_{ij} &gt; \frac{1}{2n}\) ，使每一个点 \(x_i\) 对损失函数都有一定的贡献。在低维空间里，对称 SNE 简单的使用式 \ref{qij} 。对称 SNE 最大的优点是梯度的形式更简单，可以更快的计算。来计算一下梯度，对称 SNE 的梯度与不对称 SNE 相似，如下：<br/>
\[<br/>
\frac{\partial C}{\partial y_i} = 4\sum_{j} (p_{ij} - q_{ij})(y_i - y_j)<br/>
\]</p>

<p>详细推导过程如下：<br/>
\[<br/>
\begin{align}<br/>
\frac{\partial C}{\partial y_i} &amp;= \frac{\partial \sum_i \sum_j p_{ij} \log(p_{ij}/q_{ij})}{\partial q_{ij}} \cdot \frac{\partial q_{ij}}{\partial y_i} \nonumber\\<br/>
&amp;= -\sum_i\sum_j \frac{p_{ij}}{q_{ij}} \frac{\partial q_{ij}}{\partial y_i}\nonumber\\<br/>
&amp;= -\sum_m\sum_n \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}\nonumber\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\label{mnf}\\<br/>
\end{align}<br/>
\]</p>

<p>先看第一项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial \big[{\exp(-||y_m-y_n||^2)}/{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\big]}{\partial y_i}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\exp(-||y_m-y_n||^2)(\sum_{k \neq i,l=i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{k=i,l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2))}{(\sum_{k\neq l} \exp(-||y_k - y_l||^2))^2}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \frac{\sum_{j \neq i} 2(y_j-y_i) \exp(-||y_j - y_i||^2) - \sum_{j\neq i} 2(y_i - y_j)\exp(-||y_i - y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \frac{\sum_{j \neq i} 2(y_j-y_i-y_i+y_j) \exp(-||y_k - y_i||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij}\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第二项<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} &amp;=-\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \frac{\partial \big[{\exp(-||y_i-y_m||^2)}/{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\big]}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(\frac{-2(y_i-y_m)\exp(-||y_i-y_m||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}- \frac{\exp(-||y_i-y_m||^2)(\sum_{k \neq i,l=i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{k=i,l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2))}{(\sum_{k\neq l} \exp(-||y_k - y_l||^2))^2}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(-2q_{mi}(y_i-y_m) - q_{mi}\frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - \frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - \frac{\sum_{j \neq i} 2(y_j-y_i) \exp(-||y_j - y_i||^2) - \sum_{j\neq i} 2(y_i - y_j)\exp(-||y_i - y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - \frac{\sum_{j \neq i} 2(y_j-y_i-y_i + y_j) \exp(-||y_j - y_i||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}}\ \bigg(-2(y_i-y_m) - {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\bigg)\\<br/>
&amp;= 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + \sum_{m\neq i}{p_{mi}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第三项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i} &amp;=-\sum_{n\neq i}\frac{p_{in}}{q_{in}} \frac{\partial \big[{\exp(-||y_i-y_n||^2)}/{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\big]}{\partial y_i}\\<br/>
&amp;= -\sum_{n\neq i}\frac{p_{in}}{q_{in}} \bigg(\frac{-2(y_i-y_n)\exp(-||y_i-y_n||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}- \frac{\exp(-||y_i-y_n||^2)(\sum_{k \neq i,l=i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{k=i,l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2))}{(\sum_{k\neq l} \exp(-||y_k - y_l||^2))^2}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}\frac{p_{in}}{q_{in}} \bigg(-2q_{in}(y_i-y_n) - q_{in}\frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - \frac{\sum_{k \neq i} 2(y_k-y_i) \exp(-||y_k - y_i||^2) - \sum_{l\neq i} 2(y_i - y_l)\exp(-||y_i - y_l||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - \frac{\sum_{j \neq i} 2(y_j-y_i) \exp(-||y_j - y_i||^2) - \sum_{j\neq i} 2(y_i - y_j)\exp(-||y_i - y_j||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - \frac{\sum_{j \neq i} 2(y_j-y_i-y_i + y_j) \exp(-||y_j - y_i||^2)}{\sum_{k\neq l} \exp(-||y_k - y_l||^2)}\bigg)\\<br/>
&amp;= -\sum_{n\neq i}{p_{in}}\ \bigg(-2(y_i-y_n) - {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\bigg)\\<br/>
&amp;= 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n\neq i}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
\end{align*}<br/>
\]</p>

<p>代入式 \ref{mnf} 得：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}-\sum_{m\neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i}<br/>
-\sum_{m=i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + \sum_{m\neq i}{p_{mi}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}} + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n\neq i}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n\neq i}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
&amp;\because \quad p_{ii} = 0 \quad\Rightarrow\quad \sum_{n\neq i}p_{in} = \sum_{n}p_{in}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) + \sum_{n}{p_{in}} {\sum_{j \neq i} 4(y_j-y_i) q_{ij}}\\<br/>
&amp;= \sum_{m}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n) \\<br/>
\end{align*}<br/>
\]</p>

<p>考虑到：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{m} \sum_{n} p_{mn} &amp;= \sum_{m}\sum_{n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}\\<br/>
&amp;= \sum_{m\neq n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)} + \sum_{m=n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}\\<br/>
&amp;= \sum_{m\neq n} \frac{\exp(-||x_m-x_n||^2/2\sigma^2)}{\sum_{k \neq l} \exp(-||x_k - x_l||^2/2\sigma^2)}\\<br/>
&amp;= 1<br/>
\end{align*}<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= \sum_{m}\sum_{n} {p_{mn}} \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n)\\<br/>
&amp;= \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{m\neq i}{p_{mi}} (y_i-y_m) + 2\sum_{n\neq i}{p_{in}} (y_i-y_n)\\<br/>
&amp;= \sum_{j \neq i} 4(y_j-y_i) q_{ij} + 2\sum_{j\neq i}{p_{ij}} (y_i-y_j) + 2\sum_{j\neq i}{p_{ij}} (y_i-y_j)\\<br/>
&amp;= \sum_{j\neq i} 4(y_i-y_j)(p_{ij} - q_{ij})\\<br/>
&amp;= \sum_{j} 4(y_i-y_j)(p_{ij} - q_{ij})\\<br/>
\end{align*}<br/>
\]</p>

<p>推导结束。</p>

<p>在初步实验中，我们观察到对称 SNE 产生的映射和非对称 SNE 的一样好，有时候甚至会略好一点。</p>

<h4 id="toc_6">拥挤问题 crowding problem</h4>

<p>考虑一组嵌在高维空间里的二维曲线流形上的数据点，在小范围内可以近似于线形。它可以很好地在二维图上模拟数据点之间小的成对距离，这通常有个经典的“Swiss roll”的例子。现在设想一下一个具有10个维度的流形，它嵌在一个更高维的空间中。有几个原因导致在二维空间里的成对距离不能如实地模拟在10维空间里的数据点的距离。例如，在10维中可能有11个数据点之间的距离相等，在二维空间里无法得到可信的映射（二维空间最多就3个距离相等的点）。以数据点 \(i\) 为中心的球体体积是 \(r^m\) ，其中 \(r\) 是半径，\(m\) 是球体的维度，假设球体中数据点是均匀分布在 \(i\) 的周围的，看一下从 \(i\) 到其他点的距离随维度增加参生的变化：</p>

<p>代码如下：</p>

<pre><code class="language-python"># -*- coding: utf-8 -*-
import matplotlib.pyplot as plt
import numpy as np
from numpy.linalg import norm

npoints = 1000 # 抽取1000个m维球内均匀分布的点
plt.figure(figsize=(20, 4))
for i, m in enumerate((2, 3, 5, 10)):
    # 这里模拟m维球中的均匀分布用到了拒绝采样，即先生成m维立方中的均匀分布，再剔除m维球外部的点
    accepts = []
    while len(accepts) &lt; 1000:
        points = np.random.rand(500, m)
        accepts.extend([d for d in norm(points, axis=1) if d &lt;= 1.0]) # 拒绝采样
    accepts = accepts[:npoints]
    ax = plt.subplot(1, 4, i+1)
    ax.set_xlabel(&#39;distance&#39;) # x轴表示点到圆心的距离
    if i == 0:
        ax.set_ylabel(&#39;count&#39;) # y轴表示点的数量
    ax.hist(accepts, bins=np.linspace(0., 1., 50), color=&#39;green&#39;)
    ax.set_title(&#39;m={0}&#39;.format(str(m)), loc=&#39;left&#39;)
plt.show()
</code></pre>

<p>效果如下：</p>

<div align="center">
    <img width="700" src="media/15042890159558/15333754587813.jpg" />
</div>

<p>图中可以看出随着维度 \(m\) 的增大，大多数数据点都分布在球体的表面，与点 \(x_i\) 的距离分布极不平衡。如果将这种距离保留到低维空间中，肯定会出现拥挤问题。注意，拥挤问题并非只会出现在 SNE 中，实际上很多维度缩放技术上都会出现。</p>

<h4 id="toc_7">t 分布 Student-t distribution</h4>

<p>由于对称 SNE 实际上匹配高维空间和低维空间数据点的联合概率而不是它们的距离，因此我们有更自然的方式去缓解拥挤问题。在高维空间中，我们使用高斯分布将距离转换为概率，在低维映射中，我们使用比高斯分布更重尾部的 \(t\) 分布来转换距离为概率，这允许高维空间中低等距离在映射后有一个较大的距离。</p>

<p>假设 \(X\) 服从标准正态分布</p>

<p>在 t-SNE 中，我们使用有一个自由度的 t 分布(n=1)作为低维映射中的重尾分布，使用这个分布，联合概率分布 \(q_{ij}\) 可以被定义为：<br/>
\[<br/>
q_{ij} = \frac{(1+||y_i-y_j||^2)^{-1}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}<br/>
\]</p>

<p>此外，t分布是无限多个高斯分布的叠加，计算上不是指数的，会方便很多。优化的梯度如下：<br/>
\[<br/>
\frac{\partial C}{\partial y_i} = 4\sum_{j} (p_{ij}-q_{ij}) (y_i-y_j) (1+||y_i-y_j||^2)^{-1}<br/>
\]</p>

<p>推导过程如下：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= \frac{\partial \sum_{i} \sum_{j} p_{ij} \log (p_{ij} / q_{ij})}{\partial y_i} \\<br/>
&amp;= -\sum_{i}\sum_{j} \frac{p_{ij}}{q_{ij}} \frac{\partial q_{ij}}{\partial y_i}\\<br/>
&amp;= -\sum_{m}\sum_{m} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} - \sum_{m \neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} - \sum_{m=i}\sum_{n \neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\\<br/>
\end{align*}<br/>
\]</p>

<p>先看第一项：<br/>
\[<br/>
\begin{align*}<br/>
-\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial [(1+||y_m-y_n||^2)^{-1}]/[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]}{\partial y_i}\\<br/>
&amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{-(1+||y_m-y_n||^2)^{-1}[2\sum_{k\neq i}\sum_{l=i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k=i} \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}]}{[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]^2}\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{mn} \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2 \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\\ <br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{mn} \big[2\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} -2 \sum_{l\neq i} q_{li} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-1}\big]\\<br/>
&amp;= \sum_{m\neq i}\sum_{n\neq i} p_{mn} \big[2\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} -2 \sum_{k\neq i} q_{ki} (y_i - y_k)( 1+ ||y_i - y_k||^2)^{-1}\big]\\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n\neq i} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} \\<br/>
\end{align*}<br/>
\]</p>

<p>再看第二项：<br/>
\[<br/>
\begin{align*}<br/>
- \sum_{m \neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} &amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \frac{\partial [(1+||y_m-y_i||^2)^{-1}]/[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]}{\partial y_i}\\<br/>
&amp;=-\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(\frac{2(y_m-y_i)[(1+||y_m-y_i||^2)^{-2}]}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}} -\frac{(1+||y_m-y_i||^2)^{-1}[2\sum_{k\neq i}\sum_{l=i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k=i} \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}]}{[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]^2}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}\frac{p_{mi}}{q_{mi}} \bigg(2 q_{mi} (y_m-y_i)(1+||y_m-y_i||^2)^{-1}- q_{mi} \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k\neq i} (y_i - y_k)( 1+ ||y_i - y_k||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i} {p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- \frac{4\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{m\neq i}{p_{mi}} \bigg(2(y_m-y_i)(1+||y_m-y_i||^2)^{-1}- {4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\bigg)\\<br/>
&amp;= -2\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} + 4\sum_{m\neq i}\sum_{n=i} {p_{mi}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
\end{align*}<br/>
\]</p>

<p>再看第三项：<br/>
\[<br/>
\begin{align*}<br/>
- \sum_{m= i}\sum_{n\neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i} &amp;= -\sum_{n\neq } \frac{p_{in}}{q_{in}} \frac{\partial [(1+||y_n-y_i||^2)^{-1}]/[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]}{\partial y_i}\\<br/>
&amp;=-\sum_{n\neq i} \frac{p_{in}}{q_{in}} \bigg(\frac{2(y_n-y_i)[(1+||y_n-y_i||^2)^{-2}]}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}} -\frac{(1+||y_n-y_i||^2)^{-1}[2\sum_{k\neq i}\sum_{l=i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k=i} \sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}]}{[\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}]^2}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} \frac{p_{in}}{q_{in}} \bigg(2 q_{in} (y_n-y_i)(1+||y_n-y_i||^2)^{-1}- q_{in} \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{l\neq i} (y_i - y_l)( 1+ ||y_i - y_l||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- \frac{2\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2} - 2\sum_{k\neq i} (y_i - y_k)( 1+ ||y_i - y_k||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- \frac{4\sum_{k\neq i} (y_k-y_i) (1+||y_k-y_i||^2)^{-2}}{\sum_{k\neq l} (1+||y_k-y_l||^2)^{-1}}\bigg)\\<br/>
&amp;= -\sum_{n\neq i} {p_{in}} \bigg(2(y_n-y_i)(1+||y_n-y_i||^2)^{-1}- {4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\bigg)\\<br/>
&amp;= -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n\neq i}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
\end{align*}<br/>
\]</p>

<p>三项相加，所以：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= -\sum_{m\neq i}\sum_{n\neq i} \frac{p_{mn}}{q_{mn}} \frac{\partial q_{mn}}{\partial y_i} - \sum_{m \neq i}\sum_{n=i} \frac{p_{mi}}{q_{mi}} \frac{\partial q_{mi}}{\partial y_i} - \sum_{m=i}\sum_{n \neq i} \frac{p_{in}}{q_{in}} \frac{\partial q_{in}}{\partial y_i}\\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n\neq i} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} + 4\sum_{m\neq i}{p_{mi}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n\neq i}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n\neq i}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
&amp;\because \quad p_{ii} = 0 \quad\Rightarrow\quad \sum_{n\neq i}{p_{in}}  = \sum_{n}{p_{in}} \\<br/>
&amp;= 4\sum_{m\neq i}\sum_{n} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} + 4\sum_{n}{p_{in}} {\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}}\\<br/>
&amp;= 4\sum_{m}\sum_{n} p_{mn} \sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1}  -2\sum_{m\neq i}\sum_{n=i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} -2\sum_{n\neq i} {p_{in}} (y_n-y_i)(1+||y_n-y_i||^2)^{-1} \\<br/>
&amp;= 4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} \sum_{m}\sum_{n} p_{mn}  -4\sum_{m\neq i}\sum_{n=i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} \\<br/>
\end{align*}<br/>
\]</p>

<p>考虑到（证明如对称 SNE）：<br/>
\[<br/>
\sum_m \sum_n p_{mn} = 1<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial C}{\partial y_i} &amp;= 4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} \sum_{m}\sum_{n} p_{mn}  -4\sum_{m\neq i} {p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} \\<br/>
&amp;= 4\sum_{k\neq i} q_{ki} (y_k-y_i) (1+||y_k-y_i||^2)^{-1} -4\sum_{m\neq i}{p_{mi}} (y_m-y_i)(1+||y_m-y_i||^2)^{-1} \\<br/>
&amp;= 4\sum_{j\neq i} q_{ij} (y_j-y_i) (1+||y_i-y_j||^2)^{-1} -4\sum_{j\neq i}{p_{ij}} (y_j-y_i)(1+||y_i-y_j||^2)^{-1} \\<br/>
&amp;= 4\sum_{j\neq i} (p_{ij}  - q_{ij})(y_i-y_j)(1+||y_i-y_j||^2)^{-1} \\<br/>
\end{align*}<br/>
\]</p>

<p>推导结束。</p>

<p>t-sne的有效性，也可以从上图中看到：横轴表示距离，纵轴表示相似度, 可以看到，对于较大相似度的点，t分布在低维空间中的距离需要稍小一点；而对于低相似度的点，t分布在低维空间中的距离需要更远。这恰好满足了我们的需求，即同一簇内的点(距离较近)聚合的更紧密，不同簇之间的点(距离较远)更加疏远。</p>

<p>总结一下，t-SNE的梯度更新有两大优势：</p>

<ol>
<li>对于不相似的点，用一个较小的距离会产生较大的梯度来让这些点排斥开来。</li>
<li>这种排斥又不会无限大(梯度中分母)，避免不相似的点距离太远。</li>
</ol>

<h3 id="toc_8">算法步骤</h3>

<p><b>输入</b>：数据集 \(\mathcal X = \{x_1,x_2,...,x_n\}\)，困惑度 \(\text{Perplexity}\)，迭代次数 \(T\) ，学习速率 \(\eta\) ，动量 \(\alpha^{(t)}\)<br/>
<b>输出</b>：在低维空间的表现 \(\mathcal Y= \{y_1,y_2,...,y_n\}\)<br/>
<b>算法过程</b>：</p>

<ul>
<li>计算在给定困惑度 \(\text{Perplexity}\) 下的 \(p_{j|i}\)</li>
<li>计算 \(p_{ij} = \frac{1}{2n}(p_{j|i} + p_{i|j}) \)</li>
<li>使用 (0,10<sup>{-4}I)</sup> 随机初始化 \(\mathcal Y\)</li>
<li><p>迭代，从 \(t = 1\) 到 \(T\)， 做如下操作:</p>

<ul>
<li>计算低维空间的 \(q_{ij}\) </li>
<li>计算梯度</li>
<li>更新 \(Y^{(t)}=Y^{(t−1)}+ \eta \frac{\partial C}{\partial Y}+ \alpha^{(t)}(Y^{(t−1)}−Y^{(t−2)})\)</li>
<li>结束</li>
</ul></li>
<li><p>结束</p></li>
</ul>

<p>优化过程中可以尝试的两个trick:</p>

<ol>
<li>提前压缩 (early compression) :开始初始化的时候，各个点要离得近一点。这样小的距离，方便各个聚类中心的移动。可以通过引入 L2 正则项(距离的平方和)来实现。</li>
<li>提前夸大 (early exaggeration) ：在开始优化阶段，\(p_{ij}\) 乘以一个大于1的数进行扩大，来避免因为 \(q_{ij}\) 太小导致优化太慢的问题。比如前50次迭代，\(p_{ij}\) 乘以4。</li>
</ol>

<h4 id="toc_9">不足</h4>

<p>主要不足有四个:</p>

<ol>
<li>主要用于可视化，很难用于其他目的。比如测试集合降维，因为他没有显式的预估部分，不能在测试集合直接降维；比如降维到10维，因为t分布偏重长尾，1个自由度的t分布很难保存好局部特征，可能需要设置成更高的自由度。</li>
<li>t-SNE倾向于保存局部特征，对于本征维数(intrinsic dimensionality)本身就很高的数据集，是不可能完整的映射到2-3维的空间</li>
<li>t-SNE没有唯一最优解，且没有预估部分。如果想要做预估，可以考虑降维之后，再构建一个回归方程之类的模型去做。但是要注意，t-sne中距离本身是没有意义，都是概率分布问题。</li>
<li>训练太慢。有很多基于树的算法在t-sne上做一些改进</li>
</ol>

<hr/>

<p><a href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf">Visualizing Data Using T-SNE</a><br/>
<a href="http://www.datakit.cn/blog/2017/02/05/t_sne_full.html">t-SNE完整笔记</a> <br/>
<a href="http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/?from=timeline&amp;isappinstalled=0">从SNE到t-SNE再到LargeVis</a><br/>
<a href="https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/">t-SNE原生numpy实现</a><br/>
<a href="https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm">t-SNE介绍与实现</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15041093080052.html">线性判别分析 LDA</a></h1>
			<p class="meta"><time datetime="2017-08-31T00:08:28+08:00" 
			pubdate data-updated="true">2017/8/31</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>前面我们讨论过PCA、SVD对数据降维，但是PCA和SVD都是无监督的方法，而在一些有标签的数据中，如果能结合标签对数据降维，效果会更好。因此产生了LDA的方法，LDA英文全称是Linear Discriminant Analysis，线性判别方法，LDA作为一种降维方法，在有效降低维度的同时保证了数据的可分性。</p>

<div align="center">
    <img src="media/15041093080052/15274469363430.jpg" width="400px" />
</div>
如上图如果不考虑数据的标签，采用PCA方法对数据降维到一维空间，由PCA可知将按照最大方差的方向进行映射也就是映射到红线的位置，本来易分的数据将会变得不易分，对于这个例子来说是得不偿失的。而我们如果将所有点都投影到黑线上，效果将非常好，这就是LDA方法所考虑的。

LDA方法的基本思想是将高维数据映射到最佳鉴别空间，达到降维和提取特征的目的，投影后保证在新空间数据点具有最大的类间距离和最小的类内距离。也就是上图中蓝色点之间的距离最小，而蓝色点和绿色点之间的距离最大。在继续讨论LDA之前，先看一些相关的前置知识。

#前置知识

#### 投影

对于一个高维空间里的样本$X_i$投影到一个向量$W$上，如果$X_i$在投影前是在是一个$n$维空间，我们期望投影后降低到$k$维空间，那么$W$将是一个$n\times k$形状的矩阵。设在新空间中（可能是低维）的点为$Z_i$，满足：
$$
Z_i = W^T X_i
$$

其中$Z_{ij}=W_j^TX_i$表示点$X_i$在新坐标空间中第$j$维的坐标。如果我们将$Z_i$还原到原空间，可以通过$X^*_i = WZ_i$，其中$X_{ij} = W_jZ_i$表示新空间点$Z_i$转换回原空间在第j维的坐标。在本文中如果我们将二维空间数据点投影到一条直线上，如下图所示，点$X=(2,4)^T$在向量$w=(-\frac{\sqrt{2}}{2},\frac{\sqrt{2}}{2})^T$上的投影为$Z=W^TX = \sqrt{2}$。

<div align="center">
    <img src="media/15041093080052/15276993092656.jpg" width="350px" />
</div>

<p>在SVD的前置知识里，我们已经提到过通过正交矩阵将点可以从一个坐标系转换到另一个坐标系，这是一种\(W\)是正交矩阵的投影特例。</p>

<h4 id="toc_0">Rayleigh商矩阵</h4>

<p>定义Rayleigh商矩阵：<br/>
\[<br/>
R(A,x) = \frac{x^HAx}{x^Hx}<br/>
\]</p>

<p>其中\(x\)是非零向量，而\(A\)是\(n\times n\)的Hermitian矩阵（厄米特矩阵），厄米特矩阵是共轭转置等于本身的矩阵。假设\(A\)的\(n\)个特征值依次为\(\lambda_1\le\lambda_2\le...\le\lambda_n\)，则有：<br/>
\[<br/>
\lambda_1 \le R(A,x) \le \lambda_n<br/>
\]</p>

<p>证明：假设特征值\(\lambda_1,\lambda_2,...,\lambda_n\)对应的单位特征向量为：\(x_1,x_2,...,x_n\)，由于\(A\)是厄米特矩阵，可知\(A\)可以正交对角化，即特征矩阵\(X=(x_1,x_2,...,x_n)\)同时也是个单位正交矩阵，每一个元素都可看成向量空间的一组正交基。将向量\(x\)用这组正交基表示：<br/>
\[<br/>
x = a_1x_1+a_2x_2+....a_nx_n=(x_1,x_2,...,x_n)(a_1,a_2,...,a_n)^H = X\boldsymbol a<br/>
\]</p>

<p>其中\(\boldsymbol a = (a_1,a_2,...,a_n)^H\)，将上式代入Rayleigh矩阵可得：<br/>
\[<br/>
\begin{align*}<br/>
R(A,x) = \frac{x^HAx}{x^Hx} &amp;= \frac{(X\boldsymbol a)^HA(X\boldsymbol a)}{(X\boldsymbol a)^H(X\boldsymbol a)} \\<br/>
&amp;= \frac{\boldsymbol a^H X^H A X \boldsymbol a}{\boldsymbol a^H X^H X \boldsymbol a}<br/>
\end{align*}<br/>
\]</p>

<p>由实对称矩阵对角会性质可知：\(X^TAX=\Lambda\)，其中每一个对角线元素都是\(A\)的特征值。且正交矩阵\(X\)满足\(X^HX = 1\)所以：<br/>
\[<br/>
\begin{align*}<br/>
R(A,x) = \frac{x^HAx}{x^Hx} &amp;= \frac{\boldsymbol a^H X^H A X \boldsymbol a}{\boldsymbol a^H X^H X \boldsymbol a} \\<br/>
&amp;= \frac{\boldsymbol a^H \Lambda \boldsymbol a}{\boldsymbol a^H \boldsymbol a} \\<br/>
&amp;= \frac{[a_1,a_2,...,a_n] \left[ \begin{array}\\\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n\\\end{array}\right] \left[\begin{array}\\a_1\\a_2\\...\\a_n\\\end{array}\right]}{\boldsymbol a^H \boldsymbol a} \\<br/>
&amp;=\frac{\sum_{i=1}^N\lambda_i a_i^2}{\sum_{i=1}^N a_i^2}<br/>
\end{align*}<br/>
\]</p>

<p>所以我们可以将\(R(A,x)\)看成\(\lambda_n\)的加权平均值，权系数是\(a_i^2\)，假设\(\lambda_1\le\lambda_2\le...\le\lambda_n\)，明显对于任意\(i=(1,2,...,n)\)有\(\lambda_ia_i^2\ge \lambda_1a_i^2\)，所以\(\sum_{i=1}^N\lambda_ia_i^2\ge n\lambda_1a_i^2=\sum_{i=1}^N\lambda_1a_i^2 \)，所以：<br/>
\[<br/>
R(A,x) = \frac{\sum_{i=1}^N\lambda_i a_i^2}{\sum_{i=1}^N a_i^2} \ge \frac{\sum_{i=1}^N\lambda_1a_i^2}{\sum_{i=1}^N a_i^2} = \lambda_1<br/>
\]</p>

<p>同理可证：\(R(A,x) \le \lambda_n\)。综合可知：<br/>
\[<br/>
\lambda_1 \le R(A,x) \le \lambda_n<br/>
\]</p>

<p>当\(R(A,x)\)取最大值或最小值时，令\(R(A,x)=\lambda\)，此时\(\lambda\)是A的特征值：<br/>
\[<br/>
\begin{align*}<br/>
&amp;R(A,x) = \frac{x^HAx}{x^Hx} = \lambda \\<br/>
&amp;\Rightarrow x^HAx = \lambda x^Hx<br/>
\end{align*}<br/>
\]</p>

<p>两边同时左乘\((x^{H})^{-1}\)得：\(Ax = \lambda x\)，所以此时\(\lambda\)对应的特征向量为\(x\)。</p>

<p>另外当\(x\)是正交矩阵时，\(x^Hx=1\)，\(R(A,x) = x^HAx\)，这个形式在很多理论中都有使用。</p>

<h4 id="toc_1">广义Rayleigh商矩阵</h4>

<p>定义广义Rayleigh商矩阵:<br/>
\[<br/>
R(A,B,x) = \frac{x^HAx}{x^HBx}<br/>
\]</p>

<p>其中A,B都是\(n\times n\)的厄米特矩阵，且B正定，那么这种形式的R(A,B,x)最大值与最小值是多少呢？其实很容易想到，只要我们设\(x^{&#39;}\)，然后能将上式化为R(A,x)形式即可。</p>

<p>首先看分母，我们希望\(x^HBx=x^{&#39;H}x^{&#39;}\)，所以可以分解得：<br/>
\[<br/>
x^HBx =x^H(B^{1/2})^2x= x^H(B^{1/2})^HB^{1/2}x=(B^{1/2}x)^H(B^{1/2}x)<br/>
\]</p>

<p>这样如果令\(x{&#39;} = B^{1/2}x\)，则满足我们期望，此时\(x = B^{-1/2}x^{&#39;}\)，代入得：<br/>
\[<br/>
\begin{align*}<br/>
x^HBx &amp;= (B^{-1/2}x^{&#39;})^HBB^{-1/2}x^{&#39;} = x^{&#39;H}(B^{-1/2})^HBB^{-1/2}x^{&#39;} = x^{&#39;H}B^{-1/2}BB^{-1/2}x^{&#39;}  = x^{&#39;H}x^{&#39;} \\<br/>
x^HAx &amp;= (B^{-1/2}x^{&#39;})^HAB^{-1/2}x^{&#39;} = x^{&#39;H}(B^{-1/2})^HAB^{-1/2}x^{&#39;} = x^{&#39;H}B^{-1/2}AB^{-1/2}x^{&#39;} <br/>
\end{align*}<br/>
\]</p>

<p>所以\(R(A,B,x)\)可以化为\(R(A,B,x{&#39;})\)：<br/>
\[<br/>
R(A,B,x&#39;) = \frac{x^{&#39;H}B^{-1/2}AB^{-1/2}x^{&#39;} }{x^{&#39;H}x^{&#39;}}<br/>
\]</p>

<p>由普通Rayleigh商的性质可知\(R(A,B,x^{&#39;})\)的最大值为\(B^{-1/2}AB^{-1/2}\)特征值的最大值，最小值为\(B^{-1/2}AB^{-1/2}\)特征值的最小值。此时我们考虑假设特征值为\(\lambda\)，对应的特征向量为\(x^{&#39;}\)，有：<br/>
\[<br/>
B^{-1/2}AB^{-1/2} x^{&#39;} = \lambda x^{&#39;}<br/>
\]</p>

<p>两边同左乘上\(B^{-1/2}\)，可得：<br/>
\[<br/>
B^{-1}AB^{-1/2} x^{&#39;} = \lambda B^{-1/2} x^{&#39;} \Leftrightarrow B^{-1}A(B^{-1/2} x^{&#39;}) = \lambda (B^{-1/2} x^{&#39;})<br/>
\]</p>

<p>所以\(B^{-1}AB^{-1/2}\)的特征值等同于\(B^{-1}A\)的特征值，所以\(R(A,B,x)\)的最大值为\(B^{-1}A\)特征值的最大值，最小值为\(B^{-1}A\)特征值的最小值，对应的特征向量为\(B^{-1/2}x^{&#39;}\)，即\(x\)，实现了一个完美的统一。</p>

<h1 id="toc_2">LDA解释</h1>

<p>为什么叫线性判别分析呢？所谓的线性是将高维空间投影到直线上（可能是多条直线），直线的函数解析式叫做线性函数，通常函数解析式如下面的形式：<br/>
\[<br/>
y=w^Tx+b<br/>
\]</p>

<p>由前面可知如果将两个数据点\(x_i\)投影到直线上，那么投影后的点的坐标为\(W^Tx_i\)，LDA希望通过线性函数投影后的数据点可以很好通过一个判别式划分。我们首先来看一下二分类问题，然后将其推广到多分类问题上。</p>

<h2 id="toc_3">二分类问题</h2>

<p>假设我们有数据集\(D = ((x_1,y_1),(x_2,y_2),...,(x_m,y_m))\)，其中任意\(x_i\)一个\(n\)维的向量，\(y_i \in (0,1)\)。我们使用\(X_i(i=0,1)\)表示\(D\)中的两类样本集，\(N_i(i=0,1)\)表示样本集\(X_i\)的数量，\(u_i(i=0,1)\)表示样本集\(X_i\)的均值向量，\(\Sigma_i(i=0,1)\)表示样本集\(X_i\)的方差（没有分母的）。</p>

<p>\(u_i\)方程表示为：<br/>
\[<br/>
u_i = \frac{1}{N_i}\sum_{x \in X_i}x\quad(i=0,1)<br/>
\]<br/>
\(\Sigma_i\)方程表示：<br/>
\[<br/>
\Sigma_{i} = \sum_{x\in X_i}(x-u_i)(x-u_i)^T\quad(i=0,1)<br/>
\]</p>

<p>由于是二分类问题，当我们将数据投影到一条直线上，假设投影向量为\(W\)，由\(W\)投影后两类样本集的中心点分别为\(W^Tu_0\)和\(W^Tu_1\)，投影后的方差为：<br/>
\[<br/>
\begin{align*}<br/>
\Sigma^{new}_{i} &amp;= \sum_{x\in X_i}(w^Tx-w^Tu_i)^2 = \sum_{x\in X_i}(w^Tx-w^Tu_i)(w^Tx-w^Tu_i)^T \\<br/>
&amp;= \sum_{x\in X_i} w^T(x-u_i)(x-u_i)^Tw = w^T\Sigma_iw<br/>
\end{align*}<br/>
\]</p>

<p>LDA期望投影后的数据易区分，满足同类数据尽可能密集，也就是希望最小化方差\(w^T\Sigma_0w+w^T\Sigma_1w\)。非同类元素尽可能分离，即最大化均值距离\(||w^Tu_0-w^Tu_1||^2\)，综上可以定义优化目标为：<br/>
\[<br/>
\begin{equation}<br/>
J=\frac{||w^Tu_0-w^Tu_1||^2}{w^T\Sigma_0w+w^T\Sigma_1w} = \frac{w^T(u_0-u_1)(u_0-u_1)^Tw}{w^T(\Sigma_0+\Sigma_1)w} \label{J}<br/>
\end{equation}<br/>
\]</p>

<p>定义类内方差\(S_w\)为：<br/>
\[<br/>
S_w = \Sigma_0+\Sigma_1 = \sum_{x\in X_0}(x-u_0)(x-u_0)^T + \sum_{x\in X_1}(x-u_1)(x-u_1)^T<br/>
\]</p>

<p>定义类间距离\(S_b\)为：<br/>
\[<br/>
S_b = (u_0-u_1)(u_0-u_1)^T<br/>
\]</p>

<p>这样优化目标可以改写为：<br/>
\[<br/>
J = \frac{w^TS_bw}{w^TS_ww}<br/>
\]</p>

<p>对比广义Rayleigh商矩阵，发现形式一模一样，现在利用广义Rayleigh商矩阵的性质可知\(J\)的最大值即为矩阵\(S_w^{-1}S_b\)的最大特征值，此时对应的特征向量为\(w\)。</p>

<p>对于二分类问题来说，设\(\lambda_w = (u_0-u_1)^Tw\)，所以\(S_bw = (u_0-u_1)\lambda_w\)，将其代入特征方程\(S_w^{-1}S_bw = \lambda w\)得\(S_w^{-1} (u_0-u_1)\lambda_w = \lambda w\)，可解得\(w = \frac{\lambda_w}{\lambda}S_w^{-1} (u_0-u_1)\)。</p>

<p>由于\((u_0-u_1)\)是一个\(n\)维数据，并由前面投影的知识\(w\)的形状为\((n \times 1)\)，所以乘积\(\lambda_w=(u_0-u_1)^Tw\)是一个标量。由\(J\)的方程（\ref{J}）可知我们\(w\)的大小增大或缩小多少倍对于结果并没有影响，所以我们并不关心\(w\)的大小，只关心\(w\)的方向，将常数省去可得\(w = S_w^{-1} (u_0-u_1)\)，也就意味着当我们求出二分类的方差和均值就可以确定最佳投影方向\(w\)了。</p>

<h2 id="toc_4">多分类问题</h2>

<p>同样我们假设数据集\(D=((x_0,y_0),(x_1,y_1),...,(x_m,y_m))\)，其中任意的\(x_i\)是一个\(n\)维向量；\(y_i\in (C_1,C_2,...,C_k)\)，也就是数据集包含\(k\)类数据；数据集大小为\(N\)。在二类LDA中，是将原数据投影到一条直线（一维）上，由前置知识中可知\(W\)是一个\((n \times 1)\)的矩阵，而在多分类中，需要将数据投影到低维空间上，假设投影后的维度为 \(d\) ，投影向量\(W\)是一个\((n\times d)\)的矩阵，定义\(u_i\)为第\(\,i\,\)类的均值向量。<br/>
\[<br/>
u_i = \frac{1}{N_i}\sum_{x \in X_i} x<br/>
\]</p>

<p>此时需要将之前我们定义的概念做一下替换，定义类内散度矩阵\(S_W\)替换二分类LDA中的方差，即：<br/>
\[<br/>
S_W = \sum_{i=1}^k \Sigma_i = \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T<br/>
\]</p>

<p>定义投影后的类内距离\(J_W\)，其中点\(x\)投影后为\(W^Tx\)，中心点\(u_i\)投影后为\(W^Tu_i\)，可得：<br/>
\[<br/>
J_W = \sum_{i=1}^k \sum_{x\in X_i}(W^Tx-W^Tu_i)(W^Tx-W^Tu_i)^T = W^T\sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^TW = W^TS_WW<br/>
\]</p>

<p>定义类间散度矩阵\(S_B\)替换二分类LDA中的类间距离，但是此时已经不能用两个类中心的距离来表示类间散度距离了，考虑下图：</p>

<div align="center">
    <img width="300px" src="media/15041093080052/15280361373656.jpg" />
</div>

<p>定义全局中心点 \(u\) ：<br/>
\[<br/>
\begin{equation}<br/>
u = \frac{1}{N}\sum_{i=1}^N x_i = \frac{1}{N} \sum_{i=1}^k \sum_{x\in X_i} x= \frac{1}{N} \sum_{i=1}^k N_i u_i \label{u_u_i}<br/>
\end{equation}<br/>
\]</p>

<p>定义全局散度矩阵\(S_t\)为每一个点到全局中心点\(u\)的向量距离：<br/>
\[<br/>
S_t = \sum_{i=1}^N (x_i-u)(x_i-u)^T<br/>
\]</p>

<p>考虑到全局散度矩阵\(S_t\)=类内散度矩阵\(S_W\)+类间散度矩阵\(S_B\)，所以：<br/>
\[<br/>
\begin{align}<br/>
S_B &amp;= S_t - S_W = \sum_{i=1}^N (x_i-u)(x_i-u)^T - \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T \nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}(x - u)(x-u)^T - \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T \nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}[(x - u)(x-u)^T-(x-u_i)(x-u_i)^T ]\nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}(xx^T - xu^T-ux^T+uu^T-xx^T+xu_i^T+u_ix^T-u_iu_i^T) \nonumber\\<br/>
&amp;=\sum_{i=1}^k \sum_{x\in X_i}(- xu^T-ux^T+uu^T+xu_i^T+u_ix^T-u_iu_i^T) \nonumber\\<br/>
&amp;=\sum_{i=1}^k(-\sum_{x\in X_i}xu^T-\sum_{x\in X_i}ux^T+\sum_{x\in X_i}uu^T+\sum_{x\in X_i}xu_i^T+\sum_{x\in X_i}u_ix^T-\sum_{x\in X_i}u_iu_i^T) \label{S_B_T_W}\\<br/>
\end{align}<br/>
\]</p>

<p>考虑到\(u_i\)为第\(i\)类的均值向量，即：<br/>
\[<br/>
\begin{align*}<br/>
&amp;u_i = \frac{1}{N_i}\sum_{x\in X_i}x \quad\Rightarrow\quad \sum_{x\in X_i}x = N_iu_i \\<br/>
&amp;u_i^T = \frac{1}{N_i}\sum_{x\in X_i}x^T \quad\Rightarrow\quad \sum_{x\in X_i}x^T = N_iu_i^T \\<br/>
\end{align*}<br/>
\]</p>

<p>将上式代入公式（\ref{S_B_T_W}）中得：<br/>
\[<br/>
\begin{align}<br/>
S_B &amp;= \sum_{i=1}^k(-\sum_{x\in X_i}xu^T-\sum_{x\in X_i}ux^T+\sum_{x\in X_i}uu^T+\sum_{x\in X_i}xu_i^T+\sum_{x\in X_i}u_ix^T-\sum_{x\in X_i}u_iu_i^T)  \nonumber\\<br/>
&amp;= \sum_{i=1}^k(-N_iu_iu^T-N_iuu_i^T+N_iuu^T+N_iu_iu_i^T+N_iu_iu_i^T-N_iu_iu_i^T) \nonumber\\<br/>
&amp;= \sum_{i=1}^kN_i(-u_iu^T-uu_i+uu^T+u_iu_i^T) \nonumber\\<br/>
&amp;= \sum_{i=1}^kN_i(u_i-u)(u_i-u)^T \label{S_B}<br/>
\end{align}<br/>
\]</p>

<p>抛去数学推导，直观上看，观察类间散度矩阵\(S_B\)，其实就是每一个类的中心点到全局中心点\(u\)的向量距离，由于每一个类包含数据数量不同，使用了\({N_i}\)作为第\(i\)类的权重。</p>

<p>定义投影后的类间距离\(J_B\)，局部中心点\(u_i\)投影后为\(W^Tu_i\)，全局中心点\(u\)在投影后为\(W^Tu\)，得：<br/>
\[<br/>
J_B = \sum_{i=1}^kN_i(W^Tu_i-W^Tu)(W^Tu_i-W^Tu)^T = W^T\sum_{i=1}^kN_i(u_i-u)(u_i-u)^TW = W^TS_BW<br/>
\]</p>

<p>则目标函数\(J(W)为\)：<br/>
\[<br/>
J(W) = \frac{J_B}{J_W} = \frac{W^TS_BW}{W^TS_WW}<br/>
\]</p>

<p>我们的目标是最大化\(J(W)\)，而当成比例的放大或缩小\(W\)时，并不影响\(J(W)\)的取值，因此我们关心的是\(W\)的方向，而不在意\(W\)的大小。因此我们可以固定分母为1，那么目标方程组为（这里我将求最大化问题变成了求最小值问题，其实等价）：<br/>
\[<br/>
\begin{align*}<br/>
&amp;min_W\quad -W^TS_BW \\<br/>
&amp;s.t. \quad \quad W^TS_WW = 1<br/>
\end{align*}<br/>
\]</p>

<p>利用拉格朗日乘子法定义拉格朗日朗日方程：<br/>
\[<br/>
L(W,\alpha) = -W^TS_BW + \alpha(W^TS_WW-1)<br/>
\]</p>

<p>其中\(\lambda\)为乘子，满足\(\lambda \neq 0\)。<br/>
先求\(L(W,\alpha)\)对\(W\)求导，并令其等于0，即：<br/>
\[<br/>
\begin{align}<br/>
\frac{\nabla L(W,\alpha)}{\nabla W} &amp;= \frac{-W^TS_BW + \lambda(W^TS_WW-1)}{\nabla W} \nonumber\\<br/>
&amp;= -(S_B+S_B^T)W+\alpha(S_W+S_W^T)W \label{LW}\\<br/>
\end{align}<br/>
\]</p>

<blockquote>
<p>矩阵求导公式，\(\alpha\)是实数，\(\beta\)和\(X\)为向量，\(A\),\(B\),\(C\)是与\(X\)无关的矩阵：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac{\partial \beta X}{\partial X^T} = \beta \\<br/>
&amp;\frac{\partial X^T\beta}{\partial X} = \beta \\<br/>
&amp;\frac{\partial X^TAX}{\partial X} = (A+A^T)X \\<br/>
\end{align*}<br/>
\]</p>
</blockquote>

<p>因为：<br/>
\[<br/>
S_B^T = （\sum_{i=1}^kN_i(u_i-u)(u_i-u)^T)^T = \sum_{i=1}^kN_i(u_i-u)(u_i-u)^T = S_B \\<br/>
S_W^T = (\sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T)^T = \sum_{i=1}^k \sum_{x\in X_i}(x-u_i)(x-u_i)^T = S_W <br/>
\]</p>

<p>上式带入公式（\ref{LW}）可得：<br/>
\[<br/>
\frac{\nabla L(W,\alpha)}{\nabla W} = -2S_BW + 2\lambda S_WW = 0<br/>
\]</p>

<p>如果\(S_W\)为非奇异，即\(S_W^{-1}\)存在，上式可得：\(S_W^{-1}S_BW = \lambda W\)，也就是\(W\)的每一列都是\(S_W^{-1}S_B\)的特征向量。特征值越大的特征向量包含的信息越丰富，所以首先求出\(S_W^{-1}S_B\)的特征值，\(W\)为前 \(d\) 个非零特征值对应的特征向量组成的特征矩阵。</p>

<h4 id="toc_5">多分类的维度问题</h4>

<p>多分类中我们假设经过\(W\)投影后的数据集在 \(d\) 维空间，那么接下来将讨论 \(d\) 的范围。由于 \(S_B\) 矩阵中的 \(\mu_i-\mu\) 的秩为1，结合（\ref{S_B}）和秩的性质6（见附录：矩阵的秩小于等于各个相加矩阵的秩的和），因此SB的秩最多为k。由公式（\ref{u_u_i}）知\(\mu_k\) 可以用前k-1个 \(\mu_i\) 表示出来，因此 \(S_B\) 的秩最多为k-1，由秩的性质7可知\(R(S_W^{-1}S_B) \le min\{R(S_W^{-1}),R(S_B)\}\) ，所以\(S_W^{-1}S_B\)的秩最大为k-1。</p>

<p>由矩阵的秩与非零特征值的关系：对于任何n阶方阵，都有\(\mu (A) \le R(A)\)，即非零特征值的个数小于矩阵的秩。具体证明见文章最后。所以可以得出\(S_W^{-1}S_B\)非零特征值个数最大为k-1个，所以对应的特征向量最多也为k-1个，即\(W\)的列数最多有\(k-1\)列，那么 \(d\) 也最大为k-1维。</p>

<h2 id="toc_6">LDA算法流程</h2>

<p>输入：同样我们假设数据集\(D=((x_0,y_0),(x_1,y_1),...,(x_m,y_m))\)，其中任意的\(x_i\)是一个\(n\)维向量；\(y_i\in (C_1,C_2,...,C_k)\)，也就是数据集包含\(k\)类数据；<br/>
输出：降维后的样本集\(D′\)。</p>

<p>1） 计算类内散度矩阵\(S_W\)<br/>
2） 计算类间散度矩阵\(S_B\)<br/>
3） 计算矩阵\(S_W^{-1}S_B\)<br/>
4） 计算\(S_W^{-1}S_B\)的最大的 \(d\) 个特征值和对应的 \(d\) 个特征向量\((w_1,w_2,...,w_d)\),得到投影矩阵\(W\)<br/>
5） 对样本集中的每一个样本特征\(x_i\)，转化为新的样本\(z_i=W^Tx_i\)<br/>
6） 得到输出样本集\(D′={(z_1,y_1),(z_2,y_2),...,((z_m,y_m))}\)</p>

<h2 id="toc_7">LDA的局限性</h2>

<ol>
<li><p>存在秩限制，对于 \(k\) 类问题，至多可生成 \(k-1\) 维子空间。LDA降维后的维度区间在 \([1,k-1]\) ，与原始特征数 \(m\) 无关，对于二值分类，最多投影到1维。</p></li>
<li><p>类间散度矩阵必须非奇异。在一些小样本数据集中，样本总数可能小于样本维数，此时\(S_W\)奇异，将不能使用上述LDA算法。</p></li>
</ol>

<h2 id="toc_8">LDA 改进算法</h2>

<h4 id="toc_9">PCA + LDA</h4>

<p>在一些人脸识别等小样本问题上，需要面对的一个小问题是类内散度奇异，这是由于训练图像的个数 N 远小于每一个图像的维度。Belhomecour 等人提出一个解决方案，先做一次PCA降维，解决\(S_W\)的奇异问题，然后再应用LDA将训练集将维到\(k-1\)维度。</p>

<h6 id="toc_10">还有一些其他的改进算法 MLDA 等，相关文献较少，以后需要时再看吧</h6>

<h2 id="toc_11">附录：</h2>

<h4 id="toc_12">秩的性质：</h4>

<p>1） \(0 \le R(A_{m\times n}) \le min\{m,n\}\)<br/>
2） \(R(A^T) = R(A)\)<br/>
3） 若A~B，则\(R(A) = R(B)\)<br/>
4） 若P,Q可逆，则\(R(PAQ) = R(A)\)<br/>
5） \(max\{R(A),R(B)\} \le R(A,B) \le R(A)+R(B)\)<br/>
6） \(R(A+B) \le R(A)+R(B)\)<br/>
7） \(R(AB) \le min\{R(A),R(B)\}\)<br/>
8） 若\(A_{m\times n}B_{n\times l} = O\)，则\(R(A) + R(B) \le n\)</p>

<h4 id="toc_13">矩阵的秩与非零特征值的关系</h4>

<p>论文看<a href="http://xueshu.baidu.com/s?wd=paperuri%3A%28f0a2034422bc0816eb555fa33cb95b1f%29&amp;filter=sc_long_sign&amp;tn=SE_xueshusource_2kduw22v&amp;sc_vurl=http%3A%2F%2Fwww.doc88.com%2Fp-317741888504.html&amp;ie=utf-8&amp;sc_us=4282568566058718085">这里</a>(Chrome打开)</p>

<h6 id="toc_14">定理：对于任意 \(n\) 阶方阵，都有 \(\mu (A) \le r(A)\)，即矩阵的非零特征值的个数不大于矩阵的秩。</h6>

<p>证明：<br/>
当\(|A|\neq 0\)时，此时\(A\)可逆，并有\(r(A) = n\)。假设\(\lambda_1,\lambda_2,...,\lambda_n\)是方阵\(A\)的全部特征值，那么\(|A| = \lambda_1\lambda_2...\lambda_n\neq 0\)，所以\(\lambda_i\neq 0(i=1,2,...,n)\)，所以\(\mu(A) = r(A)\)。</p>

<p>当\(|A| = 0\)时，设\(r(A) = r &lt; n\)，对于特征值\(\lambda\)满足：<br/>
\[<br/>
|\lambda I-A| = \left ( \begin{array}{cccccc} <br/>
\lambda-a_{11}&amp;-a_{12}&amp;...&amp;-a_{1r}&amp;...&amp;-a_{1n}\\<br/>
-a_{21}&amp;\lambda-a_{22}&amp;...&amp;-a_{2r}&amp;...&amp;-a_{2n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
-a_{r1}&amp;-a_{r2}&amp;...&amp;\lambda-a_{rr}&amp;...&amp;-a_{rn}\\<br/>
-a_{r+1,1}&amp;-a_{r+1,2}&amp;...&amp;\lambda-a_{r+1,r}&amp;...&amp;-a_{r+1,n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
-a_{n1}&amp;-a_{n2}&amp;...&amp;-a_{nr}&amp;...&amp;\lambda-a_{nn}<br/>
\end{array} \right )<br/>
\]</p>

<p>考虑矩阵的行向量组\((a_1,a_2,...,a_n)^T\)，这里不妨设\(a_1,a_2,...,a_r\)为线形无关的 \(r\) 个向量。则\(a_{r+1},a_{r+2},...,a_n\)均可由\(a_1,a_2,...,a_r\)线形表示，设\(a_i=k_{i1}a_1+k_{i2}a_2+...+k_{ir}a_r\)，其中\(i=r+1,r+2,...,n\)，我们现在只看第 \(r+1\) 行的每一个元素，用前 \(r\) 行表示得：<br/>
\[<br/>
\begin{align*}<br/>
a_{r+1,1}&amp;=k_{r+1,1}a_{11}+k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1}\\<br/>
a_{r+1,2}&amp;=k_{r+1,1}a_{12}+k_{r+1,2}a_{22}+...+k_{r+1,r}a_{r2}\\<br/>
&amp;...\\<br/>
a_{r+1,n}&amp;=k_{r+1,1}a_{1n}+k_{r+1,2}a_{2n}+...+k_{r+1,r}a_{rr}<br/>
\end{align*}<br/>
\]</p>

<p>现在对\(|\lambda I-A|\)的第\((r+1)\)行做行列式变换，分别用\(k_{r+1,j}\)乘上\(|\lambda I-A|\)的第 \(j\)(\(j=1,2,...,r\)) 行后加上它，我们知道行列式变换结果不变，分开计算每一个元素，先看第一项：</p>

<p>\[<br/>
\begin{align*}<br/>
|\lambda I-A|_{r+1,1} &amp;\sim |\lambda I-A|_{r+1,1} + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1} \\<br/>
&amp;= -a_{r+1,1} + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1} \\<br/>
\end{align*}<br/>
\]</p>

<p>将之前\(a_{r+1,1}\)的线形表示形式带入上式得：</p>

<p>\[<br/>
\begin{align*}<br/>
|\lambda I-A|_{r+1,1} &amp;\sim -a_{r+1,1} + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1}\\<br/>
&amp;= (-k_{r+1,1}a_{11}-k_{r+1,2}a_{21}-...k_{r+1,r}a_{r1}) + k_{r+1,1}(\lambda-a_{11}) + k_{r+1,2}a_{21}+...+k_{r+1,r}a_{r1} = k_{r+1,1}\lambda<br/>
\end{align*}<br/>
\]</p>

<p>同理可得其他项，按照这种方式最终可得：<br/>
\[<br/>
\begin{align*}<br/>
|\lambda I-A| &amp;\sim \left ( \begin{array}{cccccc} <br/>
\lambda-a_{11}&amp;-a_{12}&amp;...&amp;-a_{1r}&amp;-a_{1,r+1}&amp;...&amp;-a_{1n}\\<br/>
-a_{21}&amp;\lambda-a_{22}&amp;...&amp;-a_{2r}&amp;-a_{2,r+1}&amp;...&amp;-a_{2n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;..&amp;...\\<br/>
-a_{r1}&amp;-a_{r2}&amp;...&amp;\lambda-a_{rr}&amp;a_{r,r+1}&amp;...&amp;-a_{rn}\\<br/>
k_{r+1,1}\lambda&amp;k_{r+1,2}\lambda&amp;...&amp;k_{r+1,r}\lambda&amp;\lambda&amp;...&amp;0\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
k_{n,1}\lambda&amp;k_{n,2}\lambda&amp;...&amp;k_{n,r}\lambda&amp;0&amp;...&amp;\lambda<br/>
\end{array} \right ) \\<br/>
&amp;= \lambda^{n-r}\left ( \begin{array}{cccccc} <br/>
\lambda-a_{11}&amp;-a_{12}&amp;...&amp;-a_{1r}&amp;-a_{1,r+1}&amp;...&amp;-a_{1n}\\<br/>
-a_{21}&amp;\lambda-a_{22}&amp;...&amp;-a_{2r}&amp;-a_{2,r+1}&amp;...&amp;-a_{2n}\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;..&amp;...\\<br/>
-a_{r1}&amp;-a_{r2}&amp;...&amp;\lambda-a_{rr}&amp;a_{r,r+1}&amp;...&amp;-a_{rn}\\<br/>
k_{r+1,1}&amp;k_{r+1,2}&amp;...&amp;k_{r+1,r}&amp;1&amp;...&amp;0\\<br/>
...&amp;...&amp;...&amp;...&amp;...&amp;...&amp;...\\<br/>
k_{n,1}&amp;k_{n,2}&amp;...&amp;k_{n,r}&amp;0&amp;...&amp;1<br/>
\end{array} \right ) \\<br/>
\end{align*}<br/>
\]</p>

<p>由此可见至少\(|\lambda I-A| = 0\)有\((n-r)\)个零特征值，也就是它最多拥有\(n-(n-r)=r\)个非零特征值。结合\(r(A) = r\)，所以\(u(A) \le r(A)\)。<br/>
得证。</p>

<h6 id="toc_15">其他关于矩阵秩的论文：<a href="https://wenku.baidu.com/view/f0deb94a8762caaedc33d426.html">方阵的秩与特征值的关系</a></h6>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15037711738928.html">奇异值分解 SVD</a></h1>
			<p class="meta"><time datetime="2017-08-27T02:12:53+08:00" 
			pubdate data-updated="true">2017/8/27</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>SVD，英文全称是Singular Values Decomposition，关于奇异值的解释，参考一下百度百科里的介绍，设\(A\)是一个m*n的矩阵，那么\(AA^T\)的q个特征值得平方根叫做\(A\)的特征值。在PCA的介绍中，我们提到了特征值分解的方式来实现提取特征，特征值分解要求必须是方阵。而奇异值分解的目的也是提取特征值，但是针对的是任意矩阵。SVD除此之外还可以用来做图片压缩，在推荐系统中的应用也是名声大噪。</p>

<h2 id="toc_0">前置知识</h2>

<p>在学习SVD之前需要一些线性代数的知识，下面做一些简单介绍。</p>

<h4 id="toc_1">正交矩阵</h4>

<p>在线形代数里，若矩阵\(A\)满足\(AA^T=I\)或\(A^TA=I\)，其中\(E\)为单位矩阵，那么可以说\(n\)阶实矩阵为正交矩阵。<br/>
\[<br/>
\begin{align*}<br/>
(AA^T)_{ij} = \sum_{k=0}^N a_{ik} a_{kj} = I_{ij}<br/>
\end{align*}<br/>
\]</p>

<p>由单位矩阵的性质可知主对角线上的元素不为0，其他元素都为0，可知\(A\)的各行两两相交，且\(||A^T||=1\)，同理\(A\)的列向量两两正交且\(||A||=1\)。</p>

<p>一个正交矩阵对应的变换叫做正交变换，这个变换有一些特点。假设我们在空间里有一个点\(X=(2,4)^T\)，那么现在我们用一个正交矩阵\(A=\left [ \begin{array}{cc}\frac{\sqrt{2}}{2} &amp; -\frac{\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} &amp; \frac{\sqrt{2}}{2} \end{array} \right ]\)来对其做正交变换，所以得到的新的坐标点的位置为\(X^{&#39;}=A^TX=(3\sqrt{2},\sqrt{2})^T\)，我们将得到的新的坐标点在新的正交基构成的坐标系中表示出来，如下图：</p>

<div align="center">
    <img src="media/15037711738928/15273990942816.jpg" width="500px" />
</div>

<p>由上图可知，坐标点的\(X\)的位置其实并没有发生改变，只是在相对应不同的坐标系位置发生了改变，实际上也就是只是将坐标系旋转了。</p>

<p>正交矩阵其实是一种特殊的每一个元素都是实数的酉矩阵，一个\(n\times n\)的复数矩阵\(U\)，满足：<br/>
\[<br/>
U^{H}U = UU^{H} = I<br/>
\]<br/>
其中\(U^{H}\)是\(U\)的共轭转置矩阵，那么\(U\)则被称为酉矩阵。</p>

<h2 id="toc_2">SVD介绍</h2>

<p>设\(X\)是一个\(m*n\)的矩阵，则存在\(m\)阶正交矩阵\(U\)和\(n\)阶正交矩阵\(V\)，在复数领域就是酉矩阵，满足：<br/>
\[<br/>
X = U\Sigma V^T = U\left [ \begin{array}{cccc}\sigma_1&amp;&amp;&amp;\\&amp;\sigma_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\sigma_r\\&amp;&amp;&amp;0\\\end{array}\right ]V<br/>
\]</p>

<p>其中\(\sigma_1&gt;\sigma_2&gt;\sigma_r\)被称为奇异值，\(U\)和\(V\)的前r列向量被称为奇异向量。一般前10%甚至1%的奇异值，将能代表超过99%的信息量。关于奇异值和奇异向量的求解就是SVD分解。</p>

<h2 id="toc_3">SVD分解</h2>

<p>在PCA中操作往往是对数据集\(X\)的协方差矩阵\((X-\overline{X})(X-\overline{X})^T\)进行提取特征值，但是特征值提取只能是方阵，那么对于非方阵提取特征值便可以通过SVD的方式。奇异值分解是一种能分解任意矩阵的方法，对于\(m\times n\)的矩阵\(X\)有：<br/>
\[<br/>
X = U\Sigma V^T<br/>
\]</p>

<p>其中\(\Sigma\)是一个\(m\times n\)的矩阵，除主对角线的元素外都为0，主对角线的元素则是奇异值，按照从大到小排列。\(U\)是一个\(m\times m\)的方阵，称为\(X\)的左奇异向量，\(V\)是一个\(n \times n\)的方阵，称为\(X\)的右奇异向量，它们都是正交矩阵，满足\(UU^T=I,VV^T=I\)。</p>

<p>现在开始讨论\(U\)和\(V\)和\(\Sigma\)的求解：<br/>
\[<br/>
X = U\Sigma V^T \Rightarrow X^T = V\Sigma^TU^T \Rightarrow XX^T = U\Sigma V^TV\Sigma^TU^T=U(\Sigma\Sigma^T)U^T<br/>
\]</p>

<p>因为\((XX^T)^T = XX^T\)，所以\(XX^T\)是一个对称向量，由对称向量的性质，\(n\)阶对称向量，必有正交矩阵\(P\)，满足\(A = P\Lambda P^T\)，所以结合上式可以认为左奇异向量\(U\)是对称矩阵\(XX^T\)的特征向量。同理：<br/>
\[<br/>
X^TX = V\Sigma^TU^TU\Sigma V^T = V(\Sigma^T\Sigma) V^T<br/>
\]</p>

<p>可知右奇异向量\(V\)可看做对称矩阵\(X^TX\)的特征向量。同时我们也能将\(\Sigma^T\Sigma\)看做对称矩阵\(XX^T\)或\(X^TX\)的特征值组成的矩阵，也就是奇异值可以通过\(X^TX\)或\(XX^T\)特征值取平方根来求得。</p>

<p>这里说奇异值可以通过\(X^TX\)或\(XX^T\)特征值取平方根来求得，那就必然存在两个必然条件：<br/>
(1) \(X^TX\)或\(XX^T\)的特征值必须是非负数<br/>
(2) \(A^TA\)和\(AA^T\)的非零特征值必须相等（为了说明清楚，换个表示）</p>

<p>证明（1）：假设矩阵的\(X^TX\)的特征值\(\sigma\)对应的特征向量是\(v\)，有正交矩阵的性质可知\(v^Tv = 1\)：<br/>
\[<br/>
X^TX v = \sigma v \Rightarrow \sigma=v^TX^TX v = ||Xv||^2<br/>
\]</p>

<p>所以得证\(\sigma\ge 0\)，同理可知\(XX^T\)的特征向量必是非负数。</p>

<p>证明（2）：首先证明向量\(A^TA\)与\(AA^T\)有相等个非零特征值：<br/>
设矩阵\(A\)是\(m\times n\)的矩阵，由矩阵秩的性质可知\(r(A)=r(A^T)\)。对于任意的向量\(x\)，如果\(Ax = 0\)则 \(A^TAx = A^T0 = 0\)，即\(Ax=0\)的解空间是\(A^Ax=0\)的解空间。如果\(A^TAx = 0\)时，两边同左乘\(x^T\)得\(x^TA^TAx = (Ax)^TAx= 0 \)，也就是\(||Ax||=0\)，所以\(Ax=0\)，即\(A^TAx=0\)的解空间是\(Ax=0\)的解空间。结合前面知：\(Ax=0\)与\(A^TAx=0\)拥有相同的解空间，所以\(r(A)=r(A^TA)\)，同理可证：\(r(A^T)=r(AA^T)\)。</p>

<p>设\(r(A) = r\)，所以\(r=r(A)=r(A^TA)\)=\(r(A^T)=r(AA^T)\)，因为\(AA^T\)是实对称向量，并由秩的定义可知\(AA^T\)化成行列式后有\(r\)个非零行，即\(AA^T\sim\left[\begin{array}\\\sigma_1&amp;&amp;&amp;\\&amp;\ddots&amp;&amp;\\&amp;&amp;\sigma_r&amp;\\&amp;&amp;&amp;0\\\end{array}\right]\)，其中\(\sigma_n\)是\(AA^T\)的特征值，\(r=AA^T\)非零特征值得个数。同理\(r=A^TA\)非零特征值得个数。</p>

<p>再证明\(A^TA\)的非零特征值也是\(AA^T\)的特征值：<br/>
设\(\sigma\)是\(A^TA\)的特征值，所以有\(A^TAv=\sigma v\)，两边同时左乘\(A\)得：\(AA^T(Av) = \sigma Av\)，这可以看成\(\sigma\)是\(AA^T\)的特征值，其中对应的特征向量是\(Av\)，所以\(A^TA\)的特征值也是\(AA^T\)的特征值。反之也可证明\(AA^T\)的特征值也是\(A^TA\)的特征值。</p>

<p>综上（1）（2）可知\(A^TA\)与\(AA^A\)特征值的区别就在零特征值的数量。</p>

<p>那么我们在求出\(X^TX\)或\(XX^T\)任意一个特征值后，可以利用左右奇异向量的关系，在求出其中一个的前提下，求出另一个，而不用再通过特征值得方式计算，假设\(\sigma_i\)为\(X\)的奇异值：<br/>
\[<br/>
X = U\Sigma V^T \Rightarrow AV = U\Sigma \Rightarrow Xv_i = \sigma_iu_i\\\Rightarrow u_i = Xv_i/\sigma_i<br/>
\]</p>

<p>因为特征值与奇异值的关系，可知\(X^TX\)的特征值为\(\sigma_i^2\)，假设\(X^TX\)对应的特征向量为\(v_i\)，则：<br/>
\[<br/>
\begin{align*}<br/>
&amp;X^TX v_i = \sigma_i^2 v_i \\<br/>
&amp;\Rightarrow v_i^T X^TXv_i = \sigma_i^2 v_i^Tv_i \\<br/>
&amp;\Rightarrow \sigma_i^2 = ||Xv_i||^2 \\<br/>
\end{align*}<br/>
\]</p>

<p>注意到：<br/>
\[<br/>
XX^Tu_i = XX^T\frac{Xv_i}{\sigma_i} = X\frac{X^TXv_i}{\sigma_i}=X\frac{\sigma_i^2 v_i}{\sigma_i} = \sigma_i^2\frac{Xv_i}{\sigma_i} = \sigma_i^2p_i<br/>
\]</p>

<p>所以\(u_i\)是\(XX^T\)的特征向量，其实这个在上面已经知道了。</p>

<p>且有：<br/>
\[<br/>
u_i^Tu_j = (\frac{Xv_i}{\sigma_i})^T\frac{Xv_j}{\sigma_j} = \frac{(Xv_i)^T}{\sigma_i}\frac{Xv_j}{\sigma_j} = \frac{v_i^TX^TXv_j}{\sigma_i\sigma_j} = \frac{v_i^T\sigma_j^2v_j}{\sigma_i\sigma_j}=\frac{\sigma_j}{\sigma_i}v_i^Tv_j<br/>
\]</p>

<p>令\(\delta_{ij}=v_i^Tv_j\)，则：<br/>
\[<br/>
u_i^Tu_j=\frac{\sigma_j}{\sigma_i}\delta_{ij}<br/>
\]</p>

<p>当特征向量\(v_i\)是一组正交单位特征向量时：<br/>
当\(i \neq j\)时\(\delta_{ij}=v_iv_j=0\)，此时\(u_i^Tu_j=\frac{\sigma_j}{\sigma_i}\delta_{ij}=0=\delta_{ij}\)；<br/>
当\(i = j\)时\(\sigma_i=\sigma_j\)，此时\(u_i^Tu_j=\frac{\sigma_j}{\sigma_i}\delta_{ij}=\delta_{ij}\)，<br/>
所以\(u_i\)也是一组正交单位特征向量。</p>

<h4 id="toc_4">SVD分解实例</h4>

<p>求解\(A = \left ( \begin{array}{cc} 1 &amp; 0\\ 1&amp;1\\ 0&amp;0\\0&amp;1\\ \end{array} \right)\)<br/>
首先计算\(AA^T=\left ( \begin{array}{cc} 1 &amp; 0\\ 1&amp;1\\ 0&amp;0\\0&amp;1\\ \end{array} \right)\cdot\left ( \begin{array}{cc}  1&amp;1&amp;0&amp;0\\ 0&amp;1&amp;0&amp;1\\ \end{array} \right) = \left(\begin{array}{cc}1 &amp; 1&amp;0&amp;0\\1&amp;2&amp;0&amp;1\\0&amp;0&amp;0&amp;0\\0&amp;1&amp;0&amp;1\\\end{array}\right)\) ，然后计算\(A^TA\)的特征向量就是左奇异矩阵\(U\)。<br/>
\[<br/>
|AA^T-\lambda I| = \left | \begin{array}{cccc}1-\lambda &amp;1&amp;0&amp;0 \\ 1&amp;2-\lambda &amp;0&amp;1 \\0&amp;0&amp; -\lambda&amp;0 \\0&amp;1&amp;0&amp;1-\lambda \\\end{array}\right | = -\lambda\left | \begin{array}{cc}1-\lambda&amp;1&amp;0\\1&amp;2-\lambda&amp;1\\0&amp;1&amp;1-\lambda\end{array}\right|=0\\<br/>
\Rightarrow -\lambda[(1-\lambda)^2(2-\lambda)-2(1-\lambda)] =0<br/>
\]</p>

<p>可以求出\(\lambda_1=3\,,\lambda_2=1\,,\lambda_3=\lambda_4=0\)。<br/>
当\(\lambda_1=3\)时：<br/>
\[<br/>
(AA^T-\lambda I)\overrightarrow{\nu} = \left(\begin{array}{cccc}-2&amp;1&amp;0&amp;0\\1&amp;-1&amp;0&amp;1\\0&amp;0&amp;-3&amp;0\\0&amp;1&amp;0&amp;-2\\\end{array}\right)\left(\begin{array}{c}x_1\\x_2\\x_3\\x_4\\\end{array}\right) \\<br/>
\Rightarrow \left \{ \begin{array}\\-2x_1+x_2=0\\x_1-x_2+x_4=0\\-3x_3=0\\x_2-2x_4=0\\\end{array}\right .<br/>
\]</p>

<p>可以求得其中一个解为\(x1=1\,,x2=2\,,x_3=0\,,x4=1\)，归一化后得：<br/>
\[<br/>
\overrightarrow{\nu} = \left ( \begin{array}{c}<br/>
\frac{1}{\sqrt{6}}\\\frac{2}{\sqrt{6}}\\0\\\frac{1}{\sqrt{6}}\\\end{array}\right)<br/>
\]</p>

<p>同样的方式，可以求出特征矩阵为：<br/>
\[<br/>
V = \left ( \begin{array}{c}<br/>
\frac{1}{\sqrt{6}}&amp;\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\frac{2}{\sqrt{6}}&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
0&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
\frac{1}{\sqrt{6}}&amp;-\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\end{array}\right)<br/>
\]</p>

<p>我们知道这就是左奇异矩阵\(U\)，同理再计算\(A^TA\)的特征值\(\lambda_1=3\,,\lambda_2=1\)，代入求得右奇异矩阵\(V\)：<br/>
\[<br/>
V=\left ( \begin{array}{cc}<br/>
\frac{\sqrt{2}}{2}&amp;\frac{\sqrt{2}}{2}\\\frac{\sqrt{2}}{2}&amp;-\frac{\sqrt{2}}{2}\\<br/>
\end{array} \right )<br/>
\]</p>

<p>前面我们说过\(\Sigma\)主对角线的元素，也就是奇异值，是特征值得平方根，所以可求得：<br/>
\[<br/>
\Sigma = \left ( \begin{array}{cc}<br/>
\sqrt{3}&amp;0\\0&amp;1\\0&amp;0\\0&amp;0\\<br/>
\end{array} \right )<br/>
\]</p>

<p>所以矩阵\(A\)被分解为了3个矩阵的乘积：<br/>
\[<br/>
A = \left ( \begin{array}{c}<br/>
\frac{1}{\sqrt{6}}&amp;\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\frac{2}{\sqrt{6}}&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
0&amp;0&amp;-\frac{1}{2}&amp;\frac{1}{2}\\<br/>
\frac{1}{\sqrt{6}}&amp;-\frac{\sqrt{2}}{2}&amp;\frac{1}{2}&amp;-\frac{1}{2}\\<br/>
\end{array}\right) \cdot \left ( \begin{array}{cc}<br/>
\sqrt{3}&amp;0\\0&amp;1\\0&amp;0\\0&amp;0\\<br/>
\end{array} \right ) \cdot \left( \begin{array}{cc}<br/>
\frac{\sqrt{2}}{2}&amp;\frac{\sqrt{2}}{2}\\\frac{\sqrt{2}}{2}&amp;-\frac{\sqrt{2}}{2}\\<br/>
\end{array} \right )<br/>
\]</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15034227314732.html">主成分分析 PCA</a></h1>
			<p class="meta"><time datetime="2017-08-23T01:25:31+08:00" 
			pubdate data-updated="true">2017/8/23</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在介绍主成分分析之前，简单看一下方差、协方差，特征值，特征向量的概念，了解这些后才能更好了解主成分分析。</p>

<h2 id="toc_0">代数基础知识</h2>

<h4 id="toc_1">方差 variance</h4>

<p>在统计学中，方差被描述为样本与总体平均数之间的差异，假设样本数据为\(X_i\,:\,i=1;2;...;N\)，定义：<br/>
\[<br/>
\mu = \frac{\sum_{i=1}^N X_i}{N}<br/>
\]</p>

<p>为总体平均数，对于总体的方差公式为（\(\sigma^2\)代表方差，\(\sigma\)代表标准差）：<br/>
\[<br/>
\sigma^2 = \frac{\sum_{i=1}^N (X_i - \mu)^2}{N}<br/>
\]</p>

<p>假设样本均值为\(\overline{X}\)，样本方差定义为为：<br/>
\[<br/>
S^2 = \frac{\sum_{i=1}^N(x_i-\overline{X})^2}{n-1}<br/>
\]</p>

<p>这里的n为样本x的数量，这里和总体方差不同的是除以的是n-1，而不是n，这是由于除以n-1是无偏方差，如果除以n会比总体方差要小。</p>

<blockquote>
<h4 id="toc_2">无偏方差为什么除以n-1？</h4>

<p>假设数据集X上，有多次抽样\(X_1\)、\(X_2\)、...、\(X_n\)，每一个样本的平均值即为\(\overline{X_1}\)、\(\overline{X_2}\)、...、\(\overline{X_n}\)，随着抽样的次数逐渐增多，样本平均值的平均值将会越来越近总体平均值，即\(E(\overline{X}) = \mu\)，此时也就是无偏估计。</p>

<p>首先我们来假设无偏方差是如下形式：<br/>
\[<br/>
S^2 = \frac{1}{n}\sum_{i=1}^N(x_i-\overline X)^2<br/>
\]<br/>
所以求无偏方差的期望为：<br/>
\[<br/>
\begin{align*}<br/>
E[S^2] &amp;= E[\frac{1}{n} \sum_{i=1}^N(x_i-\overline X)^2] \\<br/>
&amp;= E[\frac{1}{n} \sum_{i=1}^N (x_i - \mu + \mu - \overline X)^2] \\<br/>
&amp;= E[\frac{1}{n} \sum_{i=1}^N [(x_i - \mu)^2 + 2(x_i - \mu)(\mu - \overline{X}) + (\mu - \overline{X})^2]] \\<br/>
&amp;= E[\frac{1}{n} \sum_{i=1}^N(x_i-\mu)^2 + \frac{1}{n}\sum_{i=1}^N 2(x_i - \mu)(\mu-\overline{X})+\frac{1}{n}\sum_{i=1}^N(\mu-\overline{X})^2] \\<br/>
&amp;\because\quad\frac{1}{n}\sum_{i=1}^N(x_i-\mu) = \frac{1}{n}\sum_{i=1}^Nx_i-\frac{1}{n}\sum_{i=1}^N\mu = \overline{X} - \mu \\<br/>
E[S^2]&amp;= E[\frac{1}{n}\sum_{i=1}^N(x_i-\mu)^2 + 2(\overline{X}-\mu)(\mu - \overline{X}) + (\mu-\overline{X})^2] \\<br/>
&amp;=E[\frac{1}{n}\sum_{i=1}^N(x_i-\mu)^2 - (\overline{X} - \mu)^2] \\<br/>
&amp;=E[\frac{1}{n}\sum_{i=1}^N(x_i-\mu)^2] - E[(\overline{X}-\mu)^2] \\<br/>
&amp;=\sigma^2-E[(\overline{X} - \mu)^2]<br/>
\end{align*} <br/>
\]</p>

<p>并有：<br/>
\[<br/>
\begin{align*}<br/>
E[(\overline{X}-\mu)^2] &amp;= E[(\overline{X}-E(\overline{X}))^2] = var(\overline{X})\\<br/>
&amp;= var(\frac{\sum_{i=1}^n X_i}{n}) \\<br/>
&amp;= \frac{1}{n^2}var(\sum_{i=1}^n X_i) \\<br/>
&amp;= \frac{1}{n^2}\sum_{i=1}^N var(X_i) \\<br/>
&amp;= \frac{1}{n}\sigma^2<br/>
\end{align*}<br/>
\]<br/>
所以：<br/>
\[<br/>
E(S^2) = \sigma^2 - E[(\overline{X} - \mu)^2] = \sigma^2-\frac{\sigma^2}{n} = \frac{n-1}{n}\sigma^2<br/>
\]<br/>
由证明其实可知我们假设的无偏方差其实是有偏差的，它比总体方差要小，此时如果我们想要得到无偏方差\(\sigma^2\)，我们希望\(S^2\)乘上\(\frac{n}{n-1}\)，得到：<br/>
\[<br/>
S^2 = \frac{n}{n-1}(\frac{1}{n} \sum_{i=1}^N(x_i-\overline X)^2) = \frac{1}{n-1}\sum_{i=1}^N(x_i-\overline X)^2<br/>
\]<br/>
证明：<br/>
\[<br/>
\begin{align*}<br/>
E[S^2] &amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i - \mu + \mu - \overline{X})^2] \\<br/>
&amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2+\frac{1}{n-1}\sum_{i=1}^N2(x_i-\mu)(\mu-\overline{X}) + \frac{1}{n-1}\sum_{i=1}^N (\mu-\overline{X})^2] \\<br/>
&amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2 - \frac{2n}{n-1}(\mu-\overline{X})^2 + \frac{n}{n-1}(\mu-\overline{X})^2] \\<br/>
&amp;= E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2 - \frac{n}{n-1}(\mu-\overline{X})^2] \\<br/>
&amp;=E[\frac{1}{n-1}\sum_{i=1}^N (x_i-\mu)^2] - E[\frac{n}{n-1}(\mu-\overline{X})^2] \\<br/>
&amp;=\frac{n}{n-1}E[\frac{1}{n}\sum_{i=1}^N (x_i-\mu)^2] - \frac{n}{n-1}E[(\mu-\overline{X})^2] \\<br/>
&amp;=\frac{n}{n-1}\sigma^2-\frac{n}{n-1} \cdot\frac{\sigma^2}{n} \\<br/>
&amp;= \sigma^2<br/>
\end{align*}<br/>
\]<br/>
得证。无偏方差为：<br/>
\[<br/>
S^2 = \frac{1}{n-1}\sum_{i=1}^N(x_i-\overline X)^2<br/>
\]</p>
</blockquote>

<h4 id="toc_3">协方差 Covariance</h4>

<p>由前面对方差的定义可知，方差是衡量数据集中数据与平均值的偏离程度，方差处理的是一维数据的情况，而在现实生活中我们处理的多是多维数据，描述的往往是多个数据同时偏离平均值的程度。我们可以仿照方差的形式：<br/>
\[<br/>
var(X) = \frac{1}{n-1}\sum_{i=1}^N (X_i - \overline{X}) = \frac{1}{n-1} \sum_{i=1}^N (X_i - \overline{X})(X_i-\overline{X})<br/>
\]<br/>
定义协方差：<br/>
\[<br/>
cov(X,Y) = \frac{1}{n-1}(X_i - \overline{X})(Y_i - \overline{Y})<br/>
\]</p>

<p>通常我们可以用偏方差来描述两个维度的数据的相关性，偏方差为正数表示两者是正相关的，反之为负数表示两者负相关，如果为0，表示两者互相独立。由协方差的定义容易知：<br/>
\[<br/>
var(X) = cov(X,X)<br/>
cov(X,Y) = cov(Y,X)<br/>
\]</p>

<p>由定义可知，协方差每次只可以描述两个维度数据，如果我们有n维数据，那么往往就需要计算\(\frac{1}{2}n(n-1)\)个协方差，于是便引入了协方差矩阵。一个三维的协方差矩阵如下所示：<br/>
\[<br/>
C = \left ( \begin{array}{ccc}<br/>
cov(x,x) &amp;&amp; cov(x,y) &amp;&amp; cov(x,z) \\<br/>
cov(y,x) &amp;&amp; cov(x,x) &amp;&amp; cov(y,z) \\<br/>
cov(z,x) &amp;&amp; cov(z,y) &amp;&amp; cov(z,z) \\<br/>
\end{array} \right)<br/>
\]</p>

<blockquote>
<p>散度矩阵：协方差矩阵的计算有除以\((n-1)\)的步骤，如果没有没有这个步骤获得的矩阵即是散度矩阵。换言之，散度矩阵等于协方差矩阵乘以\((n-1)\)。</p>
</blockquote>

<h4 id="toc_4">特征值和特征向量</h4>

<p>对于一个向量\(A\)，通过应用非零向量\(\overrightarrow{\nu}\)后仅仅相当于将\(\overrightarrow{\nu}\)同比例的缩放\(\gamma\)倍，那么我们称\(\overrightarrow{\nu}\)是特征向量，\(\gamma\)是特征值：<br/>
\[<br/>
A\overrightarrow{\nu} = \lambda\overrightarrow{\nu}<br/>
\]</p>

<p>1、对于一个方阵A，如果存在可逆向量P，满足\(P^{-1}AP=\Lambda\)，\(\Lambda\)是一个对角矩阵，这样我们可以说方阵A可对角化。</p>

<p>首先变换表示形式，将P用其列向量的形式表示\(P = (p_1,p_2,...,p_n)\)，对角矩阵\(\Lambda\)的表示形式如下：<br/>
\[<br/>
\Lambda = \left [ \begin{array} \\<br/>
\lambda_1&amp;&amp;           &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp; \lambda_2 &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp; \ddots &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp;        &amp;&amp; \lambda_n \\<br/>
\end{array}\right ]<br/>
\]</p>

<p>得：<br/>
\[<br/>
P^{-1}AP=\Lambda \Rightarrow AP = P\Lambda<br/>
\Rightarrow A(p_1,p_2,...,p_n) = (p_1,p_2,...,p_n)\left [\begin{array} \\<br/>
\lambda_1&amp;&amp;           &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp; \lambda_2 &amp;&amp;        &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp; \ddots &amp;&amp; \\<br/>
         &amp;&amp;           &amp;&amp;        &amp;&amp; \lambda_n \\<br/>
\end{array}\right] \\<br/>
\Rightarrow (Ap_1,Ap_2,...,Ap_n) = (\lambda_1p_1,\lambda_2p_2,...,\lambda_np_n)<br/>
\]</p>

<p>由上式可知：\(Ap_n=\lambda_np_n\)，所以可以看成对角矩阵的每一个元素\(\lambda_n\)都是方阵A的特征值，可逆矩阵P对应位置的列向量\(p_n\)是其特征向量。</p>

<p>2、对于一个可逆矩阵A，它的逆矩阵的特征值是原矩阵的倒数。设\(\lambda\)是其特征值，\(\overrightarrow{\nu}\)是特征向量，则有：<br/>
\[<br/>
A\overrightarrow{\nu} = \lambda\overrightarrow{\nu}<br/>
\] </p>

<p>两边同时左乘\(A^{-1}\)，可得：<br/>
\[<br/>
\overrightarrow{\nu} = \lambda A^{-1}\overrightarrow{\nu} \\<br/>
\Rightarrow \frac{1}{\lambda}\overrightarrow{\nu} = A^{-1} \overrightarrow{\nu} \\<br/>
\]</p>

<p>所以可知，逆矩阵的特征值是原矩阵的倒数。</p>

<p>3、复正规矩阵的特征向量和特征值</p>

<p>对角矩阵、实对称矩阵(\(A^T=A\))、反实对称矩阵(\(A^T = -A\))、厄米特矩阵(\(A^H=A\))、反厄米特矩阵(\(A^H=-A\))、正交矩阵(\(AA^T=A^TA=I\))、酉矩阵(\(AA^H=A^HA=I\))等满足\(AA^H=A^HA\)条件的矩阵都叫正规矩阵。并不是正规矩阵，都是对角矩阵、实对称、反实对称矩阵等，比如\(\left [ \begin{array}{lr} 1&amp; -1\\1&amp;1\\\end{array}\right]\)，不属于上面，但是它满足\(AA^T=A^TA\)，因此也是正规矩阵。</p>

<p>定理：对于正规矩阵\(A\)都存在酉矩阵\(Q\)使得：<br/>
\[<br/>
Q^HAQ = Q^{-1}AQ = \Sigma=\left [ \begin{array}\\\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n\\\end{array}\right]<br/>
\]</p>

<p>证明：可以通过\(A\)可以通过酉向量\(P\)化为上（下）三角矩阵\(B\)，即\(B=P^TAP\)，再由\(B^TB=P^TA^TPP^TAP=P^TA^TAP=P^TAA^TP=BB^T\)，因为\(B\)是上（下）三角矩阵，通过比较\(BB^T=B^TB\)对角线位置的元素，可知\(B\)是对角矩阵。</p>

<p>所以对于任意的复正规矩阵具有一组正交特征向量基，复正规矩阵可以被分解为：<br/>
\[<br/>
A = U \Sigma U^H<br/>
\]</p>

<p>其中U为一个酉矩阵，进一步：<br/>
\(A\)为厄米特矩阵\(\quad\Leftrightarrow\quad\)\(\Sigma\)的每个对角元都为实数。<br/>
\(A\)为反厄米特矩阵\(\quad\Leftrightarrow\quad\)\(\Sigma\)的每个对角元都为0或虚数。<br/>
\(A\)为酉矩阵\(\quad\Leftrightarrow\quad\)\(\Sigma\)的全部特征元的模为1。</p>

<p>继续：<br/>
\[<br/>
\begin{align*}<br/>
&amp;A = U \Sigma U^H \\<br/>
\Rightarrow &amp;AU = U\Sigma\\<br/>
\Rightarrow &amp;A(u_1,u_2,...,u_3) = (u_1,u_2,...,u_3)\left [ \begin{array}\\\lambda_1&amp;&amp;&amp;\\&amp;\lambda_2&amp;&amp;\\&amp;&amp;\ddots&amp;\\&amp;&amp;&amp;\lambda_n\\\end{array}\right]\\<br/>
\Rightarrow &amp;(Au_1,Au_2,...,Au_3) = (\lambda_1u_1,\lambda_2u_2,...,\lambda_nu_n)\\<br/>
\Rightarrow &amp; Au = \lambda u\\<br/>
\end{align*}<br/>
\]</p>

<p>4、求解特征值和特征矩阵。由特征值和特征向量的定义易看出如何求解，首先是求出其特征值：<br/>
\[<br/>
A\overrightarrow{\nu} = \lambda \overrightarrow{\nu} \\<br/>
\Rightarrow (A-\lambda I)\overrightarrow{\nu} = 0<br/>
\]</p>

<p>由于特征向量\(\overrightarrow{\nu}\)不为0，所以可知\(|A-\lambda I| = 0\)，这样便可以求出特征值\(\lambda\)，再带回原式中求出特征向量\(\overrightarrow{\nu}\)</p>

<p>假设求解\(A = \left( \begin{array}{ccc}<br/>
-1 &amp;&amp; 1 &amp;&amp; 0 \\<br/>
-4 &amp;&amp; 3 &amp;&amp; 0 \\<br/>
1 &amp;&amp; 0 &amp;&amp; 2 \\<br/>
\end{array} \right)<br/>
\)的特征向量和特征值，按照之前描述需要先求出特征值，所以：<br/>
\[<br/>
\begin{align*}<br/>
|A - \lambda I | &amp;= \left | \begin{array}{ccc}<br/>
-1-\lambda &amp;&amp; 1 &amp;&amp; 0 \\<br/>
-4 &amp;&amp; 3 - \lambda &amp;&amp; 0\\<br/>
1 &amp;&amp; 0 &amp;&amp; 2-\lambda \\<br/>
\end{array} \right| = (2-\lambda)\left | \begin{array}{ccc}<br/>
-1-\lambda &amp;&amp; 1 \\<br/>
-4 &amp;&amp; 3-\lambda \\<br/>
\end{array} \right | \\<br/>
&amp;=(2-\lambda)[(-1-\lambda)(3-\lambda)+4] \\<br/>
&amp;=(2-\lambda)(\lambda^2-3\lambda+\lambda+1) \\<br/>
&amp;=(2-\lambda)(\lambda^2-2\lambda+1) \\<br/>
&amp;=(2-\lambda)(\lambda-1)^2 = 0<br/>
\end{align*}<br/>
\]</p>

<p>所以可得\(\lambda=1\)或\(\lambda=2\)。<br/>
当\(\lambda=1\)时：<br/>
\[<br/>
(A-\lambda I)\overrightarrow{\nu} = \left ( \begin{array}{ccc}<br/>
-2 &amp;&amp; 1 &amp;&amp; 0 \\<br/>
-4 &amp;&amp; 2 &amp;&amp; 0 \\<br/>
1 &amp;&amp; 0 &amp;&amp; 1 \\<br/>
\end{array} \right )\left( \begin{array} \\<br/>
x_1 \\<br/>
x_2 \\<br/>
x_3 \\<br/>
\end{array} \right) = 0\\<br/>
\Rightarrow \left \{ \begin{array}\\<br/>
-2x_1 + x_2 = 0\\<br/>
-4x_1 + 2x_2 = 0\\<br/>
x_1 + x_3 = 0\\<br/>
\end{array} \right.<br/>
\]</p>

<p>易得相应的特征向量为：\(P=\left( \begin{array}{ccc} -1 \\ -2 \\ 1 \\ \end{array} \right)\)，<br/>
同理可求得当\(\lambda=2\)是，特征向量为：\(P=\left( \begin{array}{ccc} 0 \\ 0 \\ 1 \\ \end{array} \right)\)</p>

<h2 id="toc_5">主成分分析 PCA</h2>

<p>PCA的英文名称就做Principle Component analysis，是一种常用的数据分析方法。他通过对原始数据进行线性变换，将数据转变为各维度线性无关的表示，可以用于数据降维和压缩。在机器学习中，经常我们需要处理的数据是几千维甚至是几十万维度的数据，如果直接处理，不论是对计算机性能、算法性能还是对训练时间度的要求都大大增大，这时候对高维数据降维，且不能丢失主要的信息。那么我们该如何确定该删掉哪些维度的数据呢？还有如何在最大限度减小维度的同时又能让信息损失最低呢？这就是PCA可以做的事。</p>

<p>PCA的主要目的在于保留最大信息量的同时降噪，如图：</p>

<div align="center">
    <img src="media/15034227314732/15272993250127.jpg" width="400px" />
</div>

<p>直观上来看将元素在红线上的投影来描述信息对信息的损失比蓝线要小很多，所以也就是希望投影后的方差最大化。信息处理认为信号具有较大的方差，噪音拥有较小的方差，信噪比就是信号与噪音的方差比。因此在PCA中，我们需要将数据有原始的m维数据转换到新的k维空间中，也就是我们需要找到k个正交基来描述空间。新的坐标系的选择与原始数据的构成有关，通常我们选择能使原始数据方差最大的方向作为第一个坐标轴，第二个坐标轴的选择是与第一个坐标轴正交且原始数据的投影方差最大的方向，依次类推选择k个坐标轴。</p>

<p>用一个例子来描述PCA的过程，假设我们有一个数据集如下：</p>

<p>\[<br/>
Data = \left . \begin{array}{c|c}<br/>
x &amp; y \\<br/>
\hline<br/>
2.5 &amp; 2.4 \\<br/>
0.5 &amp; 0.7 \\<br/>
2.2 &amp; 2.9 \\<br/>
1.9 &amp; 2.2 \\<br/>
3.1 &amp; 3.0 \\<br/>
2.3 &amp; 2.7 \\<br/>
2 &amp; 1.6 \\<br/>
1 &amp; 1.1 \\<br/>
1.5 &amp; 1.6 \\<br/>
1.1 &amp; 0.9 \\<br/>
\end{array} \right .<br/>
\]</p>

<p>我们首先需要求出数据集的协方差，由协方差计算公式可知需要先求出x和y分别的平均数：\(\overline{x} = 1.81,\,\overline{y} = 1.91\)，然后易求出协方差：<br/>
\[<br/>
Cov(Data) = \left ( \begin{array}{cc}<br/>
cov(x,x) &amp; cov(x,y) \\<br/>
cov(y,x) &amp; cov(y,y) \\<br/>
\end{array}\right) = \left ( \begin{array}{cc}<br/>
0.616555556 &amp; 0.615444444 \\<br/>
0.615444444 &amp; 0.716555556 \\<br/>
\end{array} \right )<br/>
\]</p>

<p>接下来求出该协方差矩阵的特征值，令\(A = Cov(Data)\)：<br/>
\[<br/>
\begin{align*}<br/>
| A - \lambda I| &amp;= \left | \begin{array}{cc}<br/>
0.616555556-\lambda &amp; 0.615444444 \\<br/>
0.615444444 &amp; 0.716555556-\lambda \\<br/>
\end{array} \right | = (0.616555556-\lambda)(0.716555556-\lambda)-0.615444444^2 \\<br/>
&amp;= \lambda^2 - 1.333111112\lambda + 0.06302445 = 0 \\<br/>
\end{align*}<br/>
\]</p>

<p>由一元二次方程的求解易得：<br/>
\[<br/>
\lambda = \left ( \begin{array}{cc}<br/>
1.28402770 \\<br/>
0.04908340 \\<br/>
\end{array}\right )<br/>
\]</p>

<p>将特征值排序后，选择k个最大的特征值，因为这里只有2个特征值，假设k=1，则取最大特征值\(\lambda\)=1.28402770，然后计算对应的特征向量：<br/>
\[<br/>
(A - \lambda I )\overrightarrow{\nu} = \left ( \begin{array}{cc}<br/>
-0.667472144 &amp; 0.615444444 \\<br/>
0.615444444 &amp; -0.567472144 \\<br/>
\end{array} \right ) \left(\begin{array} \\<br/>
x_1\\<br/>
x_2\\<br/>
\end{array} \right ) \\<br/>
\Rightarrow \left \{ \begin{array}\\<br/>
-0.667472144 x_1 + 0.615444444 x_2 = 0\\<br/>
0.615444444 x_1 - 0.567472144 x_2 = 0<br/>
\end{array} \right .<br/>
\]</p>

<p>很容易算出其中一个解:<br/>
\[<br/>
\overrightarrow{\nu} = \left \{ \begin{array} \\0.67787339 \\0.73517867 \\\end{array} \right.<br/>
\]</p>

<p>再将样本数据乘上特征向量，得到投影后的在一维空间内新数据：<br/>
\[<br/>
data^1 = \left ( \begin{array}{cc}<br/>
3.45911228 \\<br/>
0.85356176\\<br/>
3.6233396 \\<br/>
2.90535252 \\<br/>
4.30694352 \\<br/>
3.54409121 \\<br/>
2.53203265 \\<br/>
1.48656993 \\<br/>
2.19309596 \\<br/>
1.40732153 \\<br/>
\end{array} \right )<br/>
\]</p>

<p>如果说我们的目的是将原数据从二维空间降维到一维空间，那么现在已经完成了。这里也完成了对数据的压缩，现在我们可以通过\(data^1\)和\(\overrightarrow{\nu}\)来表示原始数据，可以用\(data^1\)乘上\(\overrightarrow{\nu}^T\)来还原原始数据：<br/>
\[<br/>
data^{new} = data^1 \overrightarrow{\nu}^T = \left ( \begin{array}{cc}<br/>
2.34484017 &amp;  2.54306557\\<br/>
0.57860681 &amp;  0.6275204 \\<br/>
2.4561655 &amp;  2.66380199\\<br/>
1.96946116 &amp;  2.1359532 \\<br/>
2.9195624 &amp;  3.16637301\\<br/>
2.40244512 &amp;  2.60554026\\<br/>
1.71639756&amp;   1.8614964 \\<br/>
1.0077062 &amp;   1.0928945 \\<br/>
1.48664139&amp;  1.61231737 \\<br/>
0.95398582&amp;  1.03463277 \\<br/>
\end{array} \right )<br/>
\]</p>

<p>和原始数据对比发现，压缩后的数据保留了大多数信息。</p>

<h4 id="toc_6">矩阵的迹</h4>

<p>在继续下面的PCA的最近重构解释小节之前，需要一些矩阵的迹的了解。在线性代数中，一个n*n的方阵A，主对角线上的各元素之和为矩阵的迹或者迹数，一般即为tr(A)。</p>

<p>矩阵\(A=(a_1,a_2,...,a_i)\)的F范数与矩阵的迹的关系为\(||A||_F^2 = tr(AA^T)\)：<br/>
\[<br/>
||A||_F^2 = \sum_{i=1}^N \sum_{j=1}^N a_{ij}^2 \\<br/>
(AA^T)_{ij} = A_i^TA_j = \sum{k=1}^N a_{ik}a_{jk} \\<br/>
tr(AA^T) = \sum_{i=1}^N (AA^T)_{ii} = \sum_{i=1}^N \sum_{k=1}^N a_{ik}^2 = ||A||_F^2<br/>
\]</p>

<p>矩阵的迹满足几个性质：</p>

<p>(1) \(tr(A+B) = tr(A)+tr(B)\)</p>

<p>证明：<br/>
\[<br/>
\because\quad(A+B)_{ij} = A_{ij}+B_{ij} \\<br/>
\therefore\quad tr(A+B) = \sum_i^N (A+B)_{ii} = \sum_{i=1}^N (A_{ii}+B_{ii}) = \sum_{i=1}^N A_{ii} + \sum_{j=1}^N B_{jj} = tr(A) + tr(B)<br/>
\]</p>

<p>(2) \(tr(AB) = tr(BA)\)</p>

<p>证明：<br/>
\[<br/>
\begin{align*}<br/>
\because \quad &amp;(AB)_{ij} = \sum_{k=1}^N a_{i,k}b_{k,j} \\<br/>
&amp;(BA)_{ij} = \sum_{k=1}^N b_{i,k} a_{k,j} \\<br/>
\therefore \quad &amp; tr(AB) = \sum_{i=1} (AB)_{ii} = \sum_{i=1}^N \sum_{k=1}^N a_{i,k} b_{k,i} =    tr(BA)<br/>
\end{align*}<br/>
\]</p>

<p>(3) 由(2)知：\(tr(ABC)=tr(CAB) = tr(CBA)\)<br/>
(4) 由转置的性质可知：\(tr(A) = tr(A^T)\)<br/>
(5) \(\nabla_{A} tr(AB) = B^T \)<br/>
(6) \(\nabla_{A} tr(ABA^TC) = CAB+C^T+AB^T \)<br/>
使用链式求导证明：<br/>
\[<br/>
\nabla_A tr(ABA^TC) = (A^TC)^T\nabla_A tr(AB) + AB \nabla_A tr(A^TC) = C^TAB^T + C^TAB<br/>
\]</p>

<h4 id="toc_7">PCA的最近重构解释</h4>

<p>假设数据集\(D=(x_1,x_2,...,x_m)\)，样本大小为m，原始数据为x_i为\(n\)维数据，再假定投影变换后得到的新坐标系为\((w_1,w_2,...,w_n)\)，正交向量有\(||w_i||=1,||w_iw_j||=0:j\neq i\)，若丢弃了部分新坐标系的坐标，即维度降低到\(k\)维（\(k&lt;m\)），那么\(x_i\)在低维坐标系中\(z_i=(z_{i1},z_{i2},...,z_{ik})\)，其中\(z_{ij}=w_j^Tx_i\)是\(x_i\)在低维坐标系第\(j\)维的坐标，若基于\(z_i\)来重构\(x_i\)，则\(\hat{x_i} = \sum_{j=1}^k z_{ij}w_j\)：</p>

<p>我们希望在映射到新空间后保存最大信息，定义损失函数为：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^m ||\hat {x_i}-x_i||_F^2 &amp;= \sum_{i=1}^m ||\sum_{j=1}^k z_{ij}w_j - x_i||_F^2 \\<br/>
&amp;= \sum_{i=1}^m(\sum_{j=1}^k\sum_{l=1}^k z_{ij}w_jz_{il}w_l - 2\sum_{j=1}^k z_{ij}w_j x_i + x_i^2) \\<br/>
\end{align*}<br/>
\]</p>

<p>由\(w_i^2 = 1\)和\(w_iw_j=0\)可知：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^m ||\hat {x_i}-x_i||_F^2 &amp;= \sum_{i=1}^m z^Tz - 2\sum_{i=1}^m z_i^TW^Tx_i + const<br/>
\end{align*}<br/>
\]</p>

<p>根据\(tr(AB)=tr(BA)\)以及\(z = W^Tx_i\)（关于矩阵的迹的性质不了解的可以，看文章最后），得：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^m ||\hat {x_i}-x_i||_F^2 &amp;= -tr(W^T(\sum_{i=1}^m x_ix_i^T) W) + const \\<br/>
&amp;= -tr(W^TXX^TW) + const<br/>
\end{align*}<br/>
\]</p>

<p>所以原始问题方程组为求解方程组的极大值：<br/>
\[<br/>
\begin{align*}<br/>
min_{W}\quad&amp; -tr(W^TXX^TW) + const\\<br/>
s.t. \quad&amp;WW^T = I \\<br/>
\end{align*}<br/>
\]</p>

<p>利用拉格朗日乘子法，引入拉格朗日乘子\(\alpha\)：<br/>
\[<br/>
L(W,\alpha) = -tr(W^TXX^TW) + const + \alpha(I-WW^T)<br/>
\]</p>

<p>那现在原始问题便变成了求解拉格朗日函数极大极小问题，先求\(L(W,\alpha)\)的最小值，让\(L(W,\alpha)\)对\(W\)求导得：<br/>
\[<br/>
\nabla_W L(W,\alpha) = X^TXW - \alpha W = 0 \\<br/>
\Rightarrow X^TXW = \alpha W<br/>
\]</p>

<p>所以求得最优解时\(W\)为协方差矩阵\(X^TX\)的特征向量，特征值越大的特征向量所包含的信息越丰富。</p>

<h4 id="toc_8">高维空间的PCA运算</h4>

<p>在现实生活中，由于样本的高维特征，比如在图像处理中，图像的每一个像素都是一个维度。如果我们采用上面的PCA方法运算，先计算协方差，那么我们将会得到一个n*n的协方差矩阵，这个矩阵不论是计算还是存储都比较复杂，因此不可取。</p>

<p>在高维特征中，假设有100个样本组成数据集\(X=(x_1,x_2,...,x_{100})\)，每一个样本的维度为10000维，那么协方差矩阵\(C=XX^T\)将是10000维的方阵，考虑一个替代的矩阵\(T=X^T\)代替协方差矩阵，，假设\(\lambda\)和\(P\)分别为协方差矩阵的特征值和特征向量，所以有：<br/>
\[<br/>
XX^TP = \lambda P \Leftrightarrow CP = \lambda P<br/>
\]</p>

<p>若\(\lambda^{new}\)和\(P^{new}\)为替代矩阵的特征值和特征向量：<br/>
\[<br/>
X^TXP^{new} = \lambda^{new} P^{new}<br/>
\]</p>

<p>两边同时左乘\(X\)，那么：<br/>
\[<br/>
XX^TXP^{new} = X\lambda^{new} P^{new} \Rightarrow XX^T(XP^{new}) = \lambda^{new}(XP^{new}) \\<br/>
\Rightarrow C(XP^{new}) = \lambda (XP^{new})<br/>
\]</p>

<p>通过上式可以知道协方差矩阵的特征值等于替代矩阵的特征值，其特征向量等于替代矩阵的特征向量左乘上\(X\)，所以我们可以通过求解替代矩阵的特征值和特征向量来完成PCA操作。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15025588355749.html">支持向量机 SVM</a></h1>
			<p class="meta"><time datetime="2017-08-13T01:27:15+08:00" 
			pubdate data-updated="true">2017/8/13</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>支持向量机（support vector machine，SVM）是一个有监督的机器学习算法，它的基本模型是定义在特征空间的间隔最大的线性分类器。利用核技巧将输入数据映射到高维空间，来实现非线性分类器。</p>

<h2 id="toc_0">支持向量机基础</h2>

<p>为了方便讲明白SVM的工作原理，下面主要结合图片和公式说明，如图1，假设在二维空间里有两类线性可分的数据，直观上看，很容易在中间画出一条线将两类数据分开。</p>

<div align="center">
    <img src="media/15025588355749/15263132529256.jpg" width="350"></img>
    <center>图1：二维空间里数据</center>
    <br/>
</div>

<p>定义超平面（即分割线）可以通过如下线性方程组来描述：<br/>
\[<br/>
\begin{equation}<br/>
\boldsymbol w^T \boldsymbol x + b = 0<br/>
\end{equation}<br/>
\]</p>

<p>其中\(\boldsymbol w=(w_1;w_2;w_3;...;w_d)\,\)为法向量，\(b\,\)是超平面的截距，显然这个划分超平面可以被这两个参数\(\boldsymbol w\,\)和\(\,b\,\)确定，后面此超平面将简称为超平面（\(\boldsymbol w\),\(b\)）。</p>

<p>假设超平面能很好的将训练样本分类，如果定义图1中红色点为正类，即\(y_i=1\)，此时希望\(\boldsymbol w^T \boldsymbol x &gt; 0\)，另一侧蓝色点为负类，即\(y_i=-1\)，此时希望\(\boldsymbol w^T \boldsymbol x &lt; 0\)，易知分类决策函数可以定义为：</p>

<p>\[<br/>
\begin{equation}<br/>
y = sign(\boldsymbol w_T \boldsymbol x + b)<br/>
\end{equation}<br/>
\]</p>

<p>如图2所示，两个超平面都能满足条件，那到底哪个超平面才是最优的超平面呢？也就是\(\boldsymbol w \)和\(\,b\,\)应该如何确定其最优值。</p>

<div align="center">
    <img width="350" src="media/15025588355749/15263148208656.jpg" />
    <p>图2：超平面</p>
</div>

<h4 id="toc_1">函数间隔（Function Margin）</h4>

<p>对于给定的超平面（\(\boldsymbol w,b\)），定义超平面关于点（\(x_i,y_i\)）的函数间隔为<br/>
\[<br/>
\begin{equation}<br/>
\label{gammahat}<br/>
    \hat\gamma_i=y_i(\boldsymbol w^T \boldsymbol x_i+b)<br/>
\end{equation}<br/>
\]</p>

<p>定义超平面关于整个数据集\(\,T\,\)的函数间隔为数据集内关于所有点函数间隔的最小值：<br/>
\[<br/>
    \hat\gamma = \min \hat\gamma_i\,,i=1;2;...;N<br/>
\]</p>

<p>函数间隔可以表示分类预测的正确性和确信度，但是选择分离超平面仅靠函数间隔是不够的。超平面的选择是希望间隔最大化，如果使用函数间隔表示，那么成比例的增大\(\boldsymbol w\)和\(b\)，比如将它们改为\(2\boldsymbol w\)和\(2b\)，那么就能使函数间隔增大2倍，可是实际我们知道这对超平面的选择没有任何帮助。因此我们需要对函数间隔归一化，这也就变成了几何间隔。</p>

<p>\[<br/>
\gamma_i = \frac{y_i(\boldsymbol w^T \boldsymbol x_i + b)}{||\boldsymbol w||}<br/>
\]</p>

<h4 id="toc_2">几何间隔（Geometric Margin)</h4>

<p>如图3，定义点\(A\)与超平面的距离为超平面关于点\(A\)的几何间隔，由距离公式可知<br/>
\[<br/>
    \gamma_i = \frac{|\boldsymbol w^T \boldsymbol x_i + b|}{||\boldsymbol w||}<br/>
\]</p>

<blockquote>
<p>距离公式：点（\(x_0,y_0\)）到点\(Ax+By+C=0\)的距离为：<br/>
\[d = \frac{|Ax_0+By_0+C|}{\sqrt{A^2+B^2}}\]</p>
</blockquote>

<p>当点\(y_i=1\)时，\(\boldsymbol w^T \boldsymbol x_i + b&gt;0\)，有：<br/>
\[|\boldsymbol w^T \boldsymbol x_i + b| = y_i(\boldsymbol w^T \boldsymbol x_i + b) \]<br/>
当点\(y_i=-1\)时，\(\boldsymbol w^T \boldsymbol x_i + b&lt;0\)，有：<br/>
\[|\boldsymbol w^T \boldsymbol x_i + b| = y_i(\boldsymbol w^T \boldsymbol x_i + b) \]</p>

<p>所以超平面关于点\(A\)（\(x_0,y_0\)）的几何间隔可以表示为：<br/>
\[<br/>
\begin{equation}<br/>
\label{gamma}<br/>
\gamma_i = y_i(\frac{\boldsymbol w^T x_i + b}{||w||})=y_i(\frac{\boldsymbol w^T}{|\boldsymbol w|}x_i+\frac{b}{||\boldsymbol w||})<br/>
\end{equation}<br/>
\]</p>

<p>定义超平面关于整个数据集\(\,T\,\)的几何间隔为数据集内关于所有点的几何间隔的最小值：<br/>
\[<br/>
    \gamma = \min \gamma_i\,,i=1;2;...;N<br/>
\]</p>

<p>从公式\((\ref{gammahat})和(\ref{gamma})\)可知函数间隔和几何间隔的关系为：<br/>
\[<br/>
    \gamma_i = \frac{\hat\gamma_i}{||\boldsymbol w||}\\<br/>
    \gamma = \frac{\hat\gamma}{||\boldsymbol w||}<br/>
\]</p>

<p>如果\(||w||=1\)时，函数间隔和几何间隔相等，当\(\boldsymbol w\)和\(b\)成比例的增大时，函数间隔相应增大，而几何间隔不变。</p>

<p>现在可以知道，最大间隔分离超平面的问题可以表示为如下的方程组：</p>

<p>\[<br/>
\begin{align}<br/>
\max_{\boldsymbol w,b}\quad&amp;\gamma \\<br/>
s.t\quad&amp;y_i(\frac{\boldsymbol w^T}{|\boldsymbol w|}x_i+\frac{b}{||\boldsymbol w||}) \ge \gamma\,,i=1;2;...;N<br/>
\end{align}<br/>
\]</p>

<p>考虑到函数间隔和几何间隔的关系式，可将上面方程组改写为：</p>

<p>\[<br/>
\begin{align*}<br/>
\max_{\boldsymbol x,b}\quad&amp;\frac{\hat\gamma}{||\boldsymbol w||}\\<br/>
s.t.\quad&amp;y_i(\boldsymbol w^T x_i+b) \ge \hat\gamma<br/>
\end{align*}<br/>
\]</p>

<p>上面已经讨论过函数间隔的取值并不影响几何间隔的变化（将\(\boldsymbol w\)和\(b\)成比例的增大或缩小\(\lambda\)倍，函数间隔就能相应变化\(\lambda\)倍，而此时几何间隔不变）。因此对于求解上面方程，函数间隔\(\hat\gamma\)的取值无关紧要，为方便计算，取\(\hat\gamma=1\)，这样方程组变成求\(\frac 1{||w||}\)的最大值。</p>

<p>可以得到最优化方程组为：<br/>
\[<br/>
\begin{align}<br/>
\max_{\boldsymbol x,b}\quad&amp;\frac{1}{||\boldsymbol w||}\\<br/>
\label{8}<br/>
s.t.\quad&amp;y_i(\boldsymbol w^T x_i+b) -1 \ge 0<br/>
\end{align}<br/>
\]</p>

<div align="center">
    <img width="440" src="media/15025588355749/15263213657308.jpg" />
    <p>图3：支持向量与间隔</p>
</div>

<h4 id="toc_3">支持向量（Support Vector）</h4>

<p>如图3所示，如果定义超平面为（\(\boldsymbol w,b\)），则有两条过离超平面最近的两个点的平行线，这两条线到超平面的距离都为\(\gamma\)，其中这两个距离超平面最近的点就是支持向量。支持向量是使公式\((\ref{8})\)等号成立的点，也就是：<br/>
\[<br/>
    y_i(\boldsymbol w^T \boldsymbol x + b)-1 = 0<br/>
\]</p>

<p>这里可以注意到过支持向量的两条线形成一个长带，分离超平面位于中间，长带的宽度被称为间隔，定义间隔为\(H\)，则：<br/>
\[H=2*\gamma=2\frac{\hat\gamma}{||w||}=\frac 2{||w||}\]</p>

<p>在决定分离超平面时只有支持向量起作用，而其他点并不起作用，因此这种分离方法叫做支持向量机。</p>

<h2 id="toc_4">问题求解</h2>

<p>在前面已经提到，找到超平面使间隔最大化相当于求解最优化方程组：</p>

<p>\[<br/>
\begin{align*}<br/>
\max_{\boldsymbol w,b}\quad&amp;\frac{1}{||\boldsymbol w||}\\<br/>
s.t.\quad&amp;y_i(\boldsymbol w^T x_i+b) -1 \ge 0<br/>
\end{align*}<br/>
\]</p>

<p>由于求\(\frac 1 {||w||}\)的最大值其实等价于求解\(\frac1 2||w||^2\)的最小值，所以最优化方程组也就从求解最大值变成求解最小值，即：<br/>
\[<br/>
\begin{align}<br/>
\min_{\boldsymbol w,b}\quad&amp;\frac{1}{2}\boldsymbol ||w||^2 \label{m_w_b} \\<br/>
s.t. \quad &amp; y_i(\boldsymbol w^T \boldsymbol x_i -b) -1 \ge 0 \label{s_t_q_y}\\<br/>
\end{align}<br/>
\]</p>

<p>下面使用拉格朗日乘子法求解这个不等式约束（如果不了解拉格朗日乘子法的，可以看文章后面），定义拉格朗日函数为：<br/>
\[<br/>
\begin{equation}<br/>
\label{svm_L}<br/>
L(\boldsymbol w,b,\alpha) = \frac{1}{2} ||\boldsymbol w||^2 - \sum_{i=1}^N\alpha_i[y_i(\boldsymbol w^T \boldsymbol x+b)-1] \quad s.t. \alpha_i \ge 0<br/>
\end{equation}<br/>
\]</p>

<p>这里将对原始问题的求解变成对拉格朗日对偶问题\(\max_{\alpha} \min_{\boldsymbol w,b}L(\boldsymbol w,b,\alpha)\)求解，这个求解过程可以分成两部分：<br/>
(1)求\(\min_{\boldsymbol w,b}L(\boldsymbol w,b,\alpha)\)</p>

<p>可以直接对\(L(\boldsymbol w,b,\alpha)\)对\(\boldsymbol w\)和\(b\)求导：<br/>
\[<br/>
\begin{align*}<br/>
    \nabla_{\boldsymbol w}L(\boldsymbol w,b,\alpha) &amp;= \boldsymbol w - \sum_{i=1}^N \alpha_i y_i x_i = 0 \\<br/>
    \nabla_{\boldsymbol b}L(\boldsymbol w,b,\alpha) &amp;= -\sum_{i=1}^N \alpha_i y_i = 0<br/>
\end{align*}<br/>
\]</p>

<p>得：<br/>
\[<br/>
\begin{align}<br/>
    \boldsymbol w = \sum_{i=1}^N \alpha_i y_i x_i \label{x_z_0}\\<br/>
    \sum_{i=1}^N \alpha_i y_i = 0 \label{x_z_1}\\<br/>
\end{align}<br/>
\]</p>

<p>将上结果代入公式（\ref{svm_L}）中可得：<br/>
\[<br/>
\begin{align}<br/>
    \min_{w,b}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 - \sum_{i=1}^N \alpha_i[y_i(\sum_{j=1}^N \alpha_j y_j x_j x_i + b) -1] \nonumber\\<br/>
    &amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 - \sum_{i=1}^N \alpha_iy_i(\sum_{j=1}^N \alpha_j y_j x_j x_i + b) +\sum_{i=1}^N \alpha_i \nonumber\\<br/>
    &amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i y_i b +\sum_{i=1}^N \alpha_i \nonumber\\<br/>
    &amp;= -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
\end{align}<br/>
\]</p>

<p>(2)求\(\min_{\boldsymbol w,b}L(\boldsymbol w,b,\alpha)\)对\(\alpha\)的最大值，即：<br/>
\[<br/>
\begin{align}<br/>
&amp;\max_{\alpha} -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
&amp;s.t.\quad\sum_{i=1}^N \alpha_i y_i = 0 \nonumber \\<br/>
&amp;\qquad\quad \alpha_i \ge 0 :i=1;2;...;N \nonumber \\<br/>
\end{align}<br/>
\]</p>

<p>将这个公式变化一下，从求极大值等价转换为求极小值，就可以得到等价最优化方法：<br/>
\[<br/>
\begin{align}<br/>
&amp;\min_{\alpha} \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \alpha_i \label{d_o_0}\\<br/>
&amp;s.t.\quad\sum_{i=1}^N \alpha_i y_i = 0 \label{d_o_1}\\<br/>
&amp;\qquad\quad \alpha_i \ge 0 :i=1;2;...;N \label{d_o_2}\\<br/>
\end{align}<br/>
\]</p>

<p>现在求解原始问题（\ref{m_w_b}）和（\ref{s_t_q_y}）可以转为求解对偶问题（\ref{d_o_0}）~（\ref{d_o_2}），对于线性可分数据集，假设对偶问题（\ref{d_o_0}）~（\ref{d_o_2}）对\(\alpha\)的解为\(\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_N^*)\)。<br/>
根据公式（\ref{x_z_0}）可以求出：<br/>
\[<br/>
\begin{equation}<br/>
\boldsymbol w^* = \sum_{i=1}^N \alpha_i^* y_i x_i \label{d_2_y_0}\\<br/>
\end{equation}<br/>
\]</p>

<p>其中在KKT条件（\ref{d_o_2}）上要求至少有一个\(\alpha_j^* \gt 0\)，因为如果\(\alpha^* = 0\)，那么得出\(w^*=0\)，原始问题中分割超平面将与输入数据无关，总是将所有数据分到一侧，不符合要求。根据KKT条件的互补松弛条件可知：<br/>
\[<br/>
\begin{equation}<br/>
\alpha_i^*(y_i(w^*.x_i+b^*)-1) = 0:i=1;2;...;N<br/>
\end{equation}<br/>
\]</p>

<p>结合至少存在一个\(\alpha^*_j &gt; 0\)，易知：<br/>
\[<br/>
\begin{equation}<br/>
y_j(w^*.x_j+b^*)-1 = 0<br/>
\end{equation}<br/>
\]</p>

<p>两边同时乘以\(y_j\)，注意奥\(y_j^2=1\)，所以可得：<br/>
\[<br/>
\begin{equation}<br/>
b^* = y_j-w^*.x_j = y_j - \sum_{i=1}^N \alpha_i^* y_i (x_i.x_j) \label{d_2_y_1}\\<br/>
\end{equation}<br/>
\]</p>

<p>至此，可以知道在求得对偶问题的解\(\alpha^*\)后，可以通过（\ref{d_2_y_0}）和（\ref{d_2_y_1}）求得原始问题的解\(w^*\)和\(b^*\)，在这个计算中由于对于每一个符合\(\alpha_j &gt; 0\)条件的\(\alpha_j\)都能求出一个\(b^*\)，所以实际计算过程时可以取所有满足条件的样本点上的平均值。</p>

<h2 id="toc_5">软间隔最大化</h2>

<p>在实际问题中，并不是所有问题都是绝对的线性可分的，比如在一些存在噪音的情况下，此时我们需要分割超平面具有一定的容错性，我们给函数间隔加上一定的松弛变量，这样约束条件变为：<br/>
\[<br/>
y_i(\boldsymbol x_i+b)\ge 1-\zeta_i<br/>
\]</p>

<p>对每一个\(\zeta_i\)都要支付一个代价\(\zeta_i\)，所以目标函数变为：<br/>
\[<br/>
\frac{1}{2}||\boldsymbol w||^2+\text{C}\sum_{i=1}^N \zeta_i<br/>
\]</p>

<p>这里的\(\text{C}\gt 0\)被称为惩罚系数，当\(\text{C}\)越大对误分类的惩罚越大，反之越小。</p>

<p>那么对于软间隔最大化的线性支持向量机问题最优化方程组如下：<br/>
\[<br/>
\begin{align}<br/>
\min_{\boldsymbol w,b,\zeta} \quad &amp; \frac{1}{2}||\boldsymbol w||^2+\text{C}\sum_{i=1}^N \zeta_i \label{o_with_z_0}\\<br/>
s.t. \quad&amp; y_i(\boldsymbol w x_i + b) \ge 1 - \zeta_i:i=1;2;...;N \label{o_with_z_1}\\<br/>
\quad&amp;\zeta_i \gt 0:i = 1;2;...;N \label{o_with_z_2}\\<br/>
\end{align}<br/>
\]</p>

<h4 id="toc_6">原始问题与对偶问题</h4>

<p>直接求解原始问题比较困难，可以通过对偶问题间接求解，原始问题（\ref{o_with_z_0}）~（\ref{o_with_z_2}）的拉格朗日函数为：<br/>
\[<br/>
\begin{equation}<br/>
L(\boldsymbol w,b,\zeta,\alpha,\mu) = \frac{1}{2}||\boldsymbol w||^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N \alpha_i(y_i(\boldsymbol w x_i + b) -1 + \zeta_i) - \sum_{i=1}^N\mu_i \zeta_i<br/>
\end{equation}<br/>
\]</p>

<p>其中\(\alpha \ge 0,\mu \ge 0\).<br/>
对偶问题是求拉格朗日函数的极大极小值，先求\(L(\boldsymbol w,b,\zeta,\alpha,\mu)\)对\(\boldsymbol w\)，\(b\)和\(\zeta\)的极小值：<br/>
\[<br/>
\begin{align*}<br/>
\nabla_{\boldsymbol w}L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= \boldsymbol w - \sum_{i=1}^N \alpha_i y_i x_i = 0 \\<br/>
\nabla_{b}L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= -\sum_{i=1}^N \alpha_i y_i = 0 \\<br/>
\nabla_{\zeta}L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= C-\alpha_i-\mu_i = 0<br/>
\end{align*}<br/>
\]</p>

<p>得：<br/>
\[<br/>
\begin{align}<br/>
&amp;\boldsymbol w = \sum_{i=1}^N \alpha_i y_i x_i \label{o_with_z_r_0}\\<br/>
&amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{o_with_z_r_1}\\<br/>
&amp;\text{C} - \alpha_i - \mu_i = 0 \label{o_with_z_r_2}\\<br/>
\end{align}<br/>
\]</p>

<p>将结果（\ref{o_with_z_r_0}）~（\ref{o_with_z_r_2}）代入到拉格朗日函数中：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w,b,\zeta} L(\boldsymbol w,b,\zeta,\alpha,\mu) &amp;= \frac{1}{2}||\boldsymbol w||^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N \alpha_i(y_i(\boldsymbol w x_i + b) -1 + \zeta_i) - \sum_{i=1}^N\mu_i \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N \alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b) -1 + \zeta_i) - \sum_{i=1}^N\mu_i \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i(1-\zeta_i) - \sum_{i=1}^N\mu_i \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i - \sum_{i=1}^N (\alpha_i + \mu_i) \zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 + \text{C}\sum_{i=1}^N \zeta_i - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i - \text{C}\sum_{i=1}^N\zeta_i \\<br/>
&amp;= \frac{1}{2}(\sum_{i=1}^N \alpha_i y_i x_i)^2 - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i \\<br/>
&amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N\alpha_i(y_i((\sum_{j=1}^N \alpha_j y_j x_j) x_i + b)) + \sum_{i=1}^N \alpha_i \\<br/>
&amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \alpha_i y_i b + \sum_{i=1}^N \alpha_i \\<br/>
&amp;= -\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
\end{align*}<br/>
\]</p>

<p>在对\(\min_{\boldsymbol w,b,\zeta}L(\boldsymbol w,b,\zeta,\alpha,\mu)\)求 \(\alpha\) 的极大值：<br/>
\[<br/>
\begin{align}<br/>
\max_{\alpha} \quad &amp;-\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j + \sum_{i=1}^N \alpha_i \\<br/>
s.t. \quad &amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{s_t_with_r_1}\\<br/>
\quad\quad\quad &amp;\alpha_i \ge 0:i=1;2;...;N \label{s_t_with_r_2}\\<br/>
\quad\quad\quad &amp;\text{C} - \alpha_i - \mu_i = 0:i=1;2;...;N \label{s_t_with_r_3}\\<br/>
\quad\quad\quad &amp;\mu_i \ge 0:i=1;2;...;N \label{s_t_with_r_4}\\<br/>
\end{align}<br/>
\]</p>

<p>结合（\ref{s_t_with_r_3}）和（\ref{s_t_with_r_4}）可知：<br/>
\[<br/>
\mu_i = \text{C} - \alpha_i \ge 0 \Rightarrow \alpha_i \le \text{C}<br/>
\]</p>

<p>再结合（\ref{s_t_with_r_2}）可得：<br/>
\[<br/>
0 \le \alpha_i \le \text{C}<br/>
\]</p>

<p>所以软间隔原始问题的对偶问题为：<br/>
\[<br/>
\begin{align}<br/>
\max_{\alpha} \quad &amp;\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j x_i x_j - \sum_{i=1}^N \alpha_i \label{d_t_with_r_0}\\<br/>
s.t. \quad &amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{d_t_with_r_1}\\<br/>
\quad\quad\quad &amp;0 \le \alpha_i \le C:i=1;2;...;N \label{d_t_with_r_2}\\<br/>
\end{align}<br/>
\]</p>

<h4 id="toc_7">软间隔问题求解</h4>

<p>已经将求解原始问题的最小值转变为求对偶问题 \ref{d_t_with_r_0} 的最大值，，设 \(\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_N^*)\) 是对偶问题的一个解， \(\boldsymbol w^*\)，\(b^*\) 是原始问题的解。由拉格朗日乘子法可知对偶问题等价于原始问题需要满足KKT条件，如下：<br/>
\[<br/>
\begin{eqnarray}<br/>
&amp;\nabla_{\boldsymbol w}L(\boldsymbol w^*,b^*,\zeta^*,\alpha^*,\mu^*) = \boldsymbol w^* - \sum_{i=1}^N \alpha_i^* y_i x_i = 0 \label{d_with_z_kkt_1}\\<br/>
&amp;\nabla_{b}L(\boldsymbol w^*,b^*,\zeta^*,\alpha^*,\mu^*) = -\sum_{i=1}^N \alpha^*_i y_i = 0 \nonumber\\<br/>
&amp;\nabla_{\zeta}L(\boldsymbol w^*,b^*,\zeta^*,\alpha^*,\mu^*) = C-\alpha^*_i-\mu^*_i = 0 \label{d_with_z_kkt_2}\\<br/>
&amp;\sum_{i=1}^N \alpha^*_i(y_i(w^*x_i+b^*) - 1 + \zeta_i^*) = 0 \label{d_with_z_kkt_3}\\<br/>
&amp;\sum_{i=1}^N \mu^*_i \zeta^*_i = 0 \label{d_with_z_kkt_4}\\<br/>
&amp;y_i(w^*x_i + b^*) - 1 + \zeta^*_i \ge 0 \label{d_with_z_kkt_5} \\<br/>
&amp;\zeta_i^* \ge 0 \nonumber \\<br/>
&amp;\alpha^*_i \ge 0 \nonumber \\<br/>
&amp;\mu^*_i \ge 0 \nonumber \\<br/>
\end{eqnarray}<br/>
\]</p>

<p>由公式（\ref{d_with_z_kkt_1}）易得：<br/>
\[<br/>
\begin{equation}<br/>
\boldsymbol w^* = \sum_{i=1}^N \alpha_i^* y_i x_i \label{d_with_z_r_b_a_1}\\<br/>
\end{equation}<br/>
\]</p>

<p>由\(0 \le \alpha_i \le \text{C}\)结合公式（\ref{d_with_z_kkt_2}）可知：<br/>
\[<br/>
\begin{equation}<br/>
\mu_i^* = C - \alpha_i^*<br/>
\end{equation}<br/>
\]</p>

<ol>
<li>当\(\alpha_i^*=0\)时，可知\(w^*=0\)此时样本点对分离超平面的选择没有任何作用，</li>
<li>当\(\alpha_i^*=C\)时，可知\(\mu_i^* = 0\)，结合公式（\ref{d_with_z_kkt_4}）知存在\(\zeta_i^* \gt 0\)，此时\(y_i y=1-\zeta_i^* \lt 0\)，会出现样本点被误分类。</li>
<li><p>当\(0 \lt\alpha_i^* \lt C\)时，可知\(\mu_i^* &gt; 0\)，结合公式（\ref{d_with_z_kkt_4}）知任意\(\zeta_i^* = 0\).<br/>
将\(0 \lt\alpha_i^* \lt C\)和\(\zeta_i^* = 0\)代入公式（\ref{d_with_z_kkt_3}）得：<br/>
\[<br/>
\begin{equation}<br/>
y_j(w^*+b^*)-1 = 0 \Rightarrow b^* = y_j - \sum_{i=1}^N \alpha_i^* y_i x_i x_j  \label{d_with_z_r_b_a_2}<br/>
\end{equation}<br/>
\]</p>

<p>所以当我们求出对偶问题的结果\(\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_i^*)\)时，可以通过公式（\ref{d_with_z_r_b_a_1}）和（\ref{d_with_z_r_b_a_2}）求出\(w^*\)和\(b^*\).在这个计算中由于对于每一个符合\(0 &lt; \alpha_j^* &lt; C\)条件的\(\alpha_j^*\)都能求出一个\(b^*\)，所以实际计算过程时可以取所有满足条件的样本点上的平均值。</p>

<p>分割超平面为：<br/>
\[<br/>
\begin{equation}<br/>
y = \boldsymbol w^{*T} \boldsymbol x + b^* = \sum_{i=1}^N\alpha^*_i y_i x_i x + b^* \label{with_z_r} <br/>
\end{equation}<br/>
\]</p></li>
</ol>

<h2 id="toc_8">核技巧（Kernel trick）</h2>

<p>首先通过一个简单的例子来了解一下核技巧，如下图是两类数据（用不同颜色区分）：</p>

<div align="center">
    <img width="350px" src="media/15025588355749/15265669014230.jpg" />
</div>

<p>显然这两类数据是线性不可分的，需要一个分段函数才能将其分开，但是如果我们通过某种核技巧将数据中的点，映射到高维空间，这两类数据就会变的线性可分，如下图所示：</p>

<div align="center">
    <img width="350px" src="media/15025588355749/15265668464657.jpg" />
</div>

<p>在这个例子中，从原空间到新空间的映射函数\(\varphi(x) = (x-a)(x-b) \)。这个例子说明用线性分类方法求解非线性问题通常分为两步，首先使用合适的映射函数将数据点从低维空间映射到新空间（一般是高维空间或无限维空间），使数据线性可分的可能性增大，然后在新空间内用线性分类方法从训练数据中学习分类模型。</p>

<p>在实际问题中，往往直接定义映射函数是难以做到的，所以往往只定义核函数\(K(x,z)\)。在前面对SVM的讲解中，我们可以看到数据点往往都是都是以内积的形式出现的，假设我们定义一个函数\(f(x_i,x_j)\)满足：<br/>
\[<br/>
f(x_i,x_j) = &lt;\varphi(x_i),\varphi(x_j)&gt;<br/>
\]</p>

<p>也就是原样本点数据经过一个函数的输出与原样本点经过一个映射函数之后的新数据点\(\varphi(x_i)\)，\(\varphi(x_j)\)的内积相同。<br/>
这里举个简单的例子，数据空间里有两个数据点\(x_i=(\eta_1,\eta_2)\)和\(x_j=(\xi_1,\xi_2)\)，设想我们有一个函数：\(f(x_i,x_j)=(&lt;x_i,x_j&gt;)^2\)，映射函数为：\(\varphi(x_i,x_j) = (x_i^2,2x_ix_j,x_j^2)\)，那么：<br/>
\[<br/>
\begin{align*}<br/>
&lt;\varphi(x_i),\varphi(x_j)&gt; &amp;= &lt;(\eta_1^2,\eta_1\eta_2,\eta_2^2),(\xi_1,\xi_1\xi_2,\xi_2^2)&gt; \\&amp;=\eta_1^2\xi_1^2+ +2\eta_1\eta_2\xi_1\xi_2+\eta_2^2 \xi_2^2 \\<br/>
&amp; = (\eta_1\xi_1+\eta_2\xi_2)^2 \\<br/>
&amp; = f(x_i,x_j)<br/>
\end{align*}<br/>
\]</p>

<p>两种计算方式不同但是结果相同，一种是在低维空间直接通过核函数运算结果，一种是在转换后的高维空间进行计算内积。在实际项目中，可能我们需要映射到的高维空间是维度很大，甚至是无限维，所以映射后再计算内积计算量很大，所以我们通常只需要一个核函数计算低维度的数据，这种情况下我们也并不需要知道映射函数，可能也并不能知道具体的映射函数。</p>

<p>那什么样的函数可以被用作核函数呢？开始讨论：</p>

<p>定义一个核矩阵\(K\)，其中\(K_{i,j}=K(x_i,x_j)\)，根据核函数的定义：\(K_{ij}=K(x_i,x_j) = &lt;\varphi(x_i),\varphi(x_j)&gt;=&lt;\varphi(x_j),\varphi(x_i)&gt; = K(x_j,x_i) = K_{ji}\)，矩阵\(K\)是一个对称矩阵。<br/>
对于任意一个向量\(\boldsymbol z\)，得：<br/>
\[<br/>
\begin{align*}<br/>
\boldsymbol z^TK\boldsymbol z &amp;= \left[\begin{array}{ccc}<br/>
z_1\\<br/>
z_2\\<br/>
...\\<br/>
z_i\\<br/>
...\\<br/>
z_n <br/>
\end{array}<br/>
\right]^T \cdot \left[ \begin{array}{ccc}<br/>
K_{1,1} &amp;&amp; K_{1,2} &amp;&amp; ... &amp;&amp; K_{1,j} &amp;&amp; ... &amp;&amp; K_{1,n} \\<br/>
K_{2,1} &amp;&amp; K_{2,2} &amp;&amp; ... &amp;&amp; K_{2,j} &amp;&amp; ... &amp;&amp; K_{2,n} \\<br/>
... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... \\<br/>
K_{i,1} &amp;&amp; K_{i,2} &amp;&amp; ... &amp;&amp; K_{i,j} &amp;&amp; ... &amp;&amp; K_{i,n} \\<br/>
... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... &amp;&amp; ... \\<br/>
K_{n,1} &amp;&amp; K_{n,2} &amp;&amp; ... &amp;&amp; K_{n,j} &amp;&amp; ... &amp;&amp; K_{n,n} \\<br/>
\end{array}<br/>
\right] \cdot \left[ \begin{array}{ccc}<br/>
z_1\\<br/>
z_2\\<br/>
...\\<br/>
z_i\\<br/>
...\\<br/>
z_n <br/>
\end{array}<br/>
\right] \\<br/>
&amp;= \left[ \begin{array}{ccc}<br/>
z_1K_{1,1} + z_2K_{2,1} + ... + z_iK_{i,1} + ... + z_nK_{n,1} \\<br/>
z_1K_{1,2} + z_2K_{2,2} + ... + z_iK_{i,2} + ... + z_nK_{n,2} \\<br/>
...\\<br/>
z_1K_{1,j} + z_2K_{2,j} + ... + z_iK_{i,j} + ... + z_nK_{n,j} \\<br/>
...\\<br/>
z_1K_{1,n} + z_2K_{2,n} + ... + z_iK_{i,n} + ... + z_nK_{n,n} \\<br/>
\end{array} \right] ^T \cdot \left[ \begin{array}{ccc}<br/>
z_1\\<br/>
z_2\\<br/>
...\\<br/>
z_i\\<br/>
...\\<br/>
z_n <br/>
\end{array}<br/>
\right] \\<br/>
&amp;= (z_1K_{1,1} + z_2K_{2,1} + ... + z_iK_{i,1} + ... + z_nK_{n,1}).z_1+(z_1K_{1,2} + z_2K_{2,2} + ... + z_iK_{i,2} + ... + z_nK_{n,2}).z_2\\<br/>
&amp;\quad\,+...+(z_1K_{1,n} + z_2K_{2,n} + ... + z_iK_{i,n} + ... + z_nK_{n,n}).z_n\\<br/>
&amp;=\sum_{i=1}^N \sum_{j=1}^N z_iK_{i,j}z_j \\<br/>
&amp;=\sum_{i=1}^N \sum_{j=1}^N z_i&lt;\varphi(x_i)\cdot\varphi(x_j)&gt;z_j \\<br/>
&amp;=\sum_{i=1}^N \sum_{j=1}^N z_i\sum_{k=1}^N ([\varphi(x_i)]_k[\varphi(x_j)]_k) z_j \\<br/>
&amp;=\sum_{k=1}^N \sum_{i=1}^N \sum_{j=1}^N z_i[\varphi(x_i)]_k[\varphi(x_j)]_k z_j \\<br/>
&amp;=\sum_{k=1}^N \sum_{i=1}^N z_i [\varphi(x_i)]_k \sum_{j=1}^N z_j [\varphi(x_j)]_k\\<br/>
&amp;=\sum_{k=1}^N (\sum_{i=1}^N z_i [\varphi(x_i)]_k)^2\\<br/>
&amp;\ge 0<br/>
\end{align*} <br/>
\]</p>

<p>所以核函数矩阵\(K\)应该是半正定矩阵，这里证明了核函数矩阵的一个必要条件，核函数矩阵是对称半正定矩阵。</p>

<p>以下证明核函数矩阵的充分条件，假设\(K(x_i,x_j)\)是空间里的对称函数，考虑矩阵\(K = [K(x_i,x_j)]^n_{i,j}\)，因为\(K_{i,j}=K(x_i,x_j)=K(x_j,x_i)=K_{j,i}\)易知矩阵\(K\)是对称矩阵。</p>

<p>由同济大学线性代数第二版P128定理5可知，对于n阶对称矩阵\(K\)，则必有正交矩阵\(P\)，使\(P^{-1}KP=P^TKP=\Lambda\)，其中\(\Lambda\)是以\(K\)的n个特征值为对角元的对角矩阵：<br/>
\[<br/>
\begin{align*}<br/>
P^{-1} K P &amp;= \Lambda \Rightarrow K = P\Lambda P^{-1} = P\Lambda P^T<br/>
\end{align*}<br/>
\]</p>

<p>将\(P\)的用其列向量表示为：<br/>
\[<br/>
P = (p_1,p_2,...,p_n)<br/>
\]</p>

<p>由\(P^{-1}KP = \Lambda\)，得\(\,KP = P\Lambda\,\)，即：<br/>
\[<br/>
\begin{align*}<br/>
K(p_1,p_2,...,p_n) &amp;= (p_1,p_2,...,p_n)\left (\begin{array}<br/>
\lambda\lambda_1 &amp;&amp;           &amp;&amp;        &amp;&amp; \\<br/>
          &amp;&amp; \lambda_2 &amp;&amp;        &amp;&amp; \\<br/>
          &amp;&amp;           &amp;&amp; \ddots &amp;&amp; \\<br/>
          &amp;&amp;           &amp;&amp;        &amp;&amp; \lambda_n \\<br/>
\end{array} \right ) \\<br/>
&amp;=(p_1\lambda_1,p_2\lambda_2,\cdots,p_n\lambda_n)<br/>
\end{align*}<br/>
\]</p>

<p>于是有：<br/>
\[<br/>
Kp_i = \lambda_i p_i \quad(i=1;2;...;n)<br/>
\]</p>

<p>易知\(\lambda_i\)是\(K\)的特征值，\(P\)的列\(p_i\)是对应的特征向量。</p>

<p>我们先来展开一下\(PKP^T\)，令\(\lambda_t\)对应的特征向量\(\,p_t\,\)的第\(i\)个元素为\(p_{it}\)：<br/>
\[<br/>
\begin{align*}<br/>
P\Lambda P^T &amp;= \left[ \begin{array}{ccc}<br/>
p_{1,1}&amp;&amp;p_{1,2}&amp;&amp;\cdots&amp;&amp;p_{1,j}&amp;&amp;\cdots \\<br/>
p_{2,1}&amp;&amp;p_{2,2}&amp;&amp;\cdots&amp;&amp;p_{2,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{i,1}&amp;&amp;p_{i,2}&amp;&amp;\cdots&amp;&amp;p_{i,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{n,1}&amp;&amp;p_{n,2}&amp;&amp;\cdots&amp;&amp;p_{n,j}&amp;&amp;\cdots\\<br/>
\end{array} \right ] \left [ \begin{array}{ccc}<br/>
\lambda_{1,1}&amp;&amp;\lambda_{1,2}&amp;&amp;\cdots&amp;&amp;\lambda_{1,j}&amp;&amp;\cdots\\<br/>
\lambda_{2,1}&amp;&amp;\lambda_{2,2}&amp;&amp;\cdots&amp;&amp;\lambda_{2,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
\lambda_{i,1}&amp;&amp;\lambda_{i,2}&amp;&amp;\cdots&amp;&amp;\lambda_{i,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
\lambda_{n,1}&amp;&amp;\lambda_{n,2}&amp;&amp;\cdots&amp;&amp;\lambda_{n,j}&amp;&amp;\cdots\\<br/>
\end{array} \right ] P^T \\<br/>
&amp;= \left[ \begin{array}{ccc}<br/>
(\sum_{t=1}^N p_{1,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{1,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{1,t}\lambda_{t,j}) &amp;&amp; ... \\<br/>
(\sum_{t=1}^N p_{2,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{2,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{2,i}\lambda_{t,j}) &amp;&amp; ... \\<br/>
... &amp;&amp; ... &amp;&amp; \cdots &amp;&amp; ... &amp;&amp; ... \\<br/>
(\sum_{t=1}^N p_{i,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{i,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{i,t}\lambda_{t,j}) &amp;&amp; ... \\<br/>
... &amp;&amp; ... &amp;&amp; \cdots &amp;&amp; ... &amp;&amp; ... \\<br/>
(\sum_{t=1}^N p_{n,t}\lambda_{t,1}) &amp;&amp; (\sum_{t=1}^N p_{n,t}\lambda_{t,2}) &amp;&amp; \cdots &amp;&amp; (\sum_{t=1}^N p_{n,t}\lambda_{t,j}) &amp;&amp; ... \\<br/>
\end{array} \right] \left[ \begin{array}{ccc}<br/>
p_{1,1}&amp;&amp;p_{2,1}&amp;&amp;\cdots&amp;&amp;p_{i,1}&amp;&amp;\cdots \\<br/>
p_{1,2}&amp;&amp;p_{2,2}&amp;&amp;\cdots&amp;&amp;p_{i,2}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{1,j}&amp;&amp;p_{2,j}&amp;&amp;\cdots&amp;&amp;p_{i,j}&amp;&amp;\cdots\\<br/>
...    &amp;&amp; ...   &amp;&amp; ...  &amp;&amp;  ...  &amp;&amp; ...  \\<br/>
p_{1,n}&amp;&amp;p_{2,n}&amp;&amp;\cdots&amp;&amp;p_{i,n}&amp;&amp;\cdots\\<br/>
\end{array} \right ] \\<br/>
\end{align*}<br/>
\]</p>

<p>整个式子计算起来太长，我们只考虑\((P\Lambda P^T)_{ij}\)：<br/>
\[<br/>
\begin{align*}<br/>
(P\Lambda P^T)_{ij} &amp;= p_{j,1}(\sum_{t=1}^N p_{i,t}\lambda_{t,1}) + p_{j,2}(\sum_{t=1}^N p_{i,t}\lambda_{t,2}) + \cdots + p_{j,i}(\sum_{t=1}^N p_{i,t}\lambda_{t,j}) + ... +  p_{j,n}(\sum_{t=1}^N p_{n,t}\lambda_{t,j}) \\<br/>
&amp;= \sum_{m=1}^N [p_{j,m}\sum_{t=1}^N p_{i,t}\lambda_{t,m}] \\<br/>
&amp;= \sum_{t=1}^N \sum_{m=1}^N p_{i,t} \lambda_{t,m} p_{j,m} \\<br/>
\end{align*}<br/>
\]</p>

<p>因为\(\Lambda\)是对角矩阵，所以：<br/>
\[<br/>
\begin{align*}<br/>
\lambda_{t,m} = \left \{ \begin{array}{ccc}<br/>
\lambda_{t} &amp; t = m \\<br/>
0 &amp; e \neq m \\<br/>
\end{array} \right .<br/>
\end{align*}<br/>
\]</p>

<p>得：<br/>
\[<br/>
K = (P\Lambda P^T)_{ij} = \sum_{t=1}^N \sum_{m=1}^N p_{i,t} \lambda_{t,m} p_{j,m} = \sum_{t=1}^N p_{i,t} \lambda_t p_{j,t}<br/>
\]</p>

<p>现在假设所有的特征值都是非负的，考虑特征映射：<br/>
\[<br/>
\begin{align*}<br/>
\varphi(x_i) &amp;= (\sqrt{\lambda_t}p_{t,i})^n_{t=1}:i=1;2;...N \\<br/>
&amp;=(\sqrt{\lambda_1}p_{1,i},\sqrt{\lambda_2}p_{2,i},...,\sqrt{\lambda_t}p_{t,i},...,\sqrt{\lambda_n}p_{n,i}) \\<br/>
\end{align*}<br/>
\]</p>

<p>所以有：<br/>
\[<br/>
\begin{align*}<br/>
&lt;\varphi(x_i)\varphi(x_j)&gt; &amp;= (\sqrt{\lambda_1}p_{1i},\sqrt{\lambda_2}p_{2i},...,\sqrt{\lambda_t}p_{ti},...,\sqrt{\lambda_n}p_{ni})\cdot(\sqrt{\lambda_1}p_{1i},\sqrt{\lambda_2}p_{2i},...,\sqrt{\lambda_t}p_{ti},...,\sqrt{\lambda_n}p_{ni}) \\<br/>
&amp;= \sum_{t=1}^N \lambda_t p_{t,i} p_{t,j} = (P\Lambda P^T)_{ij} = K_{i,j} = K(x_i,x_j)<br/>
\end{align*}<br/>
\]</p>

<p>这里已经完成了充分性证明：半正定对称向量是核函数矩阵。之后，我们可以将前面的一些结论写成核函数的方式，如公式（\ref{with_z_r}）分割超平面写成核函数的形式为：<br/>
\[<br/>
\begin{equation}<br/>
y = \sum_{i=1}^N \alpha_i y_i k(x_i,x) + b^* \label{with_z_r_h}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_9">常见的核函数</h3>

<p>线性核函数（Linear kernel function）：<br/>
\[<br/>
K(x,z) = x^tz + c<br/>
\]</p>

<p>多项式核函数（Polynomial kernel function）：<br/>
\[<br/>
K(x,z) = (x\cdot z + 1)^p<br/>
\]</p>

<p>高斯核函数（Gaussian kernel function）：一个理论上可以将数据从低维空间映射到无穷维空间，使用很广泛。<br/>
\[<br/>
K(x,z) = exp(-\frac{||x-z||^2}{2\sigma^2})<br/>
\] </p>

<h2 id="toc_10">SMO算法</h2>

<p>SMO算法，英文名称：Sequence minimal optimization，中文名称：序列化最小最优算法。它是1996年有Platt发布的一个强大的算法，它将大优化问题分解成多个小优化的问题来求解。这些小优化的方法往往比较容易求解，并且对它们进行顺序求解的结果与将它们作为整体来求解的结果完全一致，在结果相同的情况下，SMO算法的效率会提升很多。</p>

<p>SMO算法的目标是求出一系列的\(\alpha\)和\(b\)，由前面可知，一旦求出\(\alpha\)，就很容易计算出权重向量\(\boldsymbol w\)和\(b\)，并得到分割超平面。SMO算法的工作原理是：每次循环中选择两个\(\alpha\)来进行优化处理。一旦找到一堆合适的\(\alpha\)，那么就增大其中一个同时减小另一个。这里所谓的“合适”就是指两个\(\alpha\)必须满足一定的条件，后面会讨论这个条件。</p>

<p>我们先来回顾一下我们SMO算法要求解的一般方程组：<br/>
\[<br/>
\begin{align}<br/>
\min_{\boldsymbol w,b,\zeta} \quad &amp; \frac{1}{2}||\boldsymbol w||^2+\text{C}\sum_{i=1}^N \zeta_i \label{smo_o_q_0}\\<br/>
s.t. \quad&amp; y_i(\boldsymbol w x_i + b) \ge 1 - \zeta_i:i=1;2;...;N \label{smo_o_q_1}\\<br/>
\quad&amp;\zeta_i \gt 0:i = 1;2;...;N \label{smo_o_q_2}\\<br/>
\end{align}<br/>
\]</p>

<p>然后引入拉格朗日方程，根据其对偶问题求出\(\boldsymbol w\)以及\(\alpha_i\)的关系：<br/>
\[<br/>
\begin{align}<br/>
&amp;\boldsymbol w = \sum_{i=1}^N \alpha_i y_i x_i \label{smo_r_0}\\<br/>
&amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{smo_r_1}\\<br/>
&amp;\text{C} - \alpha_i - \mu_i = 0 \label{smo_r_2}\\<br/>
\end{align}<br/>
\]</p>

<p>然后将这个结果带入拉格朗日对偶问题，这里使用核函数的形式，直接给出结果：<br/>
\[<br/>
\begin{align}<br/>
\min_{\alpha} \quad &amp;\frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j k(x_i,x_j) - \sum_{i=1}^N \alpha_i \\<br/>
s.t. \quad &amp;\sum_{i=1}^N \alpha_i y_i = 0 \label{smo_d_r_0}\\<br/>
\quad\quad\quad &amp;0 \le \alpha_i \le C:i=1;2;...;N \label{smo_d_r_1}\\<br/>
\end{align}<br/>
\]</p>

<p>前面我们已经说明了\(\alpha_i\)的取值范围及其意义，现在继续探究\(\alpha_i\)与\(yy_i\)的关系（这里\(y\)代表预测值\(y=\boldsymbol w^T \boldsymbol x + b\)，\(y_i\)是真实值）：</p>

<ol>
<li><p>当\(\alpha_i = 0\)时，由公式（\ref{d_with_z_kkt_2}）可知\(\mu_i=C&gt;0\)，由公式（\ref{d_with_z_kkt_4}）可知\(\zeta_i = 0\)，所以公式（\ref{d_with_z_kkt_5}）可以改写为：<br/>
\[<br/>
\begin{equation}<br/>
y_i(\boldsymbol w^{*T}x_i + b^*) - 1 + \zeta_i \ge 0 \Rightarrow y_i y \ge 1 \label{y_i_w_b_z_1} \\<br/>
\end{equation}<br/>
\]</p></li>
<li><p>当\(\alpha_i = C\)时，由公式（\ref{d_with_z_kkt_2}）可知\(\mu_i = 0\)，由公式（\ref{d_with_z_kkt_4}）可知存在\(\zeta_i &gt; 0\)，所以公式（\ref{d_with_z_kkt_3}）可以改写为：<br/>
\[<br/>
\begin{equation}<br/>
y_i(\boldsymbol w^{*T}x_i + b^*) - 1 + \zeta_i = 0 \Rightarrow y_i y = 1 - \zeta_i \le 1 \label{y_i_w_b_z_2} \\<br/>
\end{equation}<br/>
\]</p></li>
<li><p>当\(0 \le \alpha_i \le C\)时，由公式（\ref{d_with_z_kkt_2}）可知\(\mu_i &gt; 0\)，由公式（\ref{d_with_z_kkt_4}）可知存在\(\zeta_i = 0\)，所以公式（\ref{d_with_z_kkt_3}）可以改写为：<br/>
\[<br/>
\begin{equation}<br/>
y_i(\boldsymbol w^{*T}x_i + b^*) - 1 + \zeta_i = 0 \Rightarrow y_i y = 1 - \zeta_i = 1 \label{y_i_w_b_z_3} \\<br/>
\end{equation}<br/>
\] </p></li>
</ol>

<p>在SMO算法中，我们通常要选择不满足上述条件的\(\alpha_i\)来进行更新，下面来讨论不满足这些条件的情况：</p>

<ol>
<li>\(y_iy \ge 1\)时\(\alpha_i &gt;0 \)，因为原始的\(\alpha_i = 0\)</li>
<li>\(y_iy \le 1\)时\(\alpha_i &lt;C \)，因为原始的\(\alpha_i = C\)</li>
<li>\(y_iy =   1\)时\(\alpha_i = 0\)或\(\alpha_i = C\)时，因为原始的\(0 &lt; \alpha_i &lt; C\)</li>
</ol>

<p>在更新这些不满足条件的\(\alpha_i\)时，还需要满足公式（\ref{d_t_with_r_1}）\(\sum_{i=1}^N \alpha_i = 0\)条件，因此通常我们同时选择两个\(\alpha\)更新，增大其中一个，减小另外一个。假设选择的两个值是\(\alpha_1\)和\(\alpha_2\)，更新前值为\(\alpha_1^{old}\)和\(\alpha_2^{old}\)，更新后值为\(\alpha_1^{new}\)和\(\alpha_2^{new}\)，那么有：<br/>
\[<br/>
\begin{equation}<br/>
\alpha_1^{old}y_1 + \alpha_2^{old}y_2 = \alpha_1^{new}y_1 + \alpha_2^{new}y_2 = - \sum_{k \neq 1,2}^N \alpha_k \label{a_i_j_r}<br/>
\end{equation}<br/>
\]</p>

<p>令\(- \sum_{k \neq 1,2}^N \alpha_k = \varepsilon\)，这里分两种情况讨论：<br/>
第一种情况：\(y_1\)与\(y_2\)同号：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\alpha_1^{new} + \alpha_2^{new} = \varepsilon \Leftrightarrow \alpha_1^{new} = \varepsilon - \alpha_2^{new} \\<br/>
\because \quad&amp;0 \le \alpha_1^{new} \le C \\<br/>
\therefore \quad&amp;0 \le \varepsilon - \alpha_2^{new} \le C \\<br/>
\Rightarrow \quad &amp;\varepsilon - C \le \alpha_2^{new} \le \varepsilon \\<br/>
\Rightarrow \quad &amp;\alpha_1^{old} + \alpha_2^{old} -C \le \alpha_2^{new} \le \alpha_1^{old} + \alpha_2^{old} \\<br/>
\because \quad &amp; 0 \le \alpha_2^{new} \le C \\<br/>
\therefore \quad &amp; \max(0,\alpha_1^{old} + \alpha_2^{old} -C) \le \alpha_2^{new} \le \min(C,\alpha_1^{old} + \alpha_2^{old}) \\<br/>
\end{align*}<br/>
\]</p>

<p>令\(L = \max(0,\alpha_1^{old} + \alpha_2^{old} -C),\, H = \min(C,\alpha_1^{old} + \alpha_2^{old})\)，则\(L \le \alpha_2^{new} \le H\)</p>

<p>第二种情况：\(y_1\)与\(y_2\)异号：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\alpha_1^{new} - \alpha_2^{new} = \varepsilon \Leftrightarrow \alpha_1^{new} = \alpha_2^{new}  - \varepsilon \\<br/>
\because \quad&amp;0 \le \alpha_1^{new} \le C \\<br/>
\therefore \quad&amp;0 \le \alpha_2^{new} - \varepsilon \le C \\<br/>
\Rightarrow \quad &amp;\varepsilon \le \alpha_2^{new} \le C + \varepsilon \\<br/>
\Rightarrow \quad &amp;\alpha_1^{old} - \alpha_2^{old} \le \alpha_2^{new} \le C + \alpha_1^{old} - \alpha_2^{old} \\<br/>
\because \quad &amp; 0 \le \alpha_2^{new} \le C \\<br/>
\therefore \quad &amp; \max(0,\alpha_1^{old} - \alpha_2^{old}) \le \alpha_2^{new} \le \min(C,C+\alpha_1^{old} - \alpha_2^{old}) \\<br/>
\end{align*}<br/>
\]</p>

<p>令\(L = \max(0,\alpha_1^{old} - \alpha_2^{old}),\, H = \min(C,C+\alpha_1^{old} - \alpha_2^{old})\)，则\(L \le \alpha_2^{new} \le H\)</p>

<p>在知道了\(\alpha_2^{new}\)的范围之后，继续探究\(\alpha_2^{new}\)的值，由公式（\ref{a_i_j_r}）知\(\alpha_1 y_1 + \alpha_2 y_2 = \varepsilon \Rightarrow \alpha_1 y_1 = \varepsilon - \alpha_2 y_2 \)，两边同乘上\(y_1\)，因为\(y_1^2 = 1\)，所以得：\(\alpha_1 = y_1(\varepsilon - \alpha_2 y_2)\)，我们将软间隔最大化的对偶问题公式（\ref{d_t_with_r_0}）加上核函数，然后进行推导：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}\sum_{i=1}^N \sum_{j=1}^N \alpha_i \alpha_j y_i y_j k(x_i,x_j) - \sum_{i=1}^N \alpha_i \\<br/>
&amp;= \frac{1}{2}\alpha_1^2y_1^2k(x_1,x_1)+\frac{1}{2}\alpha_2^2y_2^2k(x_2,x_2)+\alpha_1\alpha_2y_1y_2k(x_1,x_2)+\alpha_1y_1\sum_{i=3}^N\alpha_iy_ik(x_1,x_i)\\<br/>
&amp;+\alpha_2y_2\sum_{i=3}^N\alpha_iy_ik(x_2,x_i)+\frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) - \alpha_1 - \alpha_2 - \sum_{i=3}^N\alpha_i<br/>
\end{align*}<br/>
\]</p>

<p>将\(\alpha_1=y_1(\varepsilon - \alpha_2y_2)\)代入式：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}[y_1(\varepsilon -\alpha_2y_2)]^2y_1^2k(x_1,x_1)+\frac{1}{2}\alpha_2^2y_2^2k(x_2,x_2)+y_1(\varepsilon -\alpha_2y_2)\alpha_2y_1y_2k(x_1,x_2) \\<br/>
&amp;+y_1(\varepsilon - \alpha_2y_2)y_1\sum_{i=3}\alpha_iy_ik(x_1,x_i) + \alpha_2y_2\sum_{i=3}^N\alpha_iy_ik(x_2,x_i) + \frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) \\<br/>
&amp;- y_1(\varepsilon - \alpha_2y_2) - \alpha_2 - \sum_{i=3}^N\alpha_i \\<br/>
&amp;=\frac{1}{2}(\varepsilon - \alpha_2y_2)^2k(x_1,x_1) + \frac{1}{2}\alpha_2^2k(x_2,x_2) + (\varepsilon-\alpha_2y_2)\alpha_2y_2k(x_1,x_2) \\<br/>
&amp;+(\varepsilon-\alpha_2y_2)\sum_{i=3}^N\alpha_iy_ik(x_1,x_i)+ \alpha_2y_2\sum_{i=3}^N\alpha_iy_ik(x_2,x_i) + \frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) \\<br/>
&amp;- y_1(\varepsilon - \alpha_2y_2) - \alpha_2 - \sum_{i=3}^N\alpha_i \\<br/>
\end{align*}<br/>
\]</p>

<p>因为在操作过程中只变化\(\alpha_1\)和\(\alpha_2\)，所以可以将不包含\(\alpha_1\)和\(\alpha_2\)的项看作常数，令\(v_1=\sum_{i=3}^N\alpha_iy_ik(x_1,x_i)\)，\(v_2 = \sum_{i=3}^N\alpha_iy_ik(x_2,x_i)\)，\(const=\frac{1}{2}\sum_{i=3}^N\alpha_i\alpha_jy_iy_jk(x_i,x_j) - \sum_{i=3}^N\alpha_i\)，所以上式可以改写为：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha) &amp;= \frac{1}{2}(\varepsilon - \alpha_2y_2)^2k(x_1,x_1) + \frac{1}{2}\alpha_2^2k(x_2,x_2) + (\varepsilon-\alpha_2y_2)\alpha_2y_2k(x_1,x_2) \\<br/>
&amp;- y_1(\varepsilon - \alpha_2y_2) - \alpha_2 +(\varepsilon-\alpha_2y_2)v_1+ \alpha_2y_2v_2 + const \\<br/>
\end{align*}<br/>
\]</p>

<p>上式可以看成只包含\(\alpha_2\)的函数，令\(W(\alpha_2)=\min_{\boldsymbol w, b, \alpha}L(\boldsymbol w,b,\alpha)\)，然后对\(\alpha_2\)求导数：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial W(\alpha_2)}{\partial \alpha_2} &amp;= -(\varepsilon-\alpha_2y_2)y_2k(x_1,x_1) + \alpha_2k(x_2,x_2)-y_2\alpha_2y_2k(x_1,x_2) + (\varepsilon-\alpha_2y_2)y_2k(x_1,x_2) +y_1y_2 - 1 \\<br/>
&amp;- y_2v_1 + y_2v_2 \\<br/>
&amp;=\alpha_2k(x_1,x_1)+\alpha_2k(x_2,x_2)-2\alpha_2k(x_1,x_2) - \varepsilon y_2k(x_1,x_1) + \varepsilon y_2k(x_1,x_2) +y_1y_2 - 1 - y_2v_1 \\<br/>
&amp;+ y_2 v_2<br/>
\end{align*}<br/>
\]</p>

<p>令其等于0，并将核函数写成核矩阵形式得：<br/>
\[<br/>
\begin{equation}<br/>
(K_{11}+K_{22}-2K_{12})\alpha_2 = y_2(y_2 - y_1 + \varepsilon K_{11} - \varepsilon K_{12} + v_1 -v_2) \label{kk_2_a}<br/>
\end{equation}<br/>
\]</p>

<p>在前面化简时，我们曾令\(v_1 = \sum_{i=3}^N\alpha_iy_ik(x_1,x_i)\)，结合公式（\ref{with_z_r_h}）考虑：<br/>
\[<br/>
\begin{align*}<br/>
v_1 &amp;= \sum_{i=1}^N\alpha_iy_ik(x_1,x_i) + b^* - \sum_{i=1}^2\alpha_iy_ik(x_1,x_i) - b^* \\<br/>
&amp;= f(x_1) -  \alpha_1^{old} y_1 K_{11} - \alpha_2^{old} y_2 K_{12} - b^*<br/>
\end{align*}<br/>
\]</p>

<p>同理：\(v_2 =f(x_2) -  \alpha_1^{old} y_1 K_{21} - \alpha_2^{old} y_2 K_{22} - b^*\)<br/>
将\(v_1\)和\(v_2\)代入式（\ref{kk_2_a}）中得：<br/>
\[<br/>
\begin{align*}<br/>
(K_{11}+K_{22}-2K_{12})\alpha_2 &amp;= y_2(y_2 - y_1 + \varepsilon K_{11} - \varepsilon K_{12} + v_1 -v_2) \\<br/>
&amp;=y_2(y_2 - y_1 + \varepsilon K_{11} - \varepsilon K_{12} + f(x_1) -  \alpha_1^{old} y_1 K_{11} - \alpha_2^{old} y_2 K_{12} -f(x_2) +  \alpha_1^{old} y_1 K_{21} \\<br/>
&amp;+ \alpha_2^{old} y_2 K_{22})<br/>
\end{align*}<br/>
\]</p>

<p>将\(\varepsilon = \alpha_1^{old}y_1 + \alpha_2^{old}y_2\)代入上式，并用\(E_i\)表示预测值\(f(x_i)\)与真实值\(y_i\)的差：<br/>
\[<br/>
\begin{align*}<br/>
(K_{11}+K_{22}-2K_{12})\alpha_2^{new,unc} &amp;=y_2(y_2 - y_1 + (\alpha_1^{old}y_1 + \alpha_2^{old}y_2) K_{11} - (\alpha_1^{old}y_1 + \alpha_2^{old}y_2) K_{12} \\<br/>
&amp;+ f(x_1) -  \alpha_1^{old} y_1 K_{11} - \alpha_2^{old} y_2 K_{12} -f(x_2) +  \alpha_1^{old} y_1 K_{21} + \alpha_2^{old} y_2 K_{22}) \\<br/>
&amp;=y_2(y_2 - y_1 + \alpha_2^{old}y_2 K_{11} - 2\alpha_2^{old}y_2K_{12} + \alpha_2^{old} y_2 K_{22}+ f(x_1) -f(x_2) \\<br/>
&amp;=(K_{11}-2K_{12}+K_{22})\alpha_2^{old} + y_2[(f(x_1) - y_1)-(f(x_2) - y_2)] \\<br/>
\Rightarrow \alpha_2^{new,unc} &amp;= \alpha_2^{old} + \frac{y_2(E_1-E_2)}{K_{11}-2K_{12}+K_{22}}<br/>
\end{align*}<br/>
\]</p>

<p>令\(\eta=K_{11}+K_{22}-2K_{12}\)，则\(\alpha_2^{new,unc}=\alpha_2^{old} + \frac{y_2(E_1-E_2)}{\eta}\)，前面我们已经求出了\(\alpha_2^{new}\)的范围，所以经剪辑后：<br/>
\[<br/>
\begin{align*}<br/>
\alpha_2^{new} = \left \{ \begin{array}<br/>
HH \quad &amp; \alpha_2^{new,unc} &gt; H \\<br/>
a_2^{new,unc} \quad &amp; L \le a_2^{new,unc} \le H \\<br/>
L \quad &amp; \alpha_2^{new,unc} &lt; L<br/>
\end{array} \right .<br/>
\end{align*}<br/>
\]</p>

<p>再由\(\alpha_2^{new}\)求解\(\alpha_1^{new}\)得：<br/>
\[<br/>
\begin{align*}<br/>
\because\quad&amp;\alpha_1^{new}y_1 + \alpha_2^{new}y_2 = \alpha_1^{old}y_1 + \alpha_2^{old}y_2 \\<br/>
\therefore\quad&amp;\alpha_1^{new} = \alpha_1^{old} + y_1y_2(\alpha_2^{old} - \alpha_2^{new})<br/>
\end{align*}<br/>
\]</p>

<p>在每次完成\(\alpha\)更新后，接下来重新计算阈值\(b\)，由公式（\ref{with_z_r_h}）可知，当\(0 &lt; \alpha_1^{new} &lt; C\)时：<br/>
\[<br/>
\sum_{i=1}^N\alpha_iy_iK_{i1} + b^* = y_i \Rightarrow b^* = y_i - \sum_{i=1}^N\alpha_iy_iK_{i1}\<br/>
\]</p>

<p>于是：<br/>
\[<br/>
b_1^{new} = y_1 - \sum_{i=3}^N\alpha_iy_iK_{i1} - \alpha_1^{new}y_iK_{11} - \alpha_2^{new}y_2K_{21}<br/>
\]</p>

<p>由\(E_1\)的定义有：<br/>
\[<br/>
E_1 = \sum_{i=1}^N \alpha_i y_i K_{i1} = \sum_{i=3}^N \alpha_i y_i K_{i1} + \alpha_1^{old}y_1K_{11} + \alpha_2^{old}y_2K_{21} + b^{old} - y_1<br/>
\]</p>

<p>前面两项可以结合得：<br/>
\[<br/>
b_1^{new} = - E_1 + (\alpha_1^{old}-\alpha_1^{new})y_1K_{11} + (\alpha_2^{old}-\alpha_2^{new})y_2K_{21} + b^{old} <br/>
\]</p>

<p>那么同理有：\(b_2^{new} = - E_2 + (\alpha_1^{old}-\alpha_1^{new})y_1K_{12} + (\alpha_2^{old}-\alpha_2^{new})y_2K_{22} + b^{old}\)<br/>
所以\(b\)的更新规则如下：<br/>
\[<br/>
\begin{equation}<br/>
b^* = \left \{ \begin{array}<br/>
bb_1 \quad&amp; 0 &lt; \alpha_1 &lt; C \\<br/>
b_2 \quad&amp; 0 &lt; \alpha_2 &lt; C \\<br/>
\frac{1}{2}(b_1+b_2) \quad&amp; 其他<br/>
\end{array} \right .<br/>
\end{equation}<br/>
\]</p>

<h2 id="toc_11">多分类问题</h2>

<p>对于多分类问题，比如手写数字识别的问题，类别的数量超过2种，此时变出现多分类问题。通常使用的解决方案有两种：一对多训练和多一对一训练。</p>

<h4 id="toc_12">一对多训练 one-versus-the-rest</h4>

<p>这种方法是在K分类的数据集上训练处K个分类器，每个分类器将样本分为\(k_i\)类与非\(k_i\)类。每个样本在测试的时候需要被分类K次，预测出是否属于\(k_i\)数据分类，但是很可能一个数据会被分为到几个类。这时候就需要函数间隔作为分类的确信度，取确信度最大的分类作为预测分类。</p>

<p>这种方法的弊端在于可能出现样本不平衡的情况，一边是1类数据，一边是K-1类数据，这种情况可以通过欠采样解决，但是效果不好。在实际工作中往往不采用，而是采用下面多一对一的分类器。</p>

<h4 id="toc_13">多一对一训练 one-versus-one</h4>

<p>这种方式在K分类的数据集上训练\(\frac{K(K-1)}{2}\)个分类器，也就是在每两个分类上训练处一个分类器，在测试环境，每个样本都需要被分类K-1次，然后采取投票的方式决定最终预测分类。假设有三类数据A类、B类和C类，将会训练A-B分类器，A-C分类器，B-C分类器，对于测试样本x，在A-B分类器上分为A类，在A-C分类器上分为C，在B-C分类器上分为C类，那么C得两票，A得一票，最终x被预测为C。但是这种方法也可能导致分不了类，刚才的例子中，x在B-C分类器上分为B类，那么A、B、C各得一票，x归属哪一类就不好判断了。</p>


		</div>

		

	</article>
  
	<div class="pagination">
	
<a href="archives.html">Blog Archives</a>
	 
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98.html"><strong>最短路径问题&nbsp;(5)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E8%81%9A%E7%B1%BB%E9%97%AE%E9%A2%98.html"><strong>聚类问题&nbsp;(9)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%85%B6%E4%BB%96%E7%AE%97%E6%B3%95.html"><strong>其他算法&nbsp;(6)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95.html"><strong>基础算法&nbsp;(23)</strong></a>
	         <p class="cat-children-p"> 
	        
	        	<a href="SVM.html">SVM&nbsp;(1)</a>&nbsp;&nbsp;
	        
	        	<a href="SNE.html">SNE&nbsp;(1)</a>&nbsp;&nbsp;
	        
	        	<a href="EM.html">EM&nbsp;(5)</a>&nbsp;&nbsp;
	        
	        	<a href="%E5%86%B3%E7%AD%96%E6%A0%91.html">决策树&nbsp;(2)</a>&nbsp;&nbsp;
	        
	        	<a href="HMM.html">HMM&nbsp;(3)</a>&nbsp;&nbsp;
	        
	        	<a href="%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.html">集成学习&nbsp;(8)</a>&nbsp;&nbsp;
	        
	        	<a href="%E9%99%8D%E7%BB%B4.html">降维&nbsp;(3)</a>&nbsp;&nbsp;
	        
	         </p> 
	      </li>
	  
	      <li class="post">
	        <a href="%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.html"><strong>数学基础&nbsp;(14)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="Python%E5%AD%A6%E4%B9%A0.html"><strong>Python学习&nbsp;(2)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html"><strong>神经网络&nbsp;(15)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0.html"><strong>增强学习&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15454660806753.html">深度学习中的正则化-Dropout方法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15446218642343.html">图像相似度方法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15436296136092.html">蒙特卡罗树搜搜 MCTS</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15424711438602.html">人工神经网络-GAN</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15418610530072.html">人工神经网络-SOM自组织系统</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    

<script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>