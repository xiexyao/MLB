
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>
    
  EM - 邪逍遥
  

  </title>
  <meta name="author" content="">
  <meta name="description" content="历经千重罪，练就不死心">

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link href="asset/css/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="atom.xml" rel="alternate" title="邪逍遥" type="application/atom+xml">
  <script src="asset/js/modernizr-2.0.js"></script>
  <script src="asset/js/jquery.min.js"></script>
  <script src="asset/highlightjs/highlight.pack.js"></script>
  <link href="asset/highlightjs/styles/solarized_light.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script>hljs.initHighlightingOnLoad();</script>

  <style type="text/css">
  .cat-children-p{ padding: 6px 0px;}
  .hljs{background: none;}
  </style>
  <script type="text/javascript">
  var isAddSildbar = true;
  </script>
  <script src="asset/js/octopress.js" type="text/javascript"></script>
</head>
<script type="text/javascript">
//链接新开窗口
function addBlankTargetForLinks () {
  $('a[href^="http"]').each(function(){
      $(this).attr('target', '_blank');
  });
}
$(document).ready(function(event) {
  addBlankTargetForLinks();
});
</script>
<body   >
  <header role="banner"><hgroup>
  <h1><a href="index.html">邪逍遥</a></h1>
  
    <h2>历经千重罪，练就不死心</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">

  <li id=""><a target="self" href="index.html">Home</a></li>

  <li id=""><a target="_self" href="archives.html">Archives</a></li>

</ul>

</nav>
  <div id="main">
    <div id="content"> 
<div class="blog-index">

	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15109408623126.html">GMM与最大期望算法</a></h1>
			<p class="meta"><time datetime="2017-11-18T01:47:42+08:00" 
			pubdate data-updated="true">2017/11/18</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>EM算法的一个重要应用时高斯混合模型的参数估计，高斯混合模型应用广泛，在许多情况下，EM算法时学习高斯混合分布的有效方法。先来介绍一下高斯混合分布 GMM 和相关的几个概念：</p>

<h4 id="toc_0">高斯分布</h4>

<p>高斯分布（Gaussian Distribution），有时也被称为正太分布，在自然界中最常见的存在。假设对我国成年男人的身高作出统计，如下图：</p>

<div align="center">
    <img width='300' src='media/15109408623126/15326117493088.jpg'/>
</div>

<p>这个图形非常直观的展现了高斯分布的形状，高斯函数的数学定位为 \(N(\mu,\sigma^2)\)，其中 \(\mu\) 为分布的平均值，\(\sigma\) 为分布的标准差：<br/>
\[<br/>
\mathcal N(y|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})<br/>
\]</p>

<p>上面身高的高斯分布便是在 \(N(172,36)\) 下绘制的分布图。期望值决定了分布的位置，标准差决定分布的振幅。</p>

<h4 id="toc_1">混合高斯分布</h4>

<p>高斯混合分布（Gaussian Mixture Model）是指多个高斯分布的线性分布，理论上高斯混合分布能模拟出任何分布形状。高斯混合模型的数学定义如下：<br/>
\[<br/>
\begin{align*}<br/>
P(y|\theta) &amp;=\sum_{k=1}^K P(\text{第}k\text{个高斯分布}|\theta)  P(y|\text{第}k\text{个高斯分布},\theta)\\<br/>
&amp;= \sum_{k=1}^K \alpha_k \mathcal N(y|\theta_k)\\<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(\alpha_k\) 是系数，\(\alpha_k \ge 0\)，\(\sum_{k=1}^K \alpha_k = 1\)，\(\mathcal N(y|\theta_k)\) 是高斯分布密度，\(\theta_k=(\mu_k,\sigma_k^2)\)：<br/>
\[<br/>
\mathcal N(y|\theta_k) = \frac{1}{\sqrt{2\pi}\sigma_k} exp(-\frac{(y-\mu_k)^2}{2\sigma_k^2})<br/>
\]</p>

<p>称为第 \(k\) 个分模型。</p>

<p>如下图是分别是我国成年男女的身高分布：</p>

<div align="center">
    <img width='360' src="media/15109408623126/15326156226146.jpg" />
</div>

<p>假设成年男人的身高满足高斯分布 \(N(\mu_1,\sigma_1)\)，成年女人身高满足高斯分布 \(N(\mu_2,\sigma_2)\)，我国男女的比例分别是 \(\alpha_1\) 和 \(\alpha_2\) ，混合高斯分布模型如下：<br/>
\[<br/>
P(y|\theta) = \alpha_1 \mathcal N(y|\mu_1,\sigma_1) + \alpha_2 \mathcal N(y|\mu_2,\sigma_2)<br/>
\]</p>

<p>上式中未知的参数有六个，\(\theta=(\alpha_1,\mu_1,\sigma_2,\alpha_2,\mu_2,\sigma_2)\)。如果要从 GMM 的分布中随机地取一个点的话，实际上可以分为两步：首先随机地在这 \(K\) 个分布之中选一个，每个分布被选中的概率实际上就是它的系数 \(\alpha_k\) ，选中单个分布之后，比如上图蓝色的分布，这里已经回到了普通的 Gaussian 分布，转化为已知的问题。</p>

<h5 id="toc_2">高斯混合模型参数估计的 EM 算法</h5>

<p>假设观察数据 \(y_1,y_2,...y_n\) 由高斯混合模型生成：<br/>
\[<br/>
P(y|\theta) =  \sum_{k=1}^K \alpha_k \mathcal N(y|\theta_k)<br/>
\]</p>

<p>其中 \(\theta=(\alpha_1,\alpha_2,...,\alpha_k;\theta_1,\theta_2,...,\theta_k)\) 。显然我们已经知道观察数据 \(y_1,y_2,...,y_n\) 的生成步骤：首先根据概率 \(\alpha_k\) 选择第 \(k\) 个高斯分布模型 \(\mathcal N(y,\theta_k)\) ，然后根据模型生成观察数据 \(y_j\) 。使用 \(\gamma_j\) 表示第 \(j\) 个观察数据来自的高斯分布 ，\(\gamma_{jk}\) 表示第 \(j\) 个观察数据来源于第 \(k\) 个高斯分布的概率，其定义如下：<br/>
\[<br/>
\begin{align*}<br/>
\gamma_{jk} = \left \{ \begin{array}\\<br/>
1\qquad &amp;\gamma_j = k\\<br/>
0\qquad &amp;\gamma_j \neq k\\<br/>
\end{array}\right .<br/>
\end{align*}<br/>
\]</p>

<p>其中 \(j=1,2,...,N\)，\(k=1,2,...,K\)，\(\gamma_{jk}\) 是 \(0-1\) 随机变量，容易看出：<br/>
\[<br/>
\sum_{k=1}^K \hat\gamma_{jk} = 1<br/>
\]</p>

<p>有了观察数据 \(y_j\) 以及未观察数据 \(\gamma_{jk}\)，那么完全数据是：<br/>
\[<br/>
(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}),\quad j=1,2,...,N<br/>
\]</p>

<p>先来看对于单样本 \(y_j\) 的概率：<br/>
\[<br/>
\begin{align*}<br/>
p(y_j|\gamma_{j1},\gamma_{j2},...,\gamma_{jK},\theta) &amp;= \prod_{k=1}^K [p(y_j|\gamma_{jk} ,\theta)]^{\gamma_{jk}}=\prod_{k=1}^K [\mathcal N(y_j|\theta_k)]^{\gamma_{jk}}\\<br/>
\end{align*}<br/>
\]</p>

<p>隐变量的先验概率为：<br/>
\[<br/>
p(\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta) = \prod_{k=1}^K \alpha_k^{\gamma_{jk}}<br/>
\]</p>

<p>所以单样本 \(y_j\) 的似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
p(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta) &amp;= p(y_j|\gamma_{j1},\gamma_{j2},...,\gamma_{jK},\theta) p(\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta)\\<br/>
&amp;= \prod_{k=1}^K [\mathcal N(y_j|\theta_k)]^{\gamma_{jk}} \prod_{k=1}^K \alpha_k^{\gamma_{jk}}\\<br/>
&amp;= \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}<br/>
\end{align*} <br/>
\]</p>

<p>于是，可以写出完整数据的似然函数：<br/>
\[<br/>
\begin{align*}<br/>
P(y,\gamma|\theta) &amp;= \prod_{j=1}^N p(y_j,\gamma_{j1},\gamma_{j2},...,\gamma_{jK}|\theta)\\<br/>
&amp;= \prod_{j=1}^N \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>所以完整数据的对数似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta) &amp;= \log p(y,\gamma|\theta) = \log \prod_{j=1}^N \prod_{k=1}^K \alpha_k^{\gamma_{jk}} \mathcal N(y_j|\theta_k)]^{\gamma_{jk}}\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K [\gamma_{jk} \log\alpha_k+\gamma_{jk}\log\mathcal N(y_j|\theta_k)]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K [\gamma_{jk} \log\alpha_k+\gamma_{jk}\log \frac 1 {\sqrt{2\pi}\sigma_k} \exp(-\frac{(y_j-\mu_k)^2}{2\sigma_k^2})]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
\end{align*}<br/>
\]</p>

<p>EM算法的E步骤，确定Q函数：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_\gamma[\log p(y,\gamma|\theta)|y,\theta^{i}] \\<br/>
&amp;= \sum_\gamma p(\gamma|y,\theta^{(i)}) \log p(y,\gamma|\theta)\\<br/>
&amp;= \sum_\gamma p(\gamma|y,\theta^{(i)}) \sum_{j=1}^N \sum_{k=1}^K \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\\<br/>
&amp;= \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} \\<br/>
\end{align*}<br/>
\]</p>

<p>现在计算 \(\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk}\)，因为只有当 \(\gamma_{j}=k\) 时 \(\gamma_{jk} = 1\) ，否则 \(\gamma_{jk}=0\)。所以：<br/>
\[<br/>
\sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk} = \sum_\gamma \gamma_{jk} \sum_{j=1}^N \sum_{k=1}^K p(\gamma_{jk}|y_j,\theta^{(i)}_k) = p(\gamma_{jk}=1|y_j,\theta^{(i)}_k)<br/>
\]</p>

<p>令\(\hat\gamma_{jk} = \sum_\gamma p(\gamma|y,\theta^{(i)})  \gamma_{jk}\)：</p>

<p>\[<br/>
\begin{align*}<br/>
\hat\gamma_{jk} &amp;= P(\gamma_{jk}=1|y_j,\theta_k^{(i)})\\<br/>
&amp;= \frac{P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}{P(y_j|\theta^{(i)}_k)}\\<br/>
&amp;= \frac{P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}{\sum_{k=1}^K P(y_j,\gamma_{jk}=1|\theta^{(i)}_k)}\\<br/>
&amp;= \frac{P(y_j|\gamma_{jk}=1,\theta_k^{(i)})P(\gamma_{jk}=1|\theta_k^{(i)})}{\sum_{k=1}^K P(y_j|\gamma_{jk}=1,\theta_k^{(i)})P(\gamma_{jk}=1|\theta_k^{(i)})}\\<br/>
&amp;= \frac{\alpha^{(i)}_k \mathcal N(y_j|\theta_k^{(i)})}{\sum_{k=1}^K \alpha^{(i)}_k \mathcal N(y_j|\theta_k^{(i)}) },\quad j=1,2,...,N;k=1,2,...,K<br/>
\end{align*}<br/>
\]</p>

<p>代入 Q 函数中：<br/>
\[<br/>
Q(\theta,\theta^{(i)}) = \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} \\<br/>
\]</p>

<p>EM 算法的M步骤，求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \mu_k} &amp;= \frac{\partial \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \mu_k} \\<br/>
&amp;= \sum_{j=1}^N \frac{[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \mu_k}\\<br/>
&amp;= \sum_{j=1}^N \frac{(y_j-\mu_k)}{\sigma_k^2}\hat\gamma_{jk}\\<br/>
\because &amp;\sum_{j=1}^N \frac{(y_j-\mu_k)}{\sigma_k^2}\hat\gamma_{jk} = 0\\<br/>
\therefore &amp; \sum_{j=1}^N y_j \hat\gamma_{jk}-\sum_{j=1}^N \gamma_{jk}\mu_k = 0\quad \Rightarrow\quad \mu_k = \frac{\sum_{j=1}^N y_j \hat\gamma_{jk}}{\sum_{j=1}^N\hat\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \sigma_k^2} <br/>
&amp;= \frac{\partial \sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \sigma_k^2} \\<br/>
&amp;= \sum_{j=1}^N \frac{[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \frac 1 2\log\sigma_k^2  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk}}{\partial \sigma_k^2}\\<br/>
&amp;= \sum_{j=1}^N[\frac{1}{2\sigma_k^2} + (\mu_j-y_j)^2 \frac 1 {2\sigma_k^4}]\hat\gamma_{jk}\\<br/>
&amp;= \sum_{j=1}^N \frac{\sigma_k^2+(\mu_j-y_j)^2}{2\sigma_k^4}\hat\gamma_{jk}\\<br/>
\because &amp;\sum_{j=1}^N \frac{\sigma_k^2+(\mu_j-y_j)^2}{2\sigma_k^4}\hat\gamma_{jk} = 0\\<br/>
\therefore &amp; \sum_{j=1}^N [\sigma_k^2+(\mu_j-y_j)^2]\hat\gamma_{jk} = 0\\<br/>
\Rightarrow &amp; \sigma_k^2 = \frac{\sum_{j=1}^N (\mu_j-y_j)^2\hat\gamma_{jk}}{\sum_{j=1}^N \hat\gamma_{jk}}<br/>
\end{align*}<br/>
\]</p>

<p>现在还剩下一个 \(\alpha_k\) 没有求出，这里用拉格朗日乘子法求解，原问题为：<br/>
\[<br/>
\begin{align*}<br/>
\min \quad&amp;-Q(\theta,\theta^{(i)})\\<br/>
e.t. \quad&amp;\sum_{k=1}^K \alpha_k = 1<br/>
\end{align*}<br/>
\]</p>

<p>定义拉格朗日函数：<br/>
\[<br/>
L(\alpha,\beta) = -\sum_{j=1}^N \sum_{k=1}^K[\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \alpha_k -1)\\<br/>
\]</p>

<p>原问题的极小问题可以表示为拉格朗日方程的极大极小问题，先求 \(L(\alpha,\beta)\) 对 \(\alpha\) 的极小值：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial L(\alpha,\beta)}{\partial \alpha_k} &amp;= \frac{\partial \{-\sum_{j=1}^N [\log\alpha_k+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \alpha_k -1)\}}{\partial \alpha_k}\\<br/>
&amp;= -\sum_{j=1}^N \frac 1 \alpha_k \hat\gamma_{jk} + \beta<br/>
\end{align*}<br/>
\]</p>

<p>令导数为0，可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta}<br/>
\]</p>

<p>将 \(\alpha_k\) 代入 \(L(\alpha,\beta)\) 中，得到关于 \(\beta\) 的函数 \(\min_{\alpha_k}L(\alpha,\beta)\)：<br/>
\[<br/>
\begin{align*}<br/>
\min_{\alpha_k} L(\alpha,\beta) &amp;= -\sum_{j=1}^N \sum_{k=1}^K[\log (\frac{\sum_{i=1}^N \hat\gamma_{ik}}{\beta})+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} + \beta( \sum_{k=1}^K \frac{\sum_{i=1}^N \hat\gamma_{ik}}{\beta} -1)\\<br/>
&amp;=  -\sum_{j=1}^N \sum_{k=1}^K[\log \sum_{i=1}^N \hat\gamma_{ik} - \log\beta+\log\frac 1{\sqrt{2\pi}} - \log\sigma_k  -\frac{(y_j-\mu_k)^2}{2\sigma_k^2}]\hat\gamma_{jk} +\sum_{i=1}^N \sum_{k=1}^K\hat\gamma_{ik}-\beta\\<br/>
\end{align*}<br/>
\]</p>

<p>拉格朗日乘子法可知需对 \(\min_{\alpha_k} L(\alpha,\beta)\) 求 \(\beta\) 的最大值，对 \(\beta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\min_{\alpha_k} L(\alpha,\beta)}{\partial \beta} = \frac{\sum_{j=1}^N\sum_{k=1}^K \hat\gamma_{jk}}{\beta} - 1 = \frac{N}{\beta} -1 <br/>
\end{align*}<br/>
\]</p>

<p>令导数为0，可得 \(\beta=N\)，代入可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{N}<br/>
\]</p>

<blockquote>
<p>其实不用拉格朗日求出 \(\beta\) 也可以，在求出 \(\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta}\) 后，直接考虑到：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{k=1}^K \alpha_k = 1 \quad &amp;\Rightarrow \quad \sum_{k=1}^K \frac{\sum_{j=1}^N \hat\gamma_{jk}}{\beta} = 1\\<br/>
&amp;\Rightarrow \quad \frac{\sum_{j=1}^N \sum_{k=1}^K \hat\gamma_{jk}}{\beta} = 1\\<br/>
&amp;\Rightarrow \quad \frac{N}{\beta} = 1 \\<br/>
&amp;\Rightarrow \quad \beta = N<br/>
\end{align*}<br/>
\]</p>

<p>代入可得：<br/>
\[<br/>
\alpha_k = \frac{\sum_{j=1}^N \hat\gamma_{jk}}{N}<br/>
\]</p>
</blockquote>

<p>至此，我们在隐变量已知的情况下得到了GMM的三种类型参数的求解公式。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15089443346795.html">期望最大化算法 EM</a></h1>
			<p class="meta"><time datetime="2017-10-25T23:12:14+08:00" 
			pubdate data-updated="true">2017/10/25</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>期望最大化算法的英文名称是 Expectation Maximization Algorithm，被称为机器学习十大算法之一。它是一种启发式迭代算法，是一种从不完全数据中求极大似然的算法。算法的每次迭代由两部组成：E步，求期望（Expectation）；M步，求最大值。</p>

<p>看到某篇文章中有个生动的例子阐述EM算法的核心思想：食堂大师傅炒了一盘菜，要等分给俩个人吃，显然没有必要拿天平去称分量，而是可以先随意的将菜倒入两个碗中，然后对比两个碗，从多的里面拿出少量放入少的碗里，再进行比较，再从多的里面拿出少量放入少的碗中，这个过程一直迭代下去，直到看不出哪个多一点少一点为止。</p>

<p>而EM算法便是这样，假设我们不知道A和B两个参数的值，并且如果知道了A的值，就能很容易求出B的值，知道B的值，也能很容易求出A的值。可以考虑先赋予A一个初值，通过这个值求出B的值，再反过来通过B的值求得A的值，反复迭代直到A、B收敛。</p>

<h3 id="toc_0">二硬币问题</h3>

<p>考虑一个掷硬币的例子：假设有A和B两个密度不相等硬币，它们掷出来的正面和反面的概率不相等，我们将 A 和 B 投掷出来的正面的概率设为 \(\theta_A\) 和 \(\theta_B\) ，现在独立的进行5次实验，每次实验选取 A 或 B 中一枚硬币投掷10次，统计出正面的概率。</p>

<p>在这个实验中，我们记录两组向量 \(x=(x_1,x_2,x_3,x_4,x_5)\) 和 \(z=(z_1,z_2,z_3,z_4,z_5)\) ，其中 \(x_i\in(0,1,2,3,4,5,6,7,8,9,10)\) 代表第 \(i\) 次实验中出现正面朝上的次数，\(z_i\in(A,B)\) 表示第 \(i\) 次实验投掷的是硬币A还是硬币B。这次设置的参数估计是完整数据情况，因为我们模型里关联的随机变量（每次实验的结果和投掷硬币的类型）的值都是已知的。</p>

<p>这里一个简单的估计 \(\theta_A\) 和 \(\theta_B\) 的方法是返回每一个硬币观察到的正面的比例。<br/>
\[<br/>
\begin{equation}<br/>
\hat\theta_A = \frac{\text{用 A 硬币投掷出来的正面的次数}}{\text{用 A 硬币投掷的总的次数}} \label{ybzm}\\<br/>
\hat\theta_B = \frac{\text{用 B 硬币投掷出来的正面的次数}}{\text{用 B 硬币投掷的总的次数}} \\<br/>
\end{equation}<br/>
\]</p>

<p>实际上，在统计学上这种直观的猜测被称为极大似然估计。如果用 \(\log P(x;z;\theta)\)表示得到的观察到的正面次数 \(x\) 和 使用硬币的类型 \(z\) 的联合概率的对数形式（对数似然），那么\ref{ybzm}中的公式就是求解使 \(\log P(x;z;\theta)\) 最大的 \(\hat\theta=(\theta_A,\theta_B)\) 。</p>

<div align=center>
    <img width=500 src="media/15089443346795/15308145217430.jpg">
</div>

<p>现在考虑挑战一个参数估计问题中更大的变体，我们给出正面次数的记录但不给出每一组投掷的硬币的类型。我们将 z 称为隐藏变量或潜在因子。这种新设置中的参数估计被称为不完整数据情况。这次对每一种硬币计算正面出现的比例将不再可行，因为我们将不知道每一次实验中所使用的硬币类型。然而，我们有一些方法来使数据完整（在我们的例子中，正确猜测5次实验中使用的是哪个金币），然后我们就能将不完整数据的参数估计简化到完整数据的极大似然估计。</p>

<p>可以通过一个迭代的方法得到完整数据通过下列步骤：开始时给定一个初始值 \(\hat \theta^{(t)}=(\hat\theta^{(t)}_A,\hat\theta^{(t)}_B)\)，我们通过这个初始值来估计5次实验中每一次最有可能使用的硬币是 A 还是 B。然后我们假设这些结论（即猜测指定的硬币）是正确的，然后再使用常规的最大似然估计处理来获得 \(\hat\theta^{(t+1)}\)。最后，重复这两个过程直到收敛。随着参数模型的改进，最终完成的质量也会提高。</p>

<p>如下图所示：先初始化 \(\hat\theta_A^{(0)}=0.6\) 和 \(\hat\theta_B^{(0)}=0.5\) ，我们第一轮实验掷的 5H 和 5T ，正面出现的概率是0.5，更有可能是用硬币 B 投掷，同理第二轮实验正面的概率为0.9，更有可能是硬币 A 投掷......全部猜测完之后，便可以根据我们猜测计算出投掷硬币 A 正面出现的次数是24，反面出现的次数是6，那么可以计算出硬币 A 正面出现的概率 \(\hat\theta_A^{(1)}=0.8\)，同理计算出硬币 B 正面出现的概率 \(\hat\theta_B^{(1)}=0.45\)。重复这个过程，得出最终过程。</p>

<div align=center>
    <img width=520 src="media/15089443346795/15308182178307.jpg">
</div>

<p>期望最大化算法就是对这个基本思想的改进。期望最大化算法并不需要在每一次迭代中选出一个最有可能的硬币（ A 还是 B ），而是用当前参数 \(\hat\theta^{(t)}\) 计算出投掷硬币是 A 或 B 的概率，在此基础上建立一个所有可能完成数据的加权训练数据集。最后，通过改进版本的极大似然估计处理这些加权训练数据集得出一个新的估计参数 \(\hat\theta^{(t+1)}\) 。通过使用加权训练集而不是单个的最有可能的完整数据的好处是EM算法考虑了模型在每一个完整数据的置信度。</p>

<p>如下图所示：先初始化 \(\hat\theta_A^{(0)}=0.6\) 和 \(\hat\theta_B^{(0)}=0.5\) ，我们第一轮实验掷的 5H 和 5T ，所以是用硬币 A 投掷的，正面出现的概率为 \(P_A=\text{C}_{10}^5 (\hat\theta_A^{(0)})^5 (1-\theta_A^{(0)})^5\)，如果是硬币 B 投掷的，正面出现的概率为 \(P_B=\text{C}_{10}^5 (\hat\theta_B^{(0)})^5 (1-\theta_B^{(0)})^5\)，所以投掷的是硬币 A 的概率为：\(\frac{P_A}{P_A+P_B}\thickapprox 0.45\)，同理可求的投掷的是硬币 B 的概率为：\(\frac{P_B}{P_A+P_B}\thickapprox 0.55\)。实际发生正面向上的次数是5，所以这次硬币 A 正面向上的期望为 \(5\times 0.45=2.2\)，硬币 B 正面向上的期望是 \(5\times 0.55\thickapprox 2.8\)，同理求出其他实验结果，这时候再按照完整数据求的硬币 A 正面向上的概率：<br/>
\[<br/>
\hat\theta_A^{(1)} = \frac{21.3}{21.3+8.6} = 0.71<br/>
\]<br/>
同理可求得硬币 B 正面向上的概率。重复这两个流程，便可得最终结果。</p>

<div align=center>
    <img width=520 src="media/15089443346795/15308183981554.jpg">
</div>

<p>总的来说，通过这个EM算法例子，可知EM算法包括两个步骤：E步骤求期望的过程；M步骤，求极大的过程。</p>

<h3 id="toc_1">琴生不等式 Jensen inequality</h3>

<p>1）若 \(f(x)\) 是区间 \((a,b)\) 上的凸函数，有：<br/>
\[<br/>
f[E(x)] \ge E[f(x)]<br/>
\]</p>

<p>2) 若 \(f(x)\) 是区间 \((a,b)\) 上的凹函数（下凸函数），有：<br/>
\[<br/>
f[E(x)] \le E[f(x)]<br/>
\]</p>

<p>3）加权形式凸函数，有：<br/>
\[<br/>
f(a_1x_1+a_2x_2+...+a_nx_n) \ge a_1f(x_1) + a_2f(x_2) + ... + a_nf(x_n),\sum_{i=1} a_i = 1<br/>
\]</p>

<p>4）加权形式凹函数（下凸函数），有：<br/>
\[<br/>
f(a_1x_1+a_2x_2+...+a_nx_n) \le a_1f(x_1) + a_2f(x_2) + ... + a_nf(x_n),\sum_{i=1} a_i = 1<br/>
\]</p>

<p>在本文中，使用加权形式凸函数，令 \(f(x) = \log(x)\) ，\(f(x)&#39;&#39; = (1/x)&#39; = -x^{-2} &lt; 0\)，所以 \(f(x)\) 是凸函数，则：<br/>
\[<br/>
\begin{equation}<br/>
\log[\sum_{i=1} a_i x_i] \ge \sum_{i=1} a_i f(x_i) \label{jensen0}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_2">EM算法推导</h3>

<p>现在通过一个经典的三硬币模型，来看一下EM算法的算法步骤以及推导过程。</p>

<h5 id="toc_3">三硬币模型</h5>

<p>假设有三枚硬币，记为 A，B，C。这些硬币都是密度不均匀的，投掷正面向上的概率分别为 \(\pi\)，\(p\)，\(q\)。现在进行实验：每轮实验先投掷 A 硬币，如果正面朝上，则投掷 B 硬币，如果反面朝上，则投掷 C 硬币；然后投掷选出的硬币，记录正面向上为1，反面向上为0。独立重复进行 n 次实验，假设只能观察到最终记录的结果，不能观察到掷硬币的过程，现在要估计 \(\theta=(\pi,p,q)\) 的概率参数。</p>

<p>将问题抽象出来：</p>

<ul>
<li><strong>输入</strong>：观察数据 \(Y\)</li>
<li><p><strong>输出</strong>：模型参数 \(\theta\)</p></li>
<li><p><strong>方法</strong>：定义隐变量为 \(Z\) ，则观察数据的对数似然函数 <br/>
\[<br/>
L(\theta|Y) = \log P(Y|\theta) = \log \sum_Z P(Y,Z|\theta) = \log \sum_Z P(Y|Z,\theta) P(Z|\theta)<br/>
\]</p>

<p>最大化观测数据的对数似然函数<br/>
\[<br/>
\theta^* = arg \max_\theta L(\theta|Y)<br/>
\]</p></li>
</ul>

<p>对于这个问题不能直接求解，只能通过迭代的方式求解。EM算法便是用来求解此类问题的一种迭代算法。EM算法首先选取参数的初值 \(\theta^{(0)} = (\pi^{(0)},p^{(0)},q^{(0)})\)，然后通过迭代，第 \(i\) 次迭代参数的估计值记为 \(\theta^{(i)} = (\pi^{(i)},p^{(i)},q^{(i)})\)，在第 \(i+1\) 次迭代的E步迭代参数的估计值记为 \(\theta\)。</p>

<h5 id="toc_4">E 步骤：</h5>

<p>定义完全数据 \(Y\), \(Z\) 的对数似然函数 \(\log P(Y,Z|\theta)\)，关于未观测数据 \(Z\) 在给定观测数据 \(Y\) 和当前参数估计 \(\theta_i\) 的情况下的后验概率分布 \(P(Z|Y,\theta_i)\) 的条件期望称为 \(Q\)函数：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
&amp;= \sum_Z \log P(Y,Z|\theta) P(Z|Y,\theta^{(i)}) <br/>
\end{align*}<br/>
\]</p>

<p>\(Q\) 函数中的两个概率分布：</p>

<ul>
<li><p>完全数据 \(Y\), \(Z\) 的对数似然函数 \(\log P(Y,Z|\theta)\)：<br/>
\[<br/>
\log P(Y,Z|\theta) = \log P(Y|Z,\theta)P(Z|\theta)<br/>
\]</p></li>
<li><p>未观测数据 \(Z\) 的后验概率分布 \(P(Z|Y,\theta^{(i)})\)：<br/>
\[ <br/>
\begin{equation}<br/>
P(Z|Y,\theta^{(i)})=\frac{P(Y,Z|\theta^{(i)})}{P(Y|\theta^{(i)})}=\frac{P(Y,Z|\theta^{(i)})}{\sum_{Z′}P(Y,Z′|\theta^{(i)})}=\frac{P(Y|Z,\theta^{(i)})P(Z|\theta^{(i)})}{\sum_{Z′}P(Y|Z′,\theta^{(i)})P(Z′|\theta^{(i)})}\label{zhy}<br/>
\end{equation}<br/>
\]</p></li>
</ul>

<h5 id="toc_5">M步骤：</h5>

<p>求解使 \(Q(\theta,\theta^{(i)})\) 最大的 \(\theta\) ，确定第 \(i+1\) 次迭代的参数估计值 \(\theta^{(i+1)}\) ：<br/>
\[<br/>
\theta^{(i+1)} = arg \max_\theta Q(\theta,\theta^{(i)})<br/>
\]</p>

<h5 id="toc_6">证明：</h5>

<p>在迭代过程中，我们希望新估计值 \(\theta\) 能使 \(L(\theta)\) 增加，即 \(L(\theta) &gt; L(\theta^{(i)})\)，并逐步成为最大值，所以：<br/>
\[<br/>
\begin{align}<br/>
L(\theta) - L(\theta^{(i)}) &amp;= \log P(Y|\theta) - \log P(Y|\theta^{(i)}) \nonumber\\<br/>
&amp;= \log [\sum_Z P(Z,\theta) P(Y|Z,\theta)] - \log P(Y|\theta^{(i)}) \nonumber\\<br/>
&amp;= \log [\sum_Z P(Y|Z,\theta^{(i)}) \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}] - \log P(Y|\theta^{(i)}) \label{ptl}<br/>
\end{align}<br/>
\]</p>

<p>使用式 \ref{jensen0} 得：<br/>
\[<br/>
\log [\sum_Z P(Y|Z,\theta^{(i)}) \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}] \ge \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})}<br/>
\]</p>

<p>将上式带入式 \ref{ptl} 得：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta) - L(\theta^{(i)}) &amp;\ge  \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})} - \log P(Y|\theta^{(i)})\\<br/>
&amp;= \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})}\\<br/>
\end{align*}<br/>
\] </p>

<p>令 <br/>
\[<br/>
\begin{equation}<br/>
B(\theta,\theta^{(i)}) = L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})} \label{BTT}\\<br/>
\end{equation}<br/>
\]</p>

<p>则：<br/>
\[<br/>
L(\theta) \ge B(\theta,\theta^{(i)})<br/>
\]</p>

<p>那么，\(B(\theta,\theta^{(i)})\) 是 \(L(\theta)\) 的下限。并从式 \ref{BTT} 可知：<br/>
\[<br/>
 L(\theta^{(i)}) = B(\theta^{(i)},\theta^{(i)})<br/>
\] </p>

<p>任何能使 \(B(\theta,\theta^{(i)})\) 变大的 \(\theta\) 都能使 \(L(\theta)\) 增大，选择 \(\theta^{(i+1)}\) 使 \(B(\theta,\theta^{(i)})\) 达到极大。即：<br/>
\[<br/>
\theta^{(i+1)} = arg \max_\theta B(\theta,\theta^{(i)})<br/>
\]</p>

<p>现在对 \(B(\theta,\theta^{(i)})\) 求 \(\theta^{(i+1)}\) ：<br/>
\[<br/>
\begin{align*}<br/>
\theta^{(i+1)} &amp;= arg \max_\theta B(\theta,\theta^{(i)}) = arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log \frac{P(Z,\theta) P(Y|Z,\theta)}{P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})} ] \\<br/>
&amp;= arg \max_\theta \{L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) [\log P(Z,\theta) P(Y|Z,\theta) - \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})]\} \\<br/>
&amp;= arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta) - \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})] \\<br/>
\end{align*}<br/>
\]</p>

<p>省去其中含有 \(\theta^{(i)}\) 的常数项：<br/>
\[<br/>
\begin{align*}<br/>
\theta^{(i+1)} &amp;= arg \max_\theta [L(\theta^{(i)}) + \sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta) - \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y|Z,\theta^{(i)})P(Y|\theta^{(i)})] \\<br/>
&amp;= arg \max_\theta [\sum_Z P(Y|Z,\theta^{(i)}) \log P(Z,\theta) P(Y|Z,\theta)]\\<br/>
&amp;= arg \max_\theta [\sum_Z P(Y|Z,\theta^{(i)}) \log P(Y,Z|\theta)]\\<br/>
\end{align*}<br/>
\]</p>

<p>令<br/>
\[<br/>
Q(\theta,\theta^{(i)}) = \sum_Z P(Y|Z,\theta^{(i)}) \log P(Y,Z|\theta)<br/>
\]</p>

<p>所以这就像相当于 EM 算法的一次迭代，即求 \(Q\)函数及求其极大化的过程。</p>

<h5 id="toc_7">EM算法的收敛性</h5>

<p>要证明EM 算法的收敛性，也就是每一次迭代都比以前的结果更优，也就是证明：<br/>
\[<br/>
\begin{equation}<br/>
L(\theta^{(i+1)}) \ge  L(\theta^{(i)}) \quad\Leftrightarrow\quad \log P(Y|\theta^{(i+1)}) \ge \log P(Y|\theta^{(i)})\label{LTLL}<br/>
\end{equation}<br/>
\]</p>

<p>也就是证明 \(\log P(Y|\theta)\) 单调递增，考虑到：</p>

<p>\[<br/>
\begin{align}<br/>
\because \quad &amp; \sum_Z P(Z|Y,\theta^{(i)})=1\nonumber\\<br/>
\therefore \quad &amp; \log P(Y|\theta)= [\log P(Y|\theta)]\sum_Z P(Z|Y,\theta^{(i)})\nonumber\\<br/>
&amp;\qquad\qquad = \sum_Z P(Z|Y,\theta^{(i)})\log P(Y|\theta)\nonumber\\<br/>
\because \quad &amp;P(Y|\theta) = \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)}\nonumber\\<br/>
\therefore \quad &amp; \log P(Y|\theta) = \sum_Z P(Z|Y,\theta^{(i)})\log \frac{P(Y,Z|\theta)}{P(Z|Y,\theta)}\nonumber\\<br/>
&amp;\qquad\qquad = \sum_Z P(Z|Y,\theta^{(i)}) \log P(Y,Z|\theta) - \sum_Z P(Z|Y,\theta^{(i)}) \log P(Z|Y,\theta) \nonumber\\<br/>
&amp;\qquad\qquad = E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] - E_Z[\log P(Z|Y,\theta)|Y,\theta^{(i)}]\label{slxzm}<br/>
\end{align}<br/>
\]</p>

<p>令</p>

<p>\[<br/>
\begin{align*}<br/>
H(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Z|Y,\theta)|Y,\theta^{(i)}]= \sum_Z P(Z|Y,\theta^{(i)}) \log(Z|Y,\theta)<br/>
\end{align*}<br/>
\]</p>

<p>所以式 \ref{slxzm} 可以写成 \(\log P(Y|\theta) = Q(\theta,\theta^{(i)}) - H(\theta,\theta^{(i)})\)，则：<br/>
\[<br/>
\begin{align*}<br/>
L(\theta^{(i+1)}) - L(\theta^{(i)}) &amp;= \log P(Y|\theta^{(i+1)}) - \log P(Y|\theta^{(i)}) \\<br/>
&amp;= [Q(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i+1)},\theta^{(i)})] - [Q(\theta^{(i)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)})] \\<br/>
&amp;= [Q(\theta^{(i+1)},\theta^{(i)})- Q(\theta^{(i)},\theta^{(i)})] - [H(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)})] \\<br/>
\end{align*}<br/>
\]</p>

<p>因为EM算法是求 \(\theta^{(i+1)}\) 使 \(Q(\theta,\theta^{(i)})\) 增大，所以第一项不用证明，必大于0，现证明第二项：<br/>
\[<br/>
\begin{align*}<br/>
H(\theta^{(i+1)},\theta^{(i)}) - H(\theta^{(i)},\theta^{(i)}) &amp;= \sum_Z  P(Z|Y,\theta^{(i)}) \log P(Z|Y,\theta^{(i+1)})  - \sum_Z P(Z|Y,\theta^{(i)})\log(Z|Y,\theta^{(i)}) \\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \log \frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})} \\<br/>
&amp;\le \log [\sum_Z \log P(Z|Y,\theta^{(i)}) \frac{P(Z|Y,\theta^{(i+1)})}{P(Z|Y,\theta^{(i)})} ]\\<br/>
&amp;= \log [\sum_Z P(Z|Y,\theta^{(i+1)})]\\<br/>
&amp;= 0<br/>
\end{align*}<br/>
\]  </p>

<p>所以\(L(\theta^{(i+1)}) - L(\theta^{(i)}) \ge 0\)，得证。从上面的推导可以看出，EM算法可以保证收敛到一个稳定点，但是却不能保证收敛到全局的极大值点，因此它是局部最优的算法，当然，如果我们的优化目标 \(Q(θ,θ^{(i)})\) 是凸的，则EM算法可以保证收敛到全局最大值，这点和梯度下降法这样的迭代算法相同。</p>

<h4 id="toc_8">三硬币求解</h4>

<p>我们用 \(y\) 表示观察变量，表示一次实验观察的结果是 1（正面） 或 0（反面）；使用 \(z\) 表示隐变量，表示未观察到的投掷 A 硬币的结果。一次实验观察数据 \(Y_i\) 的概率：<br/>
\[<br/>
\begin{align*}<br/>
P(Y_i=y|\theta) &amp;= \sum_z P(y,z|\theta) = \sum_z P(z|\theta)P(y|z,\theta) \\<br/>
&amp;= \pi p^y (1-p)^{1-y} + (1-\pi) q^y (1-q)^{1-y}<br/>
\end{align*}<br/>
\]</p>

<p>将观察数据表示为 \(Y=(Y_1,Y_2,...,Y_n)^T\)，不可观察数据表示为 \(Z=(Z_1,Z_2,...,Z_n)^T\)，观察数据的似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
P(Y|\theta) &amp;= P(Y_1,Y_2,...,Y_n|\theta) = \prod_{i=1}^n P(Y_i|\theta) \\<br/>
&amp;= \prod_{i=1}^n [\pi p^{y_i} (1-p)^{1-{y_i}} + (1-\pi) q^{y_i} (1-q)^{1-y_{i}}]<br/>
\end{align*}<br/>
\]</p>

<h6 id="toc_9">E步骤：</h6>

<p>先定义Q函数为：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
\end{align*}<br/>
\]</p>

<p>现在来化简 Q函数，先看：<br/>
\[<br/>
P(Y,Z|\theta) = \prod_j P(Y_j,Z_j|\theta) = \prod_j \prod_k P(Y_j,Z_j=k|\theta)^{Z_{jk}}<br/>
\]</p>

<p>这里使用 \(Z_{jk}\) 表示观察数据 \(Y_j\) 对应的隐藏数据，也就是硬币 A 的结果，在这个例子中 \(k=\{0,1\}\)：<br/>
\[<br/>
Z_{jk} = \left \{ \begin{array}\\ 1 \quad &amp; Z_j = k\\ 0 \quad &amp; Z_j \neq k\\\end{array}\right .<br/>
\]</p>

<p>所以：<br/>
\[<br/>
\begin{align*}<br/>
\log P(Y,Z|\theta) &amp;= \log \prod_j \sum_k P(Y_j,Z_j=k|\theta)^{Z_{jk}} = \sum_j \sum_k Z_{jk} \log P(Y_j,Z_j=k|\theta) <br/>
\end{align*}<br/>
\]</p>

<p>上式代入 Q函数得：<br/>
\[<br/>
\begin{align*}<br/>
Q(\theta,\theta^{(i)}) &amp;= E_Z[\log P(Y,Z|\theta)|Y,\theta^{(i)}] \\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \log P(Y,Z|\theta)\\<br/>
&amp;= \sum_Z P(Z|Y,\theta^{(i)}) \sum_j \sum_k Z_{jk} \log P(Y_j,Z_j=k|\theta)\\<br/>
&amp;= \sum_j \sum_k \sum_Z P(Z|Y,\theta^{(i)}) (Z_{jk})\log P(Y_j,Z_j=k|\theta)\\<br/>
&amp;= \sum_j \sum_k \log P(Y_j,Z_j=k|\theta) \sum_Z P(Z|Y,\theta^{(i)}) Z_{jk}\\<br/>
\end{align*}<br/>
\]</p>

<p>现在来计算 \(\sum_Z P(Z|Y,\theta^{(i)}) Z_{jk}\)，因为只有 \(Z_j=k\) 时 \(Z_{jk}=1\) ，其他都等于0，所以：<br/>
\[<br/>
\sum_Z P(Z|Y,\theta^{(i)}) Z_{jk} = \sum_Z Z_{jk} \sum_j\sum_k P(Z_j=k|Y_j,\theta^{(i)}) = P(Z_j=k|Y_j,\theta^{(i)})<br/>
\]</p>

<p>分别代入 \(k=0\) 或 \(k=1\)，得：<br/>
\[<br/>
\begin{align*}<br/>
P(Z_j=0|Y_j,\theta^{(i)}) &amp;= \frac{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}} \\<br/>
P(Z_j=1|Y_j,\theta^{(i)}) &amp;= \frac{(1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}} \\<br/>
\end{align*}<br/>
\]</p>

<p>令：</p>

<p>\[<br/>
\begin{equation}<br/>
\mu_{i,j} = \frac{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j}}{\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\pi^{(i)}) (q^{(i)})^{y_j}(1-q^{(i)})^{1-y_j}}\label{muij}<br/>
\end{equation}<br/>
\]</p>

<p>则：</p>

<p>\[<br/>
\sum_Z P(Z_j=k|Y_j,\theta^{(i)}) Z_{jk} = \left \{ \begin{array}\\<br/>
\mu_{i,j} &amp; \quad if\quad k=0\\<br/>
1-\mu_{i,j} &amp; \quad if\quad k=1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>再求 \(\sum_j \sum_k \log P(Y_j,Z_j=k|\theta)\)，分别代入 \(k=0\) 或 \(k=1\) 得：</p>

<p>\[<br/>
P(Y_j,Z_j|\theta) = \left \{ \begin{array}\\<br/>
\pi p^{y_j}(1-p)^{1-y_j}&amp; \quad if \quad k = 0\\<br/>
(1-\pi) q^{y_j}(1-q)^{1-y_j}&amp;\quad if \quad k = 1\\<br/>
\end{array} \right .<br/>
\]</p>

<p>所以Q函数可以改写为：</p>

<p>\[<br/>
Q(\theta,\theta^{(i)}) = \sum_j \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}<br/>
\]</p>

<h6 id="toc_10">M步骤</h6>

<p>Q函数对参数 \(\pi\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial \pi} &amp;= \sum_j \frac{\partial \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}}{\partial \pi}\\<br/>
&amp;= \sum_j [\mu^{i,j} \frac{p^{y_j}(1-p)^{1-y_j}}{\pi p^{y_j}(1-p)^(1-y_j)} - (1-\mu_{i,j})\frac{q^{y_j}(1-q)^{1-y_j}}{(1-\pi)q^{y_j}(1-q){1-y_j}}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}}{\pi} - \frac{1-\mu_{i,j}}{1-\pi}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}(1-\pi) - (1-\mu_{i,j})\pi}{\pi(1-\pi)}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j} - \pi}{\pi(1-\pi)}]\\<br/>
&amp;= \frac{\sum_j \mu_{i,j} - n\pi}{\pi(1-\pi)}] = 0\\<br/>
\Rightarrow \quad &amp; \pi = \frac 1 n \sum_j \mu_{i,j}<br/>
\end{align*}<br/>
\]</p>

<p>Q函数对参数 \(p\) 求导：</p>

<p>\[<br/>
\begin{align*}<br/>
\frac{\partial Q(\theta,\theta^{(i)})}{\partial p} &amp;= \sum_j \frac{\partial \{\mu^{i,j} \log [\pi p^{y_j}(1-p)^{1-y_j}] + (1-\mu^{i,j}) \log [(1-\pi) q^{y_j}(1-q)^{1-y_j}]\}}{\partial p}\\<br/>
&amp;= \sum_j [\mu_{i,j}\frac{\pi y_j p^{y_j-1}(1-p)^{1-y_j}-\pi p^{y_j}(1-y_j)(1-p)^{-y_j}}{\pi p^{y_j}(1-p)^{1-y_j}}]\\<br/>
&amp;= \sum_j [\mu_{i,j}\frac{y_j(1-p)-p(1-y_j)}{p(1-p)}]\\<br/>
&amp;= \sum_j [\frac{\mu_{i,j}(y_j-p)}{p(1-p)}]\\<br/>
&amp;= \frac{\sum_j \mu_{i,j} y_j - \sum_j \mu_{i,j}p}{p(1-p)} = 0\\<br/>
\Rightarrow \quad &amp; p = \frac{\sum_j \mu_{i,j}y_j}{\sum_j \mu_{i,j}}<br/>
\end{align*}<br/>
\]</p>

<p>Q函数对参数 \(q\)求导，同上，直接写出结果：</p>

<p>\[<br/>
q = \frac{\sum_j (1-\mu_{i,j})y_j}{\sum_j (1-\mu_{i,j})}<br/>
\]</p>

<p>综合三式得：</p>

<p>\[<br/>
\begin{align}<br/>
\pi^{(i+1)} &amp;= \frac 1 n \sum_j \mu_{i,j}\label{pii1}\\<br/>
p^{(i+1)} &amp;= \frac{\sum_j \mu_{i,j}y_j}{\sum_j \mu_{i,j}}\label{pi1}\\<br/>
q^{(i+1)} &amp;= \frac{\sum_j (1-\mu_{i,j})y_j}{\sum_j (1-\mu_{i,j})}\label{qi1}<br/>
\end{align}<br/>
\]</p>

<p>当给定初值便可以进行迭代求解了。</p>

<p>假设三硬币模型的结果如下：</p>

<p>\[<br/>
1,1,0,1,0,0,1,0,1,1<br/>
\]</p>

<p>假定一开始我们设初始值 \(\pi^{(0)}=0.5,p^{(0)} = 0.5,q^{(0)} = 0.5\)，由式 \ref{muij} 对 \(y_j=0\) 或 \(y_j=1\) ，都有：<br/>
\[<br/>
\mu_{0,0} = \frac{\pi^{(0)} (p^{(0)})^{y_0}(1-p^{(0)})^{1-y_0}}{\pi^{(0)} (p^{(0)})^{y_0}(1-p^{(0)})^{1-y_0} + (1-\pi^{(0)}) (q^{(0)})^{y_0}(1-q^{(0)})^{1-y_0}} = 0.5\\<br/>
\mu_{0,1} = \frac{\pi^{(0)} (p^{(0)})^{y_1}(1-p^{(0)})^{1-y_1}}{\pi^{(0)} (p^{(0)})^{y_1}(1-p^{(0)})^{1-y_1} + (1-\pi^{(0)}) (q^{(0)})^{y_1}(1-q^{(0)})^{1-y_1}} = 0.5\\<br/>
\]</p>

<p>利用式 \ref{pii1}、式\ref{pi1}、式 \ref{qi1} 迭代可得：<br/>
\[<br/>
\pi^{(1)} = 0.5,\quad p^{(1)} = 0.6,\quad q^{(1)} = 0.6<br/>
\]</p>

<p>由 \ref{muij} 得：</p>

<p>\[<br/>
\mu_{1,0} = 0.5,\quad \mu_{1,1} = 0.5<br/>
\]</p>

<p>继续迭代得：<br/>
\[<br/>
\pi^{(2)} = 0.5,\quad p^{(2)} = 0.6,\quad q^{(2)} = 0.6<br/>
\]</p>

<p>于是得到 \(\theta\) 的极大似然估计为：<br/>
\[<br/>
\hat \pi = 0.5,\quad \hat p = 0.6,\quad \hat q = 0.6<br/>
\]</p>

<p>另外我们可以试一下，设置不同的初值，最终结果可能不同，也就是说EM算法与初值的选取有关，选择不同的初值可能会得到不同的结果。</p>

<hr/>

<p><a href="http://www.cs.tau.ac.il/%7Ershamir/algmb/archive/EM-BW.pdf">Introduction to Expectation Maximization</a></p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15061862782517.html">最大后验概率估计 MAP</a></h1>
			<p class="meta"><time datetime="2017-09-24T01:04:38+08:00" 
			pubdate data-updated="true">2017/9/24</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>最大后验概率估计的全称是 Maximum a posteriori estimation，简称MAP。极大似然估计是通过求参数 \(\theta\) ，使似然函数估计 \(P(x_0|\theta)\)最大。最大后验概率估计顾名思义就是最大化后验概率，看一下后验概率的定义：<br/>
\[<br/>
p(\theta|x) = \frac{\pi(\theta)\prod_{i=1}^N p(x_i|\theta)}{\prod_{i=1}^N p(x_i)}<br/>
\]</p>

<p>因为样本是固定的，所以认为分母是固定的，所以最大后验概率与使 \(\pi(\theta)\prod_{i=1}^N p(x_i|\theta)\) 最大的 \(\theta\) 值同解：<br/>
\[<br/>
\hat \theta = \arg\max_\theta p(\theta|x) = \arg\max_\theta \pi(\theta)\prod_{i=1}^N p(x_i|\theta)<br/>
\]</p>

<p>其中 \(p(x|\theta)=\prod_{i=1}^N p(x_i|\theta)\) 就是似然函数，\(\pi(\theta)\) 是参数的先验知识，所以我们可以认为最大后验估计就是规则化的极大似然估计，对上式加上对数处理后：<br/>
\[<br/>
\begin{align}<br/>
\arg\max_\theta p(\theta|x) &amp;= \arg\max_\theta [\ln \prod_{i=1}^N p(x_i|\theta) + \ln\pi(\theta)]\nonumber\\<br/>
&amp;= \arg\max_\theta[\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta)] \label{hygl}<br/>
\end{align}<br/>
\]</p>

<h4 id="toc_0">二项分布</h4>

<p>在二项分布中，假设参数的先验分布满足贝塔分布 \(Be(\alpha,\beta)，\)即：<br/>
\[<br/>
\pi(\theta) = \frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}<br/>
\]</p>

<p>而二项分布中每次的结果都用 \(\theta\) 表示为：<br/>
\[<br/>
p(x_i|\theta) = \theta^{x_i}(1-\theta)^{1-x_i}<br/>
\]<br/>
将上两式带入式\ref{hygl}中，很容易得到对数后验概率为：<br/>
\[<br/>
\begin{align}<br/>
\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta) &amp;= \sum_{i=1}^N \ln [\theta^{x_i}(1-\theta)^{1-x_i}] + \ln[\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}]\label{dshy}\\<br/>
\end{align}<br/>
\]</p>

<p>要想求出对数后验概率的最大值，需要对其求导。可以分成两部分对 \(\theta\) 求导，前面一项在极大似然估计已经求出，直接给出结果：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\{\sum_{i=1}^N[ \ln[\theta^{x_i}(1-\theta)^{1-x_i}]\} = \frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i)<br/>
\end{align*}<br/>
\]</p>

<p>我们来看式\ref{dshy}的后一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\{\ln[\frac{1}{B(\alpha,\beta)}\theta^{\alpha-1}(1-\theta)^{\beta-1}]\} &amp;= \frac{\partial}{\partial \theta}[-\lnB(\alpha,\beta)+(\alpha-1)\ln\theta+(\beta-1)\ln(1-\theta)]\\<br/>
&amp;=\frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta}<br/>
\end{align*}<br/>
\]</p>

<p>所以对数后验概率对 \(\theta\) 求导结果为上面两项之和，即：<br/>
\[<br/>
\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) + \frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta}<br/>
\]</p>

<p>为求得最大值，令上式为0：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) + \frac{\alpha-1}{\theta}-\frac{\beta-1}{1-\theta} = 0\\<br/>
\Rightarrow &amp;(1-\theta)\sum_{i=1}^N x_i-\theta\sum_{i=1}^N(1-x_i)+(\alpha-1)(1-\theta) - (\beta-1)\theta = 0\\<br/>
\Rightarrow &amp;\sum_{i=1}^N x_i - \theta\sum_{i=1}^N x_i-n\theta+\theta\sum_{i=1}^N x_i + \alpha - 1 -\alpha\theta + \theta - \beta\theta + \theta = 0\\<br/>
\Rightarrow &amp; \sum_{i=1}^N x_i -n\theta + \alpha - 1 -\alpha\theta - \beta\theta +2\theta= 0\\<br/>
\Rightarrow &amp; \frac{\sum_{i=1}^N x_i + \alpha -1}{n+\alpha+\beta-2}<br/>
\end{align*}<br/>
\]</p>

<p>所以先验概率满足 \(Be(\alpha,\beta)\) 的二项分布的最大后验估计：<br/>
\[<br/>
\hat\theta = \frac{\sum_{i=1}^N x_i + \alpha -1}{n+\alpha+\beta-2}<br/>
\]</p>

<p>在投硬币的例子中这里的 \(\sum_{i=1}^N x_i\) 即为硬币正面朝上的次数， \(\sum_{i=1}^N x_i=7\) 。与MLE不同的是我们由经验一般会认为硬币的正面出现的概率为0.5，即先验概率 \(\pi(\theta) \sim Be(1,1)\)，所以由最大后验概率求得 \(\theta\) 的值为：<br/>
\[<br/>
\theta = \frac{7+1-1}{10+1+1-2} = 0.7<br/>
\]</p>

<p>有人可能会说，MLE和MAP不就是一样的吗？不是的，可以说这里只是一个偶然，如果说先验知识是硬币是均匀的，也就是这里的 \(\alpha=\beta\) ，但是他们的大小可以表示先验概率的确信度。当我们取\(\alpha=200,\beta=200\)时，在MLE中，没有考虑先验仍旧是0.7。但是在MAP中，\(\theta=\frac{7+200-1}{10+200+200-2} =0.5049\)，也就是说10次实验中7次正面朝上并不能动摇我们对先验概率的坚持。要想改变我们的看法，需要做更多的实验才可以，从这一点上来MAP比MLE有更多的可信性。</p>

<h4 id="toc_1">正太分布</h4>

<p>设 \(x_1\) , \(x_2\) , …, \(x_n\)是来自正态分布 \(N(\theta,\sigma^2)\)的一个样本，其中 \(\sigma^2\) 已知， \(\theta\)未知，假设 \(\theta\) 的先验分布亦为正态分布 \(N(\mu,\tau^2)\)，其中先验均值 \(\mu\) 和先验方差 \(\tau^2\) 均已知。</p>

<p>\[<br/>
\pi(\theta) = \frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\\<br/>
p(x_i|\theta) = \frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\\<br/>
\]</p>

<p>所以对数后验概率为：<br/>
\[<br/>
\begin{align*}<br/>
\sum_{i=1}^N \ln p(x_i|\theta)+\ln\pi(\theta)] = \sum_{i=1}^N \ln\{\frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\}+\ln\{\frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\}\\<br/>
\end{align*}<br/>
\]</p>

<p>将等式对 \(\theta\) 求导分成两部分，前面一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta}\sum_{i=1}^N \ln\{\frac{1}{\sqrt{2\pi}\sigma} \exp[-\frac{(x_i-\theta)^2}{2\sigma^2}]\} &amp;= \frac{\partial}{\partial \theta}\sum_{i=1}^N [\ln\frac{1}{\sqrt{2\pi}\sigma} -\frac{(x_i-\theta)^2}{2\sigma^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta}\frac{\sum_{i=1}^N(x_i-\theta)^2}{2\sigma^2}\\<br/>
&amp;= -\frac{\partial}{\partial \theta}\frac{\sum_{i=1}^N x_i^2-2\sum_{i=1}^N \theta x_i + \sum_{i=1}^N\theta^2}{2\sigma^2}\\<br/>
&amp;= \frac{n\theta-\sum_{i=1}^N x_i}{\sigma^2}<br/>
\end{align*}<br/>
\]</p>

<p>后面一项对 \(\theta\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial}{\partial \theta} \{\ln\{\frac{1}{\sqrt{2\pi}\tau} \exp[-\frac{(\theta-\mu)^2}{2\tau^2}]\} &amp;= \frac{\partial}{\partial \theta} [\ln\frac{1}{\sqrt{2\pi}\tau} - \frac{(\theta-\mu)^2}{2\tau^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta} [\frac{(\theta-\mu)^2}{2\tau^2}] \\<br/>
&amp;= -\frac{\partial}{\partial \theta} (\frac{\theta^2-2\mu\theta+\mu^2}{2\tau^2}) \\<br/>
&amp;= \frac{\theta-\mu}{\tau^2}<br/>
\end{align*}<br/>
\]</p>

<p>前后两项的和相加，再令其等于0：<br/>
\[<br/>
\begin{align*}<br/>
&amp; \frac{n\theta-\sum_{i=1}^N x_i}{\sigma^2} + \frac{\theta-\mu}{\tau^2} = 0\\<br/>
\Rightarrow &amp;n\tau^2\theta-\tau^2\sum_{i=1}^N x_i + \theta\sigma^2 - \mu\sigma^2 = 0\\<br/>
\Rightarrow &amp; \hat\theta = \frac{\tau^2\sum_{i=1}^N x_i + \mu\sigma^2}{n\tau^2+\sigma^2}<br/>
\end{align*} <br/>
\]</p>

<p>这里的结果和贝叶斯参数估计的结果表现形式一模一样。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15058431971790.html">极大似然估计 MLE</a></h1>
			<p class="meta"><time datetime="2017-09-20T01:46:37+08:00" 
			pubdate data-updated="true">2017/9/20</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>极大似然估计的英文全称是Maximum -likelihood Estimate，是指利用现有样本，反推能导致这样结果的最大可能的参数值（模型已定参数未知）。在一篇文章看到这样的比喻：某位同学和一个猎人出去打猎，他们同时看到了一个兔子，同时开枪，兔子应声而倒，如果要你猜测兔子是谁打死的？你可能很容易想到是猎人打死的，因为猎人命中的概率很大。这就是极大似然的思路，反推能导致这样结果的的最大可能参数。</p>

<h4 id="toc_0">算法步骤</h4>

<p>当从总体模型中选取n组观察样本后，可以这样认为，我们一次就选取到这n组观察样本，那么这n组样本的组合在总体模型中的联合概率密度最大。所以一般算法步骤如下：</p>

<p>记样本集 \(D = \{x_1,x_2,...,x_n\}\)，参数估计为 \(\theta\) ，最优参数为 \(\theta^*\)。</p>

<p>1）写出似然函数。联合概率密度 \(p(D|\theta)\) 称为相对于 \(D\) 的 \(\theta\) 的似然函数：<br/>
\[<br/>
L(\theta) = p(D|\theta) = p(x_1,x_2,...,x_n|\theta) = \prod_{i=1}^N p(x_i|\theta)<br/>
\] </p>

<p>2) 在实际分析中，累乘会不太好计算，通常作为是取对数，这里也不例外，定义对数似然函数：<br/>
\[<br/>
H(\theta) = \text{In} L(\theta) = \sum_{i=1}^N \text{In} p(x_i|\theta)<br/>
\]</p>

<p>2）对对数似然函数求导，求出令对数似然函数最大的参数值。<br/>
\[<br/>
\theta^* = arg\max_\theta L(\theta) = arg\max_\theta H(\theta) = arg\max \limits_\theta \sum_{i=1}^N \text{In} p(x_i|\theta)<br/>
\]</p>

<h4 id="toc_1">二项分布</h4>

<p>先以简单的抛硬币的例子来讲解，假设我们有一个质量不均匀的硬币，我们想知道这个硬币抛出去正面出现的概率 \(\theta\)，于是做了一个实验，抛了10次，得到的结果是（正面是1，反面是0）：<br/>
\[<br/>
\text{1}\quad\text{1}\quad\text{0}\quad\text{1}\quad\text{0}\quad\text{1}\quad\text{1}\quad\text{1}\quad\text{1}\quad\text{0}\quad<br/>
\]<br/>
如果我们抛开算法，会很容易得出 \(\theta=\frac{\text{正面次数}}{\text{正面次数}+\text{反面次数}}=0.7\)，现在通过MLE来求解一下。</p>

<p>通过上述的算法步骤先写出似然函数，假设正面出现的次数时，\(x_i=1\)：<br/>
\[<br/>
L(\theta) = \prod_{i=1}^N p(x_i|\theta) = \prod_{i=1}^N \theta^{x_i}(1-\theta)^{1-x_i}<br/>
\]<br/>
所以对数似然函数为：<br/>
\[<br/>
\begin{align*}<br/>
H(\theta) &amp;= \text{In}L(\theta) = \sum_{i=1}^N \text{In} \theta^{x_i}(1-\theta)^{1-x_i} \\<br/>
&amp;= \sum_{i=1}^N[ \text{In} \theta^{x_i}+\text{In}(1-\theta)^{1-x_i} ]\\<br/>
&amp;= \sum_{i=1}^N[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ]<br/>
\end{align*}<br/>
\]</p>

<p>对对数似然函数求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial H(\theta)}{\partial \theta} &amp;= \frac{\partial \sum_{i=1}^N[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ]}{\partial \theta}\\<br/>
&amp;= \sum_{i=1}^N \frac{\partial}{\partial \theta}[ x_i\text{In}\theta+(1-x_i)\text{In}(1-\theta) ] \\<br/>
&amp;= \sum_{i=1}^N (\frac{x_i}{\theta} - \frac{1-x_i}{1-\theta}) = \frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i)<br/>
\end{align*}<br/>
\]</p>

<p>令求导结果为0，来求得令 \(l(\theta)\)最大值的 \(\theta^*\)：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\frac 1 \theta \sum_{i=1} x_i-\frac 1 {(1-\theta)} \sum_{i=1}^N (1-x_i) = 0\\<br/>
&amp;\Rightarrow (1-\theta) \sum_{i=1} x_i = \theta (n-\sum_{i=1} x_i)\\<br/>
&amp;\Rightarrow \sum_{i=1} x_i - \theta\sum_{i=1} x_i = \theta (n-\sum_{i=1} x_i)\\<br/>
&amp;\Rightarrow \sum_{i=1} x_i = n\theta\\<br/>
&amp;\Rightarrow \theta = \frac 1 n \sum_{i=1} x_i<br/>
\end{align*}<br/>
\]</p>

<p>所以 \(\theta=0.7\) ，与我们用常识估计的相同。</p>

<h4 id="toc_2">正态分布</h4>

<p>假设样本X服从正态分布：<br/>
\[<br/>
x \sim N(\mu,\sigma^2)<br/>
\]</p>

<p>则似然函数为：<br/>
\[<br/>
L(\mu,\sigma^2) = \prod_{i=1}^N \frac 1{\sqrt{2\pi}\sigma}exp(-\frac{(x_i-\mu)^2}{2\sigma^2}) = (2\pi\sigma^2)^{-n/2} exp(-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2})<br/>
\]</p>

<p>则对数似然函数为：<br/>
\[<br/>
H(\mu,\sigma^2) = \text{In}L(\mu,\sigma^2) = -\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}+\text{In}[(2\pi\sigma^2)^{-n/2}] = -\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)<br/>
\]</p>

<p>分别用对数似然函数对 \(\mu\) 和 \(\sigma^2\) 求导：<br/>
\[<br/>
\begin{align*}<br/>
\frac{\partial H(\mu,\sigma^2)}{\partial \mu} &amp;= \frac{\partial}{\partial \mu}[-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)] \\<br/>
&amp;=\frac{\partial}{\partial \mu}[-\frac{\sum_{i=1}^N (x_i^2-2x_i\mu+\mu^2)}{2\sigma^2}]\\<br/>
&amp;=\frac{-2\sum_{i=1}^N x_i + 2\sum_{i=1}^N \mu}{2\sigma^2}\\<br/>
\Rightarrow &amp; \mu^* = \frac 1 n \sum_{i=1}^N x_i\\<br/>
\frac{\partial H(\mu,\sigma^2)}{\partial \sigma^2} &amp;= \frac{\partial}{\partial \sigma^2}[-\frac{\sum_{i=1}^N (x_i-\mu)^2}{2\sigma^2}-\frac{n}{2}\text{In}(2\pi)-\frac{n}{2}\text{In}(\sigma^2)]\\<br/>
&amp;=\frac{\sum_{i=1}^N(x_i-\mu)^2}{2\sigma^4} - \frac{n}{2\sigma^2} \\<br/>
\Rightarrow &amp; \sigma^{2*} = \frac{1}{n}\sum_{i=1}^N (x_i-\mu)^2<br/>
\end{align*}<br/>
\]</p>

<p>所以极大似然估计为 \((\mu^*,\sigma^{2*})\)。</p>


		</div>

		

	</article>
 
	<article>
		 <header>
		  	<h1 class="entry-title"><a href="15055294223433.html">朴素贝叶斯 Native Bayes</a></h1>
			<p class="meta"><time datetime="2017-09-16T10:37:02+08:00" 
			pubdate data-updated="true">2017/9/16</time></p>
		 </header>
	  	<div class="entry-content">
		  	
		  	<p>在概率论和统计学中，贝叶斯理论（或者贝叶斯法则、贝叶斯规则）通常是基于和事件相关的先验知识来描述概率事件。贝叶斯定理在很多地方都应用广泛，比如垃圾邮件、疾病预测等。</p>

<h3 id="toc_0">条件概率公式与贝叶斯定理</h3>

<p>设A、B是两个事件，在事件A发生的条件下，事件B发生的条件概率（conditional probability）为：<br/>
\[<br/>
P(B|A)<br/>
\]</p>

<p>同理在事件B发生的条件下，事件A发生的条件概率为\(P(A|B)\)<br/>
很容易想到事件A、事件B同时发生的概率等于事件A发生的概率乘上在事件A发生的条件下事件B发生的概率，即：<br/>
\[<br/>
P(AB) = P(A)P(B|A)<br/>
\]<br/>
同理也可得：\(P(AB) = P(B)P(A|B)\)<br/>
结合两式：<br/>
\[<br/>
\begin{eqnarray}<br/>
P(A)P(B|A) = P(B)P(A|B) \nonumber\\<br/>
\Rightarrow P(B|A) = \frac{P(B)P(A|B)}{P(A)} \label{bayes}<br/>
\end{eqnarray}<br/>
\]<br/>
上式（\ref{bayes}）就是贝叶斯定理公式，其中\(P(B)\)称之为先验概率（prior probability），是指在没有任何条件下事件B发生的概率，\(P(A|B)\)是事件B发生的条件事件A发生的条件概率，分母的\(P(A)\)被称为整体概率，因为它起到归一化的作用，所以又称为归一化常量。</p>

<h3 id="toc_1">全概率公式和贝叶斯定理</h3>

<p>如果事件组\(B_1\),\(B_2\),...,\(_n\)是样本空间\(\Omega\)的一个划分，A为任意事件，则：<br/>
\[<br/>
P(A) = P(A|B_1)+P(A|B_2)+...+P(A|B_n) = \sum_{i=1}^N P(A|B_i)P(B_i)<br/>
\]<br/>
全概率公式的意义在于，当直接计算\(P(A)\)不好计算时，而\(P(A|B_i)\)比较容易计算时，可以使用全概率公式计算\(P(A)\)。举个天气的实例，假设6月的某一天天晴的概率是0.4，多云的概率是0.4，下雨的概率是0.2。天晴的天气我出去玩的概率是0.4，多云的天气出去的概率是0.7，下雨的天气出去的概率是0.3，那么这一天我出去玩的概率设为\(P(play)\)：<br/>
\[<br/>
\begin{align*}<br/>
P(play) &amp;= P(play|sunny)P(sunny)+P(play|cloudy)P(cloudy)+P(play|rain)P(rain) \\<br/>
&amp;= 0.4\times 0.4 + 0.7\times 0.4 + 0.3\times 0.2 = 0.16+0.28+0.06=0.5<br/>
\end{align*}<br/>
\]<br/>
计算得出去玩的概率为0.5。</p>

<p>结合全概率公式和公式（\ref{bayes}）得：<br/>
\[<br/>
\begin{equation}<br/>
P(B_j|A) = \frac{P(B_j)P(A|B_j)}{\sum_{i=1}^N P(A|B_i)P(B_i)} \label{bayes_q}<br/>
\end{equation}<br/>
\]</p>

<h3 id="toc_2">贝叶斯定理</h3>

<p>在上面的例子中，换一种问法，假设那一天如果在我出门的条件下，各个天气状况的概率分别是多少？那么便可以使用贝叶斯定理计算：<br/>
\[<br/>
P(sunny|play) = \frac{P(sunny)P(play|sunny)}{P(play)} = \frac{0.4\times 0.4}{0.5} = 0.32\\<br/>
P(cloudy|play) = \frac{P(cloudy)P(play|cloudy)}{P(play)} = \frac{0.4\times 0.7}{0.5} = 0.56\\<br/>
P(rain|play) = \frac{P(rain)P(play|rain)}{P(play)} = \frac{0.2\times 0.3}{0.8} = 0.12\\<br/>
P(\Omega)=P(sunny|play) + P(cloudy|play) + P(rain|play) = 0.32+0.56+0.12 = 1<br/>
\]<br/>
我觉得从这个实例中已经完全可以理解贝叶斯定理了。</p>

<h3 id="toc_3">先验概率谬误</h3>

<p>先通过一个经典的例子开始说明，假设某种疾病在所有人群中的感染率是 \(0.1\%\)，医院现有的技术对于已知患病情况下，\(99\%\)的可能性可以检查出阳性；对于正常人\(99\%\)的可能性检查为正常，如果从人群中随机抽一个人去检测，医院给出的检测结果为阳性，那么这个人实际得病的概率是多少？从直观上来看，很多人会直接说\(99\%\)，那么真实情况我们来通过贝叶斯定理计算一下:<br/>
\[<br/>
\begin{align*}<br/>
P(患病|阳性) &amp;= \frac{P(患病)P(阳性|患病)}{P(阳性)} = \frac{P(患病)P(阳性|患病)}{P(阳性|患病)P(患病)+P(阳性|正常)P(正常)} \\<br/>
&amp;= \frac{0.1\%\times 99\%}{99\%\times 0.1\%+1\%\times 99.9\%} = \frac{9.9‱}{9.9‱+99.9‱} \approx 9.02\%<br/>
\end{align*}<br/>
\]</p>

<p>可知其实被检测出来是阳性，患病机率也不高。这种情况下，先验概率的大小会严重影响检测结果，很多时候会反直觉。先验概率数据不一定在每种情况下都存在，但是假如确实有这个数据你却不用，那么，你将毁于先验概率谬误，即忽略事前数据并因此作出错误决策。</p>

<p>来一句题外话：如果这个人再去医院复检，检测结果仍为阳性，那么患病概率可以算一下：<br/>
\[<br/>
\begin{align*}<br/>
P(患病|(阳性\cap 阳性)) &amp;= \frac{P(患病)P((阳性\cap 阳性)|患病)}{P((阳性\cap 阳性)|患病)P(患病)+P((阳性\cap 阳性)|正常)P(正常)} \\<br/>
\because  P((阳性\cap 阳性)|患病) &amp;= P(阳性|患病)P(阳性|患病) = 99\% \times 99\%=98.01‱\\<br/>
P((阳性\cap 阳性)|正常) &amp;= P(阳性|正常)P(阳性|正常) = 1\%\times 1\%=0.01‱ \\<br/>
\therefore P(患病|(阳性\cap 阳性)) &amp;= \frac{0.1\%\times 98.01‱}{98.01‱\times 0.1\%+0.01‱\times 99.9\%} = 90.75\%\\ <br/>
\end{align*}<br/>
\]<br/>
可见复检后患病的可信度一下子高出了10倍，还是很有效果的。</p>

<h2 id="toc_4">贝叶斯参数估计</h2>

<p>对于参数估计，一直存在两个学派的不同解决方案。频率派把需要推断的<font color=red>参数θ看做是固定的</font>未知常数，即概率虽然是未知的，但最起码是确定的一个值，同时，<font color=red>样本X 是随机的</font>，所以频率派重点研究样本空间，大部分的概率计算都是针对样本X 的分布；；贝叶斯派的观点则截然相反，他们认为<font color=red>参数是随机变量，而样本X 是固定的</font>，由于样本是固定的，所以他们重点研究的是参数的分布。在两种学派里后面要学的极大似然估计便是频率派的代表算法。而接下来的贝叶斯参数估计和后面需要学习的最大后验概率估计毫无疑问便是贝叶斯派的代表算法。</p>

<p>贝叶斯参数估计是以贝叶斯公式为理论基础的参数估计方法。假设有一个样本集\(x=(x_1,x_2,...,x_n)\)，其中参数是\(\theta=(\theta_1,\theta_2,...,\theta_k)\)，贝叶斯估计的本质就是通过固定的样本利用贝叶斯方法得到参数\(\theta\)的分布。</p>

<p>人们根据先验信息对参数 \(\theta\) 有个基本的认识，这个认识就是先验分布。然后我们通过实验对先验分布进行调整，调整的方法就是贝叶斯方程，调整的结果就是后验分布。</p>

<h4 id="toc_5">先验分布</h4>

<p>将总体中的未知参数 \(\theta\) 看作是变量，样本 \(x\) 看作是常量，可以得到关于 \(\theta\) 的方程\(\pi(\theta)\)，\(\pi(\theta)\)认为是待估计参数\(\theta\) 的先验分布，且 \(\theta\) 的取值和样本集 \(x\) 有关（以下说明中都忽略数据集，如先验分布 \(\pi(\theta,D)\) 写成 \(\pi(\theta)\) ，样本 \(\pi(x|\theta,\text{D})\) 写成 \(\pi(x|\theta)\) ）。</p>

<h4 id="toc_6">后验分布</h4>

<p>考虑到联合概率分布：<br/>
\[<br/>
h(x_1,x_2,...,x_n,\theta)=p(x_1,x_2,...,x_n|\theta)\pi(\theta)=p(\theta|x_1,x_2,...,x_n)p(x_1,x_2,...,x_n)<br/>
\]<br/>
所以可得：<br/>
\[<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{p(x_1,x_2,...,x_n|\theta)\pi(\theta)}{p(x_1,x_2,...,x_n)} = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{p(x_1,x_2,...,x_n)}<br/>
\]<br/>
对于\(p(x_1,x_2,...,x_n)\)，我们称之为边缘分布函数，记为 \(m(x)\)，如果参数空间\(\Theta=(\theta_1,\theta_2,...,\theta_n)\)是离散的，应用全概率公式，可得离散边缘分布：<br/>
\[<br/>
\begin{align*}<br/>
m(x) &amp;= p(x_1,x_2,...,x_n) = \prod_{i=1}^n p(x_i) =\prod_{i=1}^n p(x_i|\theta_1)\pi(\theta_1)+\prod_{i=1}^n p(x_i|\theta_2)\pi(\theta_2)+...+\prod_{i=1}^n p(x_i|\theta_n)\pi(\theta_n)\\<br/>
&amp;= \sum_{j}\pi(\theta_j)\prod_{i=1}^n p(x_i,\theta_j)\\<br/>
\end{align*}<br/>
\]<br/>
如果参数空间\(\Theta\)是连续的，应用积分可得连续边缘分布：<br/>
\[<br/>
m(x) = p(x_1,x_2,...,x_n) = \prod_{i=1}^n p(x_i) = \prod_{i=1}^n [\int_\theta p(x_i,\theta)\pi(\theta)d\theta]=\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta<br/>
\]<br/>
这里我们称\(p(\theta|x_1,x_2,...,x_n)\)为后验分布，可以分情况写出后验分布的公式：<br/>
1）参数空间\(\Theta=(\theta_1,\theta_2,...,\theta_n)\)是离散<br/>
\[<br/>
\begin{align}<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\sum_{j}\pi(\theta_j)\prod_{i=1}^n p(x_i,\theta_j)} \label{ls}<br/>
\end{align}<br/>
\]<br/>
2）参数空间\(\Theta\)是连续<br/>
\[<br/>
\begin{align}<br/>
p(\theta|x_1,x_2,...,x_n) = \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} \label{lx}<br/>
\end{align}<br/>
\]</p>

<p>这里介绍一些常用分布的后验分布：</p>

<h4 id="toc_7">二项分布 binomial distribution</h4>

<p>在n重伯努利试验（同样的条件下重复地、相互独立地进行的一种随机试验）中，如果它分别以概率 \(\theta\) 和 \((1-\theta)\) 取1和0为值，恰好出现 k 次1的概率为 \(p(X=k|\theta)= \text{C}_n^k\theta^k(1-\theta)^{n-k}\)，这就是二项分布的分布律，记为\(\text{X}\sim B(n,\theta)\)，当 \(n=1\) 时二项分布又称为伯努利分布。</p>

<p>假设我们实现对概率\(\theta\)没有任何信息，这种情形贝叶斯本人建议使用“等同无知”的原则，使用(0,1)上的均匀分布U(0,1)作为 \(\theta\) 的先验分布，因为在(0,1)上每一点的概率都相等，这被人称为贝叶斯假设。所以 \(\theta\) 出现的概率为\(\pi(\theta)\)<br/>
\[<br/>
\pi(\theta) = \left \{ \begin{array}\\<br/>
1\qquad 0\lt \theta \lt 1\\<br/>
0\qquad \text{其他}<br/>
\end{array}\right.<br/>
\]</p>

<p>考虑上述二项分布事件与概率 \(\theta\) 的联合概率分布：<br/>
\[<br/>
h(X=k,\theta) = f(X=k|\theta)\pi(\theta) = \text{C}_n^k\theta^k(1-\theta)^{n-k},\qquad k=1,2,...,n,0\lt \theta \lt 1<br/>
\]</p>

<p>考虑到该参数空间\(\theta\)是连续的，结合（\ref{lx}）式：<br/>
\[<br/>
\begin{align}<br/>
\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta &amp;= \int_\theta f(X=k|\theta)\pi(\theta)d\theta = \int_\theta \text{C}_n^k\theta^k(1-\theta)^{n-k} d\theta = \text{C}_n^k\int_0^1 \theta^k(1-\theta)^{n-k} d\theta \label{lllx}\\<br/>
\end{align}<br/>
\]</p>

<p>为方便令 \(j=n-k\) ，设：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j) &amp;= \int_0^1 \theta^k(1-\theta)^j d\theta<br/>
\end{align*}<br/>
\]<br/>
利用分部积分法，令 \(\mu(\theta) = (1-\theta)^j\)，令 \(v(\theta) = \frac{1}{k+1}\theta^{k+1}\)，则：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j)&amp;=\int_0^1 \theta^k(1-\theta)^j d\theta = \int_0^1 \mu(\theta)\nu(\theta)&#39; = [u(\theta)v(\theta)]^1_0-\int_0^1 \nu(\theta) \mu(x)&#39;dx \\<br/>
&amp;= [u(\theta)v(\theta)]^1_0-\int_0^1 \frac{1}{k+1}\theta^{k+1}(-j)(1-\theta)^{j-1}d\theta\\<br/>
&amp;= [u(\theta)v(\theta)]^1_0 + \frac{j}{k+1}\int_0^1 \theta^{k+1}(1-\theta)^{j-1}d\theta\\<br/>
&amp;= [u(1)v(1)-u(0)v(0)] + \frac{j}{k+1} J(k+1,j-1)\\<br/>
&amp;= \frac{j}{k+1} J(k+1,j-1)\\<br/>
\end{align*}<br/>
\]<br/>
以此类推：<br/>
\[<br/>
\begin{align*}<br/>
J(k,j) &amp;= \frac{j}{k+1} J(k+1,j-1) = \frac{j(j-1)}{(k+1)(k+2)}J(k+2,j-2) = ... = \frac{j(j-1)\cdots 2\cdot 1}{(k+1)\cdots (k+j)}J(k+j,0) \\<br/>
\end{align*}<br/>
\]<br/>
其中：<br/>
\[<br/>
J(k+j,0) = \int_0^1 \theta^{k+j}(1-\theta)^0 d\theta = \int_0^1 \theta^{k+j}d\theta = \frac{1}{k+j+1}\theta^{k+j+1}|^1_0 = \frac{1}{k+j+1}<br/>
\]<br/>
所以：<br/>
\[<br/>
J(k,j) = \frac{j(j-1)\cdots 2\cdot 1}{(k+1)\cdots (k+j)(k+j+1)} = \frac{j!}{(k+1)\cdots (k+j)(k+j+1)}<br/>
\]<br/>
考虑到伽马函数 \(\Gamma(n) = (n-1)!\)（这里不叙述伽马函数的由来，后面会有伽马函数的介绍）：<br/>
\[<br/>
J(k,j) = \frac{j!}{(k+1)\cdots (k+j)(k+j+1)} = \frac{\Gamma(j+1)\Gamma(k+1)}{\Gamma(j+k+2)}<br/>
\]<br/>
至此我们可以再看看式\ref{lllx}，代入得：<br/>
\[<br/>
\begin{align*}<br/>
\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta &amp; = \text{C}_n^k\int_0^1 \theta^k(1-\theta)^{n-k} d\theta = \text{C}_n^k \frac{\Gamma(n-k+1)\Gamma(k+1)}{\Gamma(n+2)}\\<br/>
\end{align*}<br/>
\]<br/>
将上式带入后验公式（\ref{lx}）便可得二项分布的后验概率：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta|x_1,x_2,...,x_n) &amp;= \frac{\pi(\theta)\prod_{i=1}^n p(x_i|\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} = \frac{h(X=k,\theta)}{\int_\theta\prod_{i=1}^n  p(x_i,\theta)\pi(\theta)d\theta} \\<br/>
&amp;= \frac{\Gamma(n+2)}{\text{C}_n^k\Gamma(n-k+1)\Gamma(k+1)} \text{C}_n^k\theta^k(1-\theta)^{n-k} \\<br/>
&amp;= \frac{\Gamma(n+2)}{\Gamma(n-k+1)\Gamma(k+1)} \theta^k(1-\theta)^{n-k},\qquad k=1,2,...,n,0\lt \theta \lt 1<br/>
\end{align*}<br/>
\]<br/>
对比 Beta 分布的概率密度函数：<br/>
\[<br/>
f(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1−x)^{\beta−1} = \frac{1}{B(\alpha,\beta)}x^{\alpha−1}(1−x)^{\beta−1}<br/>
\]<br/>
只要令\(\alpha=k+1,\beta = n-k+1\)，就会发现这两者形式完全一致，所以我们可以说二项分布的后验分布服从 Beta 分布，即 \(\theta|X \sim \text{Be}(k+1,n-k+1)\)，由 Beta 分布的性质可知，二项分布后验分布的期望为：<br/>
\[<br/>
\theta^* = E(\theta|X) = \frac{\alpha}{\alpha+\beta} =  \frac{k+1}{n+2}<br/>
\]</p>

<p>这里举个例子：Laplace在1786年研究了巴黎的男婴出生的比率,他希望检验男婴出生的概率 \(\theta\) 是否大于0.5.为此,他收集到1745~1770年在巴黎出生的婴儿数据.其中,男婴251527个,女婴241945个,他选用U(0,1)作为 \(\theta\) 的先验分布,则 \(\theta\) 的后验分布服从 \(\beta\) 分布，即 \(\beta\sim Be(k+1,n-k+1) = Be(251528,241946)\)，所以：<br/>
\[<br/>
\begin{align*}<br/>
&amp;n = 251527 + 241945 = 493472\\<br/>
&amp;\hat\theta = \frac{k+1}{n+2} = \frac{251527+1}{493472+2} = 0.5097<br/>
\end{align*}<br/>
\]</p>

<h4 id="toc_8">高斯分布</h4>

<p>设 \(x_1\) , \(x_2\) , …, \(x_n\)是来自高斯分布 \(N(\mu,\sigma^2)\)的一个样本，其中 \(\sigma^2\) 已知， \(\mu\)未知，假设 \(\mu\) 的先验分布亦为高斯分布 \(N(\theta,\tau^2)\)，其中先验均值 \(\theta\) 和先验方差 \(\tau^2\) 均已知。</p>

<p>由高斯分布可知样本 \(\mu\) 的先验分布概率密度函数为：<br/>
\[<br/>
\pi(\mu) = \frac{1}{\sqrt{2\pi}\tau}\exp(-\frac{(\mu-\theta)^2}{2\tau^2})<br/>
\]<br/>
样本 \(x_1\), \(x_2\) , …, \(x_n\) 的条件概率密度函数为：<br/>
\[<br/>
p(x|\mu) =\prod_i^n p(x_i|\mu) = (\frac{1}{\sqrt{2\pi}\sigma})^n \exp(\sum_i^n -\frac{(x_i-\mu)^2}{2\sigma^2})\\<br/>
\]<br/>
所以联合概率密度为：<br/>
\[<br/>
\begin{align*}<br/>
h(x,\mu) &amp;= p(x|\mu)\pi(\mu) = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(\sum_i^n -\frac{(x_i-\mu)^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(-\sum_i^n \frac{x_i^2-2\mu x_i + \mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(- \frac{\sum_i^n x_i^2-2 \sum_i^n \mu x_i + \sum_i^n \mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp; = (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(- \frac{\sum_i^n x_i^2-2 n \mu \overline x + n\mu^2}{2\sigma^2}-\frac{(\mu-\theta)^2}{2\tau^2}) \\<br/>
&amp;=  (\frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau})\exp(-(\frac{n}{2\sigma^2}+\frac{1}{2\tau^2})\mu^2  + (\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2})\mu - (\frac{\sum_i^n x_i^2}{2\sigma^2}+\frac{\theta^2}{2\tau^2}))\\<br/>
\end{align*}<br/>
\]<br/>
其中 \(\overline x = \frac{1}{n} \sum_i^n x_i\)。若令\(k = \frac{1}{\sqrt{2\pi}^{n+1}\sigma^n\tau}\)，\(A = (\frac{n}{\sigma^2}+\frac{1}{\tau^2})\)，所以 \(A&gt;0\)，\(B = (\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2})\)，\(C = (\frac{\sum_i^n x_i^2}{\sigma^2}+\frac{\theta^2}{\tau^2})\)，则：<br/>
\[<br/>
\begin{align*}<br/>
h(x,\mu) &amp;= k\cdot \exp[-\frac{1}{2}(A\mu^2-2B\mu+C)] \\<br/>
&amp;= k\cdot \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})]\nonumber\\<br/>
\end{align*}<br/>
\]</p>

<p>由于参数空间 \(\mu\) 是连续的，所以边缘分布 \(m(x)\)为：<br/>
\[<br/>
\begin{align}<br/>
m(x) &amp;= \int_\mu\prod_{i=1}^n  p(x_i,\mu)\pi(\mu)d\mu = \int_\mu h(x,\mu) d\mu\nonumber\\<br/>
&amp;=k\cdot \int_\mu \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})] d\mu\nonumber\\<br/>
&amp;=k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})]\int_\mu \exp([-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu\label{mx}\\<br/>
\end{align}<br/>
\]</p>

<p>我们先来求解这个式子<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu \label{yiim}<br/>
\end{equation}<br/>
\]<br/>
用 \(\nu\) 替换其中的 \(\mu\) 得：<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\nu \label{yiin}<br/>
\end{equation}<br/>
\]<br/>
用式\ref{yiim}和式\ref{yiin}相乘得：<br/>
\[<br/>
\begin{align*}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu \int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\nu &amp;= \int\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] \exp[-\frac{A}{2}(\nu - \frac{B}{A})^2] d\mu d\nu \\<br/>
&amp;= \int\int_{-\infty}^{\infty} \exp\{-\frac{A}{2} [(\mu-\frac{B}{A})^2+(\nu-\frac{B}{A})^2]\}d\mu d\nu<br/>
\end{align*}<br/>
\]<br/>
令\(\mu-\frac{B}{A} = r\cos\alpha\)，\(\nu-\frac{B}{A} = r\sin\alpha\)，其中\(\alpha\in[0,2\pi]，r\in[0,\infty]\)，为方便计算令\(f^2\)等于等式左边：<br/>
\[<br/>
\begin{align*}<br/>
f^2 &amp;= \int_{0}^{\infty}\int_{0}^{2\pi} \exp\{-\frac{A}{2} [(r\cos\alpha)^2+(r\sin\alpha)^2]\}r dr d\alpha\\<br/>
&amp;= \int_{0}^{\infty}\int_{0}^{2\pi} \exp(-\frac{A}{2}r^2)r dr d\alpha\\<br/>
&amp;= \int_{0}^{\infty}\exp(-\frac{A}{2}r^2)r\int_0^{2\pi} d\alpha\\<br/>
&amp;= 2\pi \int_0^\infty \exp(-\frac{A}{2}r^2)rdr\\<br/>
&amp;= 2\pi \cdot [-\frac{1}{A} \exp(-\frac{A}{2}r^2) ]^\infty_0\\<br/>
\end{align*}<br/>
\]<br/>
由前面定义\(A = (\frac{n}{\sigma^2}+\frac{1}{\tau^2})\)，显然 \(A&gt;0\)，所以：<br/>
\[<br/>
f^2 =2\pi \cdot [-\frac{1}{A} \exp(-\frac{A}{2}r^2) ]^\infty_0 = 2\pi \frac{1}{A} [\exp(0)-\exp(-\infty)] = \frac{2\pi}{A}\\<br/>
\Rightarrow f = (\frac{2\pi}{A})^{1/2}<br/>
\]</p>

<p>将上述结果带入式\ref{mx}，可知：<br/>
\[<br/>
\begin{align*}<br/>
m(x) &amp;= k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})]\int_\mu \exp([-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu \\<br/>
&amp;= k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})] (\frac{2\pi}{A})^{1/2}<br/>
\end{align*}<br/>
\]<br/>
由后验公式（\ref{lx}）可得：<br/>
\[<br/>
\begin{align*}<br/>
p(\mu|x) &amp;= \frac{\pi(\mu)\prod_{i=1}^n p(x_i|\mu)}{\int_\mu\prod_{i=1}^n  p(x_i,\mu)\pi(\mu)d\mu} = \frac{h(x,\mu)}{m(x)} = \frac{k\cdot \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2 - \frac{1}{2}(C-\frac{B^2}{A})]}{k \cdot \exp[- \frac{1}{2}(C-\frac{B^2}{A})] (\frac{2\pi}{A})^{1/2}} \\<br/>
&amp;= (\frac{A}{2\pi})^{1/2} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2]\\<br/>
&amp;= \frac{1}{2\pi\sqrt{1/A}} \exp[-\frac{(\mu - \frac{B}{A})^2}{2/A}]<br/>
\end{align*}<br/>
\]<br/>
对比高斯分布可知\(p(\mu|x)\sim N(B/A,1/A)\)，即：<br/>
\[<br/>
p(\mu|x) \sim N(\frac{\frac{n\overline x}{\sigma^2} + \frac{\theta}{\tau^2}}{\frac{n}{\sigma^2}+\frac{1}{\tau^2}},\frac 1{\frac{n}{\sigma^2}+\frac{1}{\tau^2}}) = N(\frac{n\tau^2\overline x+\theta\sigma^2}{n\tau^2+\sigma^2},\frac{\tau^2\sigma^2}{n\tau^2+\sigma^2})<br/>
\]</p>

<p>后验均值即为贝叶斯估计：<br/>
\[<br/>
\hat u = \frac{n\tau^2\overline x+\theta\sigma^2}{n\tau^2+\sigma^2}<br/>
\]</p>

<h4 id="toc_9">共轭分布法</h4>

<p>我们前面再二项分布时说如果一个没有任何先验知识的分布可以看作为“等同无知”，采用均匀分布U(0,1)作为先验分布，这里均匀分布也可以看作是贝塔分布 \(\text{Beta}(1,1)\)，所以二项分布 \(\text{B}(n,\theta)\) 的先验分布为 \(\text{Beta}(1,1)\) 时，后验分布为 \(\text{Beta}(k+1,n-k+1)\) ，其中k表示n次独立试验中正例出现的次数。这种先验分布和后验分布属于同一个分布类型的现象并不是偶然的，在上文的高斯分布也证明了这一点，先验分布是高斯分布，后验分布也是高斯分布。</p>

<p>共轭分布法就是指<strong>先验分布和后验分布属于同一个分布类型</strong>。</p>

<h4 id="toc_10">贝叶斯估计举例</h4>

<p>这个举个例子，为了提高某产品质量，某部门经理希望引入不同厂家生产的一种设备，两厂家招标时称：<br/>
<font color='#666'>1）使用厂家一设备生产后，高质量产品将占90%；</font><br/>
<font color='#666'>2）使用厂家二设备生产后，高质量产品将占70%；</font><br/>
部门经理根据以往两厂家的用户评价，认为厂家一的可信度为40%，厂家二的可信度为60%。</p>

<p>首先来数学化这些数字，将厂家一、厂家二认为是两个不同的参数\(\theta_1\)，\(\theta_2\)，那么可知 \(p(\theta_1) = 40\%;p(\theta_2) = 60\%\)，将生产高质量产品看作概率分布 \(p(x,\theta)\)，可知\(p(x,\theta_1) = 90\%\)，\(p(x,\theta_2)=70\%\)。</p>

<p>部门经理为此做了小型试验，第一次实验分别使用两厂家的设备进行生产，生产5件产品，都是高质量产品，记第一次实验为事件A，高质量产品记为1，否则为0，则：<br/>
\[<br/>
A|\theta_1 = (1,1,1,1,1)\\<br/>
A|\theta_2 = (1,1,1,1,1)<br/>
\]<br/>
第二次实验，再生产5件产品，使用设备一都是高质量产品，使用设备二4件高质量产品，记第二次实验为事件B，则：<br/>
\[<br/>
B|\theta_1 = (1,1,1,1,1)\\<br/>
B|\theta_2 = (1,1,1,1,0)\\<br/>
\]<br/>
我们利用事件A使用离散性后验分布概率：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta_1|A) &amp;= p(\theta_1|x_1,x_2,...,x_n) = \frac{p(\theta_1)\prod_{i=1}^n p(x_i|\theta_1)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} \\<br/>
&amp;= \frac{0.9^5*0.4}{0.4*0.9^5+0.6*0.7^5} = \frac{0.236}{0.236 + 0.101} = 0.700\\<br/>
p(\theta_2|A) &amp;= p(\theta_2|x_1,x_2,...,x_n) = \frac{p(\theta_2)\prod_{i=1}^n p(x_i|\theta_2)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} =0.300<br/>
\end{align*}<br/>
\]</p>

<p>通过实验一（事件A）更新了我们对厂家的可信度，计算得厂家一的可信度为0.7，厂家二的可信度为0.3，再来看第二次实验（事件B）计算可信度：<br/>
\[<br/>
\begin{align*}<br/>
p(\theta_1|A) &amp;= p(\theta_1|x_1,x_2,...,x_n) = \frac{p(\theta_1)\prod_{i=1}^n p(x_i|\theta_1)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} \\<br/>
&amp;= \frac{0.9^5*0.7}{0.7*0.9^5+0.3*0.7^4*0.3} = \frac{0.413}{0.413+0.022} = 0.949\\<br/>
p(\theta_2|A) &amp;= p(\theta_2|x_1,x_2,...,x_n) = \frac{p(\theta_2)\prod_{i=1}^n p(x_i|\theta_2)}{\sum_{j}\prod_{i=1}^n f(x_i,\theta_j)p(\theta_j)} = 0.051\\<br/>
\end{align*}<br/>
\]</p>

<p>通过实验二（事件B）计算已经可以得出厂家一的可信度为0.949，所以我们很有理由可以选择采进此设备。</p>

<p><strong>关于贝叶斯的知识还有很多，以后遇见再继续讨论~</strong></p>

<p><font color="#666"></p>

<p>我们来求解这个式子的另一种方法（只解出了一半，如果有人可以继续解下去，希望能联系我）<br/>
\[<br/>
\begin{equation}<br/>
\int_{-\infty}^{\infty} \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu<br/>
\end{equation}<br/>
\]</p>

<p>这个函数的定积分不容易直接求得，我们先看一下伽马函数 \(\Gamma(s)\) ，定义如下：<br/>
\[<br/>
\begin{equation}<br/>
\Gamma(s) = \int_0^\infty e^{-x} x^{s-1} dx\qquad (s&gt;0) \label{Gamma}<br/>
\end{equation}<br/>
\]<br/>
由余元公式可知：<br/>
\[<br/>
\Gamma(s)\Gamma(1-s) = \frac{\pi}{\sin\pi s} \qquad (0\lt s \lt 1)<br/>
\]<br/>
所以：<br/>
\[<br/>
\Gamma(\frac1 2) = \sqrt{\pi}<br/>
\]</p>

<p>对\ref{Gamma}式利用定积分换元法，\(A&gt;0\) 情况下，令 \(x = \frac{A}{2}(\mu-\frac{B}{A})^2\)，则：<br/>
\[<br/>
\begin{align*}<br/>
&amp;\because\quad dx = A(\mu-\frac{B}{A})d\mu\\<br/>
&amp;\therefore\quad \Gamma(s) = \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] [\frac{A}{2}(\mu-\frac{B}{A})^2]^{s-1} [A (\mu-\frac{B}{A})]d\mu \\<br/>
&amp;\qquad\qquad = \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] (\frac{A}{2})^{s-1}\cdot (\mu-\frac{B}{A})^{2s-1}\cdot Ad\mu \\<br/>
\end{align*}<br/>
\]<br/>
令 \(s=\frac 1 2\)：<br/>
\[<br/>
\begin{align}<br/>
\Gamma(\frac 1 2) &amp;= \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] (\frac{A}{2})^{-1/2}\cdot (\mu-\frac{B}{A})^0\cdot Ad\mu\nonumber\\<br/>
&amp;= \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2](2A)^{1/2} d\mu = \sqrt{\pi}\nonumber\\<br/>
&amp;\Rightarrow \int_0^\infty \exp[-\frac{A}{2}(\mu-\frac{B}{A})^2] d\mu = (\frac{\pi}{2A})^{1/2}\label{G0I}<br/>
\end{align}<br/>
\]<br/>
关于<br/>
\[<br/>
\begin{align}<br/>
\int_{-\infty}^0 \exp[-\frac{A}{2}(\mu - \frac{B}{A})^2] d\mu\label{GI0}<br/>
\end{align}<br/>
\]<br/>
怎么解，还没有一个好的方法，希望以后能解决。</p>

<p></font></p>

<hr/>

<p>[1] &nbsp;&nbsp;<a href="https://cosx.org/2013/01/lda-math-gamma-function">神奇的 Gamma 函数</a><br/>
[2] &nbsp;&nbsp;<a href="https://blog.csdn.net/u010945683/article/details/48950063">贝塔与伽马分布</a><br/>
[3] &nbsp;&nbsp;<a href="https://mp.weixin.qq.com/s/ZEoxYPgenFgzHuNnI2IieQ">贝塔分布生动的棒球例子</a></p>


		</div>

		

	</article>
  
	<div class="pagination">
	
<a href="archives.html">Blog Archives</a>
	 
	    
	</div>
</div>
 <aside class="sidebar"> 

	<section>
	  <h1>Categories</h1>
	  <ul id="recent_posts">
	  
	      <li class="post">
	        <a href="%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98.html"><strong>最短路径问题&nbsp;(5)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E8%81%9A%E7%B1%BB%E9%97%AE%E9%A2%98.html"><strong>聚类问题&nbsp;(9)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%85%B6%E4%BB%96%E7%AE%97%E6%B3%95.html"><strong>其他算法&nbsp;(6)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95.html"><strong>基础算法&nbsp;(23)</strong></a>
	         <p class="cat-children-p"> 
	        
	        	<a href="SVM.html">SVM&nbsp;(1)</a>&nbsp;&nbsp;
	        
	        	<a href="SNE.html">SNE&nbsp;(1)</a>&nbsp;&nbsp;
	        
	        	<a href="EM.html">EM&nbsp;(5)</a>&nbsp;&nbsp;
	        
	        	<a href="%E5%86%B3%E7%AD%96%E6%A0%91.html">决策树&nbsp;(2)</a>&nbsp;&nbsp;
	        
	        	<a href="HMM.html">HMM&nbsp;(3)</a>&nbsp;&nbsp;
	        
	        	<a href="%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.html">集成学习&nbsp;(8)</a>&nbsp;&nbsp;
	        
	        	<a href="%E9%99%8D%E7%BB%B4.html">降维&nbsp;(3)</a>&nbsp;&nbsp;
	        
	         </p> 
	      </li>
	  
	      <li class="post">
	        <a href="%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.html"><strong>数学基础&nbsp;(14)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="Python%E5%AD%A6%E4%B9%A0.html"><strong>Python学习&nbsp;(2)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html"><strong>神经网络&nbsp;(15)</strong></a>
	        
	        
	        
	      </li>
	  
	      <li class="post">
	        <a href="%E5%A2%9E%E5%BC%BA%E5%AD%A6%E4%B9%A0.html"><strong>增强学习&nbsp;(1)</strong></a>
	        
	        
	        
	      </li>
	   
	  </ul>
	</section>
	<section>
	  <h1>Recent Posts</h1>
	  <ul id="recent_posts">
	  
	      
		      <li class="post">
		        <a href="15454660806753.html">深度学习中的正则化-Dropout方法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15446218642343.html">图像相似度方法</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15436296136092.html">蒙特卡罗树搜搜 MCTS</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15424711438602.html">人工神经网络-GAN</a>
		      </li>
	     
	  
	      
		      <li class="post">
		        <a href="15418610530072.html">人工神经网络-SOM自组织系统</a>
		      </li>
	     
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	  
	      
	   
	  </ul>
	</section>
	
</aside> </div></div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 -  -
  <span class="credit">Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; Theme by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>

  
    

<script src="asset/chart/all-min.js"></script><script type="text/javascript">$(function(){    var mwebii=0;    var mwebChartEleId = 'mweb-chart-ele-';    $('pre>code').each(function(){        mwebii++;        var eleiid = mwebChartEleId+mwebii;        if($(this).hasClass('language-sequence')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = Diagram.parse($(this).text());            diagram.drawSVG(eleiid,{theme: 'simple'});        }else if($(this).hasClass('language-flow')){            var ele = $(this).addClass('nohighlight').parent();            $('<div id="'+eleiid+'"></div>').insertAfter(ele);            ele.hide();            var diagram = flowchart.parse($(this).text());            diagram.drawSVG(eleiid);        }    });});</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

</body>
</html>